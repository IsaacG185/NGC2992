## ISISscripts function reference

----

### ISISscript functions

----

### Function description

----

#### add_color_palette
##### Synopsis
 Add a color palette

##### Usage
```c
 add_color_palette (String_Type name, UInt_Type[] colors);
```
or

```c
 add_color_palette (String_Type name, Ref_Type generator);
```

##### Description

Add an array of hex values representing a color palette to the
system.

Alternatively, a function can be passed with this signature
<code>UInt_Type[] palette = generator(UInt_Type n);</code>
where <code>n</code> is the number of colors returned. It is okay to
return fewer colors than <code>n</code>, but never more.

__See also__: get_color_palette

----

#### add_hist
##### Synopsis
 add histograms

##### Usage
```c
 Struct_Type specs = add_hist([hist1,hist2,...]);
```

##### Usage
```c
 Struct_Type specs = add_hist(hist1,hist2,...);
```

##### Description

Add histogram structures with fields bin_lo, bin_hi, value, and
err. The function just assumes that the histograms are on the
same grid. It copies the grid from the very first structure in
the array, then adds the values of the subsequent structures.
Uncertainties (err) are added in quadrature.

__See also__: scale_hist, shift_hist, stretch_hist

----

#### add_plot_unit
##### Synopsis
 Create a new X-unit,Y-unit pair for isis_fancy_plots package

##### Usage
```c
 add_plot_unit(String_Type, String_Type [; ]);
```

##### Qualifiers

* SEE BELOW:

##### Description

add_plot_unit(xunit, yunit; xscale=val, yscale=val, is_energy=val,
xlabel=str, ylabel=str, pgfont=str);

Create a new X-unit and Y-unit pair for plot_counts, plot_data, plot_unfold,
and plot_fit_model.  (yunit and yscale only affect plot_unfold; plot_counts
and plot_data are only sensitive to the choice of xunit.) Set is_energy=1 if
the xunit scales as keV (otherwise it defaults to scaling as Angstroms). xscale
is the scaling of keV/xunit or A/xunit.  yscale scales \*all\* of the y-axes in
the plot_unfold plots, so it must be set appropriately to achieve a desired
effect.  xunit and yunit will be treated as lower case regardless of input.
Note that existing X-units will not be overwritten; their already defined
values will be used regardless of input.  A set of default axis labels will
be produced, with "ylabel" substituting for:

"Photons cm^{-2} s^{-1}"   (the default)

However, these labels can be rewritten using the new_plot_labels command.

To get the scalings correct, remember that plot_unfold(...;power=2) is always
photons/s/cm^2 in the absence of scalings, power=0 is proportional to flux
for wavelength based X-units, while power=3 is proportional to flux for energy
based units.  For these latter two cases, the yscale needs to account for
divisions/multiplications of the scaled X-unit.

Examples:

To produce mJy vs. THz plots, use:

add_plot_unit("thz", "mjy"; xscale=Const_eV/Const_h\*1.e12,
yscale=Const_h\*1.e26, xlabel="THz", ylabel="mJy/THz");

Const_eV/Const_h\*1.e12 ~ 4.14e-3 is keV per Terra-Hz
plot_unfold(...;power=2) produces photons/s/cm^2 =>
(photons\*xunit)/s/cm^2/xunit  (xunit scaling cancels out)

We wish to convert this to mJy:

(photons\*xunit/s/cm^2/xunit) =
[photons\*(1.e-26 ergs)\*Hz/(1.e-26 ergs)]/s/cm^2/Hz =
Hz/(1.e-26 ergs)\*mJy

hence multiplying by yscale=(1.e-26 ergs)/Hz = 1.e26\*Const_h
produces the desired scaling for plot_unfold.

To produce BTU/Acre/s vs. keV plots, use:

plot_unfold(...;power=3) for X-unit=keV produces keV/s/cm^2,
which we wish to convert to BTU/Acre/s, hence xscale=1 and:

erg_p_btu = 1.055056e10                    % ISO ergs/BTU
cmsq_p_a = 4.0468564224e7                  % cm^2 per international acre
yscale = cmsq_p_a\*Const_eV\*1.e3/erg_p_btu  % cm^2/Acre\*BTU/keV

To achieve this same Y-unit vs. other energy based X-units,
multiply yscale by keV/xunit, i.e., the value of xscale.

__See also__: fancy_plot_unit, set_plot_labels, new_plot_labels

----

#### ad_create_colormap
##### Synopsis
 creates a redshift-colormap, where yellow is exactly at
where(img==1)

##### Usage
```c
 g_br = ad_create_colormap(img,alp,gmax);
```

----

#### ad_init_raw
##### Synopsis
 subroutine, which reads the data and the header of a
raw-redshift image (used by ad_make_image)

##### Usage
```c
 (data,nre,ng,a,theta0grad) = ad_init_raw(filename);
```

----

#### ad_init_raw_timing
##### Synopsis
 subroutine, which reads the data and the header of a
raw-redshift image FOR TIMING (used by ad_make_image)

##### Usage
```c
 (data,nre,ng,a,theta0grad) = ad_init_raw_timing(filename);
```

----

#### ad_interpol_image
##### Synopsis
 interpolates the image maximal sz_max times beyond rmin

##### Usage
```c
 image = ad_interpol_image(image,alp_lo,bet_lo,sz_max,rmin);
```

__See also__: ad_make_image, ad_init_raw, ad_read_image

----

#### ad_make_image
##### Synopsis
 creates a redshift image from the raw data by sorting with
respect to alpha and beta

##### Usage
```c
 (img, alp_lo, alp_hi, bet_lo, bet_hi) = ad_make_image(filename);
```

##### Qualifiers

* sho_minmax: show the extrem values of alpha and beta?
* timing: read a Brod-Timing-FITS-Table
* field: specify which values are plotted
* disk: kuse intrinsic x and y instead of alpha and beta (only working for timing yet)

----

#### ad_read_image
##### Synopsis
 reads the image and the alpha-beta-grid from the FITS-file
created by ad_make_image

##### Usage
```c
 ad_read_image(filename);
```

__See also__: ad_make_image, ad_init_raw

----

#### ad_write_image
##### Synopsis
 subroutine, which reads the data and the header of a
raw-redshift image (ad_make_image) and writes it into a
fits-image with the filename "image_\*"

##### Usage
```c
 (img,alp,bet) = ad_write_image(filename,size [alp_extr,bet_extr]);
```

----

#### aglc
##### Synopsis
 Bin a light curve from ACIS grating events.

##### Usage
```c
 lc = aglc(tgevt, expno_ref, tbin, wmin, wmax, tg, orders[, bkg]);
```

```
or

```c
 lc = aglc(   evt_struct,    tbin, wmin, wmax, tg, orders[, bkg]);

##### Description

Given an event file name (<code>tgevt</code>) and an exposure reference file
(unfiltered events or ``stat1'') name (<code>expno_ref</code>), bin a light curve
for the specified time bin in seconds (<code>tbin</code>), wavelength ranges
specified by <code>wmin</code>, <code>wmax</code>, in Angstroms.  If <code>wmin</code> and <code>wmax</code> are arrays,
then they must be the same length and represent low-high pairs of
wavelength regions.  The argument, <code>tg</code>, is a scalar or array of
grating names, and should be one or more of <code>"HEG"</code> and <code>"MEG"</code>, or <code>"LEG"</code>
(case-insensitive); only the first character is necessary.  The
argument <code>orders</code> should be an array of integers specifying the
diffraction orders to bin (excluding zero).  If the last argument is
present, then events are binned from the background region instead of
the source region.

In the second form, an event structure as returned by
<code>aglc_read_events</code> is used instead of two file names.  This is
more efficient for multiple calls, since it avoids multiple file
reads.

The two files required in the first form are the grating coordinates
event file, probably filtered of bad events; i.e., typically the file
from which a spectrum would be binned ("Level 1.5" or "Level 2").
The second file, the exposure reference file, should be unfiltered
events or the ``stat1'' file.  It is used to count the exposed frames
to determine the exposure; any event - cosmic ray, bad pixel, photon
- will suffice to mark a frame.  Use of the ``stat1'' file is more
efficient, since it has only one entry for each unique frame.

Standard binning regions are applied for source and background
events.   They may be changed with <code>aglc_set_regs</code>.

The return value is a structure of the form

<code>time = Double_Type[]</code>        % event time, bin center, since timezero.

<code>time_min = Double_Type[]</code>    % lower edge of time bin, seconds since timezero.

<code>time_max = Double_Type[]</code>    % upper edge of time bin, seconds since timezero.

<code>counts = UInteger_Type[]</code>    % counts per time bin.

<code>count_rate = Double_Type[]</code>  % Counts per second ( counts / exposure ).

<code>stat_err = Double_Type[]</code>    % Statistical error ( sqrt(counts) ).

<code>exposure = Double_Type[]</code>    % Exposure per bin, averaged over all chips included, in seconds.

<code>timezero = Double_Type</code>      % reference time, in seconds since MJDREF.

<code>mjdref = Integer_Type</code>       % Modified Julian Day reference point of Chandra data (from event header)

<code>revidx1a = Array_Type[]</code>     % reverse index array for the grating events.

<code>revidx = Array_Type[]</code>       % reverse index array for the exposure reference events.

The times are in seconds since timezero.  Timezero is the number of
seconds since 1998.0, which is also the reference MJD.

The <code>count_rate</code> is per second, and is equivalent to counts/exposure.
The exposure is computed properly for event selections spanning
multiple CCDs with possibly different GTI tables.

The reverse indices, <code>revidx1a</code>, are returned by the <code>histogram</code>
function; for each bin of the light curve they point to
the items in the event list which have been binned.  This facilitates
subsequent operations on events in specific bins, especially when
selected on non-time criteria. (see <code>aglc_filter</code>).

<code>revidx</code> is like <code>revidx1a</code>, but for the exposure record event list.
##### Example

Compute the light curve for the sum of Ne X 12A and O VIII 19A:

<code>wlo = [12.1, 18.8];</code>

<code>whi = [12.2, 19.1];</code>

<code>g = ["H", "M"];</code>

<code>o = [-1,1];</code>

<code>c = aglc( "evt2.fits", "evt1.fits", 1000, wlo, whi, g, o );</code>

<code>hplot(c.time_min, c.time_max, c.counts);</code>

__See also__: aglc_read_events, aglc_filter, aglc_set_regs

----

#### aglc_get_ephem
##### Synopsis
 Retrieve a stored ephemeris, the last one used.

##### Usage
```c
 (jd0, pd) = aglc_get_ephem;
```

##### Description

jd0 will be the Julian day of zero phase.
pd  will be the period in days.

__See also__: aglc_pr_ephem, aglc_phased

----

#### aglc_get_regs
##### Synopsis
 Retrieve stored source and background regions
(cross-dispersion limits), and associated BACKSCAL values.

##### Usage
```c
 r = aglc_get_regs;
```

##### Description

Retrieves a structure containing the stored values used for binning
light curves for source or background.

__See also__: aglc_set_regs, aglc_reset_regs

----

#### aglc_get_trange
##### Synopsis
 Retrieve the time filter which will be applied in phase-binning.

##### Usage
```c
 (tmin, tmax) = aglc_get_trange;
```

##### Description

tmin,tmax are relative times in seconds, since the start of the
observation.

__See also__: aglc_set_trange, aglc_pr_trange;

----

#### aglc_jd_to_rotnum
##### Synopsis
 Convert Julian days to rotation number.

##### Usage
```c
 rotation_number = aglc_jd_to_rotnum( t_jd, hjd_epoch, period_days );
```

##### Description

<code>rotation_number</code> = number of full cycles plus fractional phase, given an ephemeris.

<code>t_jd</code>        = times, in Julian day numbers.

<code>hjd_epoch</code>   = epoch of zero-phase, in HJD

<code>period_days</code> = period, in days.

__See also__: aglc_tobs_to_jd, aglc_jd_to_phase, aglc_tobs_to_phase, aglc_phased, aglc

----

#### aglc_phased
##### Synopsis
 Bin a phased light curve.

##### Usage
```c
 pc = aglc_phased(tgevt, expno_ref, phase_info, ephem, wmin, wmax, tg, orders[, bkg]);
```
or

```c
 pc = aglc_phased(   evt_struct   , phase_info, ephem, wmin, wmax, tg, orders[, bkg]);

```

##### Description

Arguments are similar to those in <code>aglc</code>, with the exception of
<code>phase_info</code> and <code>ephem</code>.  For other arguments, see <code>aglc</code>.

<code>phase_info</code>  = a 3-element array giving the phase minimum, maximum,
and bin size desired for the resultant phased light
curve.
<code>ephem</code> = a two-element array giving the JD of zero phase (NOT MJD!)
and the period in days.

Definitions for Phase Curve Structure Fields
The phase curve fields are the same as for the light curve, with the exception
of phase replacing time and the addition of the ephemeris. The new fields are:

1. <code>phase</code>: Value of phase at the bin center.

2. <code>phase_min</code>: Value of phase at the low edge of the bin.

3. <code>phase_max</code>: Value of phase at the high edge of the bin.

4. <code>epoch</code>: Epoch of the ephemeris, in Julian Days (NOT MJD!).

5. period: Period of the ephemeris, in days.

__See also__: aglc, aglc_filter, aglc_read_events

----

#### aglc_pr_ephem
##### Synopsis
 Print the stored ephemeris used in the last phase-curve binning.

##### Usage
```c
 aglc_pr_ephem
```

##### Description

Retrieves the ephemeris stored by aglc_phased and prints to terminal.

__See also__: aglc_get_ephem, aglc_phased

----

#### aglc_pr_trange
##### Synopsis
 Print to the terminal the current time filter.

##### Usage
```c
 aglc_pr_trange;
```

##### Description

Prints the min and max time filter used in binning phase curves.

__See also__: aglc_set_trange, aglc_get_trange;

----

#### aglc_read_events
##### Synopsis
 Read subset of events from grating file and from exposure file into a structure.

##### Usage
```c
 Struct_Type s = aglc_read_events(String_Type tgevt, expno_ref);
```

##### Description

<code>tgevt</code> should be a Level 1.5 (or 2) grating events file name.
<code>expno_ref</code> should be a Level 1 ``stat'' or events (unfiltered) file name.
The returned value is a structure.  The detailed contents of the
structure are given below in the example.  While the exposure can
be computed from the EXPNO column of the unfiltered event file,
use of the `stat1' file is more efficient.

Definitions for Event Structure Fields:

- <code>fevt_1a</code>: File name for grating events.

- <code>fevt_exp</code>: File name for exposure reference (unfiltered events or ``stat1'' file)

- <code>expno[]</code>: Exposure number column from exposure reference file.

- <code>ccd</code>: CCD_ID column from exposure reference file.

- <code>expno_1a </code>: Exposure number column from grating event file.

- <code>ccd_1a</code>: CCD_ID column from grating event file.

- <code>tgpart</code>: TG_PART column from grating event file. (value is 1 for HEG, 2 for MEG, 0 for zero order, 99 for background)

- <code>order</code>: TG_M column from grating events file, giving the diffraction order.

- <code>tgd</code>: TG_D column from grating events file. This is the cross-dispersion coordinate in degrees.

- <code>wave</code>: TG_LAM column from grating events file, giving the wavelength of each event.

- <code>timedel</code>: TIMEDEL keyword from grating event file, needed for scaling exposure numbers to time. (See the ahelp on time.)

- <code>timepixr</code>: TIMEPIXR keyword from event file. (See the ahelp on time.)

- <code>frame_exp</code>: the exposure time per frame (EXPNO). (See the ahelp on time.)

- <code>mjdref</code>: Modified Julian Day reference time for Chandra observations, from the event file header.

- <code>tstart</code>: TSTART, from the event file header, is the observaton start time in seconds since MJDREF.

- <code>status</code>: Event status column, from the grating events file. (See the definition of ACIS status bits.)

- <code>time</code>: The TIME column from the exposure reference event file.

- <code>cycle</code>: unused.

__See also__: aglc_filter, aglc, aglc_phased

----

#### aglc_set_regs
##### Synopsis
 Set the spatial binning regions (cross-dispersion) for the source
and backgrounds on both sides, and compute the background scaling factors.

##### Usage
```c
 aglc_set_regs( s_min, s_max, b_lo_min, b_lo_max, b_hi_min, b_hi_max );
```

##### Description

Limits are given in cross-dispersion coordinates, tg_d, in units of degrees.

<code>s_min</code> = source minumum tg_d.

The center of the source region is defined as tg_d = 0.

<code>s_max</code> = source region maximum tg_d.

<code>b_lo_min</code> = background minimum, on the "low" side (tg_d < 0).

<code>b_lo_max</code> = background maxmimum, on the "low" side (tg_d < 0).

<code>b_hi_min</code> = background minimum, on the "high" side (tg_d < 0).

<code>b_hi_max</code> = background maxmimum, on the "high" side (tg_d < 0).

The limits follow the constraint that
<code>b_lo_min < b_lo_max <= s_min < s_max <= b_hi_min < b_hi_max</code>.

Default values are the same as the default spectral extraction
regions of tgextract:

<code>s_min    = -6.6e-04</code>  [ deg ]

<code>s_max    =  6.6e-04</code>  [ deg ]

<code>b_lo_min = -6.0e-03</code>  [ deg ]

<code>b_lo_max =  s_min</code>    [ deg ]

<code>b_hi_min =  s_max</code>    [ deg ]

<code>b_hi_max =  6.0e-03</code>  [ deg ]

__See also__: aglc_reset_regs, aglc_get_regs

----

#### aglc_set_status_filter
##### Synopsis
 Set a flag to specify if the grating events should be filtered on STATUS=0.

##### Usage
```c
 aglc_set_status_filter( flag );
```

##### Description

By default, the status filter is zero, meaning all good
events.  Different status bit fields qualify attributes of "bad"
pixels.  If, for some reason, the grating events have not been
filtered on status, but should be, then setting this flag causes
all events with non-zero status to be ignored.

If flag=1, then ignore events with non-zero status.
If flag=0, then accept all events.

__See also__: aglc, aglc_phased

----

#### aglc_set_trange
##### Synopsis
 Set a simple time range filter to be applied to a light curve
before extracting a phase-binned curve. This is useful for
excluding flares, which seem to predominantly occur at the
beginning or end of an observation.

##### Usage
```c
 aglc_set_trange( tmin, tmax );
```

##### Description

<code>tmin, tmax</code> are relative times in seconds, since the start of the
observation.  The interval specifies the times of interest to be included
in phase binning. <code>tmax==NULL</code> means to the end of the observation.
##### Example

<code>aglc_set_trange( 0, 2000 );   %</code> first 2ks will be included in phase binning.

<code>aglc_set_trange( 5000, NULL);  %</code> from 5ks to the end will be selected.

__See also__: aglc_get_trange, aglc_pr_trange

----

#### aglc_tobs_to_jd
##### Synopsis
 Convert Chandra obervation times, given in seconds since MJDREF, to Julian day.

##### Usage
```c
 jd = aglc_tobs_to_jd( t_obs, mjdref );
```

##### Description

<code>t_obs</code> is a scalar or array of Chandra times in seconds since <code>mjdref</code>.
<code>mjdref</code> is the Modified Julian Day reference, found in Chandra
headers, or in the aglc event structure.

__See also__: aglc_jd_to_rotnum, aglc_jd_to_phase, aglc_tobs_to_phase, aglc_read_events

----

#### aglc_write_curve
##### Synopsis
 Write a light or phase curve to a FITS bintable file

##### Usage
```c
 aglc_write_curve( outfile, hdr_ref_file, curve_struct [, history_string ] );" );
```

##### Description

<code>outfile</code> = name of output file ( <code>String_Type</code>).

<code>hdr_ref_file</code> =  Reference file for copying of header info ( <code>String_Type</code>).

<code>curve_struct</code> =  The light or phase curve structure, as created by <code>aglc</code> or  <code>aglc_phased</code>.

<code>history_string</code> = arbitrary note (<code>String_Type</code>).

__See also__: aglc, aglc_phased

----

#### air_to_vacuum
##### Synopsis
 Convert air wavelengths to vacuum wavelengths

##### Usage
```c
 Double_Type l_v[] = air_to_vacuum(Double_Type l_a[])
```

##### Description

Convert air wavelengths l_a (in Angstroem) to vacuum wavelengths l_v (in Angstroem)
for dry air at 15 degrees Celsius, 101.325 Pa, and with 450 parts per million CO2
content. Valid in the wavelength range between 2300 to 17000 Angstroem.
##### Notes

According to Equation 1 in Ciddor 1996, Applied Optics, 35, 1566:
1e8\*(l_v-l_a)/l_a = n-1 = k1/(k0-l_v^(-2)) + k3/(k2-l_v^(-2))
=> l_a = l_v / ( k1\*1e-8/(k0-l_v^(-2)) + k3\*1e-8/(k2-l_v^(-2)) + 1 )
with k0 = 238.0185 \* 1e-8 / Angstroem^2,
k1 = 5792105  \* 1e-8 / Angstroem^2,
k2 = 57.362   \* 1e-8 / Angstroem^2,
k3 = 167917   \* 1e-8 / Angstroem^2.
This function is not analytically solvable for l_v. To zeroth order,
however, l_v ~ l_a so that
l_v ~ l_a \* ( k1\*1e-8/(k0-1/l_a^2) + k3\*1e-8/(k2-1/l_a^2) + 1 ).
##### Qualifiers

* verbose [=1]: : Set to 0 to suppress warnings.

##### Example

l_v = [2000,4000,8000,16000];
print(l_v - air_to_vacuum(vacuum_to_air(l_v)));

__See also__: vacuum_to_air

----

#### Aitoff_projection
##### Synopsis
 computes an Aitoff projection

##### Usage
```c
 (Double_Type x, y) = Aitoff_projection(Double_Type l, b);
```

##### Qualifiers

* deg: <code>l</code> and <code>b</code> are in degrees, not in radian
* normalized: <code>x</code> and <code>y</code> are normalized (by <code>PI/2</code>)
such that <code>abs(x) <= 2</code> and <code>abs(y) <= 1</code>.

##### Description

NOTE: for astronomical purposes you probably want to use the
equal area Hammer-Aitoff projection rather than an Aitoff-projection.
Erroneously many astronomers call the Hammer-Aitoff projection an
Aitoff projection

<code>x = 2 \* cos(b) \* sin(l/2) / sinc(alpha);</code>

<code>y = sin(b) / sinc(alpha);</code>

where
<code>cos(alpha) = cos(b) \* cos(l/2)</code>

and
<code>sinc(alpha) = sin(alpha)/alpha</code>

__See also__: Hammer_projection, Lambert_Equal_Area_projection

----

#### alpha_ff
##### Synopsis
 Calculate the absorption coefficient for free-free absorption

##### Usage
```c
 Double_Type alpha = alpha_ff(nu,T);
```

##### Qualifiers

* Z: average nuclear charge (default=1)
* ne: electron particle density (cm^-3; default: 1e10)
* np: proton particle density (cm^-3; default: 1e10)

##### Description

This function returns the absorption coefficient for free-free radiation
(bremsstrahlung). The frequency, nu, is measured in Hz and can be an array,
the temperature T is measured in K.

For the moment this function assumes the Gauntt factor equals unity.

Note: per Kirchhoff's law the total bremsstrahlung spectrum from
a slab of size R is
B_nu(nu,T)\*(1.-exp(-R\*alpha_ff(nu,T)))

__See also__: j_ff

----

#### angle2string
##### Synopsis
 convert an angle to a string for pretty printing

##### Usage
```c
 string=angle2string(angle;qualifiers)
```

##### Qualifiers

* hoursign: angle is a hour angle, always include sign
* declination: angle is a declination, always include sign
* latitude: angle is a latitude, always include sign
* hours: display hours, not degrees
* deg: input angle is in degrees (default: radians)
* separator: string to insert between the degrees/hours,
minutes, and after the seconds. If a scalar: insert between
degrees and minutes only [e.g., ":"]. If an array: insert
the three array elements between the output numbers (e.g.,
["h","m","s"]). Default is ["d","m","s"] and ["h","m","s"]
depending on whether the hours-qualifier is set or not.
* blank: do not display leading zeros
* secfmt: sprintf format for the seconds (default:
%04.1f, i.e., a precision of 0.1 sec)
* mas: display to a precision of milliseconds
corresponds to secfmt="%06.3f"
* muas: display to a precision of microseconds
corresponds to secfmt="%08.5f"

##### Description

This function is used to produce well formatted strings out of
angular quantities which are given in radians or degrees.
(the default is radian).

Angles can be displayed either in degrees or in hours,
various separators can be used to separate the hms-terms,
and the routine can be told to always display a sign (e.g.,
for declination- or latitude-like quantities), or not.

This routine is array safe.

__See also__: hms2deg,dms2deg,generate_iauname

----

#### angle_to_rad
##### Synopsis
 converts an angle in degrees or h:m:s format into radian

##### Usage
```c
 Double_Type angle_to_rad(Double_Type x);
```

##### Qualifiers

* unit: [<code>="deg"</code>] unit of <code>x</code> (<code>"deg"</code>/<code>"hms"</code>/<code>"rad"</code>)

##### Description

<code>x</code> can be a scalar value or (unless <code>unit="rad"</code>) an array of the form

- <code>[deg, arcmin]</code> (respectively <code>[hour, min]</code> for <code>unit="hms"</code>)

- <code>[deg, arcmin, arcsec]</code> (respectively <code>[hour, min, sec]</code> for <code>unit="hms"</code>)

- <code>[sign, deg, arcmin, arcsec]</code> (respectively <code>[sign, hour, min, sec]</code>).

The latter representation is needed for <code>-1 < deg</code>/<code>hour < 0</code>.

__See also__: hms2deg,dms2deg

----

#### angular_separation
##### Usage
```c
  sep=angular_separation(ra1,dec1,ra2,dec2);
```

##### Synopsis
 calculates the angular distance between two points on a sphere

##### Qualifiers

* deg: if set, the input coordinates and output are in degrees (default: radian)
* radian: if set, the input coordinates and output are in radian (the default))

##### Description

This routine calculates the angular separation between points on the sky
with coordinates ra1/dec1 and ra2/dec2.

The function is equivalent to greatcircle_distance but is compatible in terms
of its qualifiers with the other coordinate system routines. It also returns
the angular separation in the units of the input parameters rather than
always in rad and, by using the haversine formula, is less prone to round
off errors for small angular separations.

This function is array safe (for either ra1/dec1 or ra2/dec2).

__See also__: hms2deg,dms2deg,angle2string,position_angle

----

#### ansi_escape_code
##### Synopsis
 transforms a text format, e.g., a color into its corresponding ANSI code

##### Usage
```c
 String_Type ansi_escape_code(String_Type format[, String_Type text]);
```

##### Qualifiers

* list: print a list of available keywords

##### Description

Transforms the given (human readable) format string into
a sequence of ANSI escape codes. The format string consists
of keywords, e.g., colors separated by semicolons. A list
of supported keywords is printed setting the 'list'
qualifiers.

The cursor movement keywords 'up', 'down', 'forwards', and
'back' allow an optional preceding number, which specifies
the amount of the movement.

In order to reset a previous format you may use the 'reset'
keyword. In case an optional text is provided, this text
and the reset ANSI code is appended to the returned string
automatically.
##### Example

ansi_escape_code("red;blink", "ALERT");
ansi_escape_code("3up"); % move three lines up
ansi_escape_code("blue"); % blue color \*from now on\*
ansi_escape_code("reset"); % turn off the format again

----

#### apj_size
##### Synopsis
 Set the pgplot output size to something suitable for ApJ single column (isis_fancy_plots package)

##### Usage
```c
 apj_size;
```

##### Description

Use as:
isis> id = open_print("fig1.ps/vcps"); apj_size; nice_width;
isis> plot(x,y);
isis> close_print(id,"gv");

__See also__: sov, keynote_size, nice_width, open_print, close_print, pg_color, pg_info

----

#### append_chain
##### Synopsis
 Append a chain fits file to another chain fits file

##### Usage
```c
 append_chain(String_Type chainfile1, String_Type chainfile2, String_Type chainoutfile)
```

##### Qualifiers

* verbose: show progress

##### Description

This function takes two chains stored in chainfile1 and chainfile2 written with the write_chain function
(or by emcee itself) and appends the second one to the first one, again writing a fits file.
This function does not make use of read_chain or write_chain, it's consisting only of
fits routines. The function itself does perform some sanity and safety checks (same data, same fit_fun)
but you have to make sure that you use the correct chains in the correct order.

__See also__: combine_chain, read_chain, write_chain, emcee

----

#### append_struct_arrays
##### Synopsis
 appends a structure's fields to another structures's fields

##### Usage
```c
 append_struct_arrays(Struct_Type &s, Struct_Type additional_s[]);
```

##### Description

<code>s</code> and <code>additional_s</code> have to be structures with the same fields.
<code>s</code>, which is changed by this function, has to be passed by reference.
For every <code>field</code>,

<code>s.field = [s.field, additional_s.field];</code>

The following two statements are equivalent:

<code>append_struct_arrays(&s, additional_s);</code>

<code>s = merge_struct_arrays( [s, additional_s] );</code>

__See also__: merge_struct_arrays

----

#### aproposer
##### Synopsis
 recall object names and the documentation satisfying a regular expression

##### Usage
```c
 aproposer("s")
```

##### Description

This is an extended version of S-Lang's 'apropos' function,
which may be used to get a list of all defined objects
whose name matches the regular expression "s". In addition,
the SYNOPSIS of all functions described in the documentation
files is checked on matches as well. Finally, the output is
formatted such that the matching substring and the object's
name are printed in different colors (see below for format
options).

In order to use this function instead of the intrinsic 'apropos'
function, you can put
alias("aproposer", "apropos");
into, e.g., your .isisrc file.

Further variables can be defined within the .isisrc file for
more control options:
APROPOS_ENABLE_SYNOPSIS - 0 = turn off the synopsis search
APROPOS_FORMAT_NAME     - format string for the object's name
APROPOS_FORMAT_MATCH    - format string for the substring match
APROPOS_LINE_WIDTH      - number of columns of the terminal,
which is needed to format the output (default: output of
`stty size` or 80 if the first attempt fails)
Read the documentation of 'ansi_escape_code' for details about
the format string.

__See also__: apropos, .apropos, help, who,
get_doc_files, ansi_escape_code

----

#### ARFconstruct
##### Synopsis
 Constructs an ARF in keV and cm^2-units from mirror area, filters, filter supports, detector material and additional factor information.

##### Usage
```c
 variable arf=ARFconstruct(e_lo, e_hi, mirrorareafile, filterfiles, supportfiles, open_fraction, detectorlayerfiles, factor);
```

##### Description

An ARF is built from a mirror area, filter-,
support grid-, detector layer transmission
information. The transmission files-parameters
have to be file names of transmission tables
in the format:

TEXT
TEXT
energy[0] [ev] transmission[0]
energy[1] [ev] transmission[1]
...             ...

These arrays are interpolated to the input energy
grid (e_lo, e_hi).
The open_fraction is an array with the same lenght
as the number of filter support files and gives the
fraction of the support grid that is open for X-rays.
The mirror area file has to be in the format:

TEXT
energy[0] [kev] area[0] [cm^2]
energy[1] [kev] area[1] [cm^2]
...             ...

The factor is an additional factor multiplied to the
ARF.

The return value is a structure

arf=struct{
energ_lo=e_lo,
energ_hi=e_hi,
specresp
};

To construct an ARF without mirrors included, it can be done by
setting mirrorareafile=NULL

----

#### ARFfromMirrorArea
##### Synopsis
 Sets the ARF values to the interpolated values of the given mirror area array.

##### Usage
```c
 ARFfromMirrorArea(arf, mirrorarea);
```

__See also__: ARFreadMirrorArea

----

#### ARFmultiplyDetQE
##### Synopsis
 Multiplies the ARF values with the total quantum efficiency, corresponding to the total transmission of the given detector layers.

##### Usage
```c
 ARFmultiplyDetQE(arf, detectorLayers);
```

__See also__: ARFfromMirrorArea, ARFmultiplyFilter, ARFmultiplySupport, ARFmultiplyFactor

----

#### ARFmultiplyFactor
##### Synopsis
 Multiplies the ARF values with the given factor.

##### Usage
```c
 ARFmultiplyFactor(arf, factor);
```

__See also__: ARFfromMirrorArea, ARFmultiplyFilter, ARFmultiplySupport, ARFmultiplyDetQE

----

#### ARFmultiplyFilter
##### Synopsis
 Multiplies the ARF values with the interpolated transmission of the given filter.

##### Usage
```c
 ARFmultiplyFilter(arf, filter);
```

__See also__: ARFfromMirrorArea, ARFmultiplySupport, ARFmultiplyFactor, ARFmultiplyDetQE

----

#### ARFmultiplySupport
##### Synopsis
 Multiplies the ARF values with the interpolated transmission of the given support material, taking the open fraction into account.

##### Usage
```c
 ARFmultiplySupport(arf, support, openFraction);
```

__See also__: ARFfromMirrorArea, ARFmultiplyFilter, ARFmultiplyFactor, ARFmultiplyDetQE

----

#### ARFreadHenkeTransm
##### Synopsis
 Reads a standard henke table ASCII-file and returns it as a structure. Energy (first column) must be given in eV and is converted into keV. Transmission (second column) between [0.;1.]. First 2 rows are assumed to be comments.

##### Usage
```c
 variable henketable=ARFreadHenkeTransm(henkename);
```

__See also__: ARFmultiplyFilter, ARFmultiplySupport, ARFmultiplyFactor, ARFmultiplyDetQE, ARFreadMirrorArea

----

#### ARFreadMirrorArea
##### Synopsis
 Reads the mirror area ASCII-file and returns it as a structure.

##### Usage
```c
 variable mirrorarea=ARFreadMirrorArea(mirrorname);
```

##### Description

The mirror area file has to be in the format:

TEXT
energy[0] [kev] area[0] [cm^2]
energy[1] [kev] area[1] [cm^2]

__See also__: ARFfromMirrorArea

----

#### array2image
##### Synopsis
 Converts three x, y, z arrays into a 2D array

##### Usage
```c
 image[,] = array2image(x,y,z)
```

##### Qualifiers

* nbinx: number of bins along x-axis
* nbiny: number of bins along y-axis
* xgrid: 1D array containing grid of values for x-axis. Ignores nbinx.
* ygrid: 1D array containing grid of values for y-axis. Ignores nbiny.
* func: reference to a single-parameter S-Lang function used to determine pixel values from z-values (see below).
* func_quals: struct containing additional qualifiers to be passed to the function defined in func
* include_inf: include points where x, y, or z are inf or -inf
* include_nan: Note that this means the returned 2D array is of the form
im[y,x]. By default this ignores any points with infinite or NaN values
(this can be turned off with the include_inf and include_nan switches).

##### Description

The x-y grid is determined automatically from the ranges of the data, or
can be defined by the "xgrid" and "ygrid" qualifiers. If "xgrid" or "ygrid"
is a reference to a local variable, the automatically-determined grids will
be stored in these variables. This function uses histogram2d() to bin the
data and figure out which points fall into which bins, so see that
function's documentation for how the grids are handled.

Notes regarding coordinate grids:
\* histogram2d() uses the last bin as an "overflow" bin, so user-supplied
binning should have their last bin be SMALLER than the largest x- or
y-value (otherwise you will have a column or a row with no points
included).
\* The grids define the EDGES of the bins used by histogram2d(). I think
(although I am not sure) that plot_image() and plot_contour() use any
supplied coordinate grid to define the CENTERS of the pixels. Check the
documentation of PGPLOT's PGIMAG routine to be sure.
\* Finally, I have no idea what histogram2d() does when it gets a
pathologically-designed grid (e.g., bins with zero width, overlapping
bins, or bins with lower bounds larger than their upper bounds). Please
only use monotonically-increasing bins.

The value of each pixel is, by default, the average of all points which
fall into that bin. This can be changed by passing a reference to a
function via the "func" qualifier.

The "func" qualifier must be a reference to an S-Lang function which takes
a single array as input and outputs a single value, e.g., mean(), sum(), or
length(). The input to this function is an array containing all z-values
that fall into the current pixel. However, this function also receives a
set of qualifiers. By default, this gives @func access to the data, the
coordinate grids, and the list of points in the current pixel via the
following qualifiers:
qualifier("x"), qualifier("y"), qualifier("z"): x, y, and z data coordinates
qualifier("xgrid"), qualifier("ygrid"): x and y coordinate grids
qualifier("ndx"): array of data indices in the current pixel

Extra qualifiers can be supplied via the func_quals qualifier, which
should be set to a structure containing any additional qualifiers you need.
This will be merged with the above set of qualifiers using struct_combine()
with user-defined qualifiers taking precedence over the defaults in cases
where the names are the same.

As an example, to set each pixel's value to the innner product of the
z-values and some other array of numbers (which we'll call "z2"), one could
define:
<code>
define arr2im_dotprod(zValues) {
variable z2 = qualifier("extra_array");
variable ndx = qualifier("ndx");
return inner_product(zValues,z2[ndx])[0];
}
</code>

and then after reading in or defining x, y, z, and z2 arrays, do:
<code>
variable im = array2image(x,y,z;func=&arr2im_dotprod,func_quals=struct{extra_array=z2});
</code>

By default this function removes infinite and NaN values from the x, y, and
z arrays before doing anything; the include_inf and include_nan switches
disable this behavior. Note that including infinite and/or NaN values will
cause problems for the default grids and pixel value assignment, so
include_inf and include_nan are best used with user-defined functions and
grids.

This script is under development; please contact Paul Hemphill
(pbh@space.mit.edu) regarding bugs or missing features (please do not
report missing bugs; any bugs that are not present are missing
intentionally).

__See also__: histogram2d, plot_image

----

#### array2matrix
##### Synopsis
 Transforms an Array_Type into a matrix

##### Usage
```c
 Any_Type[l,...] = array2matrix(Array_Type[l] array);
```

##### Qualifiers

* filler[=-_NaN]:: Filler for empty array entries

##### Description

Similar to array_flatten, this function flattens the
array into a single one. In contrast to array_flatten,
the array_shape of the individual entries is conserved.
If the array_shape of the individual array entries is
not the same, the maximal dimension is determined and
empty entries are being filled with the value given
with the filler qualifier.
##### Example

variable arr = Array_Type[3];
arr[0] = _reshape( [1:3\*4\*5], [3,4,5] );
arr[1] = _reshape( [1:3\*4], [3,4] );
arr[2] = _reshape( [1:2\*3\*4], [2,3,4] );

variable mat = array2matrix(arr);
print(mat);

__See also__: array_flatten

----

#### array_copy
##### Synopsis
 makes a copy of a nested array

##### Usage
```c
 Array_Type copy = array_copy(Array_Type[] array);
```

##### Description

<code>array_copy</code> copies an <code>Array_Type[]</code> with all its
entries, which can be of any Type! If an entry is a Struct_Type
<code>array_copy</code> calls <code>struct_copy</code> and if an entrie is
an <code>Array_Type[]</code>, <code>array_copy</code> calls itself.
##### Example

s = Struct_Type[1]; s[0]=struct{ a=Array_Type[1,2] };
s[0].a[[0]]=[0:9];
copy = array_copy(s); copy[0].a[[0]] = ["modified"];
print(s[0].a);

__See also__: struct_copy

----

#### array_density
##### Synopsis
 calculates the 'intensity' of an array, i.e. the invers of
the spacing

##### Usage
```c
 array_density(bin_lo, bin_hi);
```

----

#### array_fit_gauss
##### Synopsis
 performs a gaussian fit on given x- or xy-data

##### Usage
```c
 Struct_Type array_fit_gauss(x [,y] [,dy] [,c] [,s] [,a] [,o]);
```

##### Qualifiers

* frz: boolean array determining which parameters (c,s,a,o) are frozen
* keep: keeps the data and fit function (be careful, needs to be deleted for the next fit
* plot: plot the given data and oplot the fit
* oplot: only oplot the fit

##### Description

Tries to fit the given data by a gaussian and an offset. If the y-data is
omitted, the given x-data is interpreted as y-data. The x-values are then
generated as indices of the y-data.
The uncertainties of the y-data can be passed to the fit algorithm by the
`dy' parameter. If not given the errors are calculated assuming Poisson
statistics.
The four remaining parameters are the starting values:
c - center position
s - sigma
a - area
o - offset in y-direction
They may also be given by an array as parameter `c' in the order shown
above. The same order is used for the freeze status qualifier `frz'.
Performing the fit is done with the actual choosen fit method. The result
is returned as a structure of the form
Struct_Type { center, sigma, area, offset, chisqr }
where chisqr is the reduced chi-square value of the best fit.

----

#### array_flatten
##### Synopsis
 flattens an array of Array_Type[] into a single array

##### Usage
```c
 Any_Type array_flatten(Array_Type[] array);
```

##### Description

The given 'array' itself contains arrays of any
data type. This function flattens the 'array'
such that all internal arrays are merged.

Also the array can have entries of any data type,
they must be of the same type! Otherwise the function
will throw an error.
To avoid this split the array, e.g., with

arr1 = arr[where(_typeof(arr)==Double_Type)];

or if there are NULL entries,

arr1 = arr[wherenot( arr == NULL )];

and use arr1 as argument for array_flatten!

##### Example

variable arr = Array_Type[3];
arr[0] = [1,2,3,4];
arr[1] = [5,6];
arr[2] = [7,8,9];

variable arrF = array_flatten(arr);
% returns an Integer_Type[9] containing
% [1,2,3,4,5,6,7,8,9]

----

#### array_insert
##### Synopsis
 Inserts an array into another array

##### Usage
```c
 Any_Type[] = array_insert(Any_Type[] A, Any_Type[] IA, Integer_Type i);
```

##### Description

Inserts the array or single value IA into the array A at the index
position i. A and IA have to be of the same DataType_Type!
Basically it is:

[ A[[:i-1]], IA , A[[i:]] ]

##### Example

variable A  = [1:10];
variable IA = [2,1];
variable NA = array_insert( A, IA, 3 );
print(NA);

----

#### array_map_index
##### Synopsis
 Call a function on a subset of arrays

##### Usage
```c
 Array_Type array_map_index (Int_Type[] start, Int_Type[] stop,
DataType_Type type, Ref_Type func, args, ...);
```

```
or

```c
 Array_Type array_map_index (Int_Type[] index, DataType_Type type,
Ref_Type func, args, ...);
```
or

```c
 Array_Type array_map_index (Ref_Type start, Ref_Type stop,
DataType_Type type, Ref_Type func, args, ...);
```
or

```c
 Array_Type array_map_index (Ref_Type index, DataType_Type type,
Ref_Type func, args, ...);
##### Description

The <code>array_map_index</code> function is somewhat the opposite of the
<code>array_map</code>. As <code>array_map</code> allows it to apply a function to every
array element individually, <code>array_map_index</code> can be used to apply a
function (taking an array) on one or more subsamples of the target array.

Case 1: If called with <code>start</code> and <code>stop</code> the function <code>func</code> is
applied to <code>args[start[i]:stop[i]]</code> for each <code>i</code>.

Case 2: If called with only one index array <code>index</code> the function is
applied to args[index]. This is the same as <code>func(args[index]);</code>.

IMPORTANT: array_map_index applys <code>func</code> to an array!

Case 3: If called with <code>&start</code> and <code>&stop</code> the function behaves the
same as for case 1, but this is usefull when you want to nest <code>array_map</code>
calls.

Case 4: If called with <code>index</code> the it behaves the same as for case 2 but,
again, this might be usefull for <code>array_map</code> nesting.

NOTE: This function can hide a lot of important operations so it should be
avoided for implementing algorithms. However, it is very useful for fast
scripting and interactive (shell) operations.

##### Example

% Case 1: apply mean() to a subset of data
data = rand_gauss(0.1, 100) % generate 100 normal distributed random numbers
means = array_map_index([0,5,25], [99,94,74], &mean, data);
print(means);
% this outputs the same as
print(mean(data)); print(mean(data[[5:94]])); print(mean(data[[25:74]]));

% Case 2: apply mean() to specified subset
data = rand_gauss(0.1, 100) % 100 random numbers
idx = where(data < 0) % select only negative data
neg_mean = array_map_index(idx, Double_Type, &mean, data);
print(neg_mean);
% this results in the same as
print(mean(data[n]));

% Case 3: apply mean() to array of arrays
data = Array_Type[3];
data[0] = rand_gauss(0.1, 100);
data[1] = rand_gauss(0.01, 100);
data[2] = rand_gauss(1, 100);
start = [0,5,25];
stop = [99,94,74];
means = array_map(Array_Type, &array_map_index, &start, &stop,
Double_Type, &mean, data);
% returns the mean as in example for case 1 but applied to all sub arrays
% note that you have to declare the start and stop arrays explicitly because
% &[5:94] is not a valid expression

% Case 4: Same as case 3 but with only one index array

% Use array_map_index to call a function n times
rn = array_map_index([1:5], Array_Type, &rand_gauss, 0.1, 100);
% gives 5 arrays of 100 random numbers each

__See also__: array_map, array_map_qualifiers

----

#### array_map_qualifiers
##### Synopsis
 Apply a function to each element of an array (also if given as qualifier)

##### Usage
```c
 Array_Type array_map (DataType_Type type, Ref_Type func, args, ... );
```

```
or

```c
 (Array_Type, ...) array_map (DataType_Type type, ..., Ref_Type func, args, ... );
##### Description

The 'array_map_qualifiers' function is an extension of the 'array_map'
function and supports all its features.
This function also works for qualifiers! First of all qualifiers given to
the 'array_map_qualifiers' are passed onto the called function 'func'.

Furthermore if the qualifier(s) itself is an array, it will be mapped too!
This is especially helpfull when used for calls of integration function
such as 'qromb' as these require parameters to be given as qualifiers!

This functionality can be turned off with the "noqualmap"
qualifier, which is necessary for, e.g., epochfolding routines (and much
faster!)

NOTE that this function works as 'array_map', i.e., the mapping will apply
for the first argument which is an array! As the qualifiers are passed after
the arguments, an argument array will supersede a qualifier array as long as
they do not have the same length.

##### Example

define t(x){ return qualifier("a",0)\*x;};

%% Mapping function using an argument array:
print(array_map_qualifiers( Double_Type, &t, [1,2,3,4] ; a=1 ));

%% Mapping function using a qualifier array:
print(array_map_qualifiers( Double_Type, &t, 1 ; a=[1,2,3,4] ));

%% Mapping function argument array superseding qualifier array:
print(array_map_qualifiers( Double_Type, &t, [3,4,5,6] ; a=[1,2] ));

%% Mapping function using argument array AND qualifier array:
print(array_map_qualifiers( Double_Type, &t, [3,4,5,6] ; a=[1,2,3,4] ));

%% Map function using a qualifier array application on 'qromb' integrater
print(array_map_qualifiers( Double_Type, &qromb, &t, 0, 1 ; a=[0:2] ));

__See also__: array_map, struct_of_arrays_2_struct_array

----

#### array_permutation_matrix
##### Synopsis
 returns all possible permutations of the given arrays

##### Usage
```c
 Array_Type array_permutation_matrix(Array_Type[] or List_Type arrays);
```

##### Description

Calculates the index arrays of all possible permutations of the
elements in the given arrays (see the below example). The input
has to be either an array of arrays (Array_Type) or a list of
arrays (List_Type). The returned matrix (J,K) is an array of
integer arrays. The element (J,K) is the index of the K^th input
array, which corresponds to the J^th permutation.
##### Example

variable arr = Array_Type[3];
arr[0] = [10,20,30,40];
arr[1] = [50,60];
arr[2] = [70,80,90];

variable matrix = array_permutation_matrix(arr);
% Returns an Array_Type[24] corresponding to 4\*2\*3 = 24 possible
% permutations. Each element is an Integer_Type[3] containing the
% indices for each of the 3 input arrays:
% matrix[0]  = [0,0,0] -> [10,50,70]
% matrix[1]  = [1,0,0] -> [20,50,70]
% matrix[2]  = [2,0,0] -> [30,50,70]
% matrix[3]  = [3,0,0] -> [40,50,70]
% matrix[4]  = [0,1,0] -> [10,60,70]
% matrix[5]  = [1,1,0] -> [20,60,70]
% ...
% matrix[23] = [3,1,2] -> [40,60,90]

----

#### array_permute
##### Synopsis
 generates a random permutation of [0 : n-1]

##### Usage
```c
 Integer_Type[] random_array(Array_Type a)
```
or

```c
 Integer_Type[] random_array(Integer_Type n)

```

##### Description

The return value is an array of indices.
To randomize an array <code>a</code>, use <code>a[array_permute(a)]</code>.

__See also__: array_sort

----

#### array_remove
##### Synopsis
 removes one element from an array

##### Usage
```c
 Array_Type a_ = array_remove(Array_Type a, Integer_Type i);
```

##### Description

<code>a_</code> contains all elements of <code>a</code> excecpt of the one indexed by <code>i</code>.

----

#### array_split_at_extrema
##### Synopsis
 Splits an array into monotone chucks

##### Usage
```c
  Array_Type[] I = array_split_at_extrema( array );
```

----

#### array_unique
##### Synopsis
 takes elements of an array only once

##### Usage
```c
 Array_Type array_unique(Array_Type a)
```

##### Description

Duplicated array elements are removed from the array.
This function is basically
a[unique(a)]
where unique gives the indicies of the unique array
elements.

__See also__: unique

----

#### array_zip
##### Synopsis
 "zip" two or more arrays together

##### Usage
```c
 Any_Type array_zip(Any_Type[] a, b, ...);
```

##### Description

Returns an array of tuples (or higher orders), where each tuple i
contains the i-th element from each of the given arrays. The
returned array is truncated to the length of the shortest
array. Thus, the number of tuples is equal to this smallest
length.
##### Example

a = [1:10];
b = [11:20];
c = array_zip(a,b);
% c = [1,11,2,12,3,13,4,14,...,10,20];

----

#### arrtimes
##### Synopsis
 fit function for modelling arrival times

##### Usage
```c
 arrtimes(id)
```

##### Description

This model can bes used in arrival time fits. The
pulse arrival times are calculated using the
'pulse_time' function, including orbital motion
and up to the third derivative of the pulse
period. The observed pulse arrival time t_obs(n)
is calculated by

t_obs(n) = t0 + A\*n + B\*n^2 + C\*n^3 + D\*n^4
+ z(t_emit(n))/c

where A to D are coefficients depending on the
pulse period and its higher derivatives, z/c is
the Doppler Shift due to orbital motion (see
'BinaryPos' for details) and t_emit(n) is the
time, when the nth pulse is emitted in the bary-
centre of the binary. This time is found solving
the above equation:

t_emit(n) = t_obs(n) - z/c

However, this can not be solved since the
observed arrival times include the Doppler
Shift. Hence the emission time must be found
iteratively, starting at t_emit(n) = t_obs(n).
The found pulse numbers are stored in a reference
variable, if set by 'define_atime'.
The model parameters are
ppuls - pulse period (s)
pdot  - first derivative (s/s)
p2dot - second derivative (s/s^2)
p3dot - third derivative (s/s^3)
dphi  - constant additive phase shift
porb  - orbital period (d)
torb0 - time of periastron passage (MJD)
asini - projected semi major axis (lts)
ecc   - eccentricity
omega - angle of periastron (degrees)
pporb - change of orbital period (d/d)
The reference time of the pulse ephemeris,
called tpuls0 in 'atime_get_ephemeris' for
example, is fix and set by 'define_atime'.
If you know what you are doing you can
change this time using 'atime_set_ephemeris'.

__See also__: pulse_time, atime_set_ephemeris, define_atime, BinaryPos

----

#### AS
##### Synopsis
 Evaluate equations of motion, total energy, or circular velocity derived from a revised
Allen & Santillan potential

##### Usage
```c
 AS(Double_Types t, m[6,n]; qualifiers)
```

##### Qualifiers

* coords: [<code>="cyl"</code>] Use cylindrical ("cyl") or cartesian ("cart") coordinates.
* eomecd: [<code>="eom"</code>] Return equations of motion ("eom"), total energy ("energy"),
circular velocity ("circ"), or Sun-Galactic center distance ("sgcd").
* Mb: [<code>=409</code>] Mass of bulge in Galactic mass units, see Irrgang et al. 2013.
* Md: [<code>=2856</code>] Mass of disc in Galactic mass units, see Irrgang et al. 2013.
* Mh: [<code>=1018</code>] Mass scale factor of halo in Galactic mass units,
see Irrgang et al. 2013.
* bb: [<code>=0.23</code>] Bulge scale length, see Irrgang et al. 2013.
* ad: [<code>=4.22</code>] Disc scale length, see Irrgang et al. 2013.
* bd: [<code>=0.292</code>] Disc scale length, see Irrgang et al. 2013.
* ah: [<code>=2.562</code>] Halo scale length, see Irrgang et al. 2013.
* exponent: [<code>=2</code>] Exponent in the halo mass distribution, see Irrgang et al. 2013.
* cutoff: [<code>=200</code>] Halo cutoff, see Irrgang et al. 2013.

##### Description

Evaluate the equations of motion, the total energy, or the circular velocity at time 't'
derived from the revised Galactic gravitational potential by Allen & Santillan (see Model I
in Irrgang et al., 2013, A&A, 549, A137) using either cylindrical coordinates (r [kpc],
phi [rad], z [kpc]) and their canonical momenta vr [kpc/Myr], Lz [kpc^2/Myr], vz [kpc/Myr])
or cartesian coordinates (x [kpc], y [kpc], z [kpc], vx [kpc/Myr], vy [kpc/Myr], vz [kpc/Myr]),
see qualifier 'coords'.  Conservation of angular momentum Lz is implemented in the equations
of motion for cylindrical coordinates only. The total energy E_total [kpc^2/Myr^2] is not
used to integrate the equations of motion although being a conserved quantity, too. Therefore,
conservation of energy, i.e., of E_total, is a measure for the precision of the numerical
methods applied.

For computing orbits with n different initial conditions, the input parameter m is
a [6,n]-matrix with (qualifier("coords")=="cyl")   or (qualifier("coords")=="cart")
m[0,\*] = r;                                        m[0,\*] = x;
m[1,\*] = phi;                                      m[1,\*] = y;
m[2,\*] = z;                                        m[2,\*] = z;
m[3,\*] = vr;                                       m[3,\*] = vx;
m[4,\*] = Lz;                                       m[4,\*] = vy;
m[5,\*] = vz;                                       m[5,\*] = vz;
If the qualifier 'eomecd' is set to "eom", the function returns a [6,n]-matrix delta with
delta[0,\*] = vr;                                   delta[0,\*] = vx;
delta[1,\*] = Lz/r^2; % = vphi                      delta[1,\*] = vy;
delta[2,\*] = vz;                                   delta[2,\*] = vz;
delta[3,\*] = -d/dr (Potential(r,z) + Lz^2/r^2);    delta[3,\*] = -d/dx Potential(x,y,z);
delta[4,\*] = 0; % -d/dphi Potential(r,z)           delta[4,\*] = -d/dy Potential(x,y,z);
delta[5,\*] = -d/dz Potential(r,z);                 delta[5,\*] = -d/dz Potential(x,y,z);
If the qualifier 'eomecd' is set to "energy", the function returns a [1,n]-array storing
the total energy for each orbit:
E_total(r,z,vr,vz,Lz) = Double_Type[n] = 0.5\*(vr^2+vz^2+Lz^2/r^2) + Potential(r,z)
or
E_total(x,y,z,vx,vy,vz) = Double_Type[n] = 0.5\*(vx^2+vy^2+vz^2) + Potential(x,y,z)
If the qualifier 'eomecd' is set to "circ", the function returns a [1,n]-array storing
the circular velocity for each orbit:
v_circ(r,z) = Double_Type[n] = sqrt( r \* d/dr Potential(r,z) )
If the qualifier 'eomecd' is set to "sgcd", the function returns the Sun-Galactic center
distance found to fit best to this potential.
##### Example

delta = AS(0, m);
energy = AS(0, m; eomecd="energy");
v_circ = AS(0, m; eomecd="circ");
sgcd = AS(; eomecd="sgcd");

__See also__: orbit_calculator, MN_NFW, MN_TF, plummer_MW

----

#### ascii_read_table
##### Synopsis
 reads an ASCII table from a file into a structure

##### Usage
```c
 Struct_Type table = ascii_read_table(String_Type filename, String_Type formats[]);
```
or

```c
 Struct_Type table = ascii_read_table(String_Type filename, List_Type infos[]); with  infos[i] = { formats[i], columns[i] };
```
or

```c
 (table, keys) = ascii_read_table(String_Type filename, List_Type infos[]);

% with  infos[i] = { formats[i], columns[i], units[i] };

```

##### Description

The data format of the columns has to be specified as for sscanf; i.e.,
%s for strings, %d for decimal integers, %F for double precision floats, ...
Lines starting with a comment string ("#" by default; see below) are ignored.
The return value is a structure containing the table.
Therefore, the column names have to respect the conventions
for struct-field names (no special characters as "-"...).
If the column name is "", this column is skipped.
If a unit is given, the function ascii_read_table has a second return value,
namely a keys-structure which can be used for <code>fits_write_binary_table</code>.
##### Qualifiers

* comment: string which indicates comments [default = "#"]
* startline: Only lines after this number are considered.
* endline: The file is not read after this line number.
* verbose:

##### Examples

<code>variable tab1 = ascii_read_table(filename, [{"%s"}, {"%F"}, {"%F"}]);</code>

<code>%</code> reads <code>String_Type tab1.col1</code>, <code>Double_Type tab1.col2</code>, <code>Double_Type tab1.col3</code> from <code>filename</code>

<code>variable tab2 = ascii_read_table(filename, [{"%s","A"}, {"%F","B"}, {"%F","C"}]);</code>

<code>%</code> reads <code>String_Type tab2.A</code>, <code>Double_Type tab2.B</code>, <code>Double_Type tab2.C</code>

<code>variable tab3 = ascii_read_table(filename, [{"%s","A"}, {"%F",""}, {"%F","C"}]);</code>

<code>%</code> reads <code>String_Type tab3.A</code>, skips one <code>Double_Type</code> column and reads <code>Double_Type tab3.C</code>

<code>variable tab4, keys;</code>

<code>(tab4, keys) = ascii_read_table(filename, [{"%s","A"}, {"%F"}, {"%F","C","u"}]);</code>

<code>%</code> reads <code>String_Type tab4.A</code> and <code>Double_Type tab4.C</code> as before. With

<code>fits_write_binary_table(FITSfilename, "tab4", tab4, keys);</code>

<code>%</code> the unit "u" is assigned to the (second) column C.

__See also__: sscanf, fits_read_table, fits_write_binary_table, readcol

----

#### __assemblePanstarrsUrl
##### Synopsis
 Assemble a URL for the PanSTARRS image cutout server

##### Usage
```c
 String_Type __assemblePanstarrsUrl(String_Type position, Integer_Type size)
```

##### Description

position is either a set of coordinates of the form "ra+/-dec"
(e.g. "124.45+34") or a string which is used by the cutout server itself
to perform a simbad query.
size is the pixel number along the edge of the square image.
The qualifiers for the function are the set of options for filter, filetype,
and auxiliary data given in __panstarrsFilters, __panstarrsFiletypes, and
__panstarrsAuxiliary

----

#### associate_arrays
##### Synopsis
 computes the smallest pairwise difference between elements of two arrays and returns the indices

##### Usage
```c
 Struct_Type result = associate_arrays(Double_Type[n1] A, Double_Type[n2] B);
```

##### Description

For each element <code>A[i]</code> this function searches the element <code>B[j]</code>
with the smallest difference to <code>A[i]</code>. It returns the indices <code>j</code>
as <code>result.index[i]</code> and the corresponding difference as <code>result.diff[i]</code>.
##### Qualifiers

* nr_closest:  [=1]: set to N, to obtain the N closest elements.
In this case additionally the index of the second, ..., N-th closest element is
returned as <code>result.index2[\*,0], ..., result.index2[\*,N-2]</code>,
the same holds for <code>result.diff2</code>.

__See also__: array_sort

----

#### associate_coords
##### Synopsis
 computes the smallest pairwise angular separation between arrays of positions and returns the indices

##### Usage
```c
 Struct_Type result = associate_coords(Double_Type[n1] RA1, Double_Type[n1] DEC1),Double_Type[n2] RA2, Double_Type[n2] DEC2);
```

##### Qualifiers

* nr_closest: [=1]      set to N, to obtain the N closest elements.
In this case additionally the index of the second, ..., N-th closest element is
returned as <code>result.index2[\*,0], ..., result.index2[\*,N-2]</code>,
the same holds for <code>result.sep2</code>.
* unit: [<code>="deg"</code>]        unit of the angular coordinates
* alpha1_unit: [<code>="deg"</code>] unit of the RA1
* alpha2_unit: [<code>="deg"</code>] unit of the RA2
* delta1_unit: [<code>="deg"</code>] unit of the DEC1
* delta2_unit: [<code>="deg"</code>] unit of the DEC2

##### Description

For each position <code>(RA1[i], DEC1[i])</code> this function searches the element <code>(RA2[j],DEC2[j])</code>
with the smallest difference to <code>(RA1[i],DEC[i])</code>. It returns the indices <code>j</code>
as <code>result.index[i]</code> and the corresponding separation in rad as <code>result.sep[i]</code>.
The units of each coordinate can be set with the qualifier <code>unit</code>, but also independently,
as for the function <code>greatcircle_distance</code>.

__See also__: greatcircle_distance, associate_arrays

----

#### assoc_copy
##### Synopsis
 makes a copy of an associated array

##### Usage
```c
 Assoc_Type copy = assoc_copy(Assoc_Type list);
```

##### Description

<code>assoc_copy</code> returns a properly dereferenced copy of an
arbitrarily nested <code>Assoc_Type</code> with all its entries.
Depending on the Data_Type of the entries, <code>assoc_copy</code>
iteratively calls the according sub-function
(<code>struct_copy</code>, <code>array_copy</code> or <code>list_copy</code>).
If the Data_Type of one of its entries is not
one of previously mentioned ones, <code>assoc_copy</code> returns
@(Data_Type) or respectively @(entry).
##### Example

s = Struct_Type[1]; s[0]=struct{ a=Array_Type[1,2] };
s[0].a[[0]]=[0:9];
l = [{ array_copy(s), 1., [1:10] }, {"abs"}];
copy = COPY(l); copy[0][0][0].a[[0]] = ["modified"];
print(l[0][0][0].a);

__See also__: COPY, struct_copy, array_copy, list_copy

----

#### assoc_struct_combine
##### Synopsis
 associate structure fields, combine structures and fill entries

##### Usage
```c
 Struct_Type <code>comb</code> = assoc_struct_combine(Struct_Type <code>s1</code>, Struct_Type <code>s2</code>, String_Type <code>f1</code>, String_Type <code>f2</code>);
```

##### Qualifiers

* double_fill [=_NaN]: : filler for missing entries in Double_Type fields of <code>s2</code>
* float_fill [=_NaN]: :  filler for missing entries in Float_Type fields of <code>s2</code>
* integer_fill [=_0]: :  filler for missing entries in Integer_Type fields of <code>s2</code>
* string_fill [=""]: :   filler for missing entries in String_Type fields of <code>s2</code>
* flag_field_name  [="both_struct_flag"]: : additional field name for <code>comb</code>

##### Description

This function combines two structures. It uses the field with name <code>f1</code> of the
structure <code>s1</code> and that with name <code>f2</code> of <code>s2</code> to associate the entries with the function
get_intersection. The fields of the returned structure <code>comb</code> have the length of the
field <code>f1</code>. The entries in these fields are filled according to the qualifiers, if
there is no association found for this entry.
Fields of a type for which no fill qualifier is given are filled with NULL and
returned as a list. Fillers can be defined via qualifiers for all variable types.
The suffix _fill is required, i.e., for example the qualifier to define a filler
for Complex_Type is <code>complex_fill</code>.
WARNING: This function fails for more dimensional fields. If there are fields with
the same name in both structures, the field of <code>s2</code> is used, as it is done by
struct_combine. The field <code>f2</code> is not included.
The function adds a field (name can be indentified via qualifier <code>flag_field_name</code>),
which indicates if the entry was found in both structures (1) or if it exists
only in <code>f1</code> (0).

##### Examples

a = struct{source = ["1", "2", "3"], flux=[0.1, 2.5, 0.7]};
b = struct{source = ["3", "2"], redshift=[0.65, 0.03], opt_id = ["Quasar","BL Lac"]};
c = assoc_struct_combine (a,b,"source", "source");
print_struct(c);

% without filling fields, but using just common fields this corresponds to:
(i1,i2) = get_intersection(a.source,b.source);
struct_filter(a,i1);
struct_filter(b,i2);
d = struct_combine(a,b);
print_struct(d);

__See also__: get_intersection, struct_combine, struct_filter

----

#### aStar
##### Synopsis
 pathfinding algorithm A\*

##### Usage
```c
 Struct_Type aStar(Double_Type[][] graph, Integer_Type startX, startY, endX, endY);
```

##### Qualifiers

* max: find the most expensive path instead of the cheapest one
* meanCost: costs are normalized by the best path length to any point
in the graph, resulting in a mean cost on a path
* estimate: reference to a function, which estimates the cost between
two nodes in the graph (parameters: x0, y0, x1, y1). By
default, the distance between both nodes is used
* plot: plots the graph and the working progress at each step. Nodes
in the open list are shown in red, in the closed list in
blue, nodes of infinite cost in green and the best path,
finally, in black. The function sleeps 0.01 seconds after
each step or the value given with this qualifier

##### Description

Pathfinding algorithm with high performance and accuracy by
Hart, Nilsson & Raphael, "A Formal Basis for the Heuristic
Determination of Minimum Cost Paths", IEEE Transactions on
Systems Science and Cybernetics SSC4 (2), 100107, 1968

The A\* algorithm (called A Star) finds the shortest (or in general
cheapest) path between to nodes in a graph. The algorithm looks for
the best way following the lowest known heuristic cost. This cost
has to be estimated at each new discovered node and is, by default,
the straight-line distance between both points. The runtime and
accuracy of the search strongly depends on the choice of this
estimation.

The 'graph' has to be given as 2d-array defining the cost at each
point (node). Infinite costs (_Inf) are allowed and corresponds to
insuperable borders. The starting node and goal node habe to be
given as array indices 'startX', 'startY' and 'endX', 'endY',
respectively.

The returned structure contains
x    - x-indices of the best path
y    - y-indices of the best path
cost - summed costs along the best path

----

#### atime_calc_beta
##### Synopsis
 converts a pulse phaseshift into arrival times

##### Usage
```c
 (Double_Type[] arrtimes, errors) = atime_calc(Struct_Type atime, eph[, orb]);
or (Double_Type[] arrtimes, errors) = atime_calc(Double_Type[] t0, phi, error, Struct_Type eph[, orb]);
```

##### Description

Takes the structure determined by 'atime_det'
or an array of times, phase shifts and their
errors and returns the pulse arrival times
t = t0 + phi \* p(t0) [+ z(t0)/c]
To calculate the pulse period at each time
a pulse ephemeris structure is needed (see
'check_pulseperiod_orbit_struct'). If an
optional structure containing orbital
parameters is given, the Doppler shift delay
is included as well.

__See also__: atime_det, check_pulseperiod_orbit_struct, pulseperiod

----

#### atime_dataind
##### Synopsis
 returns the datasets, which contain arrival times

##### Usage
```c
 Integer_Type[] atime_dataind();
```

##### Description

Loops over all defined datasets and checks, which
are containing arrival times. Therefore the function
'atime_metavalid' is used. If no dataset is found,
the function returns NULL.

__See also__: atime_metavalid, define_atime

----

#### atime_det
##### Synopsis
 Determines the arrival times from a lightcurve using a pulse pattern

##### Usage
```c
 Struct_Type atime_det(Struct_Type lc, Struct_Type[] pattern, Double_Type t0, Struct_Type ephemeris[, Struct_Type orbit]);
or Struct_Type atime_det(String_Type lc, Struct_Type[] pattern, Double_Type t0, Double_Type[] period[, Struct_Type orbit]);
```

##### Qualifiers

* time: name of the time field in the FITS-file,
see fits_read_lc for details
* indiv: determine individual pulses. If no value
is assigned, all arrival times are re-
turned. Otherwise a given integer sets
the number of pulses to average
* movem: if 'indiv' is greater one, so it is averaged
over a number of arrival times, a
moving mean is used to get all individual
pulses. Note that the pulses are then not
statistically independent!
* ccfint: interpolates the cross correlation of the
pulse pattern and the actual analyzed
pulse to increase the accuracy. Only works
well for clear signals! The number of
interpolated bins between each original
bin is set to the assigned number
(default = 4)
* varerr: estimates the error by a local standard
deviation. Therefore the variation of the
given number of arrival times is used
(default = 10)
* mcerr: estimates the error of each arrival time
by performing Monte Carlo simulations. If
an integer is assigned it sets the number
of runs (default = 10000). Has a higher
priority than 'varerr'
* mcgaus: fit a gaussian to the Monte Carlo distri-
bution, if used for error estimation
* getpat: if multiple patterns are given, the index
of the used one is stored in this variable,
which has to be given as a reference (@var)
* match: reference to a variable (&var) where the
matching pulses are saved as structures
similar to the reference profile
* ccflim: matches below the given cross-correlation
values are skipped (default = 0), allowed
range is -1 to 1.
* chatty: boolean value for output messages
(default = 1). If set to 2, also echo
result of Monte Carlo error estimation
* debug: plot the cross correlation and the matching
pulse, echo the found phase shift and
sleep the given seconds (default = 1) or,
if set to 'user' wait until a key is
pressed

##### Description

Using one or more pulse pattern the arrival times
of pulses in a lightcurve are determined using
phase connection. The pattern must be given as a
structure with the fields
Double_Type bin_lo
Double Type bin_hi
Double_Type value
Double_Type error,
as, for example, returned by the 'epfold' function.
The lightcurve can be passed by a structure with
the fields 'time', 'rate', 'error' and 'fracexp',
or by the filename to a FITS-file.
To transform the phase shift to time, the pulse
period at the actual position in the lightcurve is
needed. For a first guess this may be a constant
value (in seconds) or an array of two elements
defining a range of periods (min/max values, in
seconds). In the latter case the pulse period is
searched by using the 'getVarPeriod' function and
additional qualifiers are passed. However, the
correct way is to pass the pulse ephemeris and
additional orbital parameters to calculate the
pulse poriod more precisely. The corresponding
structures are described in the 'check_pulseperiod_orbit_struct'
function. The values may be found by a fit to the
arrival times using a constant pulse period. This
leads to slightly different results, hence the
determination of the arrival times and their
analysis is an iterative procedure.
If the 'indiv' qualifier is omitted the given
lightcurve is folded and the returned arrival
time corresponds to the phase shift of the given
pattern to the resulting profile.
If the method for estimating the uncertainty of
the arrival times is not specified by qualifiers,
the default uncertainty is set to one phase bin.
The number of bins are derived from the given
pulse pattern.
The returned structure has the following fields:
arrtimes - array of determined arrival times (MJD)
error    - their uncertainties (days)
arrnum   - relative pulse number of each arrival
time to a specific pulse. Dramatically
increases the speed of a fit.
numref   - index of the reference pulse, should be
zero. Is updated if arrival times are
merged.
reft0    - the given reference time t0

__See also__: atime_merge, save_atime, define_atime, arrtimes, pfold

----

#### atime_det_beta
##### Synopsis
 Determines the arrival times from a lightcurve using a pulse pattern

##### Usage
```c
 Struct_Type atime_det_beta(Struct_Type lc, Struct_Type[] pattern, Double_Type t0[, Double_Type period]);
or Struct_Type atime_det_beta(String_Type lc, Struct_Type[] pattern, Double_Type t0[, Double_Type period]);
```

##### Qualifiers

* time: name of the time field in the FITS-file,
see fits_read_lc for details
* indiv: determine individual pulses. If no value
is assigned, all arrival times are re-
turned. Otherwise a given integer sets
the number of pulses to average
* movem: if 'indiv' is greater one, so it is aver-
aged over a number of arrival times, a
moving mean is used to get all individual
pulses. Note that the pulses are then not
statistically independent!
* ccfint: interpolates the cross correlation of the
pulse pattern and the actual analyzed
pulse to increase the accuracy. Only works
well for clear signals! The number of
interpolated bins between each original
bin is set to the assigned number
(default = 4)
* varerr: estimates the error by a local standard
deviation. Therefore the variation of the
given number of arrival times is used
(default = 10)
* mcerr: estimates the error of each arrival time
by performing Monte Carlo simulations. If
an integer is assigned it sets the number
of runs (default = 10000). Has a higher
priority than 'varerr'
* mcgaus: fit a gaussian to the Monte Carlo distribution, if
used for error estimation
* ccflim: matches below the given cross-correlation
values are skipped (default = 0), allowed
range is -1 to 1.
* numdif: maximum allowed deviation from expected
pulse number (default = 0.5 phases)
* match: reference to a variable (&var) where the
matching pulses are saved as structures
similar to the reference profile
* slope: reference to a variable (&var) where the
slope of the lightcurve is saved, which
is calculated by an interpolation of
the mean count rate in the single pulses
* skipsl: do not take the slope of the lightcurve
into account
* mmnorm: by default the pulse pattern and the
pulses are renormalized by
f = (f - mean(f)) / sdev(f)
If this qualifier is set, the min/max-
normalizaton is used instead
f = (f - max(f)) / (max(f) - min(f))
* chatty: boolean value for output messages
(default = 1). If set to 2, also echo
result of Monte Carlo error estimation
* debug: plot the cross correlation and the matching
pulse, echo the found phase shift and
sleep the given seconds (default = 1) or,
if set to 'user' wait until a key is
pressed

##### Description

Using one or more pulse pattern the arrival times
of pulses in a lightcurve are determined using
phase connection. The patterns must be given as a
structure with the fields
Double_Type bin_lo
Double Type bin_hi
Double_Type value
Double_Type error,
as, for example, returned by the 'epfold' function.
If multiple patterns are given, the best matching
one is used to determine the arrival times.
The lightcurve can be passed by a structure with
the fields 'time', 'rate', 'error' and 'fracexp',
or by the filename to a FITS-file.
To determine individual pulses as enabled by the
'indiv' qualifier an approximate pulse period must
be given (in seconds) to cut the lightcurve into
segments were the pulses are searches. Instead of
the pulse period an array of two elements defining
a range of periods (min/max values, in seconds)
may also be given. In that case the 'getVarPeriod'
function is used to determine the pulse period and
additional qualifiers are passed.
If the 'indiv' qualifier is omitted the given
lightcurve is folded and the returned phase shift
corresponds to the phase shift of the used pattern
to the resulting profile.
If the method for estimating the uncertainty of
the phase shifts is not specified by qualifiers,
the default uncertainty is set to one phase bin.
The number of bins are derived from the given
pulse pattern.
The returned structure has the following fields:
t0       - array of first time bins of the pulses
determined from the lightcurve (MJD)
phi      - array of phase shifts of the pulses
with respect to the used pattern
error    - uncertainties of 'phi'
arrnum   - relative pulse number of each arrival
time to a specific pulse. Dramatically
increases the speed of a fit.
numref   - index of the reference pulse, should be
zero. Is updated if arrival times are
merged.
reft0    - the given reference time t0
p0       - the given pulse period
usedpat  - index of the used pulse pattern in case
of multiple ones given
The arrival times can be calculated by
t = t0 + phi \* p0
as a first guess, since p0 is a function of time.
This fact is handled properly by the fit function
'arrtimes'. The function 'atime_calc' calculates
the arrival times according to the above equation
with respect to a given pulse ephemeris and
orbital  parameters.

__See also__: atime_calc, atime_merge, save_atime, define_atime, arrtimes, pfold

----

#### atime_get_ephemeris
##### Synopsis
 retrieves the actual model parameters of a given
dataset of pulse arrival times

##### Usage
```c
 (Struct_Type, Struct_Type) atime_get_ephemeris(Integer_Type idx);
```

##### Description

Returnes two structures containing the model parameters
of a dataset, which contains pulse arrival times. The
first structure describes the pulse ephemeris:
ppuls  - pulse period (s)
pdot   - first derivative (s/s)
p2dot  - second derivative (s/s^2)
p3dot  - third derivative (s/s^3)
tpuls0 - reference time (MJD)
The orbital parameters are stored in the second
structure:
porb   - orbital period (d)
torb0  - time of periastron passage (MJD)
asini  - projected semi major axis (lts)
ecc    - eccentricity
omega  - angle of periastron (degrees)
If porb or asini is zero, the returned orbital
structure will be set to NULL.

__See also__: arrtimes, check_pulseperiod_orbit_struct

----

#### atime_get_t0
##### Synopsis
 returns the reference time of the arrival times

##### Usage
```c
 Double_Type atime_get_t0(Integer_Type[] dataid);
```

##### Description

This function returns the emitting time of the pulse
of number 0 as used in the polynomial to calculate
pulse arrival times.

__See also__: arrtimes, pulse_time

----

#### atime_load_ephemeris
##### Synopsis
 returns previously ssaved pulse ephemeris and orbital parameters

##### Usage
```c
 atime_load_ephemeris(Integer_Type idx, String_Type filename);
or (Struct_Type, Struct_Type) atime_load_ephemeris(String_Type filename);
```

##### Description

The pulse ephemeris and orbital parameters, which
have been previously saved by using the function
'atime_save_ephemeris', are either assigned to the
given dataset 'idx' or returned as structures.
The first one defines the pulse ephemeris and the
second one the orbit.
The following commands are equal:
(eph, orb) = atime_load_ephemeris(filename);
(eph, orb, ) = evalfile(filename);

__See also__: atime_save_ephemeris, atime_get_ephemeris, evalfile

----

#### atime_merge
##### Synopsis
 merges two or more structures of arrival times into one

##### Usage
```c
 Struct_Type atime_merge(Struct_Type atime1, Struct_Type atime2);
or Struct_Type atime_merge(Struct_Type[] atime);
```

##### Qualifiers

* nosort: do not sort the merged arrival times

##### Description

Either both given structures or an array of
structures containing arrival times are merged.
The fields of the structures must be equal to
the ones described in 'atime_det'.
The relative pulse numbers and their references
are updated to the indices of the new array of
arrival times. In addition the arrival times are
sorted by time unless the 'nosort' qualifier is
given.

__See also__: atime_det

----

#### atime_merge_beta
##### Synopsis
 merges two or more structures of arrival times into one

##### Usage
```c
 Struct_Type atime_merge(Struct_Type atime1, Struct_Type atime2);
or Struct_Type atime_merge(Struct_Type[] atime);
```

##### Qualifiers

* nosort: do not sort the merged arrival times

##### Description

Either both given structures or an array of
structures containing arrival times are merged.
The fields of the structures must be equal to
the ones described in 'atime_det'.
The relative pulse numbers and their references
are updated to the indices of the new array of
arrival times. In addition the arrival times are
sorted by time unless the 'nosort' qualifier is
given.

__See also__: atime_det

----

#### atime_metavalid
##### Synopsis
 checks if a given dataset of arrival times contains valid metadata

##### Usage
```c
 Integer_Type[] atime_metavalid(Integer_Type index);
```

##### Description

If a dataset of arrival times is defined using the
'define_atime' function, there are also a lot of
addiotional needed informations defined in the
metadata. These are used by fitting the data by the
'arrtimes' fit function. This function can be used
to find all defined data containing arrival times,
which is implemented in 'atime_dataind'.

__See also__: define_atime, arrtimes, get_dataset_metadata, atime_dataind

----

#### atime_save_ephemeris
##### Synopsis
 saves pulse ephemeris and orbital parameters into as an S-lang script

##### Usage
```c
 atime_save_ephemeris(Integer_Type idx, String_Type filename);
or atime_save_ephemeris(Struct_Type eph[, Struct_Type orb], String_Type filename)
```

##### Description

The fitted pulse ephemeris and orbital paramters
of the given dataset or the structures themself
are saved into a file. This file is an S-lang
script and can be called directly or loaded by
using 'atime_load_ephemeris'.

__See also__: atime_load_ephemeris, atime_get_ephemeris

----

#### atime_set_ephemeris
##### Synopsis
 sets the actual model parameters of a given
dataset of pulse arrival times

##### Usage
```c
 atime_set_ephemeris(Integer_Type[] idx, Struct_Type eph[, Struct_Type orb]);
```

```
or

```c
 atime_set_ephemeris(Integer_Type[] idx, Double_Type eph[, Struct_Type orb]);
##### Qualifiers

* sett0: also set the reference time of the pulse
ephemeris, which is used internally

##### Description

The given structure(s) containing the pulse ephemeris
and the orbital parameters are used to set the model
parameters of dataset 'idx'. Instead of the pulse
ephemeris the pulse period may be given only. Other-
wise the structure has to contain:
ppuls  - pulse period (s)
pdot   - first derivative (s/s)
p2dot  - second derivative (s/s^2)
p3dot  - third derivative (s/s^3)
tpuls0 - reference time (MJD)
The orbital parameters are stored in the second
structure:
porb   - orbital period (d)
torb0  - time of periastron passage (MJD)
asini  - projected semi major axis (lts)
ecc    - eccentricity
omega  - angle of periastron (degrees)
By default the reference time of the pulse ephemeris
is NOT set, because this should be fixed and set to
the same time as used for the pulse pattern. This
time therefore defines the arrival time of the pulse
of number n=0. Only change this time if you know what
effects will result (see arrtimes function)!

__See also__: arrtimes, atime_get_ephemeris

----

#### atime_shiftref
##### Synopsis
 switches the shift of the reference pulse number

##### Usage
```c
 atime_shiftref(Integer_Type[] dataid[, Integer_Type boolean]);
```

##### Description

While fitting pulse arrival times a reference pulse
number may be used. The reference pulse is the
first one of the dataset, but while fitting it is
by default shifted to the pulse nearest to the
fixed reference time 'tpuls0' of the pulse ephe-
meris. With this function this shift can be turned
off (boolean=0) or on (boolean=1, default).

__See also__: arrtimes, atime_useref, atime_det

----

#### atime_sim
##### Synopsis
 simulates pulse arrival times

##### Usage
```c
 Struct_Type atime_sim([Integer_Type n,] Double_Type tmin, tmax, Struct_Type eph[, orb]);
```

##### Qualifiers

* scramble: 1 sigma noise of the simulated arrival
times in seconds (default = 0)
* dn: the increment of the arrival times if
they are not randomly generated
(default = 1)

##### Description

Simulates the orbit and the pulsation of a pulsar
and returns the pulse arrival times in the time
range given by 'tmin' and 'tmax'. If the number
of arrival times 'n' is given, then n randomly
selected arrival times are returned. The returned
structure is equal to the atime_det function.
The uncertainties of the simulated arrival times
are calculated using the 'scramble' value. If no
value is given, the uncertainties are set to 0.1%
of the pulse period to avoid ISIS from treating
the arrival times as counts, resulting in poisson
errors.
The structures describing the pulse ephemeris and
the orbit must fullfil the conditions described
in the function check_pulseperiod_orbit_struct.

NOTE
Due to speed reasons the returned arrival times
might be beyond the given time interval or not
all pulses in this interval are returned.

__See also__: atime_det, check_pulseperiod_orbit_struct, arrtimes

----

#### atime_sim_orbitimpact
##### Synopsis
 determines the impact of uncertainties of orbital
parameters on the pulse ephemeris

##### Usage
```c
 atime_sim_orbitimpact(Double_Type tmin, tmax, Struct_Type eph, orb, dorb);
```

##### Qualifiers

* tpd: number of simulated arrival times per day
(default: 10)
* pars: parameters of the pulse ephemeris which
are used to fit the simulated data
(default: ["ppuls", "pdot", "p2dot",
"p3dot"])
* range: allowed fitting ranges of the parameters
given by the 'pars' qualifier in accordant
units. The ranges have to be given as an
array of alternate min/max values for each
parameter in 'pars'

##### Description

An uncertainty of an orbital parameter may lead
to a wrong pulse ephemeris after a successful
fit of pulse arrival times. This function deter-
mines the impact of uncertainties on the pulse
ephemeris by simulating arrival times in the
range 'tmin' and 'tmax' and fitting them within
the given orbital uncertainties. The returned
structure itself contains structures for each
orbital parameter, which contain the fitted
pulse ephemeris and therefore the impact of this
parameter. The highest phase shift left in the
residuals is also returned for each orbital
parameter.
The given orbital and pulse ephemeris structure
must fullfil the conditions described in the
check_pulseperiod_orbit_struct function. The uncertainties of
the parameters are itself given by a structure,
which may either contain double types for the
errors or arrays with two elements for the lower
and upper errors.

__See also__: atime_sim, check_pulseperiod_orbit_struct, arrtimes

----

#### atime_sim_residuals
##### Synopsis
 simulates arrival times to calculate how the
residuals depend on parameter variations

##### Usage
```c
 atime_sim_residuals(Double_Type tmin, tmax, Struct_Type eph, orb, String_Type psfile);
```

##### Qualifiers

* n: number of variations for each parameter
and sign (-> 2\*n variatons, default: 3)
* tpd: number of simulated arrival times per day
(default: 10)
* mres: maximum allowed residuals (=yrange) in
units of pulse phase (default: 0.45),
must be in the range of 0.0-0.45
* minr: smallest allowed relative variation of a
parameter, used to determine the overall
variation of this parameter to produce
nice plots (default: 1e-10)
* pars: only simulate this given parameters
(default: all except tpuls0 and pporb)

##### Description

This function determines the dependency of the
residuals on the given orbit and pulse ephemeris.
Therefore pulse arrival times are simulated and
the fit parameters are variied in the way, that
the shape of the resulting residuals can be seen
well. The resulting plots are stored in a Post-
Script file specified by the filename 'psfile'.
The labels show the absolute variation of the
the parameter.
The simulated times will be in the range of
'tmin' to 'tmax' (in MJD). The orbital parameter
and the pulse ephemeris structure must be in the
same form described in the function
check_pulseperiod_orbit_struct.

__See also__: atime_sim, check_pulseperiod_orbit_struct, arrtimes

----

#### atime_useref
##### Synopsis
 switches the use of a reference pulse number

##### Usage
```c
 atime_useref(Integer_Type[] dataid[, Integer_Type boolean]);
```

##### Description

While fitting pulse arrival times the pulse number
of each pulse must be determined. By using the
atime_det function to determine the arrival times
each pulse gets a pulse number relative to the
first pulse found in the input lightcurve. Once
the pulse number of this reference pulse is deter-
mined during a fit, the numbers of all other pulses
are also set. Using this function the use of rela-
tive pulse numbers during a fit can be turned off
(boolean=0) or on (boolean=1, default).

__See also__: arrtimes, atime_det, atime_shiftref

----

#### atime_xinclude
##### Synopsis
 Specifies the datasets, which should be taken into account in the fit

##### Usage
```c
 atime_xinclude(Integer_Type[] index);
```

##### Description

During the fit only the given datasets containing
arrival times are taken into account. The remain-
ing ones are noticed such that no bins are used.
Hence the fit function and parameters are not
affected by changed dataset indices.

__See also__: xnotice_atime, define_atime

----

#### atom_name
##### Synopsis
 DEPRECATED

##### Usage
```c
 String_Type atom_name(Integer_Type Z)
```

##### Description

This function returns the symbol for atoms with proton number Z.
This function is DEPRECATED, please use element_symbol.

__See also__: element_symbol

----

#### attitude_lissajous_pattern
##### Synopsis
 creates an Attitude File for a Lissajous pattern

##### Usage
```c
 attitude_lissajous_pattern(prefix,expos,ra,dec)
```

----

#### AVLTree
##### Synopsis
 Creates a new balanced binary search tree

##### Usage
```c
 Struct_Type=AVLTree();
```

```
or

```c
 Struct_Type=AVLTree(cmpfunction);
##### Description

A binary search tree is an object that permits fast
searches and ordered operations on ordinal data types (i.e.,
data that can be sorted).

An AVLTree is a balanced binary search tree, that is, a search
tree with a structure that ensures that searches will always
be close to O(log(N)), where N is the number of elements in the
tree.

The interface of AVLTree is identical to that of BinarySearchTree,
see there for a description of the member functions.

__See also__: BinarySearchTree

----

#### AzEl_from_RAdec
##### Synopsis
 computes horizontal (azimut, elevation) coordinates from a point's (RA, dec) at a time MJD

##### Usage
```c
 (az, el) = AzEl_from_RAdec(RA, dec, MJD,  longw, lat);
```

##### Description

This function is deprecated. Please use equatorial2horizon instead.

__See also__: equatorial2horizon,horizon2equatorial

----

#### backshift
##### Synopsis
 determines the shift of an array to a reference one

##### Usage
```c
 Struct_Type backshift(Double_Type[] in, Double_Type[] ref[, Double_Type[] error]);
```

```
or

```c
 Double_Type[] backshift(Double_Type[] in, Double_Type[] ref[, Double_Type[] error]; retarr);
##### Qualifiers

* retarr: function returns the unshifted array instead
of the structure defined below

##### Description

The function 'shift' rotates an array by a given number
of indices. The function described here tries to get
this number back: an input array 'in' is assumed to be
a shifted version of the reference array 'ref'. The
shift is then determined by using the fit-function
'unshift', also taking optional 'error's into acocunt.
The returned structure, if the 'retarr'-qualifier is
not set, is defined as follows:
shift         - shift in number of indices
shift_conf    - its [lower, upper] confidence limits
relative      - relative shift between 0 and 1
relative_conf - its [lower, upper] confidence limits
redChiSqr     - reduced chi-square value of the fit

__See also__: unshift, shift_intpol, shift

----

#### barycen
##### Synopsis
 barycenter an event list, FITS extension, or FITS file

##### Usage
```c
 barytime=barycen(eventlist);
```

```
or

```c
 barycen(String_Type fitsfile);
```
or

```c
 barycen(FITS_File_Type fptr);
##### Qualifiers

* debug: if set, print debugging information
* ephemeris: pointer to or name of a FITS ephemeris file (default: DE430)
* orbit: mandatory, structure containing the orbit information, in
geocentric ICRS coordinates and velocities in tags
x,y,z,vx,vy,vz in units of m and m/s, and time in tag mjd
* deltat: if set and the routine barycenters an event list or times, return the
difference between the barycentered time and the normal time
* ra: right ascension (ICRS) of the source [rad]
* dec: declination (ICRS) of the source [rad]
* deg: if set, ra/dec are in degrees

##### Description

This routine barycenters an event list, a FITS extension that is compatible
with this routine, or all FITS extensions in a FITS file that are compatible
with this routine.

Caveat emptor: Right now the function assumes that all times are in TT and
coordinates are in the ICRS system, i.e., it does not know that certain
JPL ephemerides are NOT in this coordinate system.

__See also__: jpl_eph

----

#### bayesian_blocks
##### Synopsis
 find bayesian blocks in the given data

##### Usage
```c
 Struct_Type bayesian_blocks(Struct_Type[] data);
```

##### Qualifiers

* fp_rate: value of the false positive rate, which is
the probability that a found change point
with the current value of ncp_prior is
actually not significant (default: .01)
WARNING: This has no influence on data of
type 3, where the default ncp_prior, fp_rate
is 0.05, and it is not possible to change this
currently.
* ncp_prior: controls the tolerance level used to find
the change points. The value has to be an
array of estimates for the order of number
of blocks for each given dataset. The
probability P that the final number of
blocks N_blocks is then given by
log(P) ~ ncp_prior \* N_blocks
Thus, ncp_prior has to be decreased to
increase the final number of blocks.
The default value is determined by a
formula derived from simulations, given by
ncp_prior = 4 - log(73.53\*fp_rate\*N^-0.478)
for data modes 1 and 2 and
ncp_prior = 1.32 + 0.577\*log(N)
for data mode 3, where N is the number of
data points.
* do_iter: number of iterations on ncp_prior
(default: 0)
* dt_min: events within the given time range are
considered to be simultaneous and a new
combined event at the average time is added
(default: 0)
* num_skip: maximal number of consecutive simultaneous
events (time difference < dt_min)
* gti: structure containing the GTIs for the given
events (data mode 1) with the fields 'start'
and 'stop'. The blocks are searched for each
GTI individually, thus the function returns
an array structures! If GTIs are given only
ONE input dataset is allowed (at the moment).
* gti_mindt: all GTIs shorter than the given duration are
ignored (i.e. no blocks are searched)
(default: 0)

##### Description

This function is an S-lang implementation of the
'find_blocks_mult' MatLab-program described in
Scargle et al., 2013, ApJ 764, 167
which source code is available on the arXiv.

WARNING: The full functionality has not been tested
yet, thus please use with caution!

Depending on the fields of the input 'data' structure,
the best Bayesian block representation is determined.
The available data modes are:
1: Event data
Double_Type[] tt        - time tags of events
2: Binned data (data without specific uncertainties,
e.g., counts vs. time)
Double_Type[] tt        - time tags
Double_Type[] nn_vec    - binned data at tt
WARNING! Mode 2 possibly has bugs! Use with extreme caution!
3: Point measurements (data with known uncertainties,
e.g., radio flux vs. time)
Double_Type[] tt        - time tags
List_Type[]   cell_data - cell data at tt defined as
{ Double_Type[] data, uncertainties }

The output structure contains
change_points - time INDICES of the change points
tt_all        - combined time tags of all datasets
ncp_prior_vec - ncp_prior value of each dataset
data_matrix   - see Fig. 2 of Scargle et al. 2013
last          - index of the last change point
over tt_all
best          - fitness (=statistics) over tt_all
index_vec     - dataset index over tt_all
data_mode_vec - data mode of each dataset

The algorithm can handle multiple datasets, which are
combined internally to one dataset (tt_all). Zero
blocks are handled as well.

NOTE: in case of events (data mode 1) it is important
to provide the GTIs via the corresponing qualifier
as well. Otherwise the block statistics are
probably wrong and thus the total block
represenation!

To finally retrieve the block represenatation of the
input data, the 'get_blocks_data' function can be used.

__See also__: get_blocks_data

----

#### bayesian_blocks_cperror
##### Synopsis
 calculates the probability distribution
of the change point positions

##### Usage
```c
 Struct_Type[] bayesian_blocks(Struct_Type blocks);
```

##### Description

After
Scargle et al., 2013, ApJ 764, 167
the uncertainty of the position of a change point in
a bayesian block representation can be estimated by
calculating the fitness of a block with variing
change point position, while all other change points
are kept fix. Although inter-change-point dependencies
are neglected in this approach, it can be used to
derive proper uncertainties as long as the resulting
distributions do not overlap.

This function is an implementation of this procedure
based on the MatLab-programs 'figure_cp_error' and
'cp_prob' by the authors above.

The input 'blocks' have to be calculated previously
by the 'bayesian_blocks' function. The returned
structure array contains the probability distribution
'prob' (integral = 1.) over the time-tags 'tt' for
each change point (i.e., the array index corresponds
to the change point index). From each individual
distribution an uncertainty for the location of the
change point can be estimated via, e.g., its width.

__See also__: bayesian_blocks

----

#### bbootstrap
##### Synopsis
 1-parameter bootstrap calculation of function 'funct'

##### Usage
```c
 Array_Type bbootstrap(Array_Type data, Integer_Type num_samp
[, funct = &mean, datatype = Double_Type]);
```

##### Qualifiers

* slow: the balanced bootstrap is performed. This is
more accurate, especially for long-tailed
distributions, but is also much slower and
requires more memory.

##### Description

This function has been ported from the IDL-routine
bbootstrap.pro by H.T. Freudenreich, HSTX, 2/95

This program randomly selects values to fill sets of
the same size as 'data'. Then calculates the 'funct'
of each, which is an optional function reference with
the &mean as default. It does this 'num_samp' times.
The 'datatype' returned by 'funct' has to be provided
to initialize the array returned by this function.
If the slow-qualifier is set, the balanced bootstrap
method is used to obtain the samples, hence the name
'bbootstrap'. This method requires, however, more
virtual memory, and patience.

The user should choose 'num_samp' large enough to get
a good distribution. The sigma of that distribution
is then the standard deviation of the mean of the
returned 'funct'-vector.
For example, if input 'data' is normally distributed
with a standard deviation of 1.0, the standard
deviation of the returned 'funct'-vector (by default
the mean) will be ~1.0/sqrt(N-1), where N is the
number of values in 'data'.

WARNING: at least 5 points must be input.
The more, the better.

----

#### behr
##### Synopsis
 calculates fractional difference hardness ratio thorugh bayesian estimation

##### Usage
```c
 Double_Type (HR , HR_err_max , HR_err_min) =  behr(Double_Type soft_count, Double_Type hard_count);
```

##### Qualifiers

* scale_s: Scaling factor for soft_count;  soft_count = scale_s\*soft_count  (default = 1)
* scale_h: Scaling factor for hard_count;  hard_count = scale_h\*hard_count  (default = 1)
* back_s: background counts in the soft band
* back_h: background counts in the hard band
* bkg_scale_s: Scaling factor for source background to observed background counts in the soft band.
Expected background in source region is ~ back_s/bkg_scale_s.
* bkg_scale_h: Scaling factor for source background to observed background counts in the hard band.
Expected background in source region is ~ back_h/bkg_scale_h.
* aprox_n: = run aproximation which keeps powers of bkg_scale_h^i\*bkg_scale_s^j, with i+j <= n
* significance: significance of calculated uncertainties in percent (default = 68 per cent)
* fulloutput: if present function will additionally return the Grid used (2000 color values ranging from -0.999 to 0.999), and the
normalized probability distribution

##### Description

This function gives a bayesian estimation for the so-called fractional difference hardness ratio according to (H-S)/(H+S),
assuming that soft_count and hard_count are the \*intrinsic\* counts.
Optionally, scaling factors for the indiviudal channels can be set.
If given, background counts are taken into account presuming a separate measurement of a Poisson background.
If the background counts are given a scaling factor for the source background has to be provided as well.
An approximative approach can be used as well, by only keeping up to the n-th power in the expansion in terms of
the scaling factor of the source background.

The hardness ratio estimation and the respecitive uncertainties are returned by default.
Use qualifier if also the grid used (2000 color values ranging from -0.999 to 0.999), and the
normalized probability distribution are desired.

Based on Park et al., 2006, ApJ, 652, 610. Based on original isis-code by Mike Nowak.

__See also__: hardnessratio;

----

#### bezier
##### Synopsis
 calulates a Bezier curve from given supporting points

##### Usage
```c
 Vector_Type bez = bezier(List_Type points, Integer_Type nbins);

```

##### Description

Bezier calculates the Bezier curve between the first and last
[x,y] entry of 'points', using the other entries of 'points' as
supporting points. 'points' must be a List_Type, with each
element containing the [x,y] values of the corresponding point.
'nbins' gives the numbers of points used to calculate each part
of the curve, as well as the length of the returned curve.

##### Qualifiers

* allbez: if set, all intermediate Bezier curves are
returned as a List, containing all the Vector_Type Bezier curves.
* conline: if set, the initial lines connecting the
points are also returned, i.e., the return value becomes (Vector_Type
conlines, Vector_Type bez).

__See also__: xfig_plot_allbezier, bezNp

----

#### bezNp
##### Synopsis
 calulates a Bezier curve between vectors

##### Usage
```c
 Vector_Type bez = bezNp(Vector_Type vectors);

```

##### Description

The Bezier curve between each pair of the arrays in 'vectors'
will be calculated. The 'vectors' arrays needs to be at least two
entries.
Returned value 'bez' will be one entry shorter than 'vectors'.
Main working horse for the bezier function.

__See also__: bezier

----

#### bgsubHEXTElc
##### Synopsis
 calculates a background subtracted HEXTE lightcurve

##### Usage
```c
 Struct_Type lc = bgsubHEXTElc(Struct_Type srclc, Struct_Type bglc);
```
or

```c
 Struct_Type lc = bgsubHEXTElc(Struct_Type srclc, Struct_Type bglc1, Struct_Type bglc2);

```

##### Description

HEXTE rocking -> Background is not measured simultaneously with source data.

----

#### BinaryCor
##### Synopsis
 Removes the influence of the doublestar motion for circular or eliptical orbits.

##### Usage
```c
 Array_Type t = BinaryCor(Array_Type OR Double_Type time), time in MJD
```

##### Qualifiers

* asini: Projected semi-major axis [lt-secs], Mandatory
* porb: Orbital period at the epoch [days], Mandatory
* eccentricity: Eccentricity, (0<=e<1)
* omega: Longitude of periastron [degrees], mandatory
* t0: epoch for mean longitude of 0 degrees (periastron, MJD)
* t90: epoch for mean longitude of 90 degrees (MJD)
* pporb: rate of change of the orbital period (s/s) (default 0)
* limit: absolute precision of the correction of the  computation (days, default: 1D-6)
* maxiter: stop Newton-Raphson iteration after maxiter steps if limit is not reached (default: 20)

##### Description

(transcribed from IDL-programm BinaryCor.pro)

For each time, the z-position of the emitting object is computed
and the time is adjusted accordingly. This is iterated until
convergence is reached (usually only one iteration is necessary,
even in high elliptic cases).

Follows equations from Hilditch's book and has also been
checked against fasebin/axBary. All codes give identical results,
(to better than 1d-7s) as checked by a Monte Carlo search using
1d7 different orbits.

qualifiers t90 and t0 have to be in days and in the same time
system as time (e.g. JD or MJD)

Circular orbits:
\* if time of lower conjunction Tlow is known, set
t0=Tlow and omega=0
\* if time of ascending node is known, Tasc, set
t90=Tasc and omega=0
\* if time of mid eclipse is known, Tecl, set
t0=Tecl-0.25\*porb and omega=0

----

#### binarydigits
##### Synopsis
 retrieves a number's dual representaion

##### Usage
```c
 String_Type binarydigits(Integer_Type x)
```

##### Qualifiers

* n: [<code>=16</code>] number of bits

----

#### BinaryPos
##### Synopsis
 computes the position of a star in a binary system

##### Usage
```c
 Double_Type[] BinaryPos(Double_Type[] time)
```

##### Qualifiers

* porb: Orbital period at the epoch [same units as time argument], mandatory
* eccentricity: Eccentricity, (0<=e<1)
* omega: Longitude of periastron [degrees], mandatory
* asini: Projected semi-major axis (a sin i), mandatory for spectroscopic binaries,
give it in light seconds (a sini/c) if you want to compute a time correction
* semi: semimajor axis, mandatory for visual binaries
* bigomega: Longitude of the ascending node [degrees], mandatory for visual binaries
* incl: inclination [degrees], mandatory for visual binaries
* t0: epoch for mean longitude of 0 degrees (periastron, MJD)
* t90: epoch for mean longitude of 90 degrees (MJD)
* pporb: rate of change of the orbital period (s/s) (default 0)

##### Description

(transcribed from IDL-programm BinaryPos.pro)

For spectroscopic binaries, the z-position of the emitting object
is computed (negative: closer to Earth). In case of visual binaries
the output is a 3d array containing the xyz position of the object
in a right handed coordinate system where the z axis points away from
Earth, the x axis points towards the North Celestial Pole, and where
the y-axis increases towards East.

Follows equations from Hilditch's book.

Qualifiers t90 and t0 have to be in days and in the same time
system as time (e.g. JD or MJD)

Circular orbits:
\* if time of lower conjunction Tlow is known, set
t0=Tlow and omega=0
\* if time of ascending node is known, Tasc, set
t90=Tasc and omega=0
\* if time of mid eclipse is known, Tecl, set
t0=Tecl-0.25\*porb and omega=0

----

#### BinarySearchTree
##### Synopsis
 Creates a new binary search tree

##### Usage
```c
 Struct_Type=BinarySearchTree();
```

```
or

```c
 Struct_Type=BinarySearchTree(cmpfunction);
##### Description

A binary search tree is an object that permits fast
searches and ordered operations on ordinal data types (i.e.,
data that can be sorted).

The tree consists of nodes which are structs containing
the data (or "key") in tag "data" and references to nodes with
keys with values less than data in child[0] and to keys with
values larger than data in child[1]. In general, users of the
data structure should not worry about the structure of the
nodes and use the functions described below for all tree
operations.

Searches in a binary search tree can be fast (O(log N)) if the
search tree is balanced, that is, if there is a similar number
of nodes below each node (if that makes sense...). This is typically
the case if random (unsorted) data are inserted into the tree, and
very much not the case if ordered data are inserted. In this case
the search degenerates to O(N). The isisscripts provide a special
binary search tree called AVLTree that has the same accessor functions
as BinarySearchTree but ensures that the tree is height-balanced (at some
small additional cost for key insertions and deletions).

The BinarySearchTree and the AVLTree provide the following functions:
insert(key) - insert a data element key into the binary search tree
delete(key) - remove a data element key from the binary search tree
exists(key) - return true if the search tree contains key
search(key) - return the node containing the key (or NULL if
they key does not exist)
min         - return the minimum key of the search tree (or a subtree), or
the node containing the minimum key if the node qualifier
is set.
max         - return the maximum key of the search tree (or a subtree), or
the node containing the maximum key if the node qualifier
is set.
successor   - return the successor node to a node (i.e., the node
containing the next largest data value in the tree).
predecessor - return the predecessor node to a node (i.e., the node
containing the next smaller data value in the tree).
print       - print the structure of the tree
traversal(&func;quals) - traverse the tree, i.e., execute func for all
keys of the tree. The function func is called with each
node N (i.e., the data are found in N.data) and all
qualifiers given to traversal. The order in which the
nodes are traversed is defined by the following qualifiers:
preorder: operate on the node, then on the left children,
then on the right children
postorder: operate first on the left children, then on the
right children, then on the node
inorder (the default): operate on the left children, then
on the node, then on the right children
Note that it is permitted that func modifies the tree (e.g.,
insert new elements, delete tree elements and so on; it is
best practice to use a qualifier that specifies the tree to
let func know about it). Depending on the traversal order
the modified elements may or may not be operated on as part
of the traversal.

The default setup of the binary search tree works on all data types
where the operators <, ==, and > have been defined. For other data
types, initialize the tree with a reference to a comparison function
of the style define key_compare(k1,k2) where k1 and k2 are of the
data type contained in the search tree and which returns a negative
number if k1<k2, 0 if k1==k2, and a positive number if k1>k2 (this
is the same definition as the one used by s-lang's sort function or
by the strcmp function).

##### Example

% sort some numbers
% (obviously a better way would be array_sort...)

define arrapp(N) {
% append key of N to list
variable list=qualifier("list");
list_append(list,N.data);
}

variable arr=[1,4,6,3,5,7,8,2,9];
variable t=BinarySearchTree();
variable i;
foreach i (arr) {
t.insert(i);
}

% print the tree
t.print();

% delete element with key 8
t.delete(8);

variable ll={};
t.traversal(&arrapp;list=ll);
foreach i (ll) {
print(i);
}
% print the minimum and maximum values
()=printf("min: %S - max: %S

",t.min(),t.max());

##### Example

% setup a tree for strings
variable arr=["A","X","D","B","C"];
variable t=AVLTree(&strcmp);
variable i;
foreach i (arr) {
t.insert(i);
}
t.print();

__See also__: AVLTree,sort

----

#### binary_search
##### Synopsis
 searches a value in a sorted list

##### Usage
```c
 Integer_Type ndx=binary_search(Array_Type arr, Data_Type val);
```

##### Qualifiers

* interval: do an interval search, return
ndx such that arr[ndx]<=val<add[ndx+1], or 0 if val<=arr[0] or
length(arr) if add[-1]<=val, see description.

##### Description

The function performs a binary search for the value val in the array
arr. All data types where the comparison operators work are allowed
(i.e., mainly all numerical types).

Values in arr MUST be unique and sorted. This is not checked.
The binary search is much faster than, e.g., a call to
where, since the where function is O(n), while binary_search
scales is O(lb(N)) where lb is the logarithm to base 2.

If no qualifiers are set, the function returns the index of the array
element if val is found. The function returns -1 if the value is not found.

If the interval qualifier is set, then the function will do an interval
search such that arr[ndx]<=value<arr[ndx]. The function will return
0 if value<=arr[0] and length(arr) if value>arr[-1]. This can be
used to search the index where one would insert a number into
an array.

----

#### bin_average
##### Synopsis
 computes averages in histogram bins

##### Usage
```c
 Struct_Type bin_average(phi, rate, phi_lo[, phi_hi])
```

##### Qualifiers

* err: error on rate
* quantiles: array of quantiles to calculate for the distribution
* quartiles: calculate the .25, .5 and .75 quantiles

##### Description

The fields of the returned structure are:

- <code>bin_lo</code> and <code>bin_hi</code>, defining the bins

- <code>value</code>: the average

- <code>err</code>: the standard error of the mean

- <code>n</code>: the number of points in each bin

and, if the <code>err</code> qualifier specifies an error array:

- <code>weighted_average</code>: an error-weighted average

----

#### bknpowerlaw_xyfit
##### Synopsis
 linear xy fit function to be used with xyfit_fun

##### Usage
```c
 xyfit_fun ("bknpowerlaw");
```

##### Description

This function is not meant to be called directly!

Calling <code>xyfit_fun ("bknpowerlaw");</code> sets up a powerlaw fit
function for xy-data. It has the form <code>y = norm\*x^{-index}</code>

__See also__: xyfit_fun, define_xydata, plot_xyfit, linear_regression

----

#### blocks_between_gaps
##### Synopsis
 retrieves blocks in an array whose elements may contain gaps

##### Usage
```c
 Integer_Type blocks[] = blocks_between_gaps(Double_Type a[], Double_Type gap);
```

##### Description

The array a has to contain monotonically increasing values.
The return value will be an integer array of the same length,
whose elements start with 0 and increase by 1 whenever the difference
of sequential elements of the array a is larger than gap.

__See also__: split_struct, split_lc_at_gaps

----

#### BoundingBox
##### Synopsis
 retrieves the Bounding Box of a postscript file

##### Usage
```c
 Double_Type (x1, y1, x2, y2) = BoundingBox(String_Type psfile);
```
or

```c
 Double_Type (w, h) = BoundingBox(String_Type psfile; size);

```

##### Description

<code>x1, y1, x2, y2</code> are the values from the last line in <code>psfile</code>
of the form <code>"%%BoundingBox: x1 y1 x2 y2"</code>.
<code>x1, y1, x2, y2</code> are <code>NULL</code> if no such line is found.
##### Qualifiers

* first: Take the first matching %%BoundingBox line instead of the last.
* size: If this qualifier is set, <code>w = x2-x1</code> and <code>h = y2-y1</code> are returned.

----

#### B_lambda
##### Synopsis
 Calculates the spectral density for black body radiation (wavelength space)

##### Usage
```c
 Double_Type Blambda = B_lambda(lambda,T);
```

##### Qualifiers

* keV: T argument is kT in keV
* A: Wavelength is given in Angstroms
* Angstrom: Wavelength is given in Angstroms

##### Description

This function returns the spectral energy density of a black body,
in units erg/cm^2/s/cm/sr
Either lambda or T can be an array.

----

#### B_nu
##### Synopsis
 Calculates the spectral density for black body radiation (frequency space)

##### Usage
```c
 Double_Type Bnu = B_nu(nu,T);
```

##### Qualifiers

* keV: 1st argument is energy in keV,
T argument is kT in keV
* MHz: Frequency is given in MHz
* GHz: Frequency is given in GHz

##### Description

This function returns the spectral energy density of a black body,
in units erg/cm^2/s/Hz/sr
Either nu or T can be an array.

----

#### cart2cyl
##### Synopsis
 Convert Cartesian to cylindrical coordinates

##### Usage
```c
 cart2cyl(Double_Types x[], y[], z[], vx[], vy[], vz[]);
```

##### Description

Convert Cartesian (x,y,z,vx,vy,vz) to cylindrical (r,phi,z,vr,vphi,vz)
coordinates with phi rotating counter-clockwise from the positive x-axis.
##### Example

(r,phi,z,vr,vphi,vz) = cart2cyl(1,1,1,2,3,4);
(r,phi,z,vr,vphi,vz) = cart2cyl([1,0],[1,0],[1,0],[2,0],[3,0],[4,0]);
(r,phi,z,vr,vphi,vz) = cart2cyl( cyl2cart(1,PI/2,1,2,3,4) );

__See also__: cart2sphere, cyl2cart

----

#### cart2sphere
##### Synopsis
 Convert Cartesian to spherical coordinates

##### Usage
```c
 cart2sphere(Double_Types x[], y[], z[], vx[], vy[], vz[]);
```

##### Description

Convert Cartesian (x,y,z,vx,vy,vz) to spherical (r,phi,theta,vr,vphi,vtheta)
coordinates with polar angle phi rotating counter-clockwise from the positive
x-axis and azimuth angle theta being zero for the positive z-axis.
##### Example

(r,phi,theta,vr,vphi,vtheta) = cart2sphere(0,0,0,1,2,3);
(r,phi,theta,vr,vphi,vtheta) = cart2sphere(0,0,1,1,2,3);
(r,phi,theta,vr,vphi,vtheta) = cart2sphere(1,1,1,3,3,3);
(r,phi,theta,vr,vphi,vtheta) = cart2sphere(1,0,0,0,2,1);
(r,phi,theta,vr,vphi,vtheta) = cart2sphere([0,1],[0,0],[0,0],[1,0],[2,2],[3,1]);

__See also__: cart2cyl

----

#### CCF_1d
##### Synopsis
 calculates the cross correlation function of two (1d) arrays

##### Usage
```c
 Double_Type CCF = CCF_1d(a1, a2, Integer_Type dx);
```
or

```c
 Array_Type CCF = CCF_1d(a1, a2);

```

##### Qualifiers

* notperiodic: arrays are not extended periodically.

##### Description

The arrays <code>a1</code> and <code>a2</code> have to have the same length <code>n</code>.
They can be passed directly or as references to arrays.

By default (unless the <code>notperiodic</code> qualifier is given), both arrays
are considered to be extended with periodic boundary conditions.
When using <code>notperiodic</code>, chose <code>|dx| < n-1</code>, since the larger <code>|dx|</code>,
the smaller are the parts of the arrays that can actually be compared.

This function computes the correlation of <code>a1[x]</code> and <code>a2[x-dx]</code>:
<code>CCF = sum_x { (a1[x]-<a1>)/|a1| \* (a2[x-dx]-<a2>)/|a2| }</code>
For periodic boundary conditions, the entire array is considered,
else the index <code>x</code> takes only values such that <code>x</code> and <code>x-dx</code> are contained.
The norm <code>|a| = sqrt{ sum_x a[x]^2 }</code> ensures that for any array <code>a</code>,
<code>CCF_1d(a, a, 0) = +1</code>   and   <code>CCF_1d(a, -a, 0) = -1</code>.

If only the two arrays <code>a1</code> and <code>a2</code> are given, the function returns
an array with all possible correlations between them, i.e.:
<code>[ CCF_1d(a1, a2, 0), CCF_1d(a1, a2, 1), ..., CCF_1d(a1, a2, n-1) ]</code>
This is most reasonable for periodic boundary conditions.
##### Notes

The function is vectorized on <code>dx</code>, i.e., can handle an array <code>dx</code>.
##### Example

variable a1 = Double_Type[n];  % some data
variable a2 = Double_Type[n];  % some other data

variable dx = [-n/2 : n/2];
variable CCF_np = CCF_1d(a1, a2, dx; notperiodic);

variable CCF_p = CCF_1d(a1, a2);  % This is equivalent to:
variable CCF_p = array_map(Double_Type, &CCF_1d, &a1, &a2, [0:n-1]);

__See also__: CCF_2d

----

#### CCF_2d
##### Synopsis
 calculates the cross correlation function of two 2d-arrays (e.g., images)

##### Usage
```c
 Double_Type CCF = CCF_2d(img1, img2, Integer_Type dx, Integer_Type dy);
```

##### Description

The 2d-arrays img1 and img2 from which the CCF is to be computed can
either be passed directly or by a reference to the arrays.
This function computes the correlation of <code>img1[y, x]</code> and <code>img2[y-dy, x-dx]</code>,
where the indices (x,y) take all values such that (x,y) and (x-dx,y-dy) are contained:
<code>CCF = sum_{x,y} { (img1[y,x]-<img1>)/|img1| \* (img2[y-dy,x-dx]-<img2>)/|img2| }</code>
The norm <code>|img| = sqrt{ sum_{x,y} img[y,x]^2 }</code> ensures that <code>CCF_2d(img, +-img, 0, 0) = +-1</code>.
for any image <code>img</code>.

If <code>dx</code> or <code>dy</code> are arrays, <code>CCF</code> will be a 2d array.
##### Qualifiers

* verbose: turns on verbosity
* savebest: =&best: if <code>dx</code> or <code>dy</code> are arrays, the best combination will be saved in <code>best</code>.

__See also__: CCF_1d

----

#### cel2gal
##### Synopsis
 Transform celestial to Cartesian Galactic coordinates

##### Usage
```c
 cel2gal(Double_Types ah[], am[], as[], dd[], dm[], ds[], dist[], vrad[], pma_cos_d[], pmd[]; qualifiers)
```

##### Description

Transform celestial coordinates (right ascension [h, m, s], declination [deg, arcmin, arcsec],
distance [kpc], radial velocity [km/s], proper motion in right ascension times cosine of declination
[mas/yr], proper motion in declination [mas/yr]) to right-handed, Cartesian Galactic coordinates
(x [kpc], y [kpc], z [kpc], vx [km/s], vy [km/s], vz [km/s]) with the Galactic center at the origin,
the Sun on the negative x-axis and the z-axis pointing to the north Galactic pole implying clockwise
Galactic rotation when seen from the half space with positive z. See function 'RD2rad' for detailed
information on how to properly enter right ascension and declination.
##### Qualifiers

* parallax: Set this qualifier to use parallaxes [mas] instead of distances [kpc].
* SunGCDist: Sun-Galactic center distance [kpc];
default: 8.4 (see Model I in Irrgang et al., 2013, A&A, 549, A137)
* vxs: Sun's x-velocity component [km/s] relative to the local standard of rest;
default: 11.1 (Schoenrich, Binney & Dehnen, 2010: MNRAS 403, 1829)
* vys: Sun's y-velocity component [km/s] relative to the local standard of rest;
default: 12.24 (Schoenrich, Binney & Dehnen, 2010: MNRAS 403, 1829)
* vzs: Sun's z-velocity component [km/s] relative to the local standard of rest;
default: 7.25 (Schoenrich, Binney & Dehnen, 2010: MNRAS 403, 1829)
* vlsr: Local standard of rest velocity [km/s];
default: 242 (see Model I in Irrgang et al., 2013, A&A, 549, A137)
* GC_NGP: Celestial coordinates of the Galactic center and the north Galactic pole in the
format [ah_GC, am_GC, as_GC, dd_GC, dm_GC, ds_GC, ah_NGP, am_NGP, as_NGP, dd_NGP, dm_NGP, ds_NGP];
default: [17, 45, 37.224, -28, 56, 10.23, 12, 51, 26.282, 27, 07, 42.01] (J2000, Reid & Brunthaler, 2004, ApJ, 616, 872)

##### Example

(x, y, z, vx, vy, vz) = cel2gal(0, 0, 0, 0, 0, 0, 0, 0, 0, 0);
% -> Sun's position and velocity
(x, y, z, vx, vy, vz) = cel2gal(17, 45, 37.224, -28, 56, 10.23, 8.4, -11.1, -3.171, -5.544);
% -> Galactic center's position and velocity
(x, y, z, vx, vy, vz) = cel2gal([0,17], [0,45], [0,37.224], [0,-28], [0,56], [0,10.23], [0,8.4], [0,-11.1], [0,-3.171], [0,-5.544]);
% -> position and velocity of Sun and Galactic center stored in the same array
(x, y, z, vx, vy, vz) = cel2gal(17, 45, 37.224, -28, 56, 10.23, 8.4, -11.1, -3.171, -5.544;
GC_NGP=[17, 45, 37.1991, -28, 56, 10.221, 12, 51, 26.2755, 27, 7, 41.704]);
% -> use non-standard coordinates for Galactic center and north Galactic pole
(x, y, z, vx, vy, vz) = cel2gal( gal2cel(0, 0, 0, 0, 0, 0) );
% compute vr and vphi:
vr = (x\*vx+y\*vy)/sqrt(x^2+y^2);
vphi = (y\*vx-x\*vy)/sqrt(x^2+y^2);

__See also__: RD2rad, gal2cel

----

#### cerf
##### Synopsis
 Complex error function

##### Usage
```c
 Complex_Type[] = cerf(Complex_Type[]);
```

##### Description

Compute complex error function. Only useful in a region
with abs(z)<10.

__See also__: Faddeeva, cerfc

----

#### cerfc
##### Synopsis
 Complex error function complement

##### Usage
```c
 Complex_Type[] = cerfc(Complex_Type[]);
```

##### Description

Compute complex error function complement. Only useful in a region
with abs(z)<10.

__See also__: Faddeeva, cerf

----

#### Chandra_display_mask
##### Synopsis
 shows the content of a Chandra mask file (msk1.fits)

##### Usage
```c
 Chandra_display_mask([String_Type filename]);
```

##### Description

<code>filename</code> can be a globbing expression.
If it is omitted, <code>acis\*msk1.fits\*</code> is assumed.

The mask file contains the valid part of the CCD,
i.e., the portion for which events can be telemetered.

----

#### change_plot_options
##### Synopsis
 changes the currently used plot options

##### Usage
```c
 Struct_Type change_plot_options([plot_opt]; [default,] opt=value, opt2=value2, ...);
```

##### Description

The current plot options will be used as a starting point unless
an explicit argument <code>plot_opt</code> is specified, which is used in this case.

These plot options are then modified by the <code>opt</code> qualifiers (<code>opt</code> can be
any fieldname of the structure returned by <code>get_plot_options</code>, i.e.,
<code>xmin</code>, <code>xmax</code>, <code>ymin</code>, <code>ymax</code>, <code>xlabel</code>, <code>ylabel</code>, <code>tlabel</code>, <code>xopt</code>, <code>yopt</code>, <code>logx</code>, <code>logy</code>,
<code>color</code>, <code>start_color</code>, <code>x_unit</code>, <code>line_style</code>, <code>start_line_style</code>, <code>line_width</code>,
<code>frame_line_width</code>, <code>point_style</code>, <code>connect_points</code>, <code>char_height</code>, <code>point_size</code>,
<code>ebar_term_length</code>, <code>use_errorbars</code>, <code>use_bin_density</code>,
<code>ovp_xmin</code>, <code>ovp_xmax</code>, <code>ovp_ymin</code>, <code>ovp_ymax</code>),
unless the qualifier <code>default</code> is specified. In this latter case,
default plot options are set regardless of the starting plot options
and the other qualifiers.

The return value is the <code>get_plot_options</code> structure before <code>change_plot_options</code>
was called. It can be used to reset the plot options after a change was applied.
##### Example

<code>variable plot_options = change_plot_options(; line_style=2);</code>

<code>plot(lineX, lineY);</code>

<code>set_plot_options(plot_options);</code>

__See also__: get_plot_options, set_plot_options

----

#### chebyshev_lagrange_weights
##### Synopsis
 Get Lagrange weights for the chebyshev_nodes

##### Usage
```c
 Double_Type[] chebyshev_lagrange_weights(Int_Type n);
```

##### Qualifiers

* second: if given, return weights of second order polynomal.

##### Description

Given an integer <code>n</code> this function returns the weights for the
barycentric Lagrange polynomial for nodes placed the the Chebyshev nodes.

In case the <code>second</code> qualifier is given, the second kind Chebyshev
polynomial defines the weights, else the first kind.

__See also__: chebyshev_nodes,lagrange_weights,lagrange_poly

----

#### chebyshev_nodes
##### Synopsis
 Get nodes of Chebyshev polynomial

##### Usage
```c
 Double_Type[] nodes = chebyshev_nodes(Int_Type n);
```

##### Qualifiers

* second: if given, return nodes of second order polynomal.
* min: [=-1] rescale to min
* max: [=1] rescale to max

##### Description

Given an integer <code>n</code> this function returns the nodes
of the Chebyshev polynomial of the first kind of order <code>n</code>.

Or, if the <code>second</code> qualifier is given, the corresponding nodes
of the second kind polynomial.

The nodes are distributed between -1 and 1 per default. If the <code>min</code>
and <code>max</code> qualifiers are given the nodes are rescaled accordingly.

__See also__: chebyshev_lagrange_weights

----

#### chebyshev_poly
##### Synopsis
 Returns the Chebyshev polynomial T(n,x) of the first kind of order n

##### Usage
```c
 Double_Type[] chebyshev_poly(Double_Type[] x, n)
```

##### Description

Evaluates the Chebyshev Polynomial of the first kind of order n
via the recurrence relation

T(0,x) = 1
T(1,x) = x
T(n,x) = 2\*x\*T(n-1,x) - T(n-2,x)
##### Example

x = [-1.:1.:#100];
chebyshev_poly(x,n); % returns 5th order Chebyshev polynomial evaluated
% on [-1,1)

__See also__: cheby_sum

----

#### cheby_sum
##### Synopsis
 Returns a weighted sum of Chebyshev polynomials up to a given order

##### Usage
```c
 Double_Type[] cheby_sum(Double_Type[] [a0,a1,...aN], Double_Type[] x)
```

##### Description

Return the value of the expression

a0\*T(0,x) + a1\*T(1,x) + a2\*T(2,x) + ... + aN\*T(N,x)

Where T are Chebyshev polynomials of the first kind of order 1...N.

This is array-safe in x and implemented to be much more efficient than
explicitly using multiple calls of chebyshev_poly()!
##### Example

x = [-1.:1.:#100];
cheby_sum(x,[0, 1., 2.]); % returns chebyshev_poly(x,1)
%    + 2.\*chebyshev_poly(x,2)
% on [-1,1)

__See also__: chebyshev_poly

----

#### checkrwlc [ff]
##### Usage
```c
 Struct_Type checkrwlc(time, value, error, bin_lo, bin_hi)
```
or

```c
 Struct_Type checkrwlc (time, value, bin_lo, bin_hi) % in which case resu.erro will be zero

```

##### Description

This script implements the alogrithm proposed by M. de Kool et al. (1993)
to check for random walk in a pulse period evolution.
In principle, everything containing time and value information
can be checked for random walk with this script (i.e. a lightcurve).
The output of the script is a structure containing the fields

- bin_lo = lower delta t bin

- bin_hi = upper delta t bin

- value  = delta omega value

- erro = uncertainties calculated from the given uncertainties of the values

- dist  = not normalized delta omega value

- len = normalization facotr for delta omega (value = dist/len)

Care should be taken that, when using for period evolution, the period and the
time array should be given in the same units.

The code might not be perfectly optimized
and is getting slow for large arrays of time and value (>500).

To estimate the true errors of the result, a Monte Carlo simulation should be used.
##### Qualifiers

* grp_r: [Double]: grouping parameter as defined in Eq. 5, de Kool (1993) (default 0.1)
* verbose: [Boolean]: print progress in form of current working timebin (default: false)

__See also__: M. de Kool and U. Anzer, 1993, MNRAS, 262, 726

----

#### check_pulseperiod_orbit_struct
##### Synopsis
 checks if the pulse period- and/or orbit-structure are valid

##### Usage
```c
 Integer_Type check_pulseperiod_orbit_struct(Struct_Type structure);
or Struct_Type check_pulseperiod_orbit_struct(Double_Type pulseperiod);
```

##### Description

This function performs a checks whether the given
structure matches one of the following definitions
of a pulse period- or orbital parameter structure:

1) pulseperiod struct { % given as period over time
Double_Type[] time, % in MJD
Double_Type[] period % in seconds
}

2) pulseperiod struct { % given as taylor coefficients
Double_Type t0, % reference time in MJD
Double_Type p0[, % pulse period at t0 in seconds
Double_Type pdot[, % first derivative in s/s
Double_Type p2dot[, % second derivative in s/s^2
...
Double_Type pNdot]]] % higher orders
}

3) orbit struct {
Double_Type tau or t90, % time of periastron passage
% or mean longitude of 90 degrees in MJD
Double_Type porb, % orbital period in days
Double_Type asini, % projected semi-major axis in lt-s
Double_Type ecc[, % eccentricity
Double_Type omega] % longitude of periastron in degrees
% required if ecc > 0
}

On a successful match the number of the definition
(1-3) is returned, 0 otherwise.
Note that additional field names are allowed.

If an input pulse period (as a number) is given
instead a structure, a new pulse period structure
(type 2) is returned with t0 set to 0 and the
pulse period as given.

Note that units cannot checked by this function, but
are a suggestion. Read the help of any function using
the same definition on their required units.

__See also__: pulseperiod

----

#### cholesky_decomposition
##### Synopsis
 Decompose a matrix into the product of a lower triangular matrix and its transpose

##### Usage
```c
 Double_Type cd[n,n] = cholesky_decomposition(Double_Type m[n,n])
```

##### Description

The Cholesky decomposition is a decomposition of a symmetric, positive-definite
matrix into the (matrix) product of a lower triangular matrix and its transpose:
m = cd # transpose(cd).
The CholeskyBanachiewicz algorithm is used here to carry out the decomposition.
##### Notes

The Cholesky decomposition can be used to generate correlated variables that obey
a given covariance matrix. See the example section for details.
##### Example

m = Double_Type[3,3]; m[0,\*] = [ 9,-3,-6]; m[1,\*] = [-3,10, 5]; m[2,\*] = [-6, 5, 6];
print(m);                       % symmetric, positive-definite matrix
cd = cholesky_decomposition(m);
print(cd);                      % lower triangular matrix
print(cd#transpose(cd));        % matrix product of 'cd' and its transpose

% From three uncorrelated normal variables 'g', generate three correlated normal
% variables 'x' that obey the covariance matrix 'm':

g = Double_Type[3,100000];
g[0,\*] = grand(100000); g[1,\*] = grand(100000); g[2,\*] = grand(100000);
(cov_mat, cor_mat) = covariance_correlation_matrix(g);
print(cov_mat); % the covariance matrix of 'g' shows that there are no correlations

x = cd#g;
(cov_mat, cor_mat) = covariance_correlation_matrix(x);
print(cov_mat); % the covariance matrix of 'x' is indeed (almost) 'm'

__See also__: covariance_correlation_matrix

----

#### circle_from_points
##### Synopsis
 find the best fitting circle for a set of points

##### Usage
```c
 pars=circle_from_points(Array_Type x,Array_Type y);

```

##### Description

Given arrays of x/y coordinates of points which lie approximately on
a circle, this function returns the center coordinate and radius of
the circle. This is a numerically unstable procedure, but the
routine generally returns parameters which are good enough to start
a more advanced fitting routine.
The function is an implementation of ideas described by L. Maisonobe
in a document entitled "Finding the circle that best fits a set of
points" (see http://www.spaceroots.org/downloads.html): For each
tuple of three points of  coordinates it finds the center
and radius, which is possible in an exact manner, assuming that
the points are not on a straight line. This is done for all or a
subset of the points, and the resulting radius and center coordinates
are then averaged.
The function returns a structure with the tags xc and yc (x- and y-
coordinate of the center of the circle) and radius (radius of the circle),
or NULL if no solution could be found (points are on a straight line).

##### Qualifiers

* eps: if the determinant of the three point solution is less than
than this number, the points lie on a straight line
* maxiter: average at most maxiter tuples of three points

----

#### clear_all
##### Synopsis
 Deletes data & corresponding ARFs and RMFs

##### Usage
```c
 clear_all();
```

##### Qualifiers

* noprompt: avoid the prompt in scripts

##### Description

Deletes all data, the corresponding ARFs and RMFS, as well
as the intrinsic correction factors used for Fermi spectra.
This function removes the indicated spectra from the internal
list; it does not affect the disk files containing the spectra.

__See also__: delete_data

----

#### clip_points_polygon
##### Synopsis
 Clip points against a polygon

##### Usage
```c
 (xc,yc)=clip_points_polygon(x,y,xp,yp)
```

```
or

```c
 clipped=cohen_sutherland(points,poly)
##### Qualifiers

* evenodd: use the even-odd method to determine
* crossing: use the crossing number method
* winding: use the winding number method (the default)

##### Description

This function clips points defined by (x,y), where x and y can be arrays,
against a closed polygon defined by the arrays (xp, yp) and returns the
clipped points (xc,yc) where xc, yc are arrays (which can be empty
if all points are outside of the polygon). Here, a closed polygon
means that xp[0]==xp[-1] and yp[0]==yp[-1].

Alternatively, the points and polygon can be defined as structs,
where points=struct{ x=[], y=[] } and where the polygon is defined
as poly=struct{x=xp,y=yp}

The qualifiers define what to consider the "inside" of the polygon.

__See also__: clip_points_rectangle, greiner_hormann, point_in_polygon

----

#### clip_points_rectangle
##### Synopsis
 Clip points against a rectangle

##### Usage
```c
 (xc,yc)=clip_points_rectangle(x,y,xmin,ymin,xmax,ymax)
```

```
or

```c
 clipped=clip_points_rectangle(points,box)
##### Description

This function clips the points defined by (x,y), where x and y can be arrays,
against a rectangle defined by the corner points (xmin,ymin) and (xmax,ymax) and
returns the clipped points (xc,yc) where xc, yc are arrays (which can be empty
if all points are outside of the rectangle).

Alternatively, the points and clipping rectangle can be defined as structs,
where points=struct{ x=[], y=[] } and where the clipping rectangle is defined
either as box=struct{x=[xmin,xmax],y=[ymin,ymax]}
or as box=struct{xmin=xmin,ymin=ymin,xmax=xmax,ymax=ymax}.

__See also__: clip_points_polygon, clip_polyline_rectangle, cohen_sutherland, greiner_hormann

----

#### clip_polyline_polygon
##### Usage
```c
 clipped=clip_polyline_polygon(line,polygon)
```

##### Qualifiers

* evenodd: use the crossing number method
* crossing: use the crossing number method
* winding: use the winding number method (the default)

##### Description

This function clips a polyline defined by line=struct{x=[],y=[]},
where x and y are the points connected by the polyline, against
a closed polygon=struct{x=[],y=[]}, where again x and y are the points
connected by the polygon and where x[0]==x[-1] and y[0]==y[-1].

The function returns a list of polylines that contain the segments
of the line that are inside of the polygon. This list can be empty if
there is no overlap.

For complex polygons with intersecting segments, the qualifier defines
what constitues the inside of the polygon.

If you want to clip against a simple rectangle, use clip_polyline_rectangle
for a faster algorithm.

__See also__: point_in_polygon,clip_polyline_rectangle,clip_points_polygon

----

#### clip_polyline_rectangle
##### Synopsis
 Clip a polyline against a rectangle

##### Usage
```c
 clipped=clip_polyline_rectangle(poly,box)
```

##### Description

This function clips the polyline poly=struct{x=[],y=[]}, where x and y are arrays containing
the points of the polyline, against a rectangle defined by the corner points (xmin,ymin) and
(xmax,ymax). It returns a list of structs{x,y}, where each list element contains the points of
a segment of the polygon that is inside the box.

__See also__: clip_points_polygon, clip_polyline_rectangle, cohen_sutherland, greiner_hormann

----

#### close_plot_ps2eps
##### Synopsis
 closes a plot calls ps2eps

##### Usage
```c
 close_plot_ps2eps();
```

__See also__: close_plot, close_plot_ps2eps

----

#### close_print
##### Synopsis
 Wrapper around close_plot to allow system function to call the output file (isis_fancy_plots package)

##### Usage
```c
 close_print(window_id, String_Type);
```

##### Description

Use as:
isis> id = open_print("fig1.ps/vcps"); keynote_size; nice_width;
isis> plot(x,y);
isis> close_print(id,"gv");

__See also__: open_print, sov, open_plot, close_plot, apj_size, keynote_size, nice_width, pg_color, pg_info

----

#### cl_save
##### Synopsis
 computs single-parameter confidence lmits for several parameters, using multiple cores on one machine

##### Usage
```c
 Struct_Type results = cl_save([Integer_Type pars[]]);
```

##### Qualifiers

* strict: [=1]: restarts the calculation if a new best fit was found
* saveoutput: [=1]
* basefilename: [=<date_time>]
* level: [=1]: specifies the confidence level. Values of 0, 1, or 2
indicate 68%, 90%, or 99% confidence levels respectively.
By default, 90% confidence limits are computed.
* tolerance: convergence criterion for the calculation of the confidence
limits (see help for the conf command). Default: 1e-3
* cleanup: will remove all temporary files ending in \*.[0-9][0-9]\* from the basefilename directory

##### Description

This function is a direct copy of fit_pars, however, using
"conf_loop" to allow multi-core support on one machine. The
number of slaves is determined by the global variable
Isis_Slaves.num_slaves.
The return value <code>results = struct { index, name, value, min, max, conf_min, conf_max, buf_below, buf_above, tex }</code>
is a table with the following information for each parameter:

<code>min</code> and <code>max</code> are the minimum/maximum values allowed.
<code>conf_min</code> and <code>conf_max</code> are the confidence limits.
<code>buf_below</code> (<code>buf_above</code>) is the fraction of the allowed range <code>[min:max]</code>
which separates the lower (upper) confidence limit from <code>min</code> (<code>max</code>).
If one of these buffers is 0, your confidence interval has bounced.

__See also__: fit_pars, pvm_fit_pars, conf

----

#### cohen_sutherland
##### Synopsis
 Clip a line against a rectangle

##### Usage
```c
 (xc0,yc0,xc1,yc1)=cohen_sutherland(x0,y0,x1,y1,xmin,ymin,xmax,ymax)
```

```
or

```c
 clipped=cohen_sutherland(line,box)
##### Description

This function clips a line defined by the points (x0,y0) and (x1,y1) against
a box defined by the corner points (xmin,ymin) and (xmax,ymax) and returns
the clipped line (xc0,yc0) -- (xc1,yc1). The clipped coordinates are set
to _NaN if the line misses the box.

The line segment and clipping box can be either defined directly by giving the
coordinates or as structs, In the latter case, the line segment
is defined as line= struct{ x=[x0,x1], y=[y0,y1] } and the
rectangular box is defined either as box=struct{x=[xmin,xmax],y=[ymin,ymax]}
or as box=struct{xmin=xmin,ymin=ymin,xmax=xmax,ymax=ymax}.

__See also__: clip_points_rectangle,clip_points_polygon, clip_polyline_rectangle,greiner_hormann

----

#### colacal
##### Synopsis
 Timing Tools: Coherence and Lag Calculation

##### Usage
```c
  Struct_Type cola = colacal ([10 required inputs]);
```

##### Description

Input:
freq     - Fourier Frequency Array
cpd      - CPD Array
noicpd   - Poisson Noise Contribution to CPD
lopsd    - Non-noise-corrected PSD (low channel)
hipsd    - Non-noise-corrected PSD (high channel)
noilopsd - Noise-Contribution to low PSD
noihipsd - Noise-Contribution to high PSD
siglopsd - Noise-corrected PSD (low channel)
sighipsd - Noise-corrected PSD (high channel)
alln     - number of averaged segments in each frequency bin
Output: Struct containing
rawcof   - non-noise-corrected coherence function [Vaughan & Nowak, 1997, ApJ, 474, L43 (Eqn. 2)]
cof      - noise-corrected coherence function [Vaughan & Nowak, 1997, ApJ, 474, L43 (Eqn. 8, Part 1)]
errcof   - one-sigma uncertainty of cof [Vaughan & Nowak, 1997, ApJ, 474, L43 (Eqn. 8, Part 2)]
lag      - time lag [Nowak et al., 1999, ApJ, 510, 874 (Sect. 4)]
errlag   - one-sigma uncertainty of lag [Nowak et al., 1999, ApJ, 510, 874 (Eqn. 16)]
sigcpd   - noise-corrected cross-power-density [sigcpd = cpd - noicpd]

----

#### collect_conf_files
##### Synopsis
 Collect multiple confidence limit files from fit_pars

##### Usage
```c
 df = collect_conf_files(conffiles);
```

##### Description

This function can be used to collect multiple output files from
fit_pars and produce an easily readable data structure from it.
It is important that all spectra are fit with the same model.
The output, explained based on the example of
tbnew_simple\*powerlaw is as follows:

struct{ tbnew_simple_nh = struct{value = Double_Type[nfiles],
conf_min = Double_Type[nfiles],
conf_max = Double_Type[nfiles]},
powerlaw_norm = struct{value = Double_Type[nfiles],
conf_min = ..., conf_max = ...},
powerlaw_phoindex = ... }

where nfiles is the number of conffiles given and the entries of
the arrays value, conf_min, conf_max, etc. are the data fields of the
confidence limit files created by fit_pars. In addition, the
output contains the conffile names, the reduced chi^2, an array
of the parameters, and an array of the data field names.
##### Example

variable conffiles = glob("\*_conf.fits");
variable df = collect_conf_files(conffiles);
variable dummy_time = [0:length(conffiles)-1];
variable P = tiky_plot_new;
P.plot(dummy_time, df.powerlaw_phoindex.value, {0,0},
{df.powerlaw_phoindex.conf_min, df.powerlaw_phoindex.conf_max};
minmax);

__See also__: get_struct_field

----

#### color2hex
##### Synopsis
 converts color string to hex color.

##### Usage
```c
 Integer_Type color2hex(String_Type color)
```

__See also__: hex2color

----

#### color2rgb
##### Synopsis
 converts a 24 bit color value to r, g, b, values.

##### Usage
```c
 Integer_Type r, g, b color2rgb(Int/String_Type col)
```

##### Qualifiers

* float: If given, the channels are instead returned in the range (0-1).

##### Description

Converts a hex color to RGB values. Can be either 24 bit
value or string.

__See also__: rgb2color

----

#### color_blackbody
##### Synopsis
 Computes RGB colors of hot blackbody radiation.

##### Usage
```c
 Integer_Type color = color_blackbody(Double_Type T);
```

##### Description

<code>T</code> is the temperature of the blackbody in Kelvin.
The return value is its 24 bit RGB value.

It is computed after the code "RGB VALUES FOR HOT OBJECTS"
by Dan Bruton (astro@sfasu.edu), which can be found at
http://www.physics.sfasu.edu/astro/color.html.

----

#### color_color_data
##### Synopsis
 extracts light curves in 3 consecutive bands and the corresponding colors from an event list

##### Usage
```c
 Struct_Type dat = color_color_data(Struct_Type evts, Double_Type E0, E1, E2, E3);
```

##### Qualifiers

* dt: time resolution [default: 100]
* field: field used for selection of the bands [default: "pi"]

##### Description

<code>dat.a</code> = lightcurve in "E0 <= field < E1" band

<code>dat.b</code> = lightcurve in "E1 <= field < E2" band

<code>dat.c</code> = lightcurve in "E2 <= field < E3" band

<code>dat.</code>x<code>_</code>y = x/y color for x, y = a | b | c

__See also__: histogram

----

#### color_complex
##### Synopsis
 Converts a complex number to a RGB color

##### Usage
```c
 Integer_Type color = complex2rgb(Complex_Type z);
```

##### Description

arg(<code>z</code>) determines the hue,
|<code>z</code>| determines the lightness:
0<=|<code>z</code>|<=1 is mapped from black to color,
1<=|<code>z</code>|<inf is mapped from color to white.
The return value is a 24-bit RGB value.
##### Qualifiers

* s[=1.0]: saturation (from 0 to 1) of the color

__See also__: hsl2rgb, png_write

----

#### color_desaturate
##### Synopsis
 Weighted color to gray conversion

##### Usage
```c
 UInt_Type gray = color_desaturate(UInt_Type[] color);
```

##### Description

Converts a RGB color, hex encoded, into a weighted gray scale using:

<code>gray</code> = (0.3 \* R) + (0.59 \* G) + (0.11 \* B)

The 8 bit gray value(s) are return as UInt_Type[] in the interval [0,255].

__See also__: rgb2hsl, color2rgb

----

#### color_mix
##### Synopsis
 Mix two rgb colors

##### Usage
```c
 UInt_Type color = color_mix (UInt_Type c1, UInt_Type c2, Double_Type fraction);
```

##### Description

This function mixes two colors in rgb space. Given the rgb values in the
usual encoding in one 24bit integer, the color is mixed according to
new color  = c\*fraction + c2\*(1-fraction)
The operations are analoguous to the color mixing performed by the xcolor
package of LaTeX (the operation is similar to the color1!fraction!color2
syntax).
The function returns the integer specifying the new rgb values. <code>fraction</code>
can be an array. The colors can also be a hex string.

----

#### color_wavelength
##### Synopsis
 Computes the color values of visual light

##### Usage
```c
 UInt_Type[] color_wavelength (Double_Type[] lambda);
```

##### Description

<code>380 <= lambda <= 780</code> is the wavelength in nm.
The return value is its 24bit RGB color value.

The conversion is performed after the code by Dan Bruton,
see http://www.physics.sfasu.edu/astro/color.html.

----

#### combine_chain
##### Synopsis
 Combine several mcmc chains generated with the same configuration

##### Usage
```c
 combine_chain(Array_Type chaininfiles, String_Type chainoutfile)
```

##### Qualifiers

* verbose: show progress

##### Description

This function takes mcmc chains stored in files passed as an array of strings in chaininfiles,
written with the write_chain function (or by emcee itself) and combines them to one chain file,
again writing a fits file.
This function does not make use of read_chain or write_chain, it's consisting only of
fits routines. The function itself does perform some sanity and safety checks (same data, same fit_fun)
but you have to make sure that you use the correct chains in the correct order.

__See also__: read_chain, write_chain, emcee, append_chain

----

#### compare_modelfits
##### Synopsis
 to compare modelfit parameters of different epochs

##### Usage
```c
 compare_modelfits([array of <code>epoch fitsfiles</code>]);
```

##### Qualifiers

* plottype: [="overlay"] layout of the comparison plot,
by default it shows the overlay of all component positions,
alternatives are "distancevsmjd","fluxvsdistance","TBvsdistance"
* fileextent: [=.eps] output is given by default as .eps-file in working directory
* outputfile: give outputfile name and directory by hand
* sourcename: [=default] set the name of the source, by default the name is read from the .fits file,

set to NULL for not plotting a source name
* ra_mas: [=[20,-20]] ra range (for "overlay")
* dec_mas: [=[-20,20]] dec range (for "overlay")
* mjd_min: [=54101.0] lower limit of time axis (default: 1/1/2007)
* mjd_max: [=55927.0] lower limit of time axis (default: 1/1/2012)
* distance_min: [=0] lower limit of distance axis in mas
* distance_max: [=50] upper limit of distance axis in mas
* flux_min: [=1e-5] lower limit of flux axis in Jy
* flux_max: [=2] upper limit of flux axis in Jy
* TB_min: [=10^5] lower limit of brightness temperature axis in K
* TB_max: [=10^15] upper limit of brightness temperature axis in K
* linestyle: [=default] set to 0 if the flux values should not be conntected (or to another value for
another line style
* ex_comps: [=0] set to 1 if components should be excluded and define
the corresponding quadrant of the plot via the ex_comps-coordinates
* ex_comps_ra: [=NULL] quadrant coordinates in mas where components should be excluded
* ex_comps_dec: [=NULL] define quadrant coordinates in mas where components should be excluded

##### Description

This function creates an overlay of a VLBI-clean image and the corresponding

model of Gaussian components which are over-plotted as ellipses.

The required input format are fits-file for both the clean and the modelfit images.
The format of the output file depends on the suffix of the given

<code>filename</code>. Possible formats of the output file are PDF, EPS,

PNG, GIF, etc.
If labelling = 1 is set, the components are labeled with J0,J1,J2,... depending on
their distance to [0,0].
The counterjet components (and core) can be excluded by defining the corresponding
quadrant of the the plot via ex_comps_ra and _dec.

----

#### compare_par
##### Synopsis
 compares models saved in parameter files

##### Usage
```c
 compare_par([String_Type pattern]);
```
or

```c
 Struct_Type info = compare_par([String_Type pattern]; get_list);

```

##### Qualifiers

* fit_fun: include fit-function
* fit_fun=fitfun: only include models using the fit-function <code>fitfun</code>
* get_list: the information is not printed, but returned
* load_best: load the best fit parameters
* verbose:

##### Description

It is assumed that the corresponding data sets are already initialized.

__See also__: load_par, eval_counts

----

#### complementary_array
##### Synopsis
 returns the "difference" of arrays

##### Usage
```c
 Array_Type C = complementary_array(Array_Type B, A)
```

##### Description

<code>C = B</code> \ <code>A</code>

----

#### Compton_crosssection
##### Usage
```c
 Double_Type sigma = Compton_crosssection(Double_Type E);
```

##### Description

<code>E</code> is the energy in keV.
<code>sigma</code> is the total Klein-Nishina crosssection in cm^2:
<code>sigma = 3/4 sigma[Th] \* [  (1+y)/y^3 \* { 2y\*(1+y)/(1+2y) - log(1+2\*y) }  +  log(1+2\*y)/(2\*y)  +  (1+3y)/(1+2y)^2  ]</code>
where <code>y = E/(511 keV)</code>.

__See also__: Rybicki & Lightman (1979)

----

#### continued_fraction
##### Synopsis
 computes a continued fraction

##### Usage
```c
 Double_Type continued_fraction(UInteger_Type a[])
```

##### Description

<code>                                  1 |      1 |</code>

<code>continued_fraction(a) = a[0] + ------ + ------ + ...</code>

<code>                               | a[1]   | a[2]</code>

----

#### continued_fraction_expansion
##### Synopsis
 expands a floating point number as a continued fraction

##### Usage
```c
 UInteger_Type[] continued_fraction_expansion(Double_Type x)
```

##### Qualifiers

* verbose:
* maxlen: [<code>=64</code>]

----

#### contour_borders
##### Synopsis
 Returns outer borders of a contour

##### Usage
```c
 Double_Type[] = contour_borders(fits);
```

##### Qualifiers

* conf_level [2]: : set confidence level for which you need the borders

##### Description

This function takes as input a contour in fits-format saved with
save_conf and returns the array [par1_min,par1_max,par2_min,par2_max].
Select the confidence level with the conf_level quelifier (1,2,3).
##### Example

contour_borders("contour.fits";);

__See also__: function_name2, function_name3

----

#### contour_trq
##### Synopsis
 creates and (with qualifier trq) sends bins^2 jobs to torque (at Remeis cluster) and
calculates chi_2 values for each point for chosen 2 parameters.

##### Usage
```c
 contour_trq(String_Type inputPar1, inputPar2, Int_Type bins,
Double_Type lowLimPar1, upLimPar1,lowLimPar2, upLimPar2,
String_Type startUpFile [, parFile], outDir, time);
```

##### Qualifiers

* trq: Sends the jobs to Remeis torque

##### Description

- <code>inputPar1</code>     input parameter 1 written as in .par file
- <code>inputPar2</code>     input parameter 2 written as in .par file
- <code>bins</code>          number of chosen bins
- <code>lowLimPar1</code>    lower parameter 1 value
- <code>upLimPar1</code>     upper parameter 1 value
- <code>lowLimPar2</code>    lower parameter 2 value
- <code>upLimPar2</code>     upper parameter 2 value
- <code>startUpFile</code>   upload file (with data, binning,
noticing etc.)
- <code>parFile</code>       best fit parameter file name (optional)
- <code>outDir</code>        output directory for torque files and
calculated output files
- <code>time</code>          torque wall time

In case where values for all bins^2 points are not calculated (for
example when the torque walltime is shorter than needed), one can run
function missing_contour_trq in order to get all bins^2 values.

To plot the result use the function plot_contour_trq.

EXAMPLE

contour_trq(`relconv(1).Incl`,`reflionx(1).Xi`,32,25,35,1000,4000,"data.sl",
"results/bestFit.par","outputInclXi","02:00:00";trq);

will calculate 32 by 32 values for two parameters and write the
output files to "outputInclXi" subdirectory. It will do that by
sending the 32x32 jobs to Remeis torque via qualifier "trq", and
giving it a walltime of 02:00:00 hours.

__See also__: missing_contour_trq, plot_contour_trq

----

#### convert_units
##### Synopsis
 convers units of a physical quantity

##### Usage
```c
 convert_units(PhysicalQuantity_Type q);
```
or

```c
 PhysicalQuantity_Type convert_units(PhysicalQuantity_Type q; copy)

```

##### Qualifiers

* leng: unit of length
* time: unit of time
* mass: unit of mass
* curr: unit of electrical current
* temp: unit of temperature
* SI: sets  leng="m", time="s", mass="kg", curr="A", temp="K"
* copy: does not change unit of q, but returns a copy of q

##### Description

The allowed units are specified by the associative arrays
baseunits_length_in_m, baseunits_time_in_s,
baseunits_mass_in_kg, baseunits_current_in_A,
and baseunits_temperature_in_K
which specify the factor to the corresponding SI units.

----

#### coords_in_box
##### Synopsis
 calculates world coordinates from the relative coordinates in the plot box

##### Usage
```c
 (Double_Type x, y) = coordY_in_box(Double_Type x_rel, y_rel);
```

##### Description

Note that the x- and yrange has to be set in advance
in order to calculate the world coordinates with <code>coords_in_box</code>.

__See also__: coordX_in_box, coordY_in_box

----

#### coordX_in_box
##### Synopsis
 calculates a world x-coordinate from the relative x-coordinate in the plot box

##### Usage
```c
 Double_Type coordY_in_box(Double_Type x_rel)
```

##### Description

The left boundary of the plot box has <code>x_rel==0</code>,
and the right boundary has <code>x_rel==1</code>.
Logarithmic world-coordinates are properly taken into account.
Note that the xrange has to be set in advance
in order to calculate the world x-coordinate with <code>coordX_in_box</code>.

__See also__: coordY_in_box, coords_in_box

----

#### coordY_in_box
##### Synopsis
 calculates a world y-coordinate from the relative y-coordinate in the plot box

##### Usage
```c
 Double_Type coordY_in_box(Double_Type y_rel)
```

##### Description

The lower boundary of the plot box has <code>y_rel==0</code>,
and the upper boundary has <code>y_rel==1</code>.
Logarithmic world-coordinates are properly taken into account.
Note that the yrange has to be set in advance
in order to calculate the world y-coordinate with <code>coordY_in_box</code>.

__See also__: coordX_in_box, coords_in_box

----

#### COPY
##### Synopsis
 makes a copy of a nested Struct/Array/List_Type

##### Usage
```c
 Struct_Type copy = COPY(Struct_Type copyme);
```

```
or

```c
 Array_Type  copy = COPY(Array_Type  copyme);
```
or

```c
 List_Type   copy = COPY(List_Type   copyme);
```
or

```c
 Assoc_Type  copy = COPY(Assoc_Type   copyme);
##### Description

<code>COPY</code> returns a properly dereferenced copy of an
arbitrarily nested <code>Struct/Array or List_Type</code> with
all its entries.
Depending on the Data_Type of the initial given
copyme and the Data_Type of its entries, <code>COPY</code>
iteratively calls the  according sub-function
(<code>struct_copy</code>, <code>array_copy</code> or <code>list_copy</code>).
If the given Data_Type or one of its entries is not
one of previously mentioned ones, <code>COPY</code> returns
@(Data_Type) or respectively @(entry).

NOTE: \* Ref_Type entries will not be dereferenced, which
allows to copy XFIG-OBJECTS !!!
\* Double_Type[] is an Array_Type

##### Example

Array_Type:
s = Struct_Type[1]; s[0]=struct{ a=Array_Type[1,2] };
s[0].a[[0]]=[0:9];
copy = COPY(s); copy[0].a[[0]] = ["modified"];
print(s[0].a);

List_Type:
s = Struct_Type[1]; s[0]=struct{ a=Array_Type[1,2] };
s[0].a[[0]]=[0:9];
l = [{ array_copy(s), 1., [1:10] }, {"abs"}];
copy = COPY(l); copy[0][0][0].a[[0]] = ["modified"];
print(l[0][0][0].a);

Struct_Type:
s = Struct_Type[1]; s[0]=struct{ a=Array_Type[1,2] };
s[0].a[[0]]=[0:9]; S = struct{ f=s };
C = struct_copy(S); C.f[0].a[[0]] = ["modified"];
print(S.f[0].a);

__See also__: struct_copy, array_copy, list_copy, assoc_copy

----

#### correlation_coefficient
##### Synopsis
 calculates the [weighted] linear correlation coefficient between two arrays

##### Usage
```c
 Double_Type rho = correlation_coefficient(Double_Type x[], Double_Type y[] [ , Double_Type w[] ]);
```

##### Description

The function of the unweighted correlation coefficient reads:

<code>                     n \* sum(x\*y)  -  sum(x) \* sum(y)          </code>
<code>rho  =  -------------------------------------------------------</code>
<code>         sqrt(n\*sum(x^2)-sum(x)^2) \* sqrt(n\*sum(y^2)-sum(y)^2) </code>

w defines the weight of each point. By default it is set to w = 1.

__See also__: find_correlations

----

#### cosmo_param
##### Synopsis
 Derive full set of cosmological density parameters from a partial set

##### Usage
```c
 Struct_Type P = cosmo_param();
```

##### Qualifiers

* omega_m: value of the normalized matter density (Omega_M)
* omega_lambda: value of the normalized cosmological constant (Omega_Lambda)
* omega_k: value of the the normalized curvature term (Omega_k)
* q0: value of the deceleration parameter (q0)

##### Description

This procedure is called by lumdist to allow the user a choice
in defining any two of four cosmological density parameters.
Given any two of the four input parameters this  program will derive
the remaining two.
Omega_M      - Normalized matter energy density, non-negative numeric scalar
Omega_Lambda - Normalized cosmological constant, numeric scalar
Omega_k      - Normalized curvature parameter, numeric scalar.
This is zero for a flat universe
q0           - Deceleration parameter, numeric scalar = -R\*(R'')/(R')^2
= 0.5\*Omega_m - Omega_lambda
Here "normalized" means divided by the closure density so that
Omega_m + Omega_lambda + Omega_k = 1.    For a more
precise definition see Carroll, Press, & Turner (1992, ArAA, 30, 499).

If less than two parameters are defined, this procedure sets default
values of Omega_k=0 (flat space), Omega_lambda = 0.7, Omega_m = 0.3
and q0 = -0.55

If more than two parameters are defined upon input (overspecification),
then the first two defined parameters in the ordered list Omega_m,
Omega_lambda, Omega_k, q0 are used to define the cosmology.

(This procedure is translated from the IDL COSMO_PARAM function.)

##### Example

variable default_set = cosmo_param();
print (default_set);

variable my_set = cosmo_param(; omega_k = 0.1, omega_lambda = 0.65);
print (my_set);

__See also__: lumdist

----

#### covariance_correlation_matrix
##### Synopsis
 Compute the covariance and correlation matrices of a set of variables

##### Usage
```c
 (Double_Types cov_mat[n,n], cor_mat[n,n]) = covariance_correlation_matrix(Double_Type a[n,N])
```

##### Description

This function estimates the covariance and correlation matrices of a set of
random variables. Consider a sample 'a' of 'N' column vectors of length 'n':
a = Double_Type[n,N]. Each of the 'n' rows of 'a' may represent the realization
of a random variable. The 'n' times 'n' covariance matrix 'cov_mat' between
these 'n' variables is
cov_mat[i,j] = 1/(N-1) \* sum( (a[i,\*]-mean(a[i,\*]))\*(a[j,\*]-mean(a[j,\*])).
The 'n' times 'n' correlation matrix 'cor_mat' is
cor_mat[i,j] = cov_mat[i,j]/sigma_i/sigma_j
where 'sigma_i' is the square root of the variance of 'a_i':
sigma_i = sqrt( 1/(N-1) \* sum( (a[i,\*]-mean(a[i,\*]))^2 ) ).
##### Notes

The Cholesky decomposition of the covariance matrix can be used to generate
correlated variables that obey a given covariance matrix. See the example
section for details.
##### Example

% From three uncorrelated normal variables 'g', generate three correlated normal
% variables 'x' that obey the covariance matrix 'm':

g = Double_Type[3,100000];
g[0,\*] = grand(100000); g[1,\*] = grand(100000); g[2,\*] = grand(100000);
(cov_mat, cor_mat) = covariance_correlation_matrix(g);
print(cov_mat); % the covariance matrix of 'g' shows that there are no correlations
print(cor_mat);

m = Double_Type[3,3]; m[0,\*] = [ 9,-3,-6]; m[1,\*] = [-3,10, 5]; m[2,\*] = [-6, 5, 6];
cd = cholesky_decomposition(m);
x = cd#g; % matrix product of 'cd' and 'g'
(cov_mat, cor_mat) = covariance_correlation_matrix(x);
print(cov_mat); % the covariance matrix of 'x' is indeed (almost) 'm'
connect_points(0); plot(x[0,\*],x[2,\*]);

__See also__: cholesky_decomposition

----

#### cov_matrix
##### Synopsis
 computes a covariance matrix

##### Usage
```c
 COV = cov_matrix(Struct_Type s);
```
or

```c
 COV = cov_matrix(Double_Type X[][]);
```
or

```c
 COV = cov_matrix(Double_Type x0[], x1[], ...);

```

##### Description

<code>COV[i,j] =</code> cov(x_i, x_j) = < (x_i - <x_i>) \* (x_j - <x_j>) >

----

#### create_basic_simputfile
##### Synopsis
 creates a basic SIMPUT file

##### Usage
```c
 Struct_Type str = create_basic_simputfile(filename, RA, Dec, srcFlux, nH, powerLawIndex);
```

##### Description

This function creates a structure, which contains all necessary
info for a simple "simputfile" command to create a basic SIMPUT
file for a given point source. The flux is assumed to be given in
the 2-10 keV band by default. The file can be directly created by
adding the qualifier "eval". Otherwise a structure is returned.
This structure can be further modifed, and then evaluated with
the function "eval_simputfile".
##### Qualifiers

* crab: flux is given in units of Crab
* eval: directly evalute the returned structure (similar to call eval_simputfile(str);
* emin: lower limit of the energy band of the given flux in keV
* emax: lower limit of the energy band of the given flux in keV
* quite: don't show any output

##### Examples

<code>variable str = create_basic_simputfile("velaX-1.fits",135.528583,40.554722,100e-3,1.8,5.0;crab);</code>

__See also__: eval_simputfile,get_simputfile_struct,set_simputfile_model_grid,set_simputfile_flux

----

#### create_struct_field
##### Synopsis
 create and set the value associated with a structure field

##### Usage
```c
 Struct_Type create_struct_field(s, field_name, field_value);
```

##### Qualifiers

* skip: do not update an existing field

##### Description

Does the same as the `set_struct_field' function except
that the given field is created first if it does not
exist.

__See also__: set_struct_field, struct_combine

----

#### crossing_number_polygon
##### Usage
```c
 cn=crossing_number_polygon(P,V)
```

##### Synopsis
 return the crossing number for a point P in a polygon

##### Description

Return the crossing number for a point P in a (potentially
complex polygon defined by the vertex points V).
The polygon has to be closed, i.e. V.x[n]==V.x[0] and
V.y[n]==V.y[0] where n is the number of polygon points.

The crossing number is the number of times that a ray starting
from point P crosses the polygon.  The point is outside of the
polygon if the crossing number is even, and inside if the
crossing number is odd (even-odd rule).

The point P is a struct{x,y}, while the polygon V is
defined by its vertex points, which are stored in a
struct{x[],y[]}
where the arrays are the x- and y-coordinates.

See the URL below for more explanations.

Based on code by Dan Sunday,
http://geomalgorithms.com/a03-_inclusion.html
and patterned after Randolph Franklin (2000),
http://www.ecse.rpi.edu/Homepages/wrf/research/geom/pnpoly.html

__See also__: winding_number_polygon,point_in_polygon,simplify_polygon

----

#### cross_power_density
##### Synopsis
 Timing Tools: Cross Power Density (aka. Cross-Spectrum)

##### Usage
```c
 (cpd, errcpd) = cross_power_density(rate1, rate2, numseg, dimseg)
```

##### Description

Calculates the CPD, averaged over all segments, as
Conj(DFT(rate1))\*DFT(rate2)
using the dorDFT function. The return values are of Complex_Type.
The error is the standard error on the mean of the averaged CPD.

__See also__: dorDFT

----

#### cstat_goodness
##### Synopsis
 computes the theoretical Cash-statistics and its
uncertainty for the current data and model

##### Usage
```c
 Struct_Type ctheo = cstat_goodness();
```

##### Description

This function computes the theoretical Cash statistics for the
currently set data, using the expressions given by Kaastra
(2017, A&A 605, A51). These values are returned in the tags
cstat_theory and c_variance. The tag n_bins contains the number
of bins entering these values, it should be the same as that
obtained with eval_stat_counts().

The values can be used to compute the goodness of the fit by
comparing its best fit statistics (obtained with eval_stat_counts())
with cstat_theory and the variance. The "f-sigma" probability for
the best fit cash statistic is the range cstat_theory - f \*c_variance
to cstat_theory + f \* c_variance.

##### Qualifiers

* quiet: if set, the function will not complain if the fit
statistics is not set to Cash or if there are bins without counts.
* data: if set, uses the measured counts in the computation
(the default is the expected counts in the bin)

__See also__: kaastra_cstat_goodness,eval_stat_counts,set_fit_statistic

----

#### cutoffpl2 (fit-function)
##### Synopsis
 describes a power law with exponential cutoff in wavelength space

##### Description

S(l) = <code>norm</code> \* l^(-<code>index</code>) \* exp(-l/<code>cutoff</code>)

The bin-integrated cutoffpl2 fit-function is computed
by the incomplete Gamma-function from the GSL library.
(The original cutoffpl didn't converge for low energies.)

__See also__: cutoffpl, gamma_inc

----

#### cut_dataset_range

##### Synopsis
 Get get_data_counts-struct clipped to energy range

##### Usage
```c
 Struct_Type = cut_dataset_range (hist_index , E_min , E_max);
```

##### Description

This function will return a structre just as get_data_counts
but clipped to the energy range from E_min up to E_max (energies in keV).
##### Example

isis>id = load_data("data.fits");
isis>variable cut_spectrum = cut_dataset_range (id , 0.2 , 2.3);

__See also__: get_data_counts

----

#### cyl2cart
##### Synopsis
 Convert cylindrical to Cartesian coordinates

##### Usage
```c
 cyl2cart(Double_Types r[], phi[], z[], vr[], vphi[], vz[]);
```

##### Description

Convert cylindrical (r,phi,z,vr,vphi,vz) to Cartesian (x,y,z,vx,vy,vz)
coordinates with phi rotating counter-clockwise from the positive x-axis.
##### Example

(x,y,z,vx,vy,vz) = cyl2cart(1,PI/2,1,2,3,4);
(x,y,z,vx,vy,vz) = cyl2cart([1,0],[PI/2,0],[1,0],[2,0],[3,0],[4,0]);
(x,y,z,vx,vy,vz) = cyl2cart( cart2cyl(1,1,1,2,3,4) );

__See also__: cart2cyl

----

#### data_list (isis_fancy_plots package)
##### Synopsis
 Turn an array into a list.

##### Usage
```c
 data_list(Array);
```

##### Description

__See also__: list_to_array

----

#### data_map_function
##### Synopsis
 executes a function on specific datasets

##### Usage
```c
 data_map_function(String_Type filter, Ref_Type function, arguments...; qualifiers);
```

##### Description

Loops over all defined datasets and matches each data
information against the given filter. In the simplest
way, this filter is a string respresenting the wanted
instrument as specified in the field of 'get_data_info'.
If the 'fi' qualifier is provided, the given filter is
interpreted as if-statement, which has to be fullfiled.
Thereby, the associated data information can be accessed
via the 'info' variable. The given function is applied
to each matching dataset in the form
function(dataset, arguments...; qualifiers);
##### Example

% set the energy ranges for all RXTE-PCA sepctra
data_map_function("PCA", &xnotice_en, 3.5, 50);

% apply grouping to all Suzaku-PIN spectra
data_map_function(`is_substr(info.file, "hxd_pin")`,
&group; min_sn = 40, fi);

__See also__: get_data_info, eval, array_map

----

#### DateOfJD
##### Synopsis
 Calculates the date corresponding to a JD value

##### Usage
```c
 Struct_Type date = DateOfJD(JD);
```

##### Description

The return value is a structure of the following form:

<code>date = struct { year, month, day, hour, minute, second };</code>
The algorithm used is that by Meeus, Astronomical Formulae for
Calculators. This routine is array safe.
##### Qualifiers

* julianswitch: For JD smaller than this date, return the date
in the Julian calendar rather than in the Gregorian
calendar. The default is JD2299161 (15 October 1582),
which is appropriate for most of catholic Europe.
Note, however, that there are countries that switched
only much later (see https://en.wikipedia.org/wiki/Julian_calendar
and https://de.wikipedia.org/wiki/Gregorianischer_Kalender).
For example, Russia only switched on 1 February 1918 (Gregorian).
* julian_calendar: force returning the date in the Julian Calendar
(ignore julianswitch)
* gregorian_calendar: force returning the date in the Gregorian Calendar
(ignore julianswitch)

__See also__: JDofDate, MJDofDate

----

#### DateOfMJD
##### Synopsis
 calculates the date from its MJD value

##### Usage
```c
 Struct_Type date = dateOfMJD(MJD);
```

##### Description

The return value is a structure of the following form:

<code>date = struct { year, month, day, hour, minute, second }
and always in the Gregorian Calendar. See DateOfJD if you want more
functionality. This function is array safe.</code>

__See also__: DateOfJD, MJDofDate

----

#### dateOfMJD
##### Synopsis
 calculates the date from its MJD value

##### Usage
```c
 Struct_Type date = dateOfMJD(MJD);
```

##### Description

The return value is a structure of the following form:

<code>date = struct { year, month, day, hour, minute, second }
and always in the Gregorian Calendar. See DateOfJD if you want more
functionality. This function is array safe.</code>

__See also__: DateOfJD, MJDofDate

----

#### dayOfWeek
##### Synopsis
 returns the day of the week of the given date

##### Usage
```c
 Integer_Type dayOfWeek(Integer_Type year, month, day);
```

##### Description

This function returns the day of the week from 1 (Monday) to
7 (Sunday) of the given date in the Gregorian (default) or the
Julian calendar.

##### Qualifiers

* julian_calendar: : the date is in the Julian calendar
(default: Gregorian calendar)

##### Example

dayOfWeek(1837, 9, 9);

----

#### daysPerMonth
##### Synopsis
 returns the number of days of a month

##### Usage
```c
 Char_Type daysPerMonth(m[, y])
```

##### Description

<code>m</code> = 1, 2, ... 12 specifies the month Jan, Feb, ..., Dec.

If <code>y</code> is not specified, a non-leapyear is assumed.

__See also__: leapyear

----

#### dcf
##### Synopsis
 compute the Edelson & Krolik discrete correlation function and returns a structure with the correlation

##### Usage
```c
 dcf(time_a, val_a, tima_be, val_b);
```

##### Qualifiers

* err_a [=0]: :  array containing the measurement errors of
val_a. If given, this is taken into
account by using eq. (3) of Edelson & Krolik.
NOTE: There are lots of problems with interpreting the
DCF computed this way instead of using Edelson & Krolik,
eq. (2), and it is NOT recommended to give erra and errb
(see, e.g., White & Peterson, 1994, PASP, 106, 879)
* err_b [=0]: :	as err_a except for val_b
* minlag [=mininum time difference between time_a and time_b]: :	minumum lag to consider
* maxlag [=maximum time difference between time_a and time_b]: :	maximum lag to consider
* numf [=int(min([length(val_a) ,length(val_b) ])/10)]: :	number of lag bins for which to compute the DCF
* minpt [=10]: :	minimum number of data points for a DCF value to be

##### Description

This is the imported version of the IDL subroutine dcf.pro

It will compute the Edelson & Krolik discrete correlation function.

----

#### define_atime
##### Synopsis
 defines a dataset of arrival times

##### Usage
```c
 Integer_Type define_atime(Struct_Type atime[, Integer_Type divide]);
```

##### Qualifiers

* modnum: a reference to a variable, where to store
the pulse numbers found by the model
* noff: do not add 'arrtimes' to the actual fit-
function correspondig to the dataset

##### Description

Takes the given arrival times structure to define
an ISIS dataset. This structure may be created by
'atime_det' or loaded by 'load_atime'. Accordingly
all usual ISIS routines, which operate on datasets,
e.g. fitting, can be used. The fit function
'arrtimes' handle arrival times including orbital
motion and pulse ephemeris. If not disabled by the
'noff' qualifier the actual fit function is auto-
matically extended by the resulting dataset using
the 'arrtimes' model. It also takes the qualifier
'modnum' into account to return the pulse numbers
determined by the model. The reference to the
pulse numbers is stored into the metadata of the
dataset.
If the second parameter 'divide' is given the
dataset is defined several times accordingly to
the given integer. The datasets are then noticed
automatically such that the whole data is divided
into the given number of parts of equal length.
Each part may be then fitted individually.
The returned integer corresponds to ISIS dataset
index.

__See also__: arrtimes, atimes_det, load_atime, atime_metavalid, xnotice_atime

----

#### define_counts_2d
##### Synopsis
 defines a pseudo-spectrum from two-dimensional data

##### Usage
```c
 Integer_Type define_counts_2d(value[, err][, X, Y])
```

##### Description

<code>value</code> and <code>err</code> are 2d arrays of Double_Type.
ISIS usually deals with 1d spectra. For fitting 2d data, <code>define_counts_2d</code>
can be used to define a pseudo 1d spectrum by reshaping arrays,
to which ISIS' internal fit routines can be applied.

User defined fit-functions should not use the bin_lo, bin_hi arguments,
but the actual data-grid which can be set / obtained with <code>set</code>/<code>get_2d_data_grid</code>,
if the user doesn't prefer to take care of the data grid on his own.
If the optional 1d Double_Type arrays <code>X</code> and <code>Y</code> are specified,
<code>set_2d_data_grid</code> is already called by <code>define_counts_2d</code>.

__See also__: gauss_2d

----

#### define_xydata
##### Synopsis
 defines an xy-dataset to be modeled with xyfit_fun

<!--%{{{ -->
##### Usage
```c
 Integer_Type data_id = define_xydata ( x[], y[] [, yerr[]] );
```

```
or

```c
 Integer_Type data_id = define_xydata ( x[], xerr[], y[], yerr[] );
##### Qualifiers

* N[=1000]: : number of curve points, when xerr is considered
* x_mdl [default: array covering <code>x</code> with <code>N</code> steps]: :
(initial) x-values of the model, when <code>xerr</code> is considered
* y_mdl [default: array covering <code>y</code> with <code>N</code> steps]: :
(initial) y-values of the model, when <code>xerr</code> is considered

##### Description

This function creates a dummy spectral dataset for ISIS and stores
the xy-dataset in its metadata, which are only considered when
fitting with a dedicated xy-fit-function defined by <code>xyfit_fun</code>.
Fitting via <code>fit_counts</code> will minimize the sum of squared residuals,
see <code>xyfit_residuals</code>.

If no <code>xerr</code> is specified, the xy-fit-function will only be evaluated
at the x-values of the data. (yerr defaults to 1, if not specified.)

If <code>xerr</code> is given as well, a curve is constructed in order to compute
the residuals of the data points. The xy-fit-function may produce a
(reasonably smooth!) graph (x, y(x)) or parameterized curve (x(t), y(t)).
It operates on the model points and possibly (constant) parameters
defined by <code>set_xy_qualifier</code>. Model points for an xy-dataset
are initially defined by the <code>N</code> or <code>x_mdl</code> and <code>y_mdl</code> qualifiers.

If xerr, yerr are lists with two array entries, than the first is
interpreted as lower and second as upper uncertainty

##### Example

N = 150; (x, y) = ellipse(8, 5, 0.2\*PI, grand(N)\*1.5);
x += grand(N)+4; y += grand(N)+1;
id = define_xydata (x, ones(N), y, ones(N));
xyfit_fun("ellipse_xy");
set_xyfit_qualifier(id; curve_parameter=[0:2\*PI:#3000]);
()=fit_counts;
set_par("ellipse_xy(1).pos_angle", 30); ()=fit_counts; % help with angles...
plot_xyfit(id);
% fit_interactive(&plot_xyfit);

__See also__: xyfit_fun, set_xyfit_qualifier, xyfit_residuals, plot_xyfit

----

#### deg2dms
##### Synopsis
 Convert a floating point angle in degrees to degrees, minutes, seconds

##### Usage
```c
 (d,m,s) = deg2dms(degree)
```

##### Qualifiers

* hours: If set, return the coordinate in hours, minutes, sec (RA)
* radian: If set, the angle is in radians, not degrees

##### Description

This is a convenience routine to convert astronomical coordinates given
as a floating point number into a number in degrees, minutes, seconds.

For negative angles, the sign of the coordinate is given to the highest
non-zero integer.

Use angle2string to generate strings from angles, and generate_iauname
if you want to build strings to use in source names.

__See also__: dms2deg, hms2deg, angle2string, generate_iauname

----

#### detconst
##### Synopsis
 fit-function providing detector calibration constants

##### Usage
```c
 detconst(id)
```

##### Description

Simply returns a constant depending on the detector of
the current dataset the model is evaluated on. This can
be used to account for flux calibration differences
between several detectors.

To use this fit-function, the detectors has to be
defined first using 'detconst_init'.

__See also__: detconst_init

----

#### detconst_init
##### Synopsis
 initializes the "dectonst" fit-function

##### Usage
```c
 detconst_init(String_Type[] detectors);
or detconst_init(List_Type detectors);
```

##### Description

Before any detector calibration constants can be fitted
by using the 'detconst' fit-function, this function has
to be called. It initalizes and defines the fit-function
based on the given detector names (and if statements).

In general, the detector names are given as an array of
strings. Each entry has to represent the 'instrument'
field defined in the FITS-header of any used dataset.
Internally, the 'detconst' matches this field against
the given names and returns the corresponding parameter.

If the instrument field is not enough to determine the
parameter (e.g., if multiple instruments are build within
the same detector), a list of strings can be provided
instead of an array. If a list item itself is an array
with exactly two strings, the first one is the detector
name and the second specifies the if statement to be
evaluated to determine the corresponding parameter.
Within the if statement, information about the dataset
can be accessed via the 'info' struct (see get_data_info).

If the 'debug' qualifier is given, the S-Lang code of
the fit-function is printed out as well.
##### Example

% RXTE consisted of two instruments: PCA and HEXTE
detconst_init(["PCA", "HEXTE"]);

% SUZAKU consists of six instruments: XIS0-3, PIN,
% and GSO. PIN and GSO are, however, within one detector
% called HXD (as in the FITS-header). Thus, identify
% these two instruments via the PHA-filename
detconst_init({"XIS0", "XIS1", "XIS2", "XIS3",
["PIN", "is_substr(info.file, \"hxd_pin\")"],
["GSO", "is_substr(info.file, \"hxd_gso\")"]
}; debug);

__See also__: detconst, get_data_info, add_slang_function

----

#### diff
##### Synopsis
 returns the differences between adjacent elements in an array

##### Usage
```c
 Double_Type diff(Double_Type[] array);
```

##### Description

a = sqr([1:4]); % [1,4,9,16]
b = diff(a);    % [3,5,7]

----

#### difmap_restore
##### Synopsis
 DIFMAP is used to restore a radio image with a new beam

##### Usage
```c
 String_Type outname = difmap_restore(String_Type <code>fitsfile</code>, Double_Type <code>smajor</code>, <code>sminor</code>, <code>pos_angle</code>)
```

##### Qualifiers

* chan: [=i] choose channel (i,q,u)
* xsize: [= key "NAXIS1"] number of RA pixels
* xsetp: [= key "CDELT1"] step size of each RA pixel in mas
* ysize: [= key "NAXIS2"] number of DEC pixels
* ysetp: [= key "CDELT2"] step size of each DEC pixel in mas
* uvtaper: [= " "] pply a uvtaper before restoring
* outname: [= "xxxxMHz_restore.fits"] filename of the output, be default the
frequency is read from the input file
* overwrite: overwrite file with outname if it already exists

##### Description

This function creates a radio image with a given beam using DIFMAP. The
new beam has to be defined by its semimajor and semiminor axis and its
position angle. The new images is saved in the current working directory.
It is assumed that the UVF and MOD files have the same basename as the
provided file name if the FITS image.

__See also__: make_spix

----

#### diskline2
##### Synopsis
 describes a line emission from a relativistic accretion disk

##### Description

norm    = photons/cm\*\*2/s in the spectrum

LineE   = line energy

Betor10 = power law dependence of emissivity.
If this parameter is 10 or greater then the accretion
disk emissivity law (1-sqrt(6/R))/R\*\*3 is used.
Otherwise the emissivity scales as R\*\*par2.

Rin     = inner radius (units of GM/c\*\*2)

Rout    = outer radius (units of GM/c\*\*2)

Incl    = inclination (degrees)

(The original diskline model uses Rin(M) and Rout(M).)

__See also__: diskline / Fabian et al., MNRAS 238, 729.

----

#### disk_map
##### Synopsis
 Plots the megamaser disk using the output of Mark
Reid's Bayesian disk fitting routine.

##### Usage
```c
 disk_map(infile);
```

##### Qualifiers

* radius: : size of the plotted disk radius, in mas, default: reference radius from file
* no_axes: : flag to turn off the axes
* no_los: : flag to turn off the line-of-sight bar
* no_disk: : flag to turn off the wireframe disk model
* no_data: : flag to turn off the data points
* no_grid: : flag to turn off the grid
* no_color: : flag to plot everything in greyscale
* scale: : flag to scale the size of the data points by SNR
* reverse_x: : flag to reverse the x-axis orientation; not used here
* side: : see the maser disk along the line-of-sight in the x-y-plane
* above: : see the maser disk from above in the x-z-plane
* projection: : projects the maser spots in addition to the 3d view to the 2d planes
* scalen: : half scale length of the axes; default 1.1\*radius of the disk, axes are [-scalen,scalen]
* scalen_frac: : distance from ticlabels to axes; default 1.05
* label_dist: : distance from labels to axes; default 1.3\*radius
* tics_length: : length of the tics; default 0.2

##### Description

Plots the megamaser disk using the output of Mark
Reid's Bayesian disk fitting routine. The input file for
this script is simply a text file containing the printout
of the Bayesian program. For instance, if the Bayesian
executable had the file name "fit_disk_v20\*", then the Unix command

./fit_disk_v20\* > input.prt

would generate the appropriate input file for this script.
This script is matched to version 20 of Mark's program.
The default view on the disk is at theta=120 and phi=-130,
with the x-axis showing upwards.

This function is rewritten from the IDL program disk_map.pro
from Dom Pesce in the version from July, 22, 2014.
##### Example

For a 2D plot from above:

isis> bla=disk_map("/userdata/data/litzinger/Radio/NGC1194/accel/disk_fitting/fit_disk_v20/jan2615/outjan2715";above);
isis> bla.render("disk_map_above.pdf");

or for a 3D plot with projection:

isis> bla=disk_map("/userdata/data/litzinger/Radio/NGC1194/accel/disk_fitting/fit_disk_v20/jan2615/outjan2715";projection);
isis> bla.render("disk_map.pdf");

Be careful!: If you plotted the 3d view and would like to plot
in 2d again you have to restart isis, as it still would plot in
3d view. To set the labels and tics correctly first plot the disk
with the default values and then change the values.

__See also__: xfig_3d_orbit_on_cube

----

#### distribution_triangle
<!--%{{{ -->
##### Synopsis
 Calculate 1D and 2D probability distributions

##### Usage
```c
 Struct_Type dm = distribution_matrix(Array_Type/List_Type v);
```
or

```c
 dm = distribution_matrix(Struct_Type v);
```

##### Qualifiers

* gridX: histogram grid for dimension X where X starts counting at 0
* gridXmin: [=min(vX)] bottom boundary for dimension X grid
* gridXmax: [=max(vX)] top boundary for dimension X grid
* n: number of grid points (only relevant for min/max)
* fields: Use only struct fields given in this name array (only
relevant if input is a struct)

##### Description

Calculates the probability distributions from a given high dimensional
set of state vectors (think MCMC results). The resulting structure
can be used with <code>xfig_plot_distribution_matrix</code> to plot the distributions
in a projection like triangle matrix.

__See also__: xfig_plot_distribution_matrix

----

#### dms2deg
##### Synopsis
 Convert angle in degree, minute, seconds to floating points degrees or radian

##### Usage
```c
 degree = dms2deg(d,m,s);
```

##### Qualifiers

* hours: If set, the coordinate is given in hour, minutes, sec (RA)
* radian: If set, return angle in radians, not degrees

##### Description

This is a convenience routine to convert astronomical coordinates given
in degrees, minutes, and seconds into a floating point number.
The sign of the highest non-zero argument decides the sign of the
returned floating point number. In other words: The routine tries to
be intelligent for negative declinations in the 0>=dec>-1 strip.
For example, if the declination is -0d 14' 30.2", call this routine
as dms2deg(0,-14,30.2).

This routine is array safe (as long as d, m, s are arrays of equal length).
##### Example

% Convert the coordinates
% alpha=19h 49m 35.49s and dec=-30d 12' 31.8"
variable ra=hms2deg(19,49,35.49);
variable dec=dms2deg(-30,12,31.8);

__See also__: hms2deg

----

#### dof

##### Synopsis
 Number of degrees of freedom

##### Usage
```c
 Double_Type = dof (hist_index);
```

##### Description

Use this function to retrieve number of
degrees of freedom.
##### Example

isis>xray = load_data("data.pha");
isis>variable num = dof(1);

__See also__: num_bin

----

#### dont_use_line
##### Synopsis
 sets the EW / amplitude of a line in the lines-model to zero

##### Usage
```c
 dont_use_line([id,] line);
```

##### Description

If <code>id</code> is not specified, <code>id=1</code> is used.
<code>line</code> is the name in the lines-model, appearing as parameters
<code>line_lam</code>, <code>line_EW</code>, <code>line_FWHM</code> and <code>line_A</code>.

__See also__: lines

----

#### dopplerorbit
##### Synopsis
 fit-function for the orbital Doppler shift factor

##### Usage
```c
 fit_fun("dopplerorbit(1; qualifiers) \* ...");
```

##### Qualifiers

* t90: switch to the time of mean longitude 90 degrees (see below)
* K: switch to velocity semi amplitude (see below)
* metacor: string array of structure-field-paths inside the meta-
data of the current dataset, which will be assumed to
be time in MJD and corrected for binary motion (default:
["time"]). Set to NULL to disable any correction.

##### Description

Calculates the radial velocoity, v_rad, of a star in a binary and
returns the corresponding Doppler factor, beta, given by
beta = (1 + V_rad/Const_c)
assuming that V_rad/Const_c << 1. The grid of the data (lo,hi)
the model is fitted to needs has to be the time in MJD.

The parameters of the fit-function are:
asini - semi major axis (lt-s)
or velocity semi amplitude (km/s)
porb  - orbital period (days)
tau   - time of periastron passage (MJD)
or time of mean longitude 90 degrees (MJD)
ecc   - eccentricity
omega - longitude of periastron (degrees)
v0    - systemic velocity (km/s)

In case the 't90'-qualifier is set, the parameter 'tau' has the
meaning of the time of mean longitude of 90 degrees. In case the
'K'-qualifiers is set, the parameter 'asini' has the meaning of
the velocity semi amplitude.

The influence of the binary motion is removed from the input
time-array 'lo' using 'BinaryCor'. The corrected times are saved
as 'binarytime' into the fitfun_cache of the fit-function. This
can be used by other fit-functions, like 'pulsartaylor'.

The fit-function also corrects time arrays inside the metadata of
the current dataset (Isis_Active_Dataset). The name of the fields
are set by the 'metacor'-qualifier, which is an array of strings
giving the "path" to the field. By default, the 'time'-field
inside the metadata is corrected in order to simplify the usage
of, e.g., 'pulsartorque'. The corrected times are save into the
'metacor'-struct inside the cache using the same "path".

__See also__: radial_velocity_binary, BinaryCor, KeplerEquation

----

#### Doppler_velocity
##### Synopsis
 calculates a Doppler velocity shift from a wavelength and the rest wavelength

##### Usage
```c
 Double_Type v = Doppler_velocity(Double_Type lambda, Double_Type lambda0);
```

##### Description

<code>v = (lambda-lambda0)/lambda_0 \* c;  %</code> speed of light <code>c = 299792</code> km/s

__See also__: get_line_velocity

----

#### dorDFT
##### Synopsis
 Timing Tools: Discrete Fourier Transform

##### Usage
```c
 dft = dorDFT(rate);
```

##### Description

Performs a Fast Fourier Transform on a given rate array with the
same properties as IDL FFT:
\* Normalization = sqrt(length(rate))
\* renormalize rate around 0 by subtracting mean such that
variability is calculated wrt. mean rate
\* return only meaningful bins for PSD calculations, i.e. first
bin up to Nyquist frequency

----

#### douglas_peucker
##### Synopsis
 Simplify polygons using the Douglas Peucker Algorithm

##### Usage
```c
 (xx,yy)=douglas_peucker(x,y,d2);
```

##### Description

This function implements an algorithm to simplify complex
polygons (Douglas & Peucker, 1973, Cartographica 10(2), 112).
A recursive version presented by Hershberger & Snoeyink (1992,
Proc. 5th Intl. Symp. on Spatial Data Handling, 134-143) is
used.
For a polygon P defined by positions in given by the arrays (x,y),
the algorithm returns the polygon P2 defined by coordinates (xx,yy)
with the property that the maximum distance between the lines segments
of P and P2 is smaller than sqrt(d2).
Note 1:
The algorithm only yields a good result if P is not self-intersecting.
Note 2:
As discussed by Hershberger & Snoeyink, the worst performance of
the Douglas-Peucker-algorithm is O(N^2). Hershberger & Snoeyink (1998,
Computational Geometry 11(3-4), 175-185) present a O(N log N) algorithm.
Unfortunately for me (J. Wilms), this algorithm is too complex to be
implementable on the ICE between Hamburg and Bamberg...
Note 3:
This function is called recursively and does not perform sanity checks on
x,y,d2. If you do not know about the properties of your data, use
simplify_polygon.

__See also__: simplify_polygon

----

#### draw_plot_commands
##### Synopsis
 creates plot commands for drawing lines with the mouse

##### Usage
```c
 draw_plot_commands();
```

##### Qualifiers

* init: [<code>=1</code>] initializes plot window at the beginning

----

#### draw_progress_bar
##### Synopsis
 Draw a progress bar

##### Usage
```c
 draw_progress_bar( position , maximum )
```

##### Qualifiers

* tip: String to draw tip of the arrow (default: ">")
* bar: String to draw bar of the arrow (default: "=")
* front: String to draw space in front of arrow (default: ".")
* append: String to append to each drawn progress bar (default: "")
* columns: Columns to use to write progress bar (default: Terminal width)
* fmt: Format to use for writing the percentage info in front of the bar.
The printing function gets passed the percentage of the current
state to the function as the second argument after the format
(default: "%.1f%%", for example 01.3%)

##### Description

Draw a progress bar across the prompt.
The width of the bar (arrow) is calculated from the fraction of
position/maximum. In case position is greater than maximum nothing happens.
Note that the function automatically determines the width of the current terminal.
This procedure takes some tens of milliseconds. The function can be sped by
setting the "columns" qualifier manually.

----

#### EasterSunday
##### Synopsis
 Calculate the JD or date of Easter Sunday for the Gregorian or Julian calendar

##### Usage
```c
 jd=EasterSunday(year)
```

##### Description

This function calculates the JD of Easter Sunday for the Gregorian or
Julian (=orthodox) calendar using the algorithms given by J. Meeus, 1998,
Astronomical Algorithms, 2nd ed, William-Bell.

The function either returns the JD (more precise: the JD at midnight
of Easter Sunday), or a struct with the same format as DateOfJD.

This function is array safe, i.e., an array of years can be given.

##### Qualifiers

* mjd: Return dates in  MJD, not in JD.
* orthodox: Return the JD of Easter Sunday using the rules
appropriate for Eastern Christianity such as the
Russian Orthodox church.
* get_date: Return date as a struct (year, month, date, hour,
minute, second). If the orthodox keyword is given,
the date will be in the Julian calendar, otherwise
it will be in the Gregorian calendar.
* backward: An undocumented function with the same name
as this one existed in the isisscripts until
17 January 2020. It returned the date of Easter Sunday
in the Gregorian calendar as the number of days
since -1 March (sic!) of the given year. This
qualifier switches the current function to this
backward compatible behavior.

__See also__: DateOfJD

----

#### EchoMap
##### Synopsis
 reprocesses a signal on a given surface

##### Usage
```c
 Struct_Type EchoMap(
Struct_Type surface, Struct_Type signal
Vector_Type observer[, Double_Type length]
);
```

##### Qualifiers

* c: defines the speed of light (default: 1)
* noFiniteC: infinite speed of light
* noDoppler: disable Doppler Shift
* powRedist: reference to a function returning the re-
distributed power of all surface elements
(i.e., all parameters are arrays!) in
direction to the observer. The parameters
passed are
\* the power to be redistributed
\* the cosine of the angle between the
element and the observer
\* the surface element as structure with
the corresponding fields as below
\* wether the passed power is the surface's
intrinsic one (1) or incident power (2)
\* a reference to a variable, which may be
set to 1 to trigger re-calculating the
powers (i.e. the given function is called
again for the two cases \*after\* it was
called for both cases in the first place;
might be useful if, e.g., the incident
power changes properties of the surface)
This function is called twice: (1) for the
intrinsic power of a surface element and
(2) the reprocessed relative (!!) power. The
last parameter specifies these two cases.
If you need to pass additional qualifiers
you may set the powRedistQual-qualifier
to a structure holding the qualifiers
(default: power\*cosine_to_observer)
* response: response function of a surface element,
see EchoMap_makelc for details
* reproment: instead of returning the echo signal the
reproment structure is returned (see text)

##### Description

This function propagates the given 'signal' on an object
defined by a 'surface'. There the signal is absorbed and
re-emitted (reprocessed) by each surface element. The
resulting response signal, as seen in direction to an
'observer', is returned by calling EchoMap_makelc after
all geometrical have been calculated (called reproment
here). If the corresponding qualifier is set, the latter
call is skipped and the reproment structure is returned
instead. This structure has the following fields:
visible_obs - boolean value if the surface is visible
visible_sig   by the observer and the signal origin
lt_surf - light travel times from the signal to the
lt_obs    surface and from there to the observing plane
doppler - Doppler factor in direction to the observer
flux_int - intrinsic flux of the surface as seen by
the observer
flux_rec - received signal flux of the surface
flux_emi - emitted relative flux of the surface as seen
by the observer

The following effects are taken into account during the
calculation of the response signal:
- light travel time between each surface element to the
signal source and to the observing plane
- Doppler shift by a moving surface
- effective areas and projection effects
- power redistribution function at the surface (qualifier
'powRedist')
- power response function of the surface (qualifier
'response', see EchoMap_makelc for details)

Restrictions:
- sqrt(surface.A) << vector_norm(surface.r-signal.origin)
(small surface elements relative to distance to source)
- surface.v << c
- vector_norm(observer) != 1
- signal fields have to be sorted by time

all qualifiers are passed to EchoMap_makelc

The 'surface' structure contains the surface elements,
defined by the fields
Vector_Type[] r - position vector to each element
Double_Type[] A - area of each element
Vector_Type[] n - normal vector of each element
Vector_Type[] v - velocity vector of each element
(optional)
Double_Type[] L - intrinsic power of each element,
which will be added to the response
signal (optional, in energy/time)
The 'signal' is treated as power (energy/time) as a
function of time and defined by the fields
Double_Type[] time  - lower time bin (in seconds)
Double_Type[] power - power in each time bin
Vector_Type origin  - position vector to the signal's
source (default: (0,0,0))
Any length is considered to be in units of the speed of
light (lt-s). If another unit is used, the internal speed
of light has to be changed via the 'c' qualifier.

__See also__: EchoMap_makelc, EchoMap_binary, Vectory_Type

----

#### EchoMap_binary
##### Synopsis
 reprocesses a signal on the companion of a binary

##### Usage
```c
 Struct_Type EchoMap_binary(
Struct_Type surface, Double_Type lum, Struct_Type signal,
Struct_Type orb, Double_Type phiorb, Double_Type mq
[, Double_Type length]
);
```

##### Qualifiers

* remark: : any qualifiers are passed to 'EchoMap'

##### Description

Uses the 'EchoMap' function to reprocess an input 'signal'
on the 'surface' of the secondary star with total luminosity
'lum'. The fields required for the 'surface' and 'signal'
structure are described in the 'EchoMap' help. The
'Roche_lobe_surface' function might be useful to calculate
the deformed surface of the star within the Roche potential.
Note, that the velocities of the surface elements are
calculated automatically if no 'v' field is specified. If
not specified, the luminosity field 'L' for each surface
element is calculated as well. Thereby, it is assumed that
each surface element has the same area luminosity, such
that the total luminosity still is 'lum'.
The orbit of the binary is described by the 'orb'ital
structure an has to contain the fields as described in the
'check_ephemeris' help. In addition, the inclination can
be specified optionally via the 'i' field. To complete the
description of the binary, the mass ratio
mq = M_primary / M_companion
has to be given at last.
As default, the source of the signal is the position of
the primary star. It can be changed by setting the 'origin'
field of the signal structur to the position vector.
Using the 'phiorb' parameter the orbital phase is defined,
which corresponds to the viewing angle on the binary.

As a conclusion and for further details the reference
frame is shown in the following:
<pre>
                                   position of M2 depending
      omega (right handed)         on orbital phase
      observer (i = 0)
        z                                 0.50
        |  y                              ---
        | /                              |   |
        |/                         0.75 |  x  | 0.25
    M1  o ---- x                         |- -|
       /                                   | observer
      o M2 (phiorb = 0)                  0.00
</pre>
- orbital plane = x-y-plane (fix)
- inclination and orbital phase is realized by rotating
the observer accordingly
- distance M_1 to M_2 = 1 (fix)

WARNING: at the moment circular orbits (ecc = 0) are
are implemented only!
NOTE:    for elliptical orbits, the shape of the stars
depends on the orbital phase

__See also__: EchoMap, Roche_lobe_surface

----

#### EchoMap_makelc
##### Synopsis
 takes reprocessing information to produce a response signal

##### Usage
```c
 Struct_Type EchoMap_makelc(
Struct_Type reproment, Struct_Type signal[, Double_Type length]
);
```

##### Qualifiers

* noDoppler: disable Doppler Shift
* response: reference to a function returning the
relative emissivity of a surface element
as response to an incoming power peak at
t = 0. For details see the description
(default: delta peak at t=0)
* surfsigs: reference to a variable, which will get the
output signal for each element (2dim-array
defined as [element,power]; use the time
from the returned total signal)

##### Description

Takes the 'reproment' structure of a former run of
EchoMap and returnes the output signal produced by
reprocessing the input 'signal' on the surface used
to caluclate the reproment (i.e., the geometrical
effect of the reprocessing). By default, the returned
power vs. time is the total response to the incomming
signal. However, if the optional argument 'length' is
provided, the input signal is periodically repeated
until the output signal has at least the given length.
Furthermore, the signal is repeated backwards in time
as well such that no rising or declining parts of the
echo is visible in the output.

By default, it is assumed that each surface element
mirrors the incoming power instantaneously. More complex
behaviour can be implemented easily using the 'response'
qualifier, which defines a function returning the
relative 'power' emissivity over 'time' (in seconds) of
a surface element. Furthermore, the response has to
fullfil energy conservation such that the integrated
power does not exceed 1, but may be less, i.e. power is
reprocessed via non-radiative processes. The time
resolution of the response has to be equal or better
than the input signal!

__See also__: EchoMap

----

#### ecliptical2equatorial
##### Synopsis
 convert ecliptical (lambda,beta) to equatorial coordinates

##### Usage
```c
 (alpha,delta)=ecliptical2equatorial(lambda,beta;qualifiers)
```

```
or

```c
 Vector_Type eqp=equatorial2ecliptical(ecl;qualifiers)
##### Qualifiers

* equinox: equinox of the transformation. Float: JD, string: equinox
designation (e.g., "J2000.0" or "B1950.0";
default: J2000.0)
* deg: interpret angular arguments in degrees (default is radians!)
applies also to the return value.
* mjd: interpret equinox as a MJD (default: JD)
* true: perform calculation for apparent coordinates, i.e., include nutation terms

##### Description

The routine takes coordinates in the ecliptical (lambda, beta)
system and converts them into equatorial coordinates (right ascension,
declination), using the obliquity of the ecliptic for the equinox
and vice versa.

Alternatively, the routine also accepts a Vector_Type and then
returns an Vector_Type vector in equatorial coordinates (or
vice versa if the inverse qualifier is given).

The default equinox is J2000.0.

This routine just calls equatorial2ecliptical with all arguments and the
inverse qualifier, but is a simpler interface.

__See also__: Vector_Type, equatorial2ecliptical, JDofEpoch,dms2deg,hms2deg

----

#### edit_var
##### Synopsis
 allows to edit S-Lang variables in an editor

##### Usage
```c
 edit_var(&x);
```
or

```c
 Any_Type y = edit_var(Any_Type x);

```

##### Qualifiers

* tmpfile: temporary file [default: /tmp/edit_var_$UID_$PID]

##### Description

edit_var supports the following data types:
- Undefined_Type (=Void_Type), Null_Type,
- Integer_Type, Double_Type, Complex_Type
- String_Type, BString_Type
as well as
- Array_Type
- Assoc_Type
- Struct_Type
- List_Type
in a recursive way. (Circular linked list
are currently not supported.)

S-Lang code defining the variable x is shown
in the editor specified by the EDITOR environ-
ment variable or jed, if EDITOR is undefined.
edit_var uses jed's folding mode (one should
run 'Buffers' => 'Folding' => 'Enable Folding')
for nested data structures, which can hence be
very easily investigated.

The S-Lang code for x can be modified. After
saving the temporary file and closing the editor,
the file is evaluated, which should return an
S-Lang object that is either stored in x
(if passed by reference) or returned.
##### Example

<code>i = edit_var(struct { uc='A', s=1H, us=1UH, l=1L, ul=1UL, ll=1LL, ull=1ULL });</code>

----

#### element2Z
##### Synopsis
 returns Z for an element symbol or name

##### Usage
```c
 z=element2Z(String_Type name)
```

##### Description

This function returns the nuclear charge for the given element symbol
symbol or element name.

This function is array safe.

__See also__: element_name, element_symbol

----

#### element_name
##### Synopsis
 returns the name of the element with proton number Z

##### Usage
```c
 String_Type element_name(Integer_Type Z)
```

##### Qualifiers

* lc: return symbol or name in lower case (default: Capitalized)

##### Description

This function returns the name of the element with
nuclear charge Z for all named elements.

This function is array safe.

__See also__: element_symbol,element2Z

----

#### element_symbol
##### Synopsis
 returns the symbol of the element with proton number Z

##### Usage
```c
 String_Type element_symbol(Integer_Type Z)
```

##### Qualifiers

* full: return full element name rather than symbol
* lc: return symbol or name in lower case (default: Capitalized)

##### Description

This function returns the symbol or the name of the element with
nuclear charge Z for all named elements.
Z=0 returns 'Bare'.

This function is array safe.

__See also__: element_name, element2Z

----

#### ellipse
##### Synopsis
 calculates points on an ellipse centered at the origin

##### Usage
```c
 (Double_Type X,Y) = ellipse(Double_Type smaj, smin, posang, phi)

```

##### Qualifiers

* x: [<code>=1</code>] compression/streching factor along the x-axis
* y: [<code>=1</code>] compression/streching factor along the y-axis

##### Description

This function calculates the coordinates <code>X</code>, <code>Y</code> of an ellipse with
semimajor axis <code>smaj</code>, semiminor axis <code>smin</code>, and position angle <code>posang</code>
(measured in rad with respect to the x-axis) which is parameterized with <code>phi</code>.
The complete ellipse is covered when <code>phi</code> covers the values from 0 to 2\*PI.
##### Examples

variable phi=[0:2\*PI:#200];
plot ( ellipse(5,3,0.2\*PI,phi) );
oplot( ellipse(5,3,0.2\*PI,phi ; x=0.5) );

__See also__: enclosing_ellipse

----

#### emcee--driver
##### Synopsis
 Set emcee parallel computation method

##### Usage
```c
 driver="method;options"
```

##### Description

The driver method can be set with the function string
"method;parameter"

Available methods:
serial : The serial driver. No parallelization at all

fork : The fork (& socket) parallel driver. Per default uses
_num_cpus many tasks.
; tasks : [=_num_cpus] Number of total processes used

mpi : The mpi parallel driver using as many nodes as registered
in an mpi environment

----

#### emcee--file
##### Synopsis
 Set emcee file input and output methods

##### Usage
```c
 input="method;options"
```
or

```c
 output="method;options"
```

##### Description

The file input/output methods can be set with the function string
"method;parameter"

Available methods:
fits : Fits file interface to write the chain as fits table extension
; filename  : [emcee-<date>.fits] The input/output file name.
; parameter : If given, on read we draw new starting positions from the
parameter settings stored in the file instead of reading
the last iterations.

mike : Fits file interface (compatible to previous emcee routine)
; filename  : [emcee-<date>.fits] The input/output file name.
; parameter : if given, on read we draw new starting position from the
header
; cycle     : [=50] the number of steps to calculate before writing to
file

par  : Parameter file interface to draw initial walkers from parameter
files.
; filename : [emcee-<data>.fits] Multiple parameter files can be separated
by a semi colon with an optional additional multiplier
(separated by a colon). A string of the form
'file1.par:2;file2.par' means that 2/3 of all walkers are
drawn from file1.par and 1/3 is drawn from file2.par.

----

#### emcee--init
##### Synopsis
 Set emcee initialization function

##### Usage
```c
 init="method;parameters";
```

##### Description

The initialization method can be set with the function string
"method;parameter"
Initialization methods that read from file use the defined input
method (default: fits).

Available methods:
uniform : Draw initial walker positions from a uniform distribution
within the parameter ranges.
; width : [=1.0] Sub range used for initialization (must be <= 1).
The initiale cube center coincides as much as
possible with the current parameter values.

gauss   : Draw initial walker positions from a gaussian distribution
within parameter ranges.
; sigma : [=0.1] Sigma of the gauss function in terms of the
parameter range. I.e, sigma=1 is the full parameter
range. Allowed range between 1e-3 and 2 (outside will
be cliped).

file    : Load initial walkers from a valid chain file created by the
emcee method. This is used with 'continue'. The parameter ranges
can be different compared to a previous run. This is also true
for the number of walkers. In order to truely continue a chain
those have to be set equal to the previous run.

chain   : Draw initial walkers from an approximated CDF of an existing
chain file.
; steps : [=10] The number of steps to concider for constructing the CDF
(from the end of the chain)
; rng   : [=&rand_uniform] uniform random number generator

----

#### emcee--progress
##### Synopsis
 Set emcee progress report

##### Usage
```c
 progress="method;options"
```

##### Description

To get a progress report for the running emcee
algorithm use one of the available options.

Available report methods:
none   : Do not report
report : Report the number of steps done every n steps
; n : [=50] Report for every n steps.
; overwrite : if given, overwrite last status (useful for
interactive sessions).
; format : [="Status: %D/%T (%%P)"] The report format
where %D is the current step, %T total steps and %P
the percentage.

----

#### emcee--step
##### Synopsis
 Set emcee step algorithm

##### Usage
```c
 step="method;options"
```

##### Description

The step algorithm can be set with the function string
"method;parameter"

Available algorithms:
stretch : The stretch move as described in Goodman & Weare 2010
; scale : [=2] Scale for the range of possible moves

----

#### emcee_chain_hist_collect
##### Synopsis
 Collect chain histograms from multiple emcee files

##### Usage
```c
 Struct_Type[] chist = emcee_chain_hist_collect( String_Type[] InFiles, Interger_Type[] PID )
```

```
or

```c
 Struct_Type[] chist = emcee_chain_hist_collect( String_Type[] InFiles )
##### Qualifiers

* chatty: If given, enable informative output.
* ncut: [=0] #sim. steps to be cut from the start of the chains.
* autocut: If given, 'ncut' is automatically set, s.t. the faulty sim. steps
containing ZERO entries are deleted. These entries corresponds
to the initialisation of the walkers.
* id[=0]: Index of the InFiles to check consistency to.
* nbin[=100]: Number of histogram bins.
* pmin: Double_Type[length(PID)]: Containing parmater lower limits.
* pmax: Double_Type[length(PID)]: Containing parmater upper limits.

##### Description

Generate parameter histograms by collecting chains from several FITS Infiles
created with emcee. It is required that all InFiles are based on the same model
and data. Only InFiles are having the same 'model' key and same 'free_par'
indices are taken into account.

IMPORTANT is that a common random number server was used for all InFiles to
ensure there statistical independency! This is not checked automatically!

Chains from InFiles (passed the check) for each parameter in 'pid' are collected,
that is added to a common histogram with 'nbin' bins. With 'pmin' and 'pmax'
the limits of the histograms can be set manually, where 'pmin'/'pmax' must
be an array of the same length as 'pid'.

'id' sets the index in InFiles, which is used to perform the consistency check.

With 'ncut' the number of simulation iterations at the beginning of the
the chains which should be cut away are set.
'autocut' can be used to set 'ncut' automatically, s.t. all iteration
steps related to the walker initialization are cut away.

__See also__: emcee

----

#### emcee_hammer
##### Synopsis
 Explore parameter space with MCMC method

##### Usage
```c
 emcee_hammer (Int_Type);
```

<!--%{{{ -->
##### Qualifiers

* Basic Qualifiers:
* walkers: [=10]: Number of walkers per parameter
* continue: If given (and possible set to a file) continue chain from this file
(using init="file", file="fits" per default)
* cont: same as 'continue'
* infile: Set the input file name for reading and continuing
* outfile: Set the output file name
* clobber: Ovwerwrite output file if exists
* Advanced Qualifiers:
* init: [="uniform" or "file"] The walker initialization method
* driver: [="mpi"] The parallelization method
* step: [="stretch"] The walker step algorithm
* input: [="fits"] The file reading method
* output: [="fits"] The file writing method
* progress: ="none"] Show progres
* urand: [=&rand_uniform] PRNG for uniform numbers (Double_Type[] = urand(Int_Type))
* upick: [=&rand_int] PRNG to chose complement walker (Int_Type[] = upick(Int_Type, Int_Type, Int_Type))

##### Description

The MCMC parameter space exploration algorithm as described by
Foreman-Mackey et al. The function expects that data and a model is loaded.
The only input parameter gives the number of iterations the algorithm
performs. The resulting walker positions are written to a file which can
be set with the "outfile" qualifier.

The function allows to choose other algorithms for the step proposition,
the read and write routines and how the walker ensamble is initialized.
To get more information about the methods read 'help emcee_<method>'.

Per default a new chain is started when the function is called. To continue
a chain use the "continue" qualifier. If the intention is to continue a
previous chain, make sure the paremter ranges are set to the same values as
for the previous run. <code>emcee_hammer</code> always uses the current settings.

To set a prior for parameters use the <code>set_fit_constraint</code> interface.
This ensures that the stored fit values are according to the posterior
and not just the likelihood.

__See also__: emcee--init, emcee--step, emcee--driver, emcee--input, emcee--file, emcee--progress

----

#### emcee_merge
##### Synopsis
 Merge emcee fits files

##### Usage
```c
 emcee_merge( String_Type[] InFiles, String_Type OutFile)
```

```
or

```c
 emcee_merge( String_Type[] InFiles )
##### Qualifiers

* chatty: If given, enable informative output.
* force: If given, overwrite existing OutFile.
* adjuststeps: If given, do not disregard InFiles with different #simsteps.
Instead cut all InFiles to min(#simsteps).
* ncut: [=0] #sim. steps to be cut from the start of the chains.
* autocut: If given, 'ncut' is automatically set, s.t. the faulty sim. steps
containing ZERO entries are deleted. These entries corresponds
to the initialisation of the walkers.
* id[=0]: Index of the InFiles to check consistency to.

##### Description

Merge several FITS Infiles created with emcee into one OutFile. It is required that
all InFiles are based on the same model and data. Only InFiles are merged that
have the same 'model' key and same 'free_par' indices compared to the first file
in InFiles.

IMPORTANT is that a common random number server was used for all InFiles to
ensure their statistical independency! This is not checked automatically!

InFiles (passed the check) are merged in a sense that the different walkers
from all InFiles are incorporated into a common chain, e.g., if InFiles are
two files with 5 free Parameters, 11 walkers and 1000 nsteps, respectively,
then the OutFile has 5 free Parameters, 22 walkers and 1000 nsteps.

To be able to merge this way NSTEPS in all InFiles has to be the same. InFiles
with different NSTEPS will be disregarded. With the 'adjuststeps' qualifier
it is possible to cut all InFiles to the mininmal occuring NSTEPS. NOTE that
this means to throw away simulation iterations in all InFiles.

With 'ncut' the number of simulation iterations at the beginning of the
the chains which should be cut away are set.

An existing OutFile can be overwritten with the 'force' qualifier.

If no OutFile is given, 'string_intersection' is used to determine the
OutFile path/name!

__See also__: emcee

----

#### empty_struct
##### Synopsis
 Returns a struct with 0 fields

##### Usage
```c
  Struct_Type = empty_struct();
```

##### Description

This function returns a struct with 0 fields,
which is usable with other funtions, e.g.,
struct_field_exists.

----

#### enclosing_ellipse
##### Synopsis
 calculates the smallest ellipse enclosing two ellipses centered at the origin

##### Usage
```c
 (Double_Type smaj,smin,posang) = enclosing_ellipse(Double_Type smaj1, smin1, posang1, smaj2, smin2, posang2)

```

##### Description

This function calculates the semimajor axis <code>smaj</code>, the semiminor axis <code>smin</code>,
and the position angle <code>posang</code> of the smallest ellipse enclosing
two ellipses centered at the origin.
##### Examples

smaj1 = 5.; smin1 = 2.; posang1 = 0.3;
smaj2 = 4.; smin2 = 1.; posang2 = 0.7\*PI;
variable phi=[0:2\*PI:#200];

plot ( ellipse( enclosing_ellipse(smaj1, smin1, posang1, smaj2, smin2, posang2) ,phi) );
oplot( ellipse(smaj1, smin1, posang1 ,phi) );
oplot( ellipse(smaj2, smin2, posang2 ,phi) );

__See also__: ellipse

----

#### energyflux
##### Synopsis
 evaluates the energy flux of the current fit model in a given energy range

##### Usage
```c
 Double_Type energyflux(Double_Type Emin, Emax)
```

##### Qualifiers

* factor: [=<code>1.001</code>] step size of the logarithmic energy grid
* Emin: minimum energy of (extended) grid
* Emax: maximum energy of (extended) grid
* cgs: return flux in erg/cm^2/s

##### Description

This function calculates the energy flux of the current best fit model
in keV/cm^2/s by integrating over the model on a logarithmic energy grid.
The logarithmic step size of the model is given by the <code>factor</code>
qualifier.

In other words, energyflux returns

<code>int_{Emin}^{Emax} E \* S_E(E) dE</code>  (in keV/s/cm^2)
where <code>S_E(E)</code> (in 1/s/cm^2/keV) is defined by <code>fit_fun</code>.

If the fit-function is a convolution model, e.g., Compton reflection,
it may be necessary to use an extended grid defined by the <code>Emin</code>
and <code>Emax</code> qualifiers.

Note: While physicists generally use the term ``flux density'' for
the quantity returned by this function, with the exception of radio
astronomy astronomers generally call the returned value the ``flux''.
The change in function name is based on the experience that most
users of isisscripts did not recognize that this function is what
they required.

__See also__: eval_fun, eval_fun_keV, luminosity

----

#### energyfluxdensity
##### Synopsis
 deprecated function

##### Usage
```c
 do not use
```

##### Description

This function had the wrong name. Please use the energyflux function
instead.

__See also__: energyflux

----

#### enflux (fit-function)
##### Synopsis
 fits the photon flux in a given energy range

##### Qualifiers

* norm: If given a reference to a variable, store the
normalization factor in there.

##### Description

This function can be used as a convolution model to determine
the energy flux [keV/s/cm^2] of the model in the energy range
given by <code>E_min</code> and <code>E_max</code>. Only bins within(!) this energy range
are considered for the calculation of the flux. The energy
flux is calculated by multiplying the photon flux in each bin
by the mean energy of the bin. For that reason the model should
be evaluated on a fine grid. It is strongly recommended to use
a very fine user grid for this purpose.
As this function fits the normalization of the total convolved
model, the normalizations of its components are not defined
absolutely, but only relativ to each others. For that reason it
is meaningful to freeze the normalization of one component, at
best the one of the continuum to avoid ambiguities during
fitting.

IMPORTANT:
1) E_min and E_max have to be completely covered by the data grid
2) the function requires a fine grid for evaluation
3) absolute normalizations of functions convolved with enflux are useless

If the 1) and 2) are not fulfilled by the data (RMF grid), a user
grid has to be used (see example). In case 1) the command:
<code>set_kernel (data_id, "std;eval=all");</code> is required in order to
evaluate the model on bins outside of the range of data set <code>data_id</code>
(see set_eval_grid_method).

##### Examples

% data definition:
<code>variable lo = _A([1:10]);</code>
<code>variable hi = make_hi_grid(lo);</code>
<code>variable my_data = define_counts(lo,hi,lo,sqrt(lo));</code>

<code>variable my_emin = 2.5;</code>
<code>variable my_emax = 6.5;</code>
% defining a fine user grid
<code>define fine_grid(id, s)</code>
<code>{</code>
<code>   (s.bin_lo,s.bin_hi) = _A(log_grid(1,10,1000));</code>
<code>   return s;</code>
<code>}</code>

<code>set_eval_grid_method (USER_GRID, my_data, &fine_grid);</code>

<code>fit_fun("enflux(1,powerlaw(1))");</code>

<code>set_par("enflux(1).E_min",  my_emin,  1); % keV</code>
<code>set_par("enflux(1).E_max",  my_emax,  1); % keV</code>
<code>freeze("powerlaw(1).norm");</code>
<code>()=fit_counts();</code>
<code>list_par;</code>

% It is also possible to determine only the flux of certain
% model components, e.g., the unabsorbed flux:
<code>fit_fun(phabs(1)\*enflux(1, powerlaw(1)));</code>

__See also__: phflux, set_eval_grid_method

----

#### enlarge_image
##### Synopsis
 enlarge an image to subpixel resolution by 2d interpolation

##### Usage
```c
 Double_Type IMG = enlarge_image(img, Integer_Type n);
```
or

```c
 Double_Type IMG = enlarge_image(img, Integer_Type nx, ny);

```

##### Qualifiers

* interp: reference to interpolation function (see below)
* y_first: interpolate first in y-, then in x-direction

##### Description

The pixels of <code>img</code> are mapped to every <code>nx</code>-th pixel
in x-direction and every <code>ny</code>-th pixel in y-direction
(in the first usage, nx = ny = n) of <code>IMG</code>:
<pre>
       IMG[ [::ny], [::nx] ] = img;
</pre>
As no extrapolation is performed at the boundary,
width and height of <code>IMG</code> are smaller than <code>nx\*w</code> and <code>ny\*h</code>,
where <code>w</code> and <code>h</code> are width and height of <code>img</code>.

Intermediate pixels are interpolated using the function
specified by the <code>interp</code> qualifier, which defaults to
<code>gsl->interpol_cspline</code> if the gsl module is available,
and otherwise to ISIS' <code>interpol</code> function. In general,
it can be a reference to any function of the form
<pre>
       newy[] = interpol(newx[], oldx[], oldy[]);
</pre>
All qualifiers of <code>enlarge_image</code> are passed to <code>@interp</code>.

The interpolation is first performed in x-direction
and then in y-direction -- unless the <code>y_first</code> qualifier
is specified. For linear and cubic spline interpolation,
the final result is independent of the order.

----

#### epatplot
##### Usage
```c
 epatplot(Struct_Type events);
```

----

#### epferror
##### Synopsis
 Estimate epoch folding uncertainty with Monte-Carlo simulation
approach.

##### Usage
```c
 (Double_Type err) = epferror(Double_Type time, rate, period[, rate_error]);
```

##### Qualifiers

* pstart: start period for epoch folding period search.
(default: 0.5\*period)
* pstop: stop period for epoch folding period search.
(default: 1.5\*period)
* ntrial: number of MC iterations. (default: 20)
* pget: function reference to determine the period from the
chi^2 landscape. Arguments passed are
Double_Type[] p, stat
as returned by epfold. Has to return the period and -1
if the period could not be determined. (default: find
maximum, see below)
* pdist: set to a variable reference in order to retrieve
the simulated period distribution.
* chatty: chattiness of this function: If >0 print some debug
messages. If >1 plot the chi^2 landscape at each MC
iteration. (default: 0)
* fchatty: chattiness piped to epfold.

##### Description

Note: All qualifiers are passed to pfold (for pulse profile
calculation) and epfold (for period search)!

This routine tries to estimate the uncertainty of a previously
received period using the epoche folding approach (see epfold).
It is adopted from the IDL script with the same name, but does
not yet allow for GTI or Poisson statistics. It implements the
following strategy:
1.) calculate a mean profile with given period.
2.) compute the intensity for all times applying the
period multiplied profile.
3.) simulate an uncertainty for all times (assuming normal
distribution with sigma = error, or, if not given
sqrt(rate)).
4.) perform epoch folding for that simulated lightcurve.
5.) determine the maximum of the epoch folding chi^2 landscape
and remember the corresponding period. Use the 'pget'
qualifier in order to implement a user-defined approach!
6.) go to step 2.) Ntrial times, which results in a distribution
of determined periods.
7.) compute the standard deviation of the period distribution
obtained and return this as the uncertainty of the intial
epoch folding

NOTE: The processing may last a long time (be prepared to wait
hours to weeks)!

NOTE: Is is _important_ to use the same qualifiers used for
epfold previously for the actual data! That is epferror
has to search for the period in the same way as for the
data! This might further require to provide a function
for the determination of the best period from an epoch
folding result (see 'pget' qualifier).

References:
Davies, S.R., 1990, MNRAS 244, 93
Larsson, S., 1996, A&AS 117, 197
Leahy, D.A., Darbro, W., Elsner, R.F., et al., 1983,
ApJ 266, 160-170
Schwarzenberg-Czerny, A., 1989, MNRAS 241, 153

----

#### epfold
##### Synopsis
 peforms epoch folding on a lightcurve in a given period
interval

##### Usage
```c
 (Struct_Type res) = epfold(Double_Type t, r, pstart, pstop);
```
or

```c
 (Struct_Type res) = epfold(Double_Type t, pstart, pstop) ; (event data)
```

##### Qualifiers

* nbins: number of bins for the pulse profile (default=20)
* exact: calculate the pulse profile in a more exact way, see description of pfold (not recommended as it takes a very long time!).
* dt: exposure of every lightcurve time bin, should be given to ensure correct results.
* sampling: how many periods per peak to use (default=10)
* nsrch: how many periods to search in a linear grid (default not set)
* dp: delta period of linear period grid (default  not set)
* lstat: use L-statistics instead of chi^2 statistics
* chatty: set the verbosity, chatty-1 is piped to pfold (default=0)
* gti: GTIs for event data, given as struct{start=Double_Type, stop=Double_Type}

##### Description

Performs epoch folding on a given lightcurve between the periods
pstart and pstop. The function was adopted from
the IDL routine of the same name. GTI correction only implemented
for event-data yet.

By default, periods are sampled according to the triangular rule
for estimating the period error, using "sampling" periods per peak.
If a linear grid is to be used, either "dp" for a given distance
between two consecutive periods or "nsrch" for a given number of
periods can be given. These qualifiers are mutually exclusive.

The returned structure "res" contains four fields: "p" for the
evaluated period and "stat" for the value of the statistic used.
Additionally the field "nbins" contains the number of phase bins
used and "badp" contains indices for res.p marking periods
where the pulse profile showd empty phase bins. Values of
res.stat[res.badp] should be taken with great care!

Compared to the similar function sitar_epfold_rate, epfold.sl
uses the chi^2 statistic as a default and is based on pfold.sl,
which can take errors of the lightcurve into account.
If the qualifier "lstat" is given, the statistic is switched to
the l-stat statistic as in sitar_epfold_rate, but errors of the
lightcurve are no longer taken into account. lstat is not
available for event-data.

If the "exact" qualifier is given, the function takes the exposure
time of every time bin into account in the sense that, that a
given time bin may overlap over two phase bins. The corresponding
exposure time in every phase bin is reduced accordingly.

NOTE: the "exact" qualifiers slows the script considerably down,
depending on the length of the lightcurve and the number of bins
for up to a factor of >100!

If "exact" is not given, the script is ~10% slower than
sitar_epfold_rate.

The script is still in the develepment phase, please report any
bugs or missing features to Felix
(felix.fuerst@sternwarte.uni-erlangen.de).

NOTE: Please read
Davies, S.R., 1990, MNRAS 244, 93 (L-statistics!)
Larsson, S., 1996, A&AS 117, 197
Leahy, D.A., Darbro, W., Elsner, R.F., et al.,1983, ApJ 266, 160-170
Schwarzenberg-Czerny, A., 1989, MNRAS 241, 153

----

#### epfoldpdot
##### Synopsis
 peforms epoch folding on a lightcurve in a given period
interval

##### Usage
```c
 (Struct_Type res) = epfoldpdot(Double_Type t, r, pstart, pstop);
or (Struct_Type res) = epfoldpdot(Double_Type t, pstart, pstop) ; (event data)
```

##### Qualifiers

* nbins: number of bins for the pulse profile
* exact: calculate the pulse profile in a more exact way, see description of pfold (not recommed as it takes a very long time!).
* dt: exposure of every lightcurve time bin, should be given to ensure correct results.
* sampling: how many periods per peak to use (default=10)
* nsrch: how many periods to search in a linear grid (default not set)
* dp: delta period of linear period grid (default  not set)
* lstat: use L-statistics instead of chi^2 statistics
* chatty: set the verbosity, chatty-1 is piped to pfold (default=0)
* gti: GTIs for event data, given as struct{start=Double_Type, stop=Double_Type}
* pdstart: start p-dot for grid search (default=0)
* pdstop: stop p-dot for grid search (default=0)
* pdnsrch: search point for p-dot grid, (default = nsrch
(if defined, otherwise 10))

##### Description

Performs epoch folding on a given lightcurve between the periods
pstart and pstop and period derivatives (p-dot) pdstart and pdstop.
The function was adopted from
the IDL routine of the same name. GTI correction only implemented
for event-data yet.

By default, periods are sampled according to the triangular rule
for estimating the period error, using "sampling" periods per peak.
If a linear grid is to be used, either "dp" for a given distance
between two consecutive periods or "nsrch" for a given number of
periods can be given. These qualifiers are mutually exclusive.

P-dot is always sampled on a linear grid with  pdnsrch points.

The routine uses the S-lang function 'parallel_map' to use
Isis_Slaves.num_slaves cores on your machine for parallel
computing. On a MacBook Pro with quadcorse i7 this gives a speed
improvement of a factor ~>2 over single core calculations.

The returned structure "res" contains five fields: "p" for the
evaluated period, pd for the evaluated period derviates,
and "stat" for the value of the statistic used. "stat" is a 2D
array of dimnesion (np, npd).
Additionally the field "nbins" contains the number of phase bins
used and "badp" contains indices for res.p marking periods
where the pulse profile showd empty phase bins. Values of
res.stat[res.badp] should be taken with great care!

Compared to the similar function sitar_epfold_rate, epfold.sl
uses the chi^2 statistic as a default and is based on pfold.sl,
which can take errors of the lightcurve into account.
If the qualifier "lstat" is given, the statistic is switched to
the l-stat statistic as in sitar_epfold_rate, but errors of the
lightcurve are no longer taken into account. lstat is not
available for event-data.

If the "exact" qualifier is given, the function takes the exposure
time of every time bin into account in the sense that, that a
given time bin may overlap over two phase bins. The corresponding
exposure time in every phase bin is reduced accordingly.

NOTE: the "exact" qualifiers slows the script considerably down,
depending on the length of the lightcurve and the number of bins
for up to a factor of >100!

NOTE: "exact" qualifier is currenlty untested and may lead to
erronoeus results!

If "exact" is not given, the script is ~10% slower than
sitar_epfold_rate.

The script is still in the develepment phase, please report any
bugs or missing features to Felix
(felix.fuerst@fau.de).

NOTE: Please read
Davies, S.R., 1990, MNRAS 244, 93 (L-statistics!)
Larsson, S., 1996, A&AS 117, 197
Leahy, D.A., Darbro, W., Elsner, R.F., et al.,1983, ApJ 266, 160-170
Schwarzenberg-Czerny, A., 1989, MNRAS 241, 153

----

#### EpochofJD
##### Synopsis
 Returns the Julian or Besselian epoch of a (M)JD

##### Usage
```c
 epoch=EpochofJD(jd;qualifiers)
```

##### Qualifiers

* mjd: argument is a modified julian date, not a JD
* besselian: return the Besselian epoch
* julian: return the Julian epoch (the default)

##### Description

This function converts a (modified) julian date into the corresponding
Julian or Besselian epoch (e.g., J2000, B1950.0 etc.) using the formulae
given by Lieske (1979, A&A 73, 282) for Besselian dates and the standard
definition of the Julian Date.

If high precision is relevant, note that JD is assumed to be in TT,
note that the epoch will slowly drift with respect to Gregorian year
fractions such as those calculated by jd2year, but contrary to that
function the Julian/Besselian epoch linearly maps to TT.

This routine is array safe.

__See also__: JDofEpoch,jd2year

----

#### equation_equinoxes
##### Usage
```c
  egam = equation_equinoxes(JD;qualifiers)
```

##### Qualifiers

* mjd: the time argument is in MJD, not in JD
* deg: return equation of equinoxes in degrees
* arcsec: return equation of equinoxes in arcseconds
* mas: return equation of equinoxes in milliarcseconds
* seconds: return equation of equinoxes in seconds

##### Description

This function calculates the equation of equinoxes, i.e., the
difference between the Greenwich Mean Siderial Time and the
Greenwich Apparent Siderial Time caused by the motion of the
equinox due to nutation. The implementation uses a truncated
form of a longer series due to the IERS (2003), given by
Eq. 2.14 of Kaplan (2009, USNO circular 181). The default
returns the equation of equinoxes in radian (more commonly
the values are tabulated in units of seconds).

This function is array safe.

__See also__: gmst,nutation_angles

----

#### equatorial2ecliptical
##### Synopsis
 convert equatorial (alpha,delta) to ecliptical (lambda,beta) coordinates

##### Usage
```c
 (lambda,beta)=equatorial2ecliptical(alpha,delta;qualifiers)
```

```
or

```c
 Vector_Type ecl=equatorial2ecliptical(eqp;qualifiers)
##### Qualifiers

* equinox: equinox of the transformation. Float: JD, string: equinox
designation (e.g., "J2000.0" or "B1950.0";
default: J2000.0)
* deg: interpret angular arguments in degrees (default is radians!)
applies also to the return value.
* mjd: interpret equinox as a MJD (default: JD)
* inverse: perform the conversion from ecliptical to equatorial
coordinates (see ecliptical2equatorial() for an
equivalent interface)
* true: perform calculation for apparent coordinates, i.e., include nutation terms

##### Description

The routine takes coordinates in the equatorial (right ascension,
declination) system and converts them into ecliptical coordinates
using the obliquity of the ecliptic for the equinox and vice versa..

Alternatively, the routine also accepts an Vector_Type and then
returns a vector in ecliptical coordinates (or vice versa if the inverse
qualifier is given).

The default equinox is J2000.0.

__See also__: Vector_Type, ecliptical2equatorial, JDofEpoch,dms2deg,hms2deg

----

#### equatorial2galactic
##### Synopsis
 convert J2000.0 equatorial (alpha,delta) to galactic (l,b) coordinates

##### Usage
```c
 (l,b)=equatorial2galactic(alpha,delta;qualifiers)
```

```
or

```c
 Vector_Type gal=equatorial2galactic(eqp;qualifiers)
##### Qualifiers

* deg: interpret angular arguments in degrees (default is radians!)
applies also to the return value.
* inverse: perform the conversion from galactic to equatorial
coordinates (see galactic2equatorial() for an
equivalent interface)
* blaauw: use the original Blaauw definition of the IAU galactic
coordinate system; see below for caveats

##### Description

The function takes coordinates in the equatorial (right ascension,
declination) system and converts them into galactic
coordinates (or vice versa, if the inverse qualifier is given) for
the IAU 1958 Galactic coordinate system (Blaauw et al., 1960,
MNRAS 121, 123).

Alternatively, the routine also accepts a Vector_Type and then
returns a vector in galactic coordinates (or vice versa if the
inverse qualifier is given).

The function is for J2000.0 coordinates only, use the
precess function to convert to that equinox if needed.

See Lane (1979, PASP 91, 405) for a discussion of the subtleties of
this conversion and Johnson & Soderblom (1987, AJ 93, 864) for a
non-standard derivation of the conversion matrix (the one used here
is basically identical, but uses proper Euler angles). By default,
the conversion is done using the precessed pole and inclination for
the FK5 system (J2000.0) given by Liu et al (2011, A&A 526, A16),
which is a thorough derivation of values that are essentially
identical to those also given in the appendix of Reid & Brunthaler
(2004, ApJ 616, 872).

If the qualifier Blaauw is given, then the coordinates are first
precessed to B1950.0 and then transformed. Note that this approach
is not good for the highest precision, since no conversion from,
e.g., FK5 to FK4 coordinates is performed as this would result in a
non-orthogonal coordinate system. Please use this qualifier only
if you know what you are doing and read Liu et al. (2011) before
using the qualifier.

__See also__: Vector_Type, galactic2equatorial,precess,dms2deg,hms2deg

----

#### equatorial2horizon
##### Synopsis
 convert equatorial (alpha,delta) to horizon (elevation, azimuth) coordinates

##### Usage
```c
 (azi,ele)=equatorial2horizon(alpha,delta;qualifiers)
```

```
or

```c
 Vector_Type hor=equatorial2horizon(eqp;qualifiers)
##### Qualifiers

* JD: JD for which the calculation is to be performed (in UT1/UTC). Mandatory.
* lon: geographic longitude of the observer, positive towards the east. Mandatory.
* lat: geographic latitude of the observer, positive towards the north. Mandatory.
* deg: interpret all angular arguments in degrees (default is radians!)
applies also to the return value.
* mjd: interpret JD argument as a MJD (default: JD)
* inverse: perform the conversion from horizontal to equatorial
coordinates (see horizontal2equatorial() for an
equivalent interface)

##### Description

The routine takes coordinates in the equatorial (right ascension,
declination) system for the equinox and ecliptic of the date
(i.e., "apparent coordinates"), and converts them into the elevation
and azimuth for a given observer's position and time. Note that
the JD, lon, and lat qualifiers are mandatory!

The JD argument is to be measured in UT1, for most cases it is sufficient to
approximate this as UT. Note that ephemerides work in TDB or TT, which has
an offset of several tens of seconds. For most applications this should not
matter, especially because of the uncertainty of refraction, but please take
this into account if highest precision is needed.

Formally the coordinates have to be topocentric coordinates in
order to include parallax effects. For most applications this is not
important as long as a precision of a few arcsec or worse is needed.
Eventually a routine applying all of these effects will be provided.

Alternatively, the routine also accepts an Vector_Type and then
returns a vector in horizon coordinates (or vice versa if the inverse
qualifier is given).

__See also__: Vector_Type, horizontal2equatorial, JDofEpoch,dms2deg,hms2deg,tai2tt,utc2tai,tt2tdb

----

#### eqwFit
##### Synopsis
 fit function for replacing a feature's norm by its equivalent width

##### Usage
```c
 eqwFit(id, continuum, feature1, ..., featureN)
```

##### Description

The so-called equivalent width of a feature in a spectrum
is a measurement for its flux F_{feature} compared to the
underlying continuum F_{continuum}. It is defined as the
width 'eqw' of a rectangle centered at the features
maximum or minimum 'E_0' and with a height equal to
the continuum at E_0:

$\int F_{feature}(E) dE = F_{continuum}(E_0) \* eqw$

As a result, the equivalent width stays constant if the
flux of continuum and the feature are correlated.

The equivalent width of a feature replaces its norm. Due
to that, the norm has to be at a fixed value, e.g, 1.
The fit function defined here then scales the feature
to the equivalent width, given as a fit parameter.
The function provies several fit parameters:
E_min  - lower energy boundary for the feature's flux
E_max  - higher energy boundary
widthN - the equivalent width of the Nth feature
multiN - if 1, the feature is considered to be
multiplied with the continuum, otherwise
its additive
The returned value of the fit function is the continuum
with all the given features applied!

\*IMPORTANT\*
The number of features the fit function can handle has
to be set beforehand via 'eqwFit_init'. Once set, the
number CAN NOT be changed afterwards. The number of
given features has to be fulfilled EVERY TIME the fit
function is used! If the function should be evaluated
for less features, the remaining features have to be
set to ZERO!

\*NOTE\*
Some multiplicative models do not provide a proper
normalization, such that the norm N is defined like

model = N \* ...

For example, although the gaussian absorption 'gabs'
has a depth 'tau', due to its definition

gabs = exp(-tau \* exp(...))

it CAN NOT be used with eqwFit properly! Instead,
use additive models to mimic a multiplicative one:

mygabs = 1 - egauss
##### Example

% init the fit function to handle two features
eqwFit_init(2);

% equivalent width of a single gaussian,
% the resulting model is equal to:
% powerlaw(1) + egauss(1)
fit_fun("eqwFit(1, powerlaw(1), egauss(1), 0)");%
set_par("eqwFit(1).width1", 300); % eqw = 300eV
set_par("eqwFit(1).multi1", 0); % additive
set_par("egauss(1).area", 1, 1); % freeze area

% equivalent width of an additive and
% multiplicative gaussian,
% the resulting model is equal to:
% powerlaw(1)\*(1 - egauss(2)) + egauss(1)
fit_fun("eqwFit(1, powerlaw(1), egauss(1), 1 - egauss(2))");
set_par("eqwFit(1).width2", 200); % eqw = 200eV
set_par("eqwFit(1).multi2", 1); % multiplicative
set_par("egauss(2).area", 1, 1); % freeze area

__See also__: eqwFit_init, eqw

----

#### eqwFit_init
##### Synopsis
 initializes the fit function 'eqwFit'

##### Usage
```c
 eqwFit_init(Integer_Type N);
```

##### Description

Defines and initializes the equivalent width fit
function 'eqwFit' to handle 'N' number of features.
Note, that the number has to be set before one can
use the fit function and that it can only be set once!

__See also__: eqwFit, eqw

----

#### erfinv
##### Synopsis
 Computes the inverse error function in abs(z)<1

##### Usage
```c
 Double_Type erfinv(Double_Type z);
```

##### Qualifiers

* eps: See description. Typically not needed.

##### Description

This function computes the inverse error function, i.e.,
erf(erfinv(x))=x. This can be used to calculate a confidence level by
<code>sqrt(2)\*erfinv(fraction)</code>

By default the function uses two fast polynomial approximations
by Mike Giles which have a relative accuracy of better than 1.2e-7
over the whole interval between 0 and 1.

If the eps qualifier is given, the method switches to a Newton-Raphson
method that terminates once the relative error of the function is
smaller than eps. This is significantly slower and only needed if
an extremely high precision is needed (pretty much never). On Joern's
laptop, this method needs on average 0.08ms per function evaluation
compared to 0.03 mus for the polynomial approximation.

The function is array safe.

__See also__: erf [in gsl],cerf,cerfc

----

#### erg2keV
##### Synopsis
 converts energy from erg to keV

##### Usage
```c
 Double_Type new_value = erg2keV(Double_Type old_value)
```

##### Qualifiers

* y_fac: : divide the value by 10^{y_fac}

__See also__: plot_unfold

----

#### err_map_gaussian
##### Synopsis
 plots data points with their errorbars

##### Usage
```c
 err_map_gaussian(x, [xErr,] y, yErr);
```
or

```c
 err_map_gaussian(Struct_Type s);

```

##### Qualifiers

* xerr:                change 3-argument-syntax to <code>err_map_gaussian(x, xErr, y);</code>
* xminmax:             changes the meaning of <code>xErr</code> -- and <code>x</code>, if <code>xErr</code> is not a list
* yminmax:             changes the meaning of <code>yErr</code> -- and <code>y</code>, if <code>yErr</code> is not a list
* minmax:              equivalent to both <code>x</code>- and <code>yminmax</code>
* x_pixel [=400]:      number of x-axis bins of the image
* y_pixel [=400]:      number of y-axis bins of the image
* i:                   index-array of subset of data points to be plotted
* xmin [=min(x data)]: minimal value of x-axis
* xmax [=max(x data)]: maximal value of x-axis
* ymin [=min(y data)]: minimal value of y-axis
* ymax [=max(y data)]: maximal value of y-axis
* min_xerr [=1e-10]:   minimal error for x-values
* min_yerr [=1e-10]:   minimal error for y-values
* xlog:                switch to logarithmic x-axis
* ylog:                switch to logarithmic y-axis

##### Description

Plots a 2D gaussian for each data point. The given errors are used as the
width(1 sigma) of the Gaussian profiles. If asymmetric errors are used, the
profile is the combination of two Gaussians. The volume of each profile is
normalized.

In order to use asymetric errors for x and/or y,
the correspondig <code>Err</code> argument has to be a list <code>{ Err1, Err2 }</code>.
If one of the <code>minmax</code> qualifiers is used,
the corresponding <code>Err</code> list contains directly minimum and maximum values.

If one of the <code>minmax</code> qualifiers is used, but <code>Err</code> is not a list,
the value and <code>Err</code> arguments actually mean minimum and maximum values.
The actual value is infered to be the mean of minimum and maximum.
##### Examples

% examples with symmetrical errorbars:

plot_image( err_map_gaussian([1,2], [0.1,0.3], [1,1], [0.5,0.3];xmin=0,xmax=3,ymin=0,ymax=2) );

% examples with asymmetrical errorbars:
plot_image( err_map_gaussian([1], {[0.1],[0.3]}, [1], {[0.1],[0.1]};xmin=0,xmax=2,ymin=0,ymax=2) );

__See also__: plot_with_err

----

#### eval_array
##### Synopsis
 evaluate an expression for an array of values

##### Usage
```c
 Array_Type eval_array(Type_Type type, String_Type expression, Array_Type values)
```
or

```c
 eval_array(String_Type expression, Array_Type values);

```

##### Qualifiers

* marker: [<code>="\*"</code>] place holder in the <code>expression</code> string,
where the <code>values</code> are to be inserted
* n_markers: [=all] number of markers in <code>expression</code> to be replaced;
if positive, the first <code>n_markers</code> are replaced,
if negative, the last <code>|n_markers|</code> are replaced.

##### Description

The <code>marker</code> string in <code>expression</code> is sequentially replaced with
each value of the array <code>values</code> (note that the values are converted
through the <code>string</code> function), and the resulting string is evaluated.
Unless <code>type==Void_Type</code>, each evaluation is expected to result in one value
of this <code>type</code>, and <code>eval_array</code> returns an array of all these values.
If <code>type==Void_Type</code> (which can be omitted), no return value is expected.
##### Examples

<code>%</code> set fields in an array of structures

<code>public variable s = Struct_Type[8];  _for $1 (0, 7, 1)  s[$1] = struct { a, b };</code>

<code>eval_array("s[\*].a = 1", [0:3]);  % =>  s[[0:3]].a = 1;</code>

<code>eval_array("s[\*].a = 2", [4:7]);  % =>  s[[4:7]].a = 2;</code>

<code>%</code> using the array several times

<code>eval_array("s[\*].b = \*",     [0:3]);               % =>  s[[0:3]].b =  [0:3];</code>

<code>eval_array("s[\*].b = \* \* 2", [4:7]; n_markers=2);  % =>  s[[4:7]].b =  [4:7] \* 2;</code>

<code>%</code> using a different marker to clarify the last example

<code>eval_array("s[#].b = 2 \* #", [4:7]; marker="#");   % =>  s[[4:7]].b =  2 \* [4:7];</code>

__See also__: array_map, array_struct_field, eval

----

#### eval_fun2_keV
##### Synopsis
 evaluate a fit-function on a user-defined energy-grid

##### Usage
```c
 flux = eval_fun2_keV(handle, E_bin_lo, E_bin_hi[, params[, args]]);
```

##### Description

The fit-function given by <code>handle</code> (<code>S_E(E)</code>) is evaluated
on an arbitrary grid  defined by <code>E_bin_lo</code> and <code>E_bin_hi</code> (in keV):

<code>flux = int_{E_bin_lo}^{E_bin_hi} S_E(E) dE</code>

The unit of <code>flux</code> is ph/s/cm^2/bin.

__See also__: eval_fun2, eval_fun_keV

----

#### eval_fun_keV
##### Synopsis
 evaluate the fit-function on a user-defined energy-grid

##### Usage
```c
 Double_Type flux[] = eval_fun_keV(Double_Type E_bin_lo[], E_bin_hi[]);
```

##### Description

The currently defined fit-function <code>S_E(E)</code> is evaluated
on an arbitrary grid  defined by <code>E_bin_lo</code> and <code>E_bin_hi</code> (in keV):

<code>flux = int_{E_bin_lo}^{E_bin_hi} S_E(E) dE</code>

Note that flux is bin integrated, i.e., the unit of <code>flux</code> is
ph/s/cm^2. To plot the flux density (ph/s/cm^2/keV), you need to
divide this quantity by the bin  width de=E_bin_hi - E_bin_lo.

__See also__: eval_fun

----

#### eval_simputfile
##### Synopsis
 evaluates the SIMPUT structure

##### Usage
```c
 Integer_Type sucess = eval_simputfile(Struct_Type str);
```

##### Description

This function evalutes the SIMPUT structure, created for example
with "get_simputfile_struct". Generally, all fields of the
structure == NULL are skipped.
##### Qualifiers

* quiet: don't show any output

__See also__: create_basic_simputfile,get_simputfile_struct,set_simputfile_model_grid,set_simputfile_flux

----

#### eval_xyfun
##### Synopsis
 evaluate current xy-function for points x [y]

<!--%{{{ -->
##### Usage
```c
 (Double_Type[] x, Double_Type[] y) = eval_xyfun(Double_Type[] x [, Double_Type[] y]);
```

##### Qualifiers

* id[=Isis_Active_Dataset]::  uses parameter and model for dataset #id

##### Description

Evaluate the current xy-model on the points (x,y)

__See also__: define_xydata, xyfit_fun

----

#### eval_xyfun2
##### Synopsis
 evaluate valid xyfit_fun string with parameters

<!--%{{{ -->
##### Usage
```c
 (Double_Type[] x, Double_Type[] y) = eval_xyfun2 (handle, x[ , y, par])
```

##### Qualifiers

* qualifier::  pass qualifier structure to function

##### Description

Evaluates function <code>handle</code> (either the name of a xy-function or reference)
on the points x (and y) with parameters <code>par</code>.

__See also__: eval_xyfun, define_xydata, xyfit_fun

----

#### exponential_xyfit
##### Synopsis
 linear xy fit function to be used with xyfit_fun

##### Usage
```c
 xyfit_fun ("exponential");
```

##### Description

This function is not meant to be called directly!

Calling <code>xyfit_fun ("exponential");</code> sets up a powerlaw fit
function for xy-data. It has the form <code>y = norm\*x^{-index}</code>

__See also__: xyfit_fun, define_xydata, plot_xyfit, linear_regression

----

#### ext_info_string
##### Synopsis
 converts the ext_line_info into a string

##### Usage
```c
 String_Type ext_info_string(Struct_Type info[, Integer_Type format])
```

##### Description

format=0 => string [default]

format=1 => PGPLOT

format=2 => TeX

__See also__: ext_line_info, ext_info_string

----

#### ext_info_string_PGPLOT
##### Synopsis
 converts the ext_line_info into a PGPLOT string

##### Usage
```c
 String_Type ext_info_string_PGPLOT(Struct_Type info)
```

__See also__: ext_line_info, ext_info_string

----

#### ext_line_info
##### Usage
```c
 Struct_Type info = ext_line_info(Integer_Type id);
```
or

```c
 Struct_Type info = ext_line_info(Integer_Type Z, Integer_Type ion, Integer_Type nr);

```

__See also__: line_info

----

#### e_bv
##### Synopsis
 Calculates the E(B_V) color excess after Predehl & Schmitt (1995)

##### Usage
```c
 Double_Type = e_bv(Double_Type N_H);
```

##### Qualifiers

* R_V: Scalar specifying the ratio of total to selective extinction
R(V) = A(V) / E(B - V). If not specified, then R = 3.1
Extreme values of R(V) range from 2.3 to 5.3

##### Description

From a given hydrogen absorption column density N_H in the diredtory
of the object, the color excess E(B-V) is calculated after
Predehl & Schmitt (1995): E(B-V) = N_H/(1.79e21\*R_V).

EXAMPLE
Calculate the color excess for Cen A (RA 13h25m27.6s DEC -43d01m09s) for
N_H = 8.09e20 and an "average" reddening of for the diffuse interstellar
medium (R(V) = 3.1).

isis> N_H = 8.09e20;
isis> ebv = e_bv(N_H);
isis> print(ebv);

__See also__: fm_unred;

----

#### factorial
##### Synopsis
 calculates n!

##### Usage
```c
 Double_Type factorial(Integer_Type n);
```

##### Description

<code>n</code>!  <code>=  n \* (n-1) \* ... \* 2 \* 1</code>

Note that <code>n</code> is always converted to an integer (without rounding);
for fractional <code>n</code> use, e.g., the GSL module's Gamma function.

__See also__: gsl->gamma

----

#### factorized_arf_rmf
##### Synopsis
 changes an ARF/RMF pair into factorized ARF/normalized RMF

##### Usage
```c
 (newARF, newRMF) = factorized_arf_rmf(ARF, RMF);
```

__See also__: factor_rsp

----

#### Faddeeva
##### Synopsis
 Compute w(z) = exp((-iz)^2 erfc(-iz) for complex z

##### Usage
```c
 Complex_Type[] Faddeeva(Complex_Type[]);
```

<!--%{{{% -->
##### Description

This function uses continued fraction expansion and the algorithms described by
Humlicek () and Hui () to compute an approximation to the Faddeeva function

The algorithm used only allows to compute w(z) for Im(z)>=0, but using the relation
w(-z) = 2\*exp(-z^2)-w(-z) gives the remaining half.

The derivative is given via dw/dz = 2i/sqrt(pi) - 2\*z\*w(z)

__See also__: Faddeeva_dz

It is claimed that the algorithm has an accuracy of <4e-4.

----

#### Faddeeva_dz
##### Synopsis
 Compute derivative of Faddeeva function

##### Usage
```c
 Complex_Type[] Faddeeva_dz (Complex_Type[]);
```

##### Description

Computes complex derivative of Faddeeva function

__See also__: Faddeeva

----

#### fake_pulsar_lightcurve
##### Synopsis
 creates a synthetic lightcurve of a pulsar

##### Usage
```c
 Struct_Type synthetic_pulsar_lightcurve(
Struct_Type lightcurve or Double_Type[] time,
Double_Type or Struct_Type period[, Struct_Type orbit
[, Struct_Type profile[, Struct_Type or Double_type fluxevolution
[, Ref_Type noise_fun]]]]
);
```

##### Qualifiers

* lcdt: time resolution of the input lightcurve in days
(default: difference of first two time bins)
* interpol: function reference used to to time-grid interpolations
(default: &interpol_points)
* pfold: structure of qualifiers to be passed to 'pfold'
(default: struct { nbins = 32, dt = ..., t0 = ..., pdot = ... })
* fluxlc: structure of qualifiers to be passed to 'pulse2pulse_flux_lc'
(default: NULL)
* tophase: structure of qualifiers to be passed to 'pulseperiod2phase'
(default: struct { t0 = ... })
* chatty: show or hide output messages (default: 1)

##### Description

This function fakes a pulsar's lightcurve including the following aspects:
- longterm flux evolution (on timescales larger than the pulse period)
- lightcurve modulation by pulse profile
- pulse period change including orbital motion
- gaussian or user-defined observation noise

Two modi are possible:
a) providing an observed initial lightcurve from which all needed aspects
are derived. A pulse period or its evolution is mandatory. Certain
aspects can be overwritten by user input. The resulting faked and
the input lightcurve have the same time-grid.
b) providing the output time-grid. The to be included aspects have to be
given explicitely.

__See also__: check_pulseperiod_orbit_struct,pulse2pulse_flux_lc,pulseperiod2phase,pfold

----

#### fancy_plot_unit
##### Synopsis
 Change the x-axis, and possibly the y-axis units, in the isis_fancy_plots package.

##### Usage
```c
 fancy_plot_unit( String_Type [, String_Type]);
```

##### Description

fancy_plot_unit(xunit [,yunit]);

Change the X-axis plot units to "xunit" (as for the ISIS command
plot_unit; and change the Y-axis unit to "yunit" (default yunit=
"photons").  These will be used for the functions: plot_counts,
plot_data, plot_unfold, plot_fit_model. Unit names are case insensitive.

Available X-units:

eV, keV, MeV, GeV, TeV,
Angstrom, A, nm, um, mm, cm, m,
Hz, kHz, MHz, GHz,
psd   (used for plotting power spectra from SITAR)

Available Y-units:

photons (default), mJy, ergs, watts, psd_leahy, psd_rms

Units added via add_plot_unit are also supported.

\*\*NOTE\*\*: Y-units photons/mJy/ergs/watts affect only plot_unfold, while
psd_\* are for plot_counts, but will also affect plot_data/plot_unfold.

Fundamentally, power=1 is proportional to photons/cm^2/s/xunit
(plot_unfold) or Counts/bin (plot_counts), with higher (lower) powers
multiplying (dividing) by xunit. plot_data is always Counts/sec/xunit
("power" has no effect).

mJy: y-unit for plot_unfold/power=2 is mJy.

ergs: y-unit for plot_unfold/power=3 (xunit=keV, etc.) or power=1
(xunit=A, etc.) is ergs/cm^2/sec.

watts: Similar behavior to the ergs unit, but yielding Watts/cm^2.

psd_leahy/psd_rms are for use with SITAR timing routines, and plot
Power Spectra in Leahy or (RMS/Hz)^2 units vs. Hz, using plot_counts.

__See also__: plot_unit, add_plot_unit, set_plot_labels, new_plot_labels

----

#### fermi2MJD
##### Synopsis
 calculate MJD from Fermi seconds

##### Usage
```c
 Double_Type = fermi2MJD (Double_Type);
```

##### Description

Calculates MJD(UTC) for a given Fermi Mission
Elapsed Time (MET) in seconds.
##### Example

variable m = 239557420.0;
variable fermi_s = fermi2MJD(m);

__See also__: MJD2fermi, MJDref_satellite

----

#### filter_gti
##### Usage
```c
 Integer_Type ind[] = filter_gti(Double_Type time[], Struct_Type gti);
or                      filter_gti(Double_Type time_lo[], time_hi[], Struct_Type gti);
```

##### Qualifiers

* minfracexp: minimum fractional exposure a time bin has to have,
otherwise it is considered bad (lightcurves only, default: 1e-4)
* fracexp: if set to a reference, returns the fractional exposure
of each time bin (lightcurves only)
* exposure: if set to a reference, returns the livetime
in each time bin (lightcurves only)
* indarray: return an array of index arrays instead (in case
of events only)

##### Description

For a lightcurve given by <code>time_lo</code> and <code>time_hi</code>, this function
returns all indices <code>ind</code> to the time bins, for which the fractional
exposure time as defined by the good time intervals defined by <code>gti</code>
is at least <code>fracexp</code>.

For a list of events measured at times <code>time</code>, return a list of indices
to all events that were measured during the given set of good time intervals.
The good time intervals are defined by a <code>struct {start,stop}</code> where
<code>start</code> and <code>stop</code> define the start and stop times.

The code assumes that
- time and time_hi are in ascending order
- the gti does not contain any overlapping intervals
- gti, time, and time_hi have the same unit

Warning: the function applies a time sorting to the gti if necessary. This
will MODIFY THE INPUT since structures are passed as references in S-Lang!

----

#### find_correlations
##### Synopsis
 calculates all correlations between columns of a table

##### Usage
```c
 Struct_Type info = find_correlatins(Struct_Type s);
```

##### Description

<code>info.corr[i] = correlation_coefficient(s.<info.x[i]>, s.<info.y[i]>);</code>

__See also__: correlation_coefficient

----

#### find_function_maximum
##### Synopsis
 looks for the position of a function's maximum value

##### Usage
```c
 Double_Type x0 = find_function_maximum(Ref_Type &f, Double_Type x1, Double_Type x2);
```
or

```c
 Double_Type x0 = find_function_maximum(Ref_Type &f, Double_Type x1, Double_Type x2, &f_x0);

```

##### Qualifiers

* qualifiers: structure of qualifiers to be passed to f
* eps: [=1e-12]

##### Description

<code>f</code> has to be a real function with one argument.
A binary search is performed to find <code>x0</code> such that

<code>f(x0)  =  max( f([x1:x2]) )</code>.

If <code>f</code> is not convex in <code>[x1:x2]</code>, the algorithm does not need
to succeed. Otherwise, the accuracy of <code>x0</code> is <code>(x2-x1)\*eps</code>.

__See also__: find_function_value

----

#### find_function_value
##### Synopsis
 computes an inverse function

##### Usage
```c
 Double_Type x0 = find_function_value(Ref_Type &f, Double_Type val, x1, x2);
```

##### Qualifiers

* qualifiers: structure of qualifiers to be passed to f
* eps: [=1e-12]
* quiet: do not show error message

##### Description

<code>f</code> has to be a real function with one argument.
A binary search is performed to find <code>x0</code> such that

<code>f(x0)  =  val</code> .

If <code>f</code> is not strictly monotonic in <code>[x1:x2]</code>, the algorithm does not
need to succeed. Otherwise, the accuracy of <code>x0</code> is <code>(x2-x1)\*eps</code>.

__See also__: find_multiargumentfunction_value, find_function_maximum

----

#### find_multiargumentfunction_value
##### Synopsis
 computes an inverse function

##### Usage
```c
 Double_Type xi0 = find_multiargumentfunction_value(Ref_Type &f, Double_Type val, x1, x2, ..., xn);
```

##### Qualifiers

* qualifiers: structure of qualifiers to be passed to f
* eps: [=1e-12]

##### Description

<code>f</code> has to be a real function with n arguments.
While <code>xi = [xi_min, xi_max]</code> is an array, <code>xj</code> (for <code>j!=i</code>) are constants.
A binary search is performed to find <code>xi0</code> such that
<code>f(x1, x2, ...,  xn)  =  val</code> for <code>xi = xi0</code>.

If <code>f</code> is not strictly monotonic for <code>xi_min < xi < xi_max</code>, the algorithm does not
need to succeed. Otherwise, the accuracy of <code>xi0</code> is <code>(xi_max-xi_min)/1e12</code>.

__See also__: find_function_value

----

#### find_peak
##### Synopsis
 Written for epoch folding purposes, it finds peaks of certain characteristics

##### Usage
```c
 Struct_Type find_peak(Struct_Type input)
```

##### Description

The input should be a Struct_Type of the form:
{ p, stat, [ lc ], [ nbins_epfold ] , [ expectation ] , [ sigma ] }
The individual fields are:
\* p, stat: arrays of doubles, the peak is looked for in stat
\* lc: struct { time, rate }, the original lightcurve
\* nbins_epfold: necessary in order to obtain an error estimate
\* expectation: approximate location of the peak in p
\* sigma: approximate error the expectation value has
lc and nbins_epfold reflect the original application of this function,
but it can be used without these arguments to find peaks in other
curves.
The output is a Struct_Type of the form:
{ period, error, [ profile ], err_area, err_theory, width_lo,
width_hi, statvsp, flags, [ bayes ], [ fit ], badness }
flags is a structure of indicators regarding the quality of the
output, badness is a coarse estimate how well the process worked.
A value of 0 is desirable, 1-2 could be acceptable, 3-4 is usually
an indication of bad input data and for larger values something has
seriously gone wrong. Fields marked [] will not be output if the
qualifiers chosen require it.
In the default configuration, this function works the following way:

(1) A bayesian block analysis finds possible maxima
\* if the block analysis fails, a smoothing algorithm is used
to remove noise in the curve, since the block analysis is
quite susceptible to noise
(2) The maxima are ranked considering:
\* the width (broad is an advantage, but very broad maxima in
comparison to dp = p^2 / T resp sigma are discarded)
\* the distance to the expected value, where anything within
sigma is ranked approximately equal
(3) Maxima with a quality exceeding the tolerance level are
taken and the accurate peak is found:
\* a first estimate is a weighted mean of points within the
maximum block
\* the accurate value is determined by fitting a given
xy-function to the peak. The proportion of dp used for
choosing the range for the fit is controlled by the
qualifier fit_part. If you do not expect considerable
secondary maxima, this variable can be set as big as 1.
However, if secondary peaks are expected to occur, a value
this large can make the fit useless.
(4) For each possible peak the lightcurve is folded and the
resulting pulse profile is examined. The peak corresponding to
the best overall result is taken.

If the fit_fct qualifier is used, the function has to have the following
parameters (in this specific order):
(1) peak
(2) measure for the height
(3) measure for the broadness of the peak
(4) absolute offset
(5) measure for the asymmetry of the peak
All qualifiers can also be passed using a structure named
'find_peak_qualifiers'. If this qualifier is given, its content will
overwrite all other qualifiers. If using this structure, all
qualifiers are expected to have values (i.e. only_max = 1). This is
helpful if you want to make things easier to read in scripts.

##### Qualifiers

* only_max: neither block analysis nor fit are performed
* blocks_but_only_max: block analysis is performed but only the highest bin in the best block taken
* weighting: weights for properties of a peak [area, sharpness, distance to expectation, profile quality] (default: [1,1,1,1])
* no_fit: nlock analysis is performed but only the first estimate taken
* fit_fct: an xyfit function for the fit, passed as a string (default: "sqrsinc")
* fit_part: measure for the part of the peak used for the fit (default: .3)
* tolerance: determines how many peaks are passed to step (4), in [0,1) (default: .99)
* smoothing: how strong the smoothing algorithm works (default: 10.)
* ncp_prior: argument for block analysis. If a string is given, the default block analysis routine will be used (default: 100)
* fp_rate: argument for block analysis, see its help
* no_profile: No pfold will be executed. Corresponds to tolerance -> 1 and less computation
* nbins_pfold: argument for pfold, see its help
* pfold_not_exact: changes how pfold is executed. Recommended as long as the exact-bug is not fixed
* exact: passes the information that the statistic was calculated using the exact qualifier
* flag_info: detailed information regarding the content of the flags structure is given, NOTHING else is done
* error_info: detailed information about the calculation of errors is given, NOTHING else is done
* chatty: boolean value (default: 1);

__See also__: pulseperiod_search, epfold, pulseperiod_epfold, split_and_epfold_lc, bayesian_blocks, pfold

----

#### first_valid_digit
##### Synopsis
 gives the position of the first valid digit

##### Usage
```c
 Integer_Type fvd = first_valid_digit( Integer/Double_Type x )
```

;

----

#### fitfun_cache
##### Usage
```c
 see below
```

##### Description

The so-called caching extension is part of the ISISscripts and not
an ISIS internal feature.

The caching extension provides an easy way to manage additional data for
the internal usage of user-defined fit-functions. The cache consists of
an slang structure for each defined dataset and fit-function using this
extension. This concept is similar to the metadata associated to each
dataset (see, e.g., 'get_dataset_metadata').

Inside of a user-defined fit-function, e.g., 'myfun' the cache for this
function and the current dataset (Isis_Active_Dataset) can be retrieved
by 'fitfun_get_cache':
<pre>
    define myfun_fit(lo, hi, pars) {
      ...
      variable cache = fitfun_get_cache();
      ...
    }
</pre>
Here, the variable 'cache' would hold the corresponding slang structure.
Since slang structures are internally passed and returned via references,
any changes of the fields of 'cache' are permanent.

In order to define and/or initialize the fields of the structure, one
has to call 'fitfun_init_cache' and providing the slang structure.
For the example above this could look like
<pre>
    fitfun_init_cache("myfun", &myfun_fit, struct { tempresult, lastpars });
</pre>
The caching extension can be used to, e.g., save temporary results from
calculations, which can then be retrieved once the model is evaluated
again. For this purpose it might be useful to also save the parameters
in a field like 'lastpars' into the cache, which can then be checked
against changes:
<pre>
    define myfun_fit(lo, hi, pars) {
      ...
      variable cache = fitfun_get_cache();
      if (any(cache.lastpars != pars)) {
        ...
      }
      cache.lastpars = pars;
      ...
    }
</pre>
Please read the documentation of 'fitfun_get_cache' and
'fitfun_init_cache' fot details and further examples.

__See also__: fitfun_get_cache, fitfun_init_cache, fitfun_cache_enabled

----

#### fitfun_cache_enabled
##### Synopsis
 returns whether the ISISscripts caching extension
for fit-functions is enabled (1) or disabled (0).

##### Usage
```c
 Integer_Type fitfun_cache_enabled();
```

__See also__: fitfun_cache, fitfun_enable_cache, fitfun_disable_cache

----

#### fitfun_disable_cache
##### Synopsis
 disables the ISISscripts caching extension

##### Usage
```c
 fitfun_disable_cache();
```

__See also__: fitfun_cache, fitfun_enable_cache, fitfun_cache_enabled

----

#### fitfun_enable_cache
##### Synopsis
 enables the ISISscripts caching extension

##### Usage
```c
 fitfun_enable_cache();
```

__See also__: fitfun_cache, fitfun_disable_cache, fitfun_cache_enabled

----

#### fitfun_get_cache
##### Synopsis
 return the cache for the current dataset and the given fit-function

##### Usage
```c
 Struct_Type fitfun_get_cache([String_Type fit-function_name]);
```

##### Description

The cached slang structure for the currently evaluated
fit-function and the current dataset (Isis_Active_Dataset) is
returned. In case caching is disabled (by 'fitfun_disable_cache')
a new structure as defined using 'fitfun_init_cache' is returned.

The optional and only parameter specifies the name of a
fit-function, which stack is to be returned. This allows to share
and access the cache between different fit-functions. If this
particular fit-function has not been evaluated yet (or is not
used in the current model) NULL is returned.

Note: if the number of bins of the data grid of the current
dataset changes, the cache is initialized again with the
structure defined by 'fitfun_init_cache'. This might be
necessary as soon as, e.g., the fit-function is
'eval_fun'ed on a user-grid.
##### Example

% use the cache inside a fit-function in order to save a temporary
% result, which depends on a subset of the input parameters only
define myfun_fit(lo, hi, pars) {
...
variable cache = fitfun_get_cache();
if (any(cache.lastpars[[:1]] != pars[[:1]])) {
% assuming that 'expensive_calculation' depends on the first
two fit-parameters
cache.tempresult = expensive_calculation(pars[0], pars[1]);
}
cache.lastpars = pars;
...
return cache.tempresult ...;
}

% retrieve the cache from another fit-function inside a fit-function
define mybetter_fit(lo, hi, pars) {
...
variable ocache = fitfun_get_cache("myfun");
if (ocache != NULL) {
ocache.tempresult ...
...
}
...
}

% investigate the temporary results after a fit from the command line
isis> Isis_Active_Dataset = 2; % get the cache for this dataset
isis> cache = fitfun_get_cache("myfun");
isis> print(cache.tempresult);

__See also__: fitfun_cache, fitfun_init_cache

----

#### fitfun_init_cache
##### Synopsis

##### Usage
```c
 fitfun_init_cache(String_Type fit-function_name, Ref_Type fit-function_handle, Struct_Type init_struct);
```

##### Description

Defines the structure, which is used to initialize the cache of the
the given fit-function. This should be called after a user-defined
fit-function, which uses caching, has been added to the list of
available models.

The first parameter 'fit-function_name' specifies the name of the
fit-function, 'fit-function_handle' is the reference to the actual
function calculating the model, and 'init_struct' is the structure
the cache will be initialized with for each dataset.
##### Example

% Define a new fit-function, add it to the list of available
% models, and initialize its cache with a structure with empty
% fields. Inside the fit-function 'myfun' the value of lastpars
% can be checked on NULL or changed parameters in order to
% trigger an expensive calculation.

define myfun_fit(lo, hi, par) {
...
}

add_slang_function("myfun", ["par1", "par2", ...]);

fitfun_init_cache(
"myfun", &myfun_fit, struct { tempresult, lastpars = NULL }
);

__See also__: fitfun_cache, fitfun_get_cache

----

#### fits_add_fit
##### Synopsis
 adds different saved models and observation info togethter in one FITS table

##### Usage
```c
 Struct_Type str = fits_add_fit(String_Type filename, String_Type save1
[,String_Type save2] [, ...);
or Struct_Type str = fits_add_fit(String_Type filename, Struct_Type save1
[, Struct_Type save2] [, ...);
```

or Struct_Type str = fits_add_fit(String_Type filename, Array_Type);
##### Description

This function is based on fits_save_fit and fits_load_fit_struct.
If called with String_Type filenames, these files are loaded with
fits_load_fit_struct, merged, and saved to the (new) file
"filename".
If called with Struct_Type, these structure should have been
created with fits_save_fit_struct, which will then be merged and
saved to "filename".
If called with Array_Type, the entries of the array should either
be strings loadable with fits_load_fit_struct or structures
created with fits_save_fit_struct.
It returns the merged structure.

__See also__: fits_load_fit_struct,fits_save_fit_struct,fits_write_fits_struct,fits_save_fit,merge_struct_arrays

----

#### fits_append_binary_table
##### Synopsis
 appends a binary table to the end of a FITS file

##### Usage
```c
 fits_append_binary_table(filename, [extname], data[, keys[, hist]]);
```

##### Description

This function employs functions from ISIS' cfitsio module
in order to open/create a FITS file,
<!--    find the number of HDUs, -->
<!--    move to the end of the file, -->
and append a binary table extension.
<!--\seealso{fits_open_file, _fits_get_num_hdus, _fits_movabs_hdu, fits_write_binary_table} -->

__See also__: fits_open_file, fits_write_binary_table

----

#### fits_append_extension
##### Synopsis
 appends a FITS extension to another FITS file

##### Usage
```c
 fits_append_extension(String_Type infiles[], String_Type outfile);
```

##### Description

As the external FTOOL fappend is used for this task,
<code>infiles</code> may contain extension numbers according to the FTOOLS conventions.
The extensions are appended at the end of <code>outfile</code>.

This function should usually not be used!
ISIS' cfitsio module allows to write several extensions
into a file after opening it with fits_open_file.

__See also__: fappend [FTOOLS], fits_append_tmp_extension

----

#### fits_append_tmp_extension
##### Synopsis
 appends a temporary FITS extension to another FITS file before deleting it

##### Usage
```c
 fits_append_tmp_extension(String_Type infiles[], String_Type outfile);
```

##### Description

As the external FTOOL fappend is used for this task,
<code>infiles</code> may contain extension numbers according to the FTOOLS conventions.
The extensions are appended at the end of <code>outfile</code>.
Afterwards, all <code>infiles</code> are deleted.

This function should usually not be used!
ISIS' cfitsio module allows to write several extensions
into a file after opening it with fits_open_file.

__See also__: fappend [FTOOLS], fits_append_extension

----

#### fits_column_unit_struct
##### Synopsis
 creates a structure of FITS header keywords containing the units of columns

##### Usage
```c
 Struct_Type fits_column_unit_struct(Struct_Type data; field1=unit1, field2=unit2)
```

##### Example

<code>variable data = struct { time, rate };</code>

<code>fits_write_binary_table("lc.fits", "lightcurve", data, fits_column_unit_struct(data; time="MJD", rate="counts/s/PCU") );</code>

__See also__: fits_write_binary_table

----

#### fits_conv_to_legal_char
##### Synopsis
 converts a string into legal characters to be used as a FITS column name

##### Usage
```c
 String_Type legal_str = fits_conv_to_legal_char(String_Type str);
```

__See also__: fits_save_fit

----

#### fits_get_hdu_names
##### Synopsis
 returns the names of all extensions within a FITS-file

##### Usage
```c
 String_Type[] fits_get_hdu_names(Fits_File_Type fp);
```

##### Description

Moves to the first extension of a FITS-file using
`_fits_movabs_hdu' and then iterates over all extensions
using `_fits_movrel_hdu' to read the 'EXTNAME' keyword.
The string array of all extension names is returned.

Note that the file-pointer is located at the last
extension in the end. Furthermore the first extension
has the index 1 (at least for `_fits_movabs_hdu'), which
has to be taken into account if the indices of the name-
array are used to find specific extensions.

__See also__: fits_open_file, fits_read_key

----

#### fits_lc_exposure
##### Synopsis
 returns the exposure time of a lightcurve,
given by a FITS-file, in seconds

##### Usage
```c
 Double_Type fits_lc_exposure(String_Type file)
```

----

#### fits_list_fit_pars
##### Synopsis
 Lists parameter values and confidence intervals for a file saved with fits_save_fit.

##### Usage
```c
 fits_list_fit_pars(String_Type fit.fits)
```

##### Description

When loading a previously saved fit with fits_load_fit, <code>list_par</code>
does not print the borders of the parameter confidence intervals saved
in appropriate fields of fit.fits.
Instead the parameter limits are printed.
As a work-around use this function to get a similar list as for
<code>list_par</code> including the confidence intervals if already determined.
##### Example

isis> fits_list_fit_pars("fit.fits");

__See also__: fits_save_fit,fits_load_fit

----

#### fits_load_fit
##### Synopsis
 defines the data and model of a FITS file written by 'fits_save_fit'

##### Usage
```c
 Integer_Type = fits_load_fit(String_Type filename[, Integer_Type index = 0]);
```

##### Qualifiers

* loadfun: data load function (defualt = &load_data)
The following format is neccessary:
Argument: String_Type Filename
Return:   Dataset ID
* nodata: do not load the data
* norebin: do not notice and rebin the data
* nomodel: do not define the model
* noff: do not set the fit function. Instead
only values of existing parameters
of the current model are loaded and
set. Maybe more useful in combination
with 'nodata' to just restore actual
fit parameters without overwritting
any additional (not saved) components
* noeval: do not evaluate the model
* noerr: do not load the systematic error fraction
* toeval: structure of qualifiers
passed to 'eval_counts'
* strct: reference to a variable to return the
structure loaded by fits_load_fit_struct
* ROC: array of values to set
Rmf_OGIP_Compliance for each
spectrum before loading
(default values = 2)

##### Description

This function restores the fit saved previously
by 'fits_save_fit'. That includes the loaded
data and the used model, which is evaluated at
the end.

__See also__: fits_save_fit, fits_load_fit_struct, fits_list_fit_pars

----

#### fits_load_fit_struct
##### Synopsis
 loads a FITS file written by 'fits_save_fit'

##### Usage
```c
 Struct_Type str = fits_load_fit_struct(String_Type filename);
```

__See also__: fits_save_fit

----

#### fits_modify_header
##### Synopsis
 modifies the header of a FITS file

##### Usage
```c
 fits_modify_header(String_Type filename, keyword, value[, comment]);
```

##### Description

fits_modify_header uses the external FTOOL <code>fmodhead</code> and is therefore deprecated.
Use <code>fits_update_key</code> from ISIS' cfitsio module instead.

__See also__: fits_update_key

----

#### fits_nr_extensions
##### Synopsis
 counts the extensions of a FITS file

##### Usage
```c
 Integer_Type fits_nr_extensions(String_Type filename)
```

##### Description

This function counts the number of extensions
in addition to the primary extension, i.e.,
returns <code>fits_num_hdus(filename)-1</code>.

__See also__: _fits_get_num_hdus, fits_num_hdus

----

#### fits_num_hdus
##### Usage
```c
 Integer_Type fits_num_hdus(String_Type filename)
```

##### Description

This function is just a wrapper around the
<code>_fits_get_num_hdus</code> function from ISIS' cfitsio module.

__See also__: _fits_get_num_hdus

----

#### fits_plot_rmf
##### Synopsis
 plots a redistribution matrix from a compressed RMF file

##### Usage
```c
 fits_plot_rmf(String_Type RMFfile);
```
or

```c
 (interpol_matrix_density, Ebounds, energ) = fits_plot_rmf(RMFfile; getvalues)

```

##### Qualifiers

* nx: number of pixels in x-direction [default=400]
* ny: number of pixels in x-direction [default=300]
* getvalues: retrieves the interpolated matrix density
* noplot: skip plotting, but retrieves the interpolated matrix density

__See also__: fits_read_rmf

----

#### fits_read_key_int_frac
##### Synopsis
 reads a keyword from a FITS file, which may be split in integer and fractional part

##### Usage
```c
 fits_read_key_int_frac(String_Type filename, key);
```

__See also__: fits_read_key

----

#### fits_read_lc
##### Synopsis
 reads a light curve file in FITS format

##### Usage
```c
 Struct_Type lc = fits_read_lc(String_Type filename[]);
```

##### Description

Reads light curves from <code>filename</code>, which can be
a globbing expression, an array of filenames or both.
If there are several light curves, they will be merged
into one data structure with ascending times.

The function assures that the returned structure contains
the fields <code>time</code>, <code>rate</code> and <code>error</code>.
The time field is always converted into Modified Julian Date
according to the MJDREF[{I,F}], TIMEUNIT and TIMEZERO keywords.
##### Qualifiers

* verbose: show the filename of the light curves when reading more than one
* cut: cut all fields but time, rate, error
* rate_per_PCU: divide count rate for RXTE-PCA light curves
by number of PCUs determined from the given filterfile
(\*.xfl, see 'RXTE_nr_PCUs_from_filterfile').
* time: [=<code>"time"</code>]: name of the time field, e.g., <code>"barytime"</code>;
if <code>!= "time"</code>, this field is renamed <code>"time"</code>,
overwriting any previously existing <code>time</code> field
* time_in_s: add structure fields for time in sec, MJDref
and T0 to the output structure
* filename: add filename structure field
* extension: add number of extension to be read

__See also__: fits_read_table, fits_read_key, fits_read_key_int_frac, RXTE_nr_PCUs_from_filename

----

#### fits_read_rmf
##### Synopsis
 retrieves a matrix from a compressed RMF file

##### Usage
```c
 Struct_Type rmf = fits_read_rmf(String_Type RMFfile);
```

##### Description

<code>rmf.matrix[j,i]</code> describes <code>rmf.ebounds.</code>\*<code>[i]</code> and <code>rmf.energy.</code>\*<code>[j]</code>.
##### Qualifiers

* check: checks rmf-normalization: <code>rmf.matrixsum_ebounds</code> is the sum over all ebounds, which should be 1.
* spec: <code>rmf.whitespectrum</code> is the sum over all ebounds, which should be 1.
* float: use for larger RMFs to be able to be loaded in isis.

__See also__: fits_plot_rmf

----

#### fits_read_unsigned_img
##### Synopsis
 reads an image of unsigned integers

##### Usage
```c
 Integer_Type img[] = fits_read_unsigned_img(String_Type filename);
```

----

#### fits_save_data_model_flux
##### Synopsis
 saves ISIS spectral data into a FITS file

##### Usage
```c
 fits_save_data_model_flux([filename[, ids]]);
```

----

#### fits_save_fit
##### Synopsis
 saves the model and info of the observation to a FITS table

##### Usage
```c
 fits_save_fit(String_Type filename[, Struct/String_Type conf]);
```

##### Description

This function saves information about the model and the observation
in a FITS table. This routine combines the calls of
<code>fits_save_fit_struct</code> and <code>fits_save_fit_write</code>.

Additionally, confidence intervals can be given in form of a
structure, containig the fields
<code>name</code>:      name of the parameter like given in fit_fun(...)
<code>value</code>:     best fit value of the parameter (might have changed
during error calculation)
<code>conf_min</code>:  lower confidence limit
<code>conf_max</code>:  upper confidence limit

Therefore, the conf-Structure would, e.g., look like

variable conf = struct {
name = ["powerlaw(1).index","powerlaw(1).norm"],
value = [2,1e-4],
conf_min = [1.8,1e-5],
conf_max = [2.2,2e-4]
};

Alternatively, the filename of a FITS table created by
pvm_fit_pars or the structure returned by pvm_fit_pars can be given.

The values of the model are overwritten, as the error calculation
should only yield values equal or better than the original ones.

##### Qualifiers

* info=Struct_Type: appends the given structure to the table
* hard_limits: also saves all hard limits of the parameters
* silent: no warnings are printed to STDOUT

__See also__: fits_load_fit_struct,fits_write_TeX_table,save_par,pvm_fit_pars,fits_save_fit_struct,fits_write_fits_struct,fits_list_fit_pars

----

#### fits_save_fit_struct
##### Synopsis
 saves the model and info of the observation to a structure

##### Usage
```c
 Struct_Type str = fits_save_fit_struct([, Struct/String_Type conf]);
```

##### Description

This function saves information about the model and the observation
in a structure table. Using fits_save_fit_write it can be written to a
fits file. See "help fits_save_fit" for more information.

__See also__: fits_save_fit,fits_load_fit_write

----

#### fits_save_fit_write
##### Synopsis
 writes a FITS table with info on model and observation

##### Usage
```c
 fits_save_fit_write([, Struct/String_Type conf]);
```

##### Description

This function saves information about the model and the observation
in a FITS table. It uses the structure created by
fits_save_fit_struct. Using self-created structures might lead to
strange results. See "help fits_savs_fit" for more information.

__See also__: fits_save_fit,fits_load_fit_struct

----

#### fits_wcs_struct
##### Synopsis
 creates a structure with a WCS that can be written to FITS file

##### Usage
```c
 Struct_Type fits_wcs_struct(String_Type filename)
```
or

```c
 Struct_Type fits_wcs_struct(Double_Type X[], Y[] [, String_Type xtype, ytype[, xunit, yunit]])

```

##### Qualifiers

* arrays: return a struct { ctype=[ctype1, ctype2], ... } with arrays
instead of struct { ctype1=ctype1, ctype2=ctype2, ... }.
This form is, e.g., required by ds9_put_wcs_struct.

##### Description

The (linear) World Coordinate System (WCS) can be read from a FITS file,
or can be defined from an array of <code>X</code> and <code>Y</code> values.

----

#### fits_write_arf
##### Synopsis
 Write a FITS ancilliary response matrix file

##### Usage
```c
 fits_write_arf(arfname,arf;qualifiers);
```

##### Qualifiers

* telescope: telescope for the ARF
* instrument: instrument for the ARF
* filter: filter of the instrument
* detnam: name of the detector
* exposure: exposure time associated with the ARF
* chantype: see FITS ARF specification (default: PI)
* origin: who write this file (default: ECAP)

##### Description

Write a FITS compliant ancilliary response matrix
arfname: name of the file to be written
arf: structure containing the following fields:
bin_lo, bin_hi: energy bounds (keV)
area: array of length(ebounds.bin_lo) containing the effective
area in cm^2
note: the energies given MUST be the same as the input energies
of the corresponding response matrix!

__See also__: fits_write_rmf

----

#### fits_write_arf_diff
##### Synopsis
 writes the difference of two ARFs in a corresponding FITS file

##### Usage
```c
 fits_write_arf_diff(String_Type arffile0, arffile1, arffile2);
```

##### Description

arf0  =  arf1 - arf2

The important header keywords are copied from arf1,
assuming that they are the are the same in arf2.

----

#### fits_write_binary_table_extensions
##### Synopsis
 writes a binary FITS table with several extensions

##### Usage
```c
 fits_write_binary_table_extensions(filename, data1, data2, ...);
```

##### Description

<code>data1</code>, <code>data2</code>, ... are either just the data structures
or a list of the arguments 2, 3[, 4[, 5]] of <code>fits_write_binary_table</code>:
<code>{ extname, data[, keys[, hist]] }</code>

This function should usually not be used!
ISIS' cfitsio module allows to write several extensions
into a file after opening it with fits_open_file.
##### Examples

<code>fits_write_binary_table_extensions("data.fits", struct { a1, b1 }, struct { a2, b2 });</code>

<code>fits_write_binary_table_extensions("data.fits",</code>
<code>                                   { "first", struct { a1, b1 } },</code>
<code>                                   { "second", struct { a2, b2 } });</code>

<code>fits_write_binary_table_extensions("data.fits",</code>
<code>                                   { "first", struct { a1, b1 }, struct { key11="value11"; key12="value12" } });</code>

----

#### fits_write_gti
##### Synopsis
 creates a FITS file with good time intervals

##### Usage
```c
 fits_write_gti(String_Type filename, Struct_Type gti, Double_Type MJDref);
```
or

```c
 fits_write_gti(String_Type filename, Double_Type start[], stop[], MJDref);

```

##### Qualifiers

* creator: [<code>="isisscripts:fits_write_gti"</code>] (XMM SAS needs an arbitrary value)
* date: [<code>="1998-JAN-01"</code>] (XMM SAS needs an arbitrary value)
* combineGTIs: [<code>=1</code>]: combine intervals that adjoin each other
* verbose: [<code>=1</code>]: tell when intervals are combined

##### Description

Good time intervals are organized as <code>gti</code> structures
containing arrays <code>START</code> and <code>STOP</code> of the corresponding times,
usually measured in s since the reference date <code>MJDref</code>.
(If <code>MJDref</code> is a string, the date is read from this file.)
Intervals that adjoin each other are combined.

The header keywords <code>creator</code> and <code>date</code> (according to the qualifiers)
are written to the primary header of the created FITS file.

__See also__: fits_write_binary_table

----

#### fits_write_image
##### Synopsis
 writes an image to a FITS file

##### Usage
```c
 fits_write_image(FITSfile[, extname], image);
```
or

```c
 fits_write_image(FITSfile, extname, image, [xvalues, yvalues[, xlabel, ylabel]][, comments]);

```

##### Qualifiers

* WCS: [=<code>""</code>]: world coordinate system to use, e.g. <code>"P"</code>

##### Description

It is assumed that <code>x</code>/<code>yvalues</code> (if provided) are linear arrays,
such that <code>CRVAL = values[0]</code> and <code>CDELT = (values[-1]-values[0])/(length(values)-1)</code>.
<code>x</code>/<code>ylabel</code> can be a "label [unit]" string.

__See also__: fits_write_image_hdu

----

#### fits_write_pha_file
##### Synopsis
 writes a spectrum to an OGIP PHA file inserting the required header keywords

##### Usage
```c
 fits_write_pha_file(String_Type filename, Integer_Type data)
```

```
or

```c
 fits_write_pha_file(String_Type filename, Array_Type data[, Array_Type stat_err])

##### Description

The 'filename' argument is the name of the output FITS file.

The 'data' argument can be either the index of a data set, in
which case the isis data set is written to a file,
an array containing the spectrum.
If the array is of IntegerType, the spectrum contains total counts,
If the array is of FloatType/DoubleType, the spectrum is given in counts/s.
(DoubleType arrays will be type-casted to FloatType.)

If 'data' is an array, then the statistical uncertainty is assumed
to be Poisson, unless the errors are given in the 3rd (optional)
argument of the function, 'stat_err'. Note that this argument is
mandatory for the case of count rate spectra.
If 'data' is an index to a data set, then the errors are taken
directly from the data set.

##### Qualifiers

* TELESCOP: the "telescope" (mission/satellite name) ["unknown"]
* INSTRUME: the instrument/detector ["unknown"]
* FILTER: the instrument filter in use (if any) ["none"]
* EXPOSURE: the integration time (in seconds) for the PHA data
(assumed to be corrected for deadtime, data drop-outs etc. ) [1.0]
* AREASCAL: nominal effective area [1.0]
* BACKFILE: the name of the corresponding background file (if any) ["none"]
* BACKSCAL: background scale factor [1.0]
* CORRFILE: the name of the corresponding correction file (if any) ["none"]
* CORRSCAL: the correction scaling factor [1.0]
* RESPFILE: the name of the corresponding (default) redistribution matrix file ["none"]
* ANCRFILE: the name of the corresponding (default) ancillary response file ["none"]
* HDUCLASS: should contain the string "OGIP" to indicate that this is an OGIP style file ["OGIP"]
* HDUCLAS1: should contain the string "SPECTRUM" to indicate this is a spectrum ["SPECTRUM"]
* HDUCLAS2: indicating the type of data stored: "TOTAL", "NET", "BKG" ["TOTAL"]
* HDUVERS1: the version number of the format ["1.2.1"]
* CHANTYPE: whether the channels used in the file have been corrected in anyway,
values: "PHA" or "PI" (see also CAL/GEN/92-002, George et al. 1992, Section 7)
["PHA"]
* start_channel: start value of 'channel' column [1]

__See also__: Definition of PHA FITS format: OGIP/92-007 and OGIP/92-007a

----

#### fits_write_rmf
##### Synopsis
 Write a FITS response matrix file

##### Usage
```c
 fits_write_rmf(rmfname,rmf;qualifiers);
```

##### Qualifiers

* telescope: telescope for the response
* instrument: instrument for the response
* filter: filter of the instrument
* detnam: name of the detector
* effarea: effective area of the detector (default: 1cm\*\*2)
* lo_thresh: lower threshold of the matrix, i.e., values below
this number have been set to zero. Default: 0.
* chantype: see FITS RMF specification (default: PI)
* channel: array of channel numbers for the ebounds extension
(default: channels are assumed to start at 1)
* origin: who write this file (default: ECAP)
* constantwidth: write data with width constantwidth around
maximum of the matrix.

##### Description

Write a FITS compliant response matrix
rmfname: name of the file to be written
rmf: structure containing the following fields:
ebounds (bin_lo, bin_hi): channel energies of the response matrix
energy (bin_lo, bin_hi): input energies of the response matrix
The response matrix can be given in two ways. For most decent resolution
instruments, define the matrix as
matrix[energy,channel]: with dimensions matrix[length(energy),length(ebounds)]
If this does not work (this is the case once the total array size exceeds
the limits imposed by s-lang), then define matrix as an Array of Arrays:
matrix=Array_Type[length(energy)];
and assign an Array_Type[length(ebounds)] to each element of matrix

Note: High resolution matrices can be VERY large. This code does not yet
write variable length arrays due to time reasons. As a work around it
is possible just to write information around the diagonal using the
constantwidth qualifier.

__See also__: fits_write_arf,fits_read_rmf

----

#### fits_write_sixte_vignetting
##### Synopsis
 write a vignetting file, which can be used in a Sixte instrument configuration XML file.

##### Usage
```c
 fits_write_sixte_vignetting((string) filename, energies, offaxangles [, phi = 0]);
```

##### Description

energies given in keV, offaxis angles given in arcmin

----

#### fits_write_tex_table
##### Synopsis
 creates a TeX table ready for input in your document.tex
file.

##### Usage
```c
 fits_write_tex_table(String_Type inputFile);
```

##### Qualifiers

* pars: model names given as an array
* exclude: parameters to exclude. One can give whole
parameter name as is written in the window output, or just a main
part of it (see examples below).
* extraInfo: extra information such as target name,
exposure, etc., the input name is given in
the fits header. This qualifier can lead to
nasty look of your table.
* texMulti: tries to fix long extraInfo output in your table.
* everyPar: parameter name as given can be used as a
qualifier itself for changing:
name, digits, factor and sciMode (see
TeX_value_pm_error on how to use them).
Example:
powerlaw_1_PhoIndex_value={"name","$\Gamma$","digits",3}

* sci: change scientific output in one step, for
an easier look of the value and its errors in the table.
sci=0   will give you maximally correct output.
sci=1   will also give you nice output, but may not
care about last significant digit.
* colNames: give new names for your output columns. Applicable
only when all names change.
* fullStat: prints also chi^2_red values.
* silent: No output generated.
* flip: flips the table.
* pdf: produces pdfout.pdf file for a quick look at
your table.
* output: TeX output name, default is "default.tex"

##### Description

- <code>inFile</code>   input fits file produced by fits_save_fit.
In the case of several files(in other words
fits for the same model) produced by fits_save_fit,
first add the files with fits_add_fit and use it in
fits_write_tex_table.

Parameter names, digits, factor output have
all default values, but that can be changed
with the last mentioned qualifer in the list
above.

NOTE: the function is still under development. Hence, it may
not be applicable to all available Xspec or local models.
If issues emerge, contact refiz.duro@sternwarte.uni-erlangen.de.

##### Example

fits_write_tex_table("input.fits";
pars=["cutoffpl","reflionx","diskbb","constant"]
,exclude=["diskbb_1_tin_value","norm"]
,constant_1_factor_value=["name","$c_\mathrm{PCA}$"]
,output="my_out.tex"
.extraInfo=["target","instrument"]
,target={"name","Source"}
,flip
,pdf);

will:
1.  use input fits_save_fit file "input.fits"
2.  look for components "cutoffpl" ,"reflionx", "diskbb" and
"constant" in your main model
3.  exclude parameter "diskbb_1_tin_value" and all parameters
with "norm" in the parameter name
4.  change name of now qualifier (actually a parameter)
"constant_1_factor_value" to $c_\mathrm{PCA}$
5.  write TeX output to my_out.tex
6.  include target and instrument information
7.  change name of "target" to "Source"
8.  flip your table
9.  produce a pdfout.pdf

__See also__: fits_save_fit, fits_add_fit,  TeX_value_pm_error%

----

#### fit_brute_force
##### Synopsis
 Performs a fit by stepping the given parameters and does a
usual fit for the remaining ones

##### Usage
```c
 Struct_Type fit_brute_force(Integer_Type[] par [, Double_Type[] stepsize])
or Struct_Type fit_brute_force(String_Type[] par [, Double_Type[] stepsize])
```

##### Qualifiers

* nofit: instead of fitting the remaining parameters the
model is just evaluated
* nomap: the chi-square map will not be created
* chatty: boolean value to show the remaining time
(default=1)

##### Description

For the given parameters the best fit of the actual model
is found by going through the complete parameter range.
The parameters can be passed as an array containing their
indices or names. The stepsize for each parameter can
either be given by the second `stepsize' parameter or the
intrinsic stepsizes are used, which can be set using a
qualifier of the `set_par' function. The latter can also
be used to determine the minimum and maximum value of each
parameter. While the given parameters are stepped the other
parameters of the model are fitted by the actual fitting
method, that means the function `fit_counts' is called.
If the qualifier `nofit' is given `eval_counts' is used
instead, evaluating the model without performing a chi-
square minimization.
This function is very similar to the `get_confmap' function.
But this function steps n given parameters in a very small
grid. In contrast it is possible to perform a fit for all
parameters of the model. However BE CAREFUL as the runtime
rises exponentially with the number of parameters!! For
this reason the function is chatty by default to show the
estimated remaining time during the fit.
The returned structure contains an array `bestpar' of the
best values found for each given parameter, the corres-
ponding reduced chi-square value `bestchi' and a structure
`chimap', which holds the chi-square values for each tested
parameter combination up to two given parameters. Because
this map may be very big its creation can be suppressed by
the `nomap' qualifier. In the structure the one or two
dimensional array (depending on the number of parameters)
`chisqr' contains the reduced chi-square values. In case of
two dimensions the first one specifies the second parameter
to directly pass it to image function like `plot_image'. The
corresponding parameter values are stored in the x-field for
the first parameters and y-field for the second one.

__See also__: get_confmap, fit_counts, eval_counts, set_par, plot_image

----

#### fit_gauss_to_img_noise
##### Synopsis
 fits a gaussian profile to the distribution of pixel values

##### Usage
```c
 mu,sigma = fit_gauss_to_img_noise(<code>img</code>)
```

##### Qualifiers

* grid_scale [="log"]: change between fitting on "lin" or "log" grid
* cut_nsig [=NULL]: set to <code>N</code> in order to ignore values above
<code>N</code> sigma after the first iteration
* keep_data: do not delete loaded data after fitting

##### Description

This function fits a Gaussian profile to the distribution of
pixel values in an image (arrays of different dimensions can be
given) and returns the center <code>mu</code> and the width <code>sigma</code> of the
best fit profile.
If the majority of pixels in the image include only noise values,
the obtained <code>mu</code> and <code>sigma</code> values characterize the mean value
(base level) of the noise and its amplitude.

NOTE: If the data is kept and further fitting is performed, the following
relation has to be considered <code>mu=get_par("gauss(1).center")+min(img)-1e-5</code>
(necessary to provide a proper grid for fitting).
##### Example

img = grand(500\*500);    % image with random numbers around 0 with sigma=1
reshape(img,[500,500]);
(mu,sigma) = fit_gauss_to_img_noise (img);

__See also__: plot_vlbi_map

----

#### fit_interactive
##### Synopsis
 Interactivly change parameters and evaluate the model

##### Usage
```c
 fit_interactive(Ref_Type plotfunction[, Any_Type arg0, arg1, ...]
```

##### Description

The Ref_Type 'plotfunction' is a reference to
the plot function, which has to be used (see
example below). Any additional arguments are
passed to this function as well as given
qualifiers.
The user may changes the parameters interactivly
by the following keys:
LEFT/RIGHT: increase/decrease value of active
parameter by one stepsize
UP/DOWN   : change active parameter
PGUP/PGDN : increase/decrease stepsize by one
order
t         : freeze/thaw active parameter
r         : change range of active parameter
v         : set value of active parameter
z         : set the internal step size used by
fit_counts
m         : modify fit function
f         : perform a fit by running fit_counts
s         : show/hide frozen parameter
p/P       : load/save parameters in 'parfile'
q         : quit interactive mode
Every time the value of a parameter is changed,
the model is evaluated automatically and the
given plot function is called.
Actual parameter values and the reduced chi-
square are printed out to the plot window.
The active parameter is shown in red, thawed
ones in black and frozen ones in gray. If the
parameter turns blue, one of the borders of the
range is reached.
##### Qualifiers

* parfile: filename, which is used to save or load
the fit parameters using 'save_par' or
'load_par', respectively. The user will
be asked for if 'parfile' is not set.
* plotscript: filename, used to load in a user-defined
plotting script. If not set, function
reverts to Ref_Type 'plotfunction'.

##### Example

variable id = load_data("example.pha");
fit_fun("cutoffpl");
fit_interactive(&plot_data, id; res=1);

The appearing plot window then is internaly
called by
plot_data(id; res=1);

__See also__: eval_counts, open_plot, keyinput

----

#### fit_line
##### Synopsis
 activates a line in the lines model and fits its parameters

##### Usage
```c
 fit_line([id,] line);
```

__See also__: lines

----

#### fit_pars
##### Synopsis
 computes single-parameter confidence limits for several parameters

##### Usage
```c
 Struct_Type results = fit_pars([Integer_Type pars[]]);
```

##### Qualifiers

* strict: [=1]: restarts the calculation if a new best fit was found
* saveoutput: [=1]
* basefilename: [=<date_time>]
* level: [=1]: specifies the confidence level. Values of 0, 1, or 2
indicate 68%, 90%, or 99% confidence levels respectively.
By default, 90% confidence limits are computed.
* chi2diff: if given, fit_pars invokes fconf instead of
conf with the value given to caluculate confidence in chi2
range. Defaults to 1.0.
* tolerance: convergence criterion for the calculation of the confidence
limits (see help for the conf command). Default: 1e-3

* quiet: If set, don't print any information on stdout
##### Description

The return value <code>results = struct { index, name, value, min, max, conf_min, conf_max, buf_below, buf_above, tex }</code>
is a table with the following information for each parameter:

<code>min</code> and <code>max</code> are the minimum/maximum values allowed.
<code>conf_min</code> and <code>conf_max</code> are the confidence limits.
<code>buf_below</code> (<code>buf_above</code>) is the fraction of the allowed range <code>[min:max]</code>
which separates the lower (upper) confidence limit from <code>min</code> (<code>max</code>).
If one of these buffers is 0, your confidence interval has bounced.

__See also__: pvm_fit_pars, conf, fconf

----

#### fit_pars_read_stdoutlogfile
##### Synopsis
 reads chi2-improvements from a stdout-logfile created by (pvm_)fit_pars

##### Usage
```c
 (t, chi2) = fit_pars_read_stdoutlogfile(String_Type filename);
```

##### Description

<code>t</code> is the number of seconds since the start of (<code>pvm_</code>)<code>fit_pars</code>.

__See also__: fit_pars, pvm_fit_pars

----

#### fit_steppar
##### Synopsis
 tries to obtain better fits for a stepped parameter

##### Usage
```c
 Struct_Type result = fit_steppar(String_Type parname, parfiles[]);
```

##### Qualifiers

* method: "optimize", "interpol_guess", or "eval_all"
* extrapol: allows for extrapolation as well
* fit [=1]:
* min_improvement:
* plot:
* verbose [=1]:

##### Description

----

#### flux2lum

##### Synopsis
 Calculates the source luminosity

##### Usage
```c
 Double_Type lum = flux2lum (Double_Type flux, Double_Type z);
```

##### Qualifiers

* silent:          If set, the program will not display adopted
cosmological parameters at the terminal.
* h0: [=70] Hubble parameter in km/s/Mpc
* omega_m: [=0.3] Matter density, normalized to the closure density,
default is 0.3. Must be non-negative.
* omega_lambda: [=0.7] Cosmological constant, normalized to the
critical density.
* omega_k: [=0] curvature constant, normalized to the critical density.
Default is 0, indicating a flat universe.
* q0: [=-0.55] Deceleration parameter, numeric scalar = -R\*(R'')/(R')^2

##### Description

This function calculates the luminosity of a source
given a <code>flux</code> in erg/s/cm^2 as well as a redshift <code>z</code> using
the cosmological parameters specified by the qualifiers
(which are passed to the function <code>cosmo_param</code>). The
distance is calculated with the function <code>lumdist</code>.
<code>Flux</code> and <code>z</code> can be scalars or vectors. Use
energyflux to calculate the flux.
##### Example

variable flux=3e-13;
variable z=0.0705;
variable l = flux2lum(flux,z);

__See also__: energyflux, cosmo_param, lumdist

----

#### fm_unred
##### Synopsis
 Deredden a flux vector using the Fitzpatrick (1999) parameterization

##### Usage
```c
 Double_Type = fm_unred(Double_Type[] wave, Double_Type[] flux, Double_Type ebv);
```

##### Qualifiers

* N_H: Hydrogen absorption column
* R_V: Scalar specifying the ratio of total to selective extinction
R(V) = A(V) / E(B - V). If not specified, then R = 3.1
Extreme values of R(V) range from 2.3 to 5.3
* LMC2: If set, then the fit parameters are set to the values determined
for the LMC2 field (including 30 Dor) by Misselt et al.
Note that neither 'AVGLMC' or 'LMC2' will alter the default
value of 'R_V' which is poorly known for the LMC.
* AVGLMC: If set, then the default fit parameters c1,c2,c3,c4,gamma,x0
are set to the average values determined for reddening in the
general Large Magellanic Cloud (LMC) field by Misselt et al.
(1999, ApJ, 515, 128)
* extcurve: If set to a variable as Ref_Type, the E(wave-V)/E(B-V)
extinction curve is returned, interpolated onto the input
wavelength vector
* gamma: Width of 2200 A bump in microns (default = 0.99)
* x0: Centroid of 2200 A bump in microns (default = 4.596)
* c1: Intercept of the linear UV extinction component
(default = 2.030 - 3.007 \* c2)
* c2: Slope of the linear UV extinction component
(default = -0.824 + 4.717 / R_V)
* c3: Strength of the 2200 A bump (default = 3.23)
* c4: FUV curvature (default = 0.41)
* wilm: If N_H value has been determined using wilm abundances and Verner
cross-sections use this updated correlation (Nowak et al., 2012)
* ngc3227: Use the reddening curve for NGC3227 after Crenshaw, D.~M.,
Kraemer, S.~B., Bruhweiler, F.~C., & Ruiz, J.~R. 2001, ApJ, 555, 633
provided locally in /home/beuchert/work/ngc3227/scripts/reddening/

##### Description

The unreddened flux vector of the input 'flux' is calculated on the
wavelength vector 'wave' using the Fitzpatrick (1999) parameterization.
The scalar 'ebv' is the color excess E(B-V). If a negative EBV is supplied,
then fluxes will be reddened rather than dereddened. If the scalar is not
known the hydrogen absorption column in the directory of the object must be
given as a qualifier and E(B-V) is calculated by
E(B-V) = N_H/(1.79e21\*R_V).

The R-dependent Galactic extinction curve is that of Fitzpatrick & Massa
(Fitzpatrick, 1999, PASP, 111, 63; astro-ph/9809387 ).
Parameterization is valid from the IR to the far-UV (3.5 microns to 0.1
microns). UV extinction curve is extrapolated down to 912 Angstroms.
This Function is adopted from the IDL-Function fm_unred.

The five input qualifiers 'gamma', 'x0', 'c1', 'c2', 'c3' and 'c4' allow the
user to customize the adopted extinction curve. For example, see Clayton et al.
(2003, ApJ, 588, 871) for examples of these parameters in different interstellar
environments.

EXAMPLE
Determine how a flat spectrum (in wavelength) between 1200 A and 6500 A
is altered by a reddening of E(B-V) = 0.5. Assume an "average"
reddening for the diffuse interstellar medium (R(V) = 3.1)

isis> wave = [1200:6500:#500];                               %Create a wavelength vector from 1200 to 6500 Angstrom with 500 steps between
isis> flux = 1.\*ones(500);                                   %Create a "flat" flux vector
isis> ebv = 0.5;                                             %Value for E(B-V)
isis> variable var;                                          %Referenz for extcurve
isis> funred = fm_unred(wave, flux, ebv; extcurve=&var);     %Redden flux vector
isis> plot(wave,var);                                        %Plots the extinctioncurve versus the wavelength

__See also__: e_bv;

----

#### foucalc
##### Synopsis
 calculates power-, cross power-, coherence- and timelag-spectra for timing analysis

##### Usage
```c
 Struct_Type foucalc(Struct_Type lc, Integer_Type dimseg)
```

##### Qualifiers

* verbose:
* normtype: normalization type of PSD data, can be <code>"Miyamoto"</code> [default], <code>"Leahy"</code>, or <code>"Schlittgen"</code>
* normindiv:
* avgbkg: array of average background rates for each energy band
* numinst: [<code>=1</code>] number of activated PCUs on XTE, required for noise correction
* deadtime: [<code>=1e-5</code>] detector deadtime in seconds
* nonparalyzable: Set this qualifier if the deadtime is non-paralyzable
* fmin: minimum frequency used for RMS calculation
* fmax: maximum frequency used for RMS calculation
* RMS: DEPRECATED, use rms qualifier instead.
* rms: reference to a variable to store the signal, noise RMS and error
of each light curve in the [fmin, fmax] band. Can only be used with
normtype="Miyamoto". The error is calculated using Vaughan
et al., MNRAS 345, 1271, 2003 Eq. 11.
* avgrate: reference to a variable to store the average rate of each light curve
* compact: compact the output structure, only keep the most important quantities
* noCPD: do not calculate cross power densities and derived quantities

##### Description

<code>lc</code> contains (properly segmented) light curves in several energy bands.
The best performance is achieved with a common structure of arrays,
<code>lc = struct { time=[t_1, t_2, ...], rate1=[r1_1, r1_2, ...], rate2=... };</code>.
[However, one can also use an array of structures (with an enormous overhead),
<code>lc = [ struct { time=t_1, rate1=r1_1, rate2=...}, struct { time=t_2, rate1=r1_2, rate2=... }, ... ];</code>.]
Also specifying "rate" instead of "rate1" is possible if no CPD
should be computed.

<code>dimseg</code> is the segment size used for the FFTs, which should therefore be a power of 2.

The returned structure contains the following fields:

- <code>freq</code>:
the frequency grid

- <code>numavgall</code>:
The bin <code>i</code> in all power spectra has been averaged over <code>numavgall[i]</code> original bins.
Here, <code>numavgall[i] = numseg</code>, as no frequency rebinning has been performed.

- Power spectra for each energy band:

\* <code>rawpsd</code>, <code>errpsd = rawpsd/sqrt(numseg)</code>, <code>noipsd</code>:
the raw power spectrum (from <code>makepsd</code>),
its error from the average over segments,
and the noise level (from <code>psdcorr_zhang</code>)

\* <code>sigpsd = rawpsd - noipsd</code>:
the signal power spectrum

\* <code>rawnormpsd</code>, <code>errnormpsd</code>, <code>noinormpsd</code>, <code>effnoinormpsd = noinormpsd / sqrt(numseg)</code>:
the normalized power spectrum,
its error, the noise level,
and the effective noise level in the normalized power spectrum

\* <code>signormpsd = rawnormpsd - noinormpsd</code>:
the signal in the normalized power spectrum

- Cross power spectra, coherence and time lag functions for each pair of energy bands:

\* <code>realcpd</code>, <code>imagcpd</code>:
real and imaginary part of the cross power density

\* <code>errrealcpd</code>, <code>errimagcpd</code>:
standard error on the mean of the averaged cross power density

\* <code>noicpd = ( sigpsd_lo \* noipsd_hi + sigpsd_hi \* noipsd_lo + noipsd_lo \* noipsd_hi ) / numseg</code>

\* <code>rawcof</code>, <code>cof</code>, <code>errcof</code>:
non-noise-corrected (raw) and noise-corrected coherence function and its one-sigma uncertainty

\* <code>lag</code>, <code>errlag</code>:
time lag and its one-sigma uncertainty

__See also__: makepsd, cross_power_density, colacal, psdcorr_zhang

----

#### foufreq
##### Synopsis
 Timing Tools: Calculation of the Fourier Frequency Array

##### Usage
```c
 Double_Type freq[] = foufreq(Double_Type time[]);
```

##### Description

Calculates the Fourier frequency array corresponding
to a given equally-binned time array.

----

#### fplot
##### Synopsis
 plots data and residuals from the fits-files created with 'save_plot'

##### Usage
```c
 fplot(filename, [color, [dataset]]);
```

##### Qualifiers

* flux: plot flux [photons/s/cm^2/keV] and not [counts/bin]
* overplot: Overplot previous plot
* type: defines what should be plotted. It can have the values 'model', 'data', 'res' (residuals),
'ratio', 'diff' (difference between model an data. By default model and data is plotted.)
* nolabel: The routine uses the labels given in 'plot_options' and does not create its own.
* space: If at the qualifer 'type' data, model or diff is chosen, one can specifiy if it is
plotted in counts/bin (by default), counts/keV/s ('density') or photons/keV/s/cm^2 ('flux').
* auto: Set the ranges automatically.
* xauto: Set the x-range automatically.
* yauto: Set the y-range automatically.
* unit: Specifies the unit of the x-axis. By default the unit from the fitstable is taken.
Possible values are 'keV' or Angstrom 'A'.

##### Description

This function is designed to plot the data which was saved with
'save_plot' in a fits-file. Using the qualifiers you can choose
how the data should be displayed. By default the model and the
data is plotted in counts/bin.

The data, model and diff qualifier can be combined with the
qualifier 'flux' in order to plot in photons/s/cm^2/keV instead of
counts/bin.

To define the colors of the plot, you have to provide an array of
colors. The length of the array is equal to the number of loaded
spectra, as each color is associated with the spectra in the same order
given in the fits-file.

If you provide the array 'dataset', only these spectra are
plotted. The numbers are assinged according to the order of the
single spectra in the extension of the fits-file. Using for
example 'fv <filename>', you can easily look up these numbers, as the
instrument which created the desired spectrum is also named in the
header of each extension.
##### Examples

% save one dataset in a fits-file
save_plot("my_data",1);
% plot data and model in flux and the residuals in an additional panel
% -the data should be in red, color(2) and the data in black, color(1)
% -the ranges are set automatically
multiplot([3,1]);
fplot("my_data",2;type="data",space="flux",auto);
ofplot("my_data",1;type="model",space="flux",auto);
ofplot("my_data",2;type="res",auto);

__See also__: save_plot

----

#### fread_struct
##### Synopsis
 Read binary data from a file into a pre-defined structure

##### Usage
```c
 fread_struct(Struct_Type s, File_Type fp);
```

##### Qualifiers

* char_to_string: convert fields of an array of chars (Char_Type[])
with length greater one into strings
* chatty: be verbose

##### Description

This function uses `fread' to reads binary data from a file into
the fields of a structure. All fields have to have a defined
data type! That is at least each field value has to be set to a
certain `DataType_Type'. In case field values are arrays, the
corresponding amount of objects of the array's data type are read
from the file. The fields have to be defined in the same order as
their corresponding objects should be read from the file. Note
that the function does not return anything, but the fields of the
given structure are updated instead! Finally, make sure to use
the correct number of bits to be read for each field. In doubt
always use, e.g., Int32_Type instead of Integer_Type as the
latter might depend on how S-lang was compiled.
##### Example

% define the structure to be read
variable s = struct {
count = Int16_Type, % first, read one 16-bit integer
list = Float32_Type[10], % secondly, read 10x 32-bit floats
msg = Char_Type[64] % finally, read 64x characters
};
% read the file
variable fp = fopen("mybinaryformat.file", "r");
fread_struct(s, fp; char_to_string);
()=fclose(fp);
% print the message, which will be a string due to the
% char_to_string-qualifier
message(s.msg);

__See also__: fread

----

#### freeParameters
##### Synopsis
 find all free parameters of the current fit-function

##### Usage
```c
 Integer_Type[] freeParameters()
```

##### Description

Free parameters are not frozen, tied to another one,
or derived as functions of other parameters.

__See also__: thawedParameters

----

#### frequency2velocity
##### Synopsis
 Calculate the velocity to a given frequency.

##### Usage
```c
 frequency2velocity(freq,restfreq);
```

##### Qualifiers

* veldef: The velocity definition which must be one of
OPTICAL, RADIO, or TRUE.  Defaults to RADIO.

##### Description

Convert frequency to velocity (m/s) using the given rest
frequency and velocity definition. The units (Hz, MHz, GHz, etc)
of the frequencies to convert must match that of the rest frequency argument.

Adopted from the gbtidl script freqtovelo.pro

----

#### FriendCastor1982_dMdot_dOmega_CygX1
##### Synopsis
 calculates the mass loss rate per solid angle for Cyg X-1

##### Usage
```c
 Double_Type FriendCastor1982_dMdot_dOmega_CygX1(Double_Type theta)
```

##### Description

<code>theta</code> is the angle from the binary axis in degrees.
The return value is in units of 1e-6 solar masses / year / sr.
(The total mass loss rate <code>2 pi int dMdot/dOmega(theta) sin(theta) dtheta</code>
is 2e-6 solar masses / year.)

__See also__: Friend & Castor (1982), Fig. 4

----

#### ftest_xspec
##### Synopsis
 calculates the F-test probability as in xspec

##### Usage
```c
 Double_Type ftest_xspec(chisq2, dof2, chisq1, dof1)
```

##### Description

The new chi-square and DOF, chisq2 and dof2,
should come from adding an extra model component
to (or thawing a frozen parameter of)
the model which gave chisq1 and dof1.
If the F-test probability is low then it is
reasonable to add the extra model component.

WARNING: It is not correct to use the F-test statistic
to test for the presence of a line
(see Protassov et al astro-ph/0201457).

----

#### gal2cel
##### Synopsis
 Transform Cartesian Galactic to celestial coordinates

##### Usage
```c
 gal2cel(Double_Types x[], y[], z[], vx[], vy[], vz[]; qualifiers)
```

##### Description

Transform right-handed, Cartesian Galactic coordinates (x [kpc], y [kpc], z [kpc], vx [km/s],
vy [km/s], vz [km/s]) with the Galactic center at the origin, the Sun on the negative x-axis
and the z-axis pointing to the north Galactic pole implying clockwise Galactic rotation when
seen from the half space with positive z to celestial coordinates (right ascension [h, m, s],
declination [deg, arcmin, arcsec], distance [kpc], radial velocity [km/s], proper motion in
right ascension times cosine of declination [mas/yr], proper motion in declination [mas/yr]).
##### Qualifiers

* SunGCDist: Sun-Galactic center distance [kpc];
default: 8.4 (see Model I in Irrgang et al., 2013, A&A, 549, A137)
* vxs: Sun's x-velocity component [km/s] relative to the local standard of rest;
default: 11.1 (Schoenrich, Binney & Dehnen, 2010: MNRAS 403, 1829)
* vys: Sun's y-velocity component [km/s] relative to the local standard of rest;
default: 12.24 (Schoenrich, Binney & Dehnen, 2010: MNRAS 403, 1829)
* vzs: Sun's z-velocity component [km/s] relative to the local standard of rest;
default: 7.25 (Schoenrich, Binney & Dehnen, 2010: MNRAS 403, 1829)
* vlsr: Local standard of rest velocity [km/s];
default: 242 (see Model I in Irrgang et al., 2013, A&A, 549, A137)
* GC_NGP: Celestial coordinates of the Galactic center and the north Galactic pole in the
format [ah_GC, am_GC, as_GC, dd_GC, dm_GC, ds_GC, ah_NGP, am_NGP, as_NGP, dd_NGP, dm_NGP, ds_NGP];
default: [17, 45, 37.224, -28, 56, 10.23, 12, 51, 26.282, 27, 07, 42.01] (Reid & Brunthaler, 2004, ApJ, 616, 872)

##### Example

(ah, am, as, dd, dm, ds, dis, vrad, pma, pmd) = gal2cel(-8.4, 0, 0, 11.1, 254.24, 7.25);
% -> Sun's position and velocity
(ah, am, as, dd, dm, ds, dis, vrad, pma, pmd) = gal2cel(0, 0, 0, 0, 0, 0);
% -> Galactic center's position and velocity
(ah, am, as, dd, dm, ds, dis, vrad, pma, pmd) = gal2cel([-8.4,0], [0,0], [0,0], [11.1,0], [254.24,0], [7.25,0]);
% -> position and velocity of Sun and Galactic center stored in the same array
(ah, am, as, dd, dm, ds, dis, vrad, pma, pmd) = gal2cel(-8.4, 0, 0, 11.1, 254.24, 7.25;
GC_NGP=[17, 45, 37.1991, -28, 56, 10.221, 12, 51, 26.2755, 27, 7, 41.704]);
% -> use non-standard coordinates for Galactic center and north Galactic pole
(ah, am, as, dd, dm, ds, dis, vrad, pma, pmd) = gal2cel( cel2gal(17, 45, 37.224, -28, 56, 10.23, 8.33, -11.1, -2.91, -5.12) );

__See also__: cel2gal, rad2RD

----

#### galactic2equatorial
##### Synopsis
 convert galactic (l,b) coordinates to J2000.0 equatorial (alpha,delta)

##### Usage
```c
 (alpha,delta)=galactic2equatorial(l,b;qualifiers)
```

```
or

```c
 Vector_Type eqp=equatorial2galactic(gal;qualifiers)
##### Qualifiers

* deg: interpret angular arguments in degrees (default is radians!)
applies also to the return value.

##### Description

The function  takes coordinates in the galactic (l,b) system
and converts them into the equatorial J2000.0 system. Alternatively
the routine also accepts a Vector_Type and then returns a
vector in equatorial coordinates for J2000.0.

The function is for J2000.0 coordinates only, use the
precess function to convert the result to another equinox
if needed.

See the description of the function equatorial2galactic for
references and further information. This routine is just a
wrapper around that function, with the qualifier "inverse" set.

__See also__: Vector_Type, equatorial2galactic,precess,dms2deg,hms2deg

----

#### galactic_rotation_velocity
##### Usage
```c
 Double_Type galactic_rotation_velocity(Double_Type r; model=m)
```

##### Qualifiers

* model: <code>m=1</code> selects Model I (B&T, Fig. 2.20), <code>m=2</code> selects Model II (B&T, Fig. 2.22)
If neither <code>m=1</code> nor <code>m=2</code> is specified, the constant 220 is returned.

##### Description

<code>r</code> is the distance from the Galactic Center in kpc.
(<code>0.18 <= r <= 11.9</code> is covered by a lookup table.)
The return value is the Galactic rotation velocity in km/s.

__See also__: J. Binney & S. Tremaine: Galactic Dynamics (2nd ed.), Sect. 2.7 (pp. 110ff)

----

#### galaxy_elliptical (fit-function)
##### Synopsis
 fits a host galaxy in the optical/UV

##### Description

This function fits an elliptical host galaxy to the data, taking into
account the redshift z.

##### Examples

% data definition:
load_data("optical.pha");
fit_fun("galaxy_elliptical(1)+powerlaw(1)");

----

#### galLB_from_RAdec
##### Synopsis
 convert equatorial (RA, dec) coordinates to galactic (l, b) coordinates

##### Usage
```c
 (l, b) = galLB_from_RAdec(RA, dec);
```

##### Qualifiers

* ra_unit :  [<code>="deg"</code>]: set the unit of the right ascension <code>RA</code>
<code>l_unit="rad"</code> <code>=></code>  <code>RA</code> in rad
<code>l_unit="hms"</code> <code>=></code>  <code>RA</code> in hours as a scalar
or an array of the form <code>[H, M]</code> or <code>[H, M, S]</code>
* dec_unit:  [<code>="deg"</code>]: set the unit of the declination <code>dec</code>

##### Description

This function is deprecated. Please use equatorial2galactic instead.

__See also__: equatorial2galactic,galactic2equatorial

----

#### galridge (fit-function)
##### Synopsis
 model for Galactic Ridge Emission

##### Description

Model for Galactic Ridge emission based on measurements
and analysis by:
Ebisawa, K., et al., 2008, PASJ, 60, S223-S230
Obst, M., 2011, Bsc-Thesis, Remeis observatory

The model consists of two bremsstrahlung continua and
three gaussian emission lines, which originate from
neutral, hydrogen- and helium-like Fe K_alpha lines
at 6.40, 6.67 and 7.00 keV:
2\*bremss + 3\*egauss
The equivlant widths (areas) of those lines are set to
free by default, but scaled initially by
85:458:129
as found by Ebisawa. To fix those ratios or different
ones, one might use 'set_par_fun', e.g.

set_par_fun("galridge(1).Fe67","galridge(1).Fe64/85\*458");
set_par_fun("galridge(1).Fe70","galridge(1).Fe64/85\*129");

The line widths are all freezed to 0.05 keV.
The two continua are each described by a normalization
factor (norm1/norm2) and a plasma temperature (kT1/kT2).
By default, the second bremsstrahlung continuum is
disabled by setting its norm to zero.

__See also__: bremss,egauss,set_par_fun

----

#### gauss_2d_integrated
##### Synopsis
 fit a two dimensional Gaussian profile to a bin integrated image

##### Description

For fitting 2d data, define_counts_2d can be used to define
a pseudo 1d spectrum by reshaping arrays.
Contrary to <code>gauss_2d</code> this function allows to fit bin
integrated values. Before using the fit function <code>gauss_2d_integrated</code>
the "counts" have to be defined with <code>define_counts_2d</code> and the
data grid has to be defined with <code>set_2d_data_grid</code>.
To fit integrated values (X_lo,X_hi, Y_lo, Y_hi) have to be specified
in <code>set_2d_data_grid</code>.
##### Examples

variable delt = 0.1;
variable X = [-2:2:delt];
variable Y = @X;%
variable XX, YY;  (XX, YY) = get_grid(X, Y);
variable img = cos(XX)^2\*cos(YY)^2\*100;

variable id = define_counts_2d (img);
set_2d_data_grid (X-0.5\*delt, X+0.5\*delt,Y-0.5\*delt, Y+0.5\*delt); % valid value in pixel center
fit_fun("gauss_2d_integrated(1)");
set_fit_statistic ("chisqr;sigma=gehrels");
set_par("gauss_2d_integrated(1).x0",0);
set_par("gauss_2d_integrated(1).A", sum(img));
()=fit_counts;
plot_image(get_2d_model(id));

__See also__: gauss_2d, define_counts_2d, set_2d_data_grid

----

#### Gauss_complex
##### Synopsis
 Compute complex Gauss profile

##### Usage
```c
 Complex_Type = Gauss_complex(z, z0, sigma);
```

----

#### gcrs2j2000_matrix
##### Synopsis
 return the frame bias matrix to convert coordinates from the GCRS to J2000.0

##### Usage
```c
 Matrix33_Type mat=gcrs2j2000_matrix();
```

##### Description

This function returns the frame bias matrix needed to convert
a vector in the Geocentric Celestial Reference System (GCRS)
into the J2000.0 dynamical reference system (see
astronomical almanac, section B)

__See also__: precess,precession_matrix

----

#### gehrels_confidence
##### Synopsis
 Calculate lower and upper confidence bounds according to Gehrels, 1986

##### Usage
```c
 Double_Type[2] conf = gehrels_confidence(Integer_Type n, Double_Type CL);
```

##### Description

Estimate the lower and upper bounds of the confidence interval given by
the level CL and the number of counts n using
<code>gehrels_lower_confidence</code> and <code>gehrles_upper_confidence</code>.
Please also read the documentation of these two functions.
The first entry in the retured array is the lower bound, the second one
the upper bound.

__See also__: gehrels_lower_confidence, gehrles_upper_confidence

----

#### gehrels_error
##### Synopsis
 Calculate lower and upper error according to Gehrels, 1986

##### Usage
```c
 Double_Type[2] err = gehrels_error(Integer_Type n, Double_Type CL);
```

##### Description

Same as <code>gehrels_confidence</code> but returns the errors instead.

__See also__: gehrels_lower_confidence, gehrles_upper_confidence

----

#### gehrels_lower_confidence
##### Synopsis
 Calculate lower confidence bounds according to Gehrels, 1986

##### Usage
```c
 Double_Type gehrels_lower_confidence(Double_Type n, Double_Type CL);
```

##### Description

Estimate the lower bound of the confidence interval given by the level
CL and the number of counts n.
It uses equation 14 in Gehrels, 1986.
Please note that the confidence level must be in [0.8413,0.9995].
The values for beta and gamma necessary for the calculation are
interpolated using a single parametric powerlaw for beta and a double
parametric powerlaw for gamma which was fitted to the data given in
table 3 of Gehrels, 1986.
Reading the source code is encounraged.

__See also__: gehrels_lower_confidence, gehrels_confidence

----

#### gehrels_upper_confidence
##### Synopsis
 Calculate upper confidence bounds according to Gehrels, 1986

##### Usage
```c
 Double_Type gehrels_upper_confidence(Double_Type n, Double_Type CL);
```

##### Description

Estimate the upper bound of the confidence interval given by the level
CL and the number of counts n.
It uses equation 9 in Gehrels, 1986.
Please note that the confidence level must be in [0.8413,0.9995].

__See also__: gehrels_lower_confidence, gehrels_confidence

----

#### generate_iauname
##### Synopsis
 for a given position, generate a coordinate string obeying the IAU convention

##### Usage
```c
 string=generate_iauname(ra,dec)
```

##### Qualifiers

* prefix: prefix for the string (e.g., "XMMU_")
* radian: if set, the angles are in radians, not degrees

##### Description

This is a convenience routine to produce strings of the type
XMMU Jhhmmss.s+ddmmss
from J2000.0 positions. The routine obeys the IAU convention of
truncating (not rounding!) the coordinate to the digits shown.

The default-string is "Jhhmmss.s+ddmmss", use the prefix qualifier
to prepend the mission name.

Use angle2string to format coordinates with appropriate rounding.

__See also__: dms2deg, hms2deg, angle2string, deg2dms

----

#### geographic2vector
##### Synopsis
 Calculate a geocentric vector from geographic or geodetic coordinates.

##### Usage
```c
 Vector_Type=geographic2vector(lambda,phi,hei;qualifiers)
```

##### Qualifiers

* deg: if set, then lambda and phi are measured in degrees,
(default: radian).
* datum: a string defining the geodetic datum. The default
is WGS 84, which corresponds to GPS coordinates. Other
geodetic data are IERS 2010, GRS 80, IAU 1976, GRS 67,
IAU 1964, Hayford (1924), Clarke (1866), and Airy (1830),
per the parameters given in the Astronomical Almanac.
* geocentric: The coordinates are not geodetic, but geocentric.
In this case hei is interpreted as the distance from the
geocenter (otherwise it is the height with respect to
the reference ellipsoid).
Note: it is very rare for coordinates to be geocentric!
GPS is geodetic.

##### Description

For a given set of geodetic coordinates, i.e., geographic longitude (positive
towards the east!), latitude (positive on the Northern hemisphere), and a
height  above the reference spheroid (close to height above mean sea level),
calculate the x,y,z-position in a geocentric coordinate system. Here, the
xy-plane is the Earth's equator, the xz-plane the ITRS meridian (close to
Greenwich), and the z-axis points towards the Earth's north pole. The xyz-
values are in meters.

Note that the longitude and latitude are assumed to be in rad, unless the
deg qualifier is given. The height is in meters.

The routine returns a Vector_Type. If called with arrays, then an array
of Vector_Type is returned.

__See also__: dms2deg

----

#### get1match
##### Synopsis
 returns one (the first) matching substring of a regular expression matching

##### Usage
```c
 String_Type match_str = get1match(String_Type str, String_Type regexp);
```

##### Description

get1match is deprecated. Use S-Lang's string_matches instead.

__See also__: string_matches

----

#### getCommonGTIs
##### Synopsis
 returns a new set of GTIs which are both contained in gti1 and gti2

##### Usage
```c
 Struct_Type gti = getCommonGTIs(Struct_Type gti1, Struct_Type gti2);
```

##### Description

Good time intervals (GTIs) are stored in <code>{ start, stop }</code>-structs.

----

#### getVarPeriod
##### Synopsis
 Determines the period of a variation in a lightcurve

##### Usage
```c
 Double_Type getVarPeriod(Struct_Type lc, Double_Type minperiod, Double_Type maxperiod)
```

##### Qualifiers

* plot: plot chi-square distribution and modelled
gaussians. Pause the assigned number in
seconds between each step (default 0.3)
* nogauss: skip the gaussian fit

* PIPED TO EPFOLD: :
* dt: exposure of every lightcurve time bin, should
be given to ensure correct results.
* sampling: how many periods per peak to use (default=10)
* nsrch: how many periods to search in a linear grid (default not set)
* dp: delta period of linear period grid (default not set)
* lstat: use L-statistics instead of chi^2 statistics
* nbins: number of bins for the pulse profile
* exact: calculate the pulse profile in a more exact
way, see description of pfold (not recommed
as it takes a very long time!).
##### Description

\*\*\*\*
This function is deprecated!! It will be removed in
2017 Mai. If you heavily depend on this function,
please write an email to
matthias.kuehnel@sternwarte.uni-erlangen.de
\*\*\*\*
Performs an Epoch Folding of the lightcurve in the
given period range (same time unit as used in the
lightcurve) and returns the period corresponding
to the maximum.
If not skipped by the 'nogauss' qualifier, a gaussian
it fitted to the maximum to get its position more
accurate. The gaussian parameters and used data-
points are applied automatically and improved step
by step. The steps can be monitored using the 'plot'
qualifier.

__See also__: epfold

----

#### get_all_data

##### Synopsis
 Get a list of all data-set indices

##### Usage
```c
 List_Type = get_all_data;
```

##### Description

This function returns a list of data indices, which have been obtained via all_data.
The information is saved in a List, not an Array, which allows plotting of all datasets.

##### Example

isis>variable d = get_all_data;
isis>plot_data(d);

__See also__: all_data

----

#### get_arg_struct
##### Synopsis
 obtains the arguments/options the current isis instances was called with.

##### Usage
```c
 Struct_Type = get_arg_struct( );
```

```
or

```c
 Struct_Type = get_arg_struct( String_Type[] name, type);
##### Qualifiers

* delim: [="="] Delimeter between argument name and value (e.g., also, "=.,").
* prefix: [="--"] Argument prefix. Arguments missing this prefix are ignored.

##### Description

This function returns a Struct_Type with fields corresponding to
the names of those arguments/options the current isis instance
was called with, which have the given 'prefix'. Thereby the 'name'
is defined as the string enclosed by the 'prefix' and the 'delimeter'.

Expected SYNTAX: <prefix>"argname"<delimeter>"value"

It is possible to give several 'delimeter' as a string-chain (e.g.,
"=,.-"). If an argument/option contains several delimeters, only the
string between the 1st and 2nd delimeter is taken as value for the
corresponding name.

This function can be given an string array 'name' and 'type', assigning
a Data_Type to the argument 'name'. Thereby 'type' can be:

"d" : Integer_Type
"f" : Double_Type

Otherwise, if used without arguments ('name' & 'type'), the
values are returned as String_Type.

If an argument has no value given, i.e. does not contain a delimeter
the corresponding field of the returned structure is equal NULL.
##### Example

/> isis -g --arg --arg1=1e-3 --arg2=1.01 --arg3=abcd --arg4=1=bla

isis> print( get_arg_struct );
{arg=NULL,
arg1="1e-3",
arg2="1.01",
arg3="abcd",
arg4="1"}

isis> print( get_arg_struct("arg1","f") );
{arg=NULL,
arg1=0.001,
arg2="1.01",
arg3="abcd",
arg4="1"}

isis> print( get_arg_struct(["arg1","arg2","arg4"],["f","f","d"]) );
{arg=NULL,
arg1=0.001,
arg2=1.01,
arg3="abcd",
arg4=1}

__See also__: atof, atoi, strreplace, strtok, set_struct_field, array_map, is_substr

----

#### get_bin_corr_factor
##### Synopsis
 reads the bin correction factor set by set_bin_corr_factor

##### Usage
```c
 Double_Type[nbins] corr_factor = set_bin_corr_factor(Integer_Type data_id)
```

__See also__: load_fermi,set_bin_corr_factor

----

#### get_blocks_data
##### Synopsis
 returnes the data of a Bayesian block representation

##### Usage
```c
 Struct_Type blockdata = get_blocks_data(Struct_Type blocks[, Integer_Type dataindex]);
```

```
or

```c
 blockdata= get_blocks_data(Struct_Type[] blocks[, ...]);
##### Qualifiers

* datafun: reference to a function to be called to
derive the block data (default: see text)
* errfun: same as 'datafun', but for the block
uncertainties
* bydt: divides the output data and uncertainties
by the length of the corresponding block,
can be assigned to a number used to divide
the data to for further normalization

##### Description

Returnes the data of all block over time (e.g., a
lightcurve) with variable binsize from a previous
run of 'bayesian_blocks'. The default output
structure has the fields:
time  - lower time bin of a block
dt    - length of each block
data  - the data in the blocks and
error - and the corresponding uncertainties
The data and their uncertainties are calculated
from the original input data by functions (if
multiple dataset are present use the optional
'dataindex' parameter), which will be called for
each block and can be specified via qualifiers.
Their calling sequence is
Double_Type function(time, dt, data[, error])
where error is given in case of data mode 3
(point measurements) only. The default functions
depend on the data mode used previously:
1: Event data
datafun = sum(events)
errfun  = sqrt(sum(events))
2: Binned data
datafun = sum(nn_vec)
errfun  = sqrt(sum(nn_vec))
3: Point measurements
datafun = weighted_mean(cell_data[0],
cell_data[1]; err)
errfun  = sqrt(sumsq(datafun - cell_data[0])
/ (length(cell_data[0]) - 1)
/ length(cell_data[0]))
##### Example

% let 'evts' be a list of time-tagged events,
% find bayesian blocks
blocks = bayesian_blocks(struct { tt = evts });

% create a lightcurve of the block representation,
% 'bydt' will convert counts to rate
lc = get_blocks_data(blocks; bydt);

% plot the blocks
hplot(lc.time, lc.time+lc.dt, lc.data);

__See also__: bayesian_blocks

----

#### get_color_map
##### Synopsis
 Get an intrinsic color map or construct one

##### Usage
```c
 UInt_Type[256] map = get_color_map(name);
```

##### Qualifiers

* reverse: Reverse returned map

##### Description

Retreive a colormap, either from the internal list, or
constructed from a color palette.

Qualifiers are passed to the constructor.

__See also__: get_color_palette, png_get_colormap_names

----

#### get_color_palette
##### Synopsis
 Get a number of colors from a color palette

##### Usage
```c
 UInt_Type[] = palette get_color_palette(String_Type name, UInt_Type n);
```

##### Qualifiers

* repeat: If given, repeat colors to match <code>n</code>
* cmap: If given, force colormap search
* string: Return colormap as HEX string instead of value

##### Description

Get <code>n</code> colors (as hex encoded values) from a palette. Known
palette names can be obtained by <code>get_color_palette_names</code>.

This function forwards all qualifiers to the generator functions (if any).
If no palette matching <code>name</code> is found, a colormap is searched.
To generate a palette from a colormap only, use the <code>cmap</code>
qualifier. For information how palettes are generated from colormaps
see <code>palette--map</code>, else see <code>palette--name</code>, where <code>name</code>
is the first argument.

If it is not a colormap nor a generator function, a static color map is
used. They are usually named by like <code>family:palette</code>.
For most of them, information can be obtained via <code>palette--family</code>.

Eventually the used map only has a finite number of colors. If <code>n</code>
exceeds this number, only the maximum number of colors are returned. To
repeat colors up to <code>n</code> times, use the <code>repeat</code> qualifier.

__See also__: palette--hsl,palette--map,palette--sron

----

#### get_color_palette_names
##### Synopsis
 Get list of available color palette names

##### Usage
```c
 String_Type[] names = get_color_palette_names();
```

__See also__: get_color_palette

----

#### get_column_density_from_line
##### Synopsis

##### Usage
```c
 Double_Type N = get_column_density_from_line([Integer_Type i,] String_Type line);
```

##### Description

N  =  mc^2/[pi e^2] \* W_lambda / [f_lu \* lambda^2];

=  1.13e17/cm^2 \* (W_lambda/mA) / [f_lu \* (lambda/A)^2]

%  f_lu = mc / [8 pi^2 e^2] \* lambda^2 \* g_u / g_l \* A_ul

%       = 1.4992e-16 \* (lambda/A)^2 \* g_u / g_l \* (A_ul/s^{-1})

----

#### get_combined_data_model_residuals
##### Synopsis
 returns these 3 structures for a combination of data sets

##### Usage
```c
 (d, m, r) = get_combined_data_model_residuals(Integer_Type id[]);
```

##### Description

All <code>d</code>, <code>m</code> and <code>r</code> are <code>bin_lo, bin_hi, value, err</code> structures.
<code>d</code> and <code>m</code> are the sum of data and model counts of all data sets,
rebinned to the grid of the first data set id[0].
<code>d.err</code> is calculated from quadratic error propagation.
<code>r.value = (d.value-m.value)/d.err</code> contains the residuals
unless the <code>ratio</code> qualifier is set (see below).
##### Qualifiers

* ratio: use ratio-residuals <code>r.value = d.value/m.value</code>

__See also__: get_data_counts, get_model_counts, rebin

----

#### get_component
##### Synopsis
 to extract the component from the epoch files

##### Usage
```c
 get_component([array of position number in the epoch file], [array of epoch fits files]);
```

##### Qualifiers

* quadrant: [=1] Quadrant which is defined as a positive distance ( RA, DEC > 0 == 1 || RA < 0, DEC > 0 == 2 ||
RA < 0, DEC < 0 == 3 || RA > 0, DEC < 0 == 4)
* zero: shift all distances, so that the last component is at 0,0 ("core" component)

##### Description

This function returns a structure of a component.
The required input is the position number starting by 1 in each epoch, and a corresponding list of epoch fits files.
If a component is not existent in an epoch, the position number of the component must be 0.

----

#### get_confmap
##### Synopsis
 computes a 2d confidence map and possibly stores the fit-parameters in a file

##### Usage
```c
 conf_map = get_confmap(par1, min1, max1[, n1], par2, min2, max2[, n2]);
```

##### Qualifiers

* save: [=<code>"confmap"</code>]: save all parameters to <code>save</code>+".fits"
* fail: [=<code>NULL</code>]: failure recovery hook, see <code>conf_map_counts</code>
* mask: [=<code>NULL</code>]: region mask out hook, see <code>conf_map_counts</code>

##### Description

(All qualifiers are also passed to the <code>conf_map_counts</code> function.)

<code>par1</code> is stepped from <code>min1</code> to <code>max1</code> in <code>n1</code> (default=8) steps;
<code>par2</code> is stepped from <code>min2</code> to <code>max2</code> in <code>n2</code> (default=8) steps.
A save hook is used to write each step's parameter values and chi^2 to files
named <code>sav+"\*.dat</code>, which are finally collected by <code>get_confmap_collect_results</code>
and converted to a table.
Parameters from this table can be set with <code>set_par_from_confmap_table</code>.

__See also__: conf_grid, conf_map_counts, load_conf, plot_conf, get_confmap_collect_results, set_par_from_confmap_table

----

#### get_confmap_collect_results
##### Synopsis
 collect results produced by get_confmap

##### Usage
```c
 get_confmap_collect_results(String_Type save_basefilename);
```

##### Description

<code>get_confmap_collect_results</code> is used internally by <code>get_confmap</code>,
but it can also collect the results of an unfinsihed calculation.
##### Qualifiers

* remove_files: : if set, <code>save_basefilename+"_\*.dat"</code> files will be deleted when read
* use_file_from_save_conf: : if set, results are appended to <code>save_basefilename+".fits"</code>

__See also__: get_confmap

----

#### get_contour_lines
##### Synopsis
 finds a set of contour lines for a 2d-array of values

##### Usage
```c
 Struct_Type l[] = get_contour_lines(Double_Type f[], Double_Type f0);
```

##### Qualifiers

* save: filename of a FITS file to save contours

##### Description

<code>f</code> has to be a two-dimensional array (an image).
The return value is an array of <code>struct { x, y }</code>,
whose fields <code>x</code> and <code>y</code> contain the indices
for the contour line <code>f[y,x] = f0</code>.

----

#### get_coordinatearrays_of_image
##### Synopsis
 returns two 2d arrays of image coordinates

##### Usage
```c
 (XX, YY) = get_coordinatearrays_of_image(Any_Type img[,]);
```

##### Description

<code>XX[y, x] = x</code>  and  <code>YY[y, x] = y</code> for every coordinate (<code>x,y</code>) of <code>img</code>.

----

#### get_count_rate

##### Synopsis
 Get different variants of countrates and counts

##### Usage
```c
 Double_Type CR = get_count_rate (hist_index);
or
Double_Type (CR , CR_err) = get_count_rate (hist_index ; err);
```

##### Description

Use this function to retrive background subtracted
countrates (default), countrates, background rates, or counts
and respective uncertainties for spectra that have been loaded.
Errors are estimated using the methode described by Gehrels 1986,
see <code>gehrels_error</code> for details. If the err_asym qualifier is not
specified the average of both errors is returned. If it is, an array
is returned which contains the lower error in the first entry and the
upper error as the second entry. The default confidence level for the
error is 0.9, but can be changed using the err_conf qualifier within
the possibilities offered by <code>gehrels_error</code>.

##### Qualifiers

* tex: additional TeXoutput of CRs, choose this if you need
values and uncertainties in LaTeX-format (only printed in terminal)
* bkg: 0 (default: background subtracted CR), 1 (count rates),
2 (background count rate)
* fake: Set this qualifier if you have a faked spectrum and a
faked background (which has not been deleted!);
Assumption: hist_index(bkg) = hist_index(dset) +1 !!
* fake_expo: set exposure time of fake spectrum, in case
set_data_exposure was not used when faking
* bkg_id: set hist_index(bkg) if background is loaded or faked, if set to 0, no background
is subtracted. Will overrule the id-setting made by fake-qualifier
* E_range: Set this qualifier if you want the countrate within
a certain energy range. Use E_range = [E_min , E_max].
If not given full energy range is used. (Energy in keV!)
* counts: if present function will only return counts instead
of countrates
* err: if present function will return CR and
respective uncertainty
* err_conf: Confidence limit for the error estimation
* err_asym: Return asymmetric errorbars as an array

##### Example

isis> xray = load_data("data.pha");
isis> variable countrate = get_count_rate (1 ;tex, bkg=1 , E_range = [0.2 , 2.3]);
isis> variable counts , counts_err;
isis> (counts , counts_err) = get_count_rate (1 ;tex, bkg=1 , E_range = [0.2 , 2.3] , counts , err);

__See also__: get_data_counts; TeX_value_pm_error; cut_dataset_range;

----

#### get_dataset_response
##### Usage
```c
 Response = get_dataset_response(id, [channel]);
```

##### Synopsis
 Compute response of dataset associated to 'id' to delta peak

##### Qualifiers

* energy: If given, return response on energy grid (default: wavelength)

##### Description

This function evaluates a delta peak function set at each nominal
grid value folded through the response of dataset <code>id</code>. If a
channel is given, only the response for the corresponding channel
is calculated.

The returned value is either an array of arrays for each channel in the
detector, or the array of the response in channel <code>channel</code>.
The delta function is placed at the nominal energy of the channel. If
<code>channel</code> is outside of the detector channels, a zero array is
returned.

Per default the response is returned as 'seen' by ISIS, that is, on
a wavelength grid. Use the 'energy' qualifier to revers the
response.

__See also__: get_rmf_data_grid, assign_rmf, assign_rsp

----

#### get_data_counts_with_tot_err
##### Synopsis
 returns spectral data, taking systematic errors into account

##### Usage
```c
 Struct_Type data = get_data_counts_with_tot_err(Integer_Type id);
```

##### Description

<code>data.err = sqrt( stat_err^2 + [sys_err_frac \* data.value]^2 );</code>

__See also__: get_data_counts, get_sys_err_frac

----

#### get_ephemeris
##### Synopsis
 returns the epoch and period of an ephemeris

##### Usage
```c
 Struct_Type get_ephemeris(String_Type ephemeris)
```

##### Description

The list of known ephemerides is stored internally
and is shown if an unknown ephemeris is requested.
Ephemerides are returned as a structure, containing
at least the internal <code>name</code> of the ephemeris (which
usually contains the source name and a reference),
the epoch <code>T0</code>, and the period <code>P</code>.
More information may be stored in further reasonably named
fields, e.g., <code>Pdot</code> for the change of the period.

__See also__: orbitalphase

----

#### get_flux_corrected_convolved_model_flux
##### Synopsis
 computes the model flux which can be compared with a flux-corrected spectrum

##### Usage
```c
 Struct_Type get_flux_corrected_convolved_model_flux(Integer_Type hist_index)
```

##### Description

The flux-corrected convolved model flux is computed as

<code>            int K(R(h,E), A(E), S(E)) dE  </code>

<code> F(h)  =  --------------------------------</code> ,

<code>            int K(R(h,E), A(E),  1  ) dE  </code>

where <code>S(E)</code> is the flux model, <code>A(E)</code> is the effective area (the ARF),
<code>R(h,E)</code> is the redistribution function (the RMF),
and the kernel <code>K</code> defaults to <code>K(R,A,S) = R\*A\*S</code>.

The flux-corrected convolved model fluxes is defined in such a way
that a folded model is "unfolded" in the same way as the data are
by virtue of <code>flux_corr</code>. It can thus be compared with flux-corrected data.

__See also__: flux_corr, get_model_counts, get_model_flux, get_convolved_model_flux

----

#### get_grid
##### Usage
```c
 (XX, YY) = get_grid(Double_Type X[], Double_Type Y[]);
```

##### Description

<code>XX</code> and <code>YY</code> are two-dimensional arrays
which span the grid defined by the arrays <code>X</code> and <code>Y</code>.
##### Example

variable XX, YY;  (XX, YY) = get_grid([-2:2:0.01], [-2:2:0.01]);
plot_image( atan2(YY, XX) );

----

#### get_instrument_resolution_from_data
##### Usage
```c
 R = get_instrument_resolution_from_data(id)
```

##### Synopsis
 Compute energy resolution from data set 'id'

##### Qualifiers

* energy: If given will return the grid as energy grid
instead of wavelength

##### Description

This function can be used to estimate the instrument resolution
from the data set specified with id. The return value is a struct
{ value, bin_lo, bin_hi } where bin_lo and bin_hi is the data
grid (usually in Angstrom) and value is the resolution in keV.

Note that this function removes any binning from the data set.

__See also__: hist_fwhm_index

----

#### get_intersection
##### Synopsis
 finds elements occuring in two arrays

##### Usage
```c
 (Integer_Type i1[], i2[]) = get_intersection(array1[], array2[]);
```

##### Description

<code>array1[ i1 ]  ==  array2[ i2 ]</code>
##### Qualifiers

* ordered: assumes that <code>array1</code> and <code>array2</code> are ordered increasingly

----

#### get_lambda_parameters_of_all_lines

----

#### get_lambda_parameters_of_lines

----

#### get_lambda_parameters_of_lines_from_one_ion

----

#### get_line_labels
##### Qualifiers

* label_Ly_He:  [=1]
* print_list:

__See also__: lines

----

#### get_line_velocity
##### Synopsis
 calculates the velocity shift in a line of the lines-model

##### Usage
```c
 Double_Type v = get_line_velocity([Integer_Type i,] String_Type line);
```

##### Description

<code>lambda = get_par("lines(i).line_lam");</code>

<code>lambda0 = mean( get_line_lambdas(line) );</code>

<code>v = (lambda-lambda0)/lambda_0 \* c;  %</code> speed of light <code>c = 299792</code> km/s

__See also__: Doppler_velocity

----

#### get_map_value_at_position
##### Synopsis
 Extract map value from ra/dec position

##### Usage
```c
 Double_Type value = get_map_value_at_position(map,ra,dec);
```

##### Qualifiers

* verbose: Output detector coordinates on display. Default: 0

##### Description

This function returns the value of a map at a certain ra/dec position
using the wcs of that map. Ra/Dec coordinates must be given as
decimal numbers.

__See also__: read_difmap_fits, fitswcs_get_img_wcs, wcsfuns_project

----

#### get_modelcomponents
##### Synopsis
 load binned model component values

##### Usage
```c
 Struct_Type[] mc = get_modelcomponent( Integer_Type hist_index);
```

```
or

```c
 Struct_Type[] mc = get_modelcomponent( );
##### Qualifiers

* fct [=NULL]::  NULL:    Using 'get_model' (default)
"counts": Using 'get_model_counts'
"flux":   Using 'get_model_flux'

##### Description

For each model component (see 'get_fun_components') within the given
dataset 'hist_index' this funtion returns a stucture with three array
fields, bin_lo [Angstrom], bin_hi [Angstrom] and value, containging
only the contribution of this component to the overall model.
If 'hist_index' isn ot given all included datasets are used!

The model contribution of each component is obtained by setting all
the norm parameters (get_par_info: is_a_norm=1) of all other components
to zero and evaluating the model. NOTE THAT for each component an
'eval_counts' is called!

The 'fct' qualifier determines which function should be used to
obtain the model components.

__See also__: get_fun_components, get_model, get_model_counts, get_model_flux

----

#### get_params_from_file
##### Synopsis
 retrieves fit-parameter information from a file

##### Usage
```c
 Struct_Type params[] = get_params_from_file(String_Type params);
```

__See also__: load_par, get_params

----

#### get_params_table_from_files
##### Synopsis
 retrieves fit-parameter information from files

##### Usage
```c
 Struct_Type get_params_table_from_files(String_Type filenames[]);
```

##### Qualifiers

* free: only include free parameters
* par: array of parameters to be included
* filename: include filenames into the structure
* nominmax: do not include min max values
* eval_counts: evaluates the model and returns the statistic as well.
It is assumed that the appropriate data is already loaded.
* verbose: show name of parameter files while being processed

##### Description

<code>filename</code> may be a globbing expression.
It is assumed that all parameter files rely on the same model
and that this model can be loaded with the current data set.

----

#### get_param_from_filename
##### Synopsis
 returns a double parameter value from a string / filename

##### Usage
```c
 Double_Type val = get_param_from_filename(filename,key,regexp);
```

##### Description

For a given filename = data/f4l_flux0001000muCrabpattern.fits, the
value can be extracted by specifying the key="flux"; and a regexp
of regexp="flux\([0-9.]+\)muCrab"R;
Note that there is a strict naming convention:
1) only one "." to mark the file type
2) parameters are separated by "_"
3) the "key" parameter always has to be part of the parameter string
(i.e. fluxXXXXXXXmuCrab or fluxX.XXXXXXcgs without an underscore)

If onle one argument is given, the above example for the flux is
automatically used as key and regexp.

__See also__: simput_athenacrab

----

#### get_par_combinations
##### Synopsis
 calculates all possible parameter combinations

##### Usage
```c
 Struct_Type[] parcomb = get_par_combinations( Struct_Type par )
```

##### Description

All possible parameter combinations are calculated for the
given parameter structure. That means if there are multiple
parameters, each with there own grid all possible combinations
are returned.

'par' must be a Struct_Type, but there are no restriction
otherwise. Each field is representing a parameter and its
value its grid, which can be any Data_Type (e.g., Double_Type
or String_Type)!

NOTE that the combination is done, s.t. the last parameter
in the struct is varied first and the first parameter last,
i.e., the first parameter in the parameter combination
will stay constant longest!

##### Examples

variable par = struct{ a = [0:1:#3],
b = ["hello","world"],
c = [ 2001, 2012]
};
variable parcomb = get_par_combinations( par );
print(parcomb);

----

#### get_rainbow_col
##### Synopsis
 get a rainbow color

##### Usage
```c
 color = get_rainbow_col(Integer_Type value, Integer_Type num_colors);
```

##### Description

The value has to be within [0:num_colors-1], to get the correct
color here.

__See also__: xfig_new_color

----

#### get_ratio
##### Synopsis
 calculates data/model ratios

##### Usage
```c
 Struct_Type rat[] = get_ratio(Integer_Type id[]);
```

##### Description

Each <code>rat[i]</code> is a <code>{ bin_lo, bin_hi, value, err }</code> structure
where <code>rat[i].value</code> contains the (data counts)/(model counts)
ratios obtained for the data set <code>id[i]</code>.

If only a scalar <code>id</code> is given, only a single structure is returned.

__See also__: get_data_counts, get_model_counts, get_residuals

----

#### get_residuals
##### Synopsis
 calculates (data-model)/error residuals

##### Usage
```c
 Struct_Type res = get_residuals(Integer_Type id[]);
```

##### Description

Each <code>res[i]</code> is a <code>{ bin_lo, bin_hi, value, err }</code> structure
where <code>res[i].value</code> contains the (data counts - model counts)/error
residuals obtained for the data set <code>id[i]</code>.

If only a scalar <code>id</code> is given, only a single structure is returned.
##### Qualifiers

* noticed: restrict to noticed bins
* keV: convert Angstrom-bins to keV-bins

__See also__: get_data_counts, get_model_counts, get_ratio

----

#### get_selected_data_flux_en
##### Synopsis
 returns the flux of a data set in energy units

##### Usage
```c
 flux = get_selected_data_flux_en(id[, Emin, Emax[, alpha]]);
```

##### Description

<code>flux</code> is a <code>{ bin_lo, bin_hi, value, err}</code> structure
containing energy bins of data set <code>id</code>
and the spectral photon flux density (in 1/s/cm^2/keV, unless <code>alpha!=0</code>).

If <code>Emin</code> and <code>Emax</code> are used, only values in this energy range are considered.

If <code>alpha</code>!=0, the flux values are multiplied with E^<code>alpha</code>.
##### Example

<code>hplot( get_selected_data_flux_en(1, 4, 20, 1) );</code>

% plots the spectral energy flux density of data set 1 in the 4--20 keV range

----

#### get_simple_gpile_info
##### Synopsis
 retrieves pileup information within a simple_gpile2 model

##### Usage
```c
 Struct_Type info = get_simple_gpile_info(Integer_Type id);
```

----

#### get_simputfile_struct
##### Synopsis
 get a very basic SIMPUT structure for further editing

##### Usage
```c
 get_simputfile_struct(filename, RA, Dec flux);
```

##### Description

Note: All parameters and there usage are according to the simputfile
routine of the SIMPUT package. E.g., flux is given in erg/cm^2/s.
##### Qualifiers

* crab: flux is given in units of Crab
* emin: [2.0]: lower limit of the energy band of the given flux in keV
* emax: [10.0]: lower limit of the energy band of the given flux in keV

__See also__: create_basic_simputfile,eval_simputfile,set_simputfile_model_grid,set_simputfile_flux

----

#### get_sixte_eventfile_statistic
##### Synopsis
 Get the top-level information of a SIXTE event file

##### Usage
```c
 Struct_Type ret = get_sixte_eventfile_statistic(String_Type filename[, Double_Type flux]);
```

##### Description

This function returns the valid, invalid, fractional and
piled-up pattern numbers of the event file, together with the
exposure and a possible flux entry (the argument is passed
directly into the struct). This information is based on the
event file keywords NVALID/NGRAD1 etc., written by SIXTE.

The pattern fraction errors are calculated assuming Poisson error.
Furthermore, it is possible to calculate (energy-)resolved
pattern fractions by giving the lo, hi, and field qualifiers.
Hereby, currently no distinction between non-piled up and
piled-up patterns is made (nvalids = TYPE>=0).

If the given event file is an already loaded FITS file
(Struct_Type), the reading of the relevant header keywords is
skipped and only the energy/channel resolved patterns are
returned (requires lo, hi, and field qualifiers).
##### Qualifiers

* lo: low grid for calculation of pattern fractions (in
unit of fields
* hi: high grid
* field: Name of event file column for filtering (for
example "signal" or "pha")
* nphot: Adds an additional struct field with number of
photons in the SIXTE event file

__See also__: ratio_error_prop

----

#### get_sixte_xml_data
##### Synopsis
 Loads a SIXTE XML file and outputs their attributes and values

##### Usage
```c
 Struct_Type xmlinfo = get_sixte_xml_data(String_Type filename);
```

##### Notes

This function currently only supports XMLs of the Athena WFI and
eROSITA missions.

----

#### get_source_counts
##### Synopsis
 calculates source counts, background counts and background-subtracted source counts from given spectrum, with errors

##### Usage
```c
 Double_Type get_source_counts(Integer_Type id, Integer_Type backid, Double_Type emin, Double_Type emax);
```

##### Description

- spectrum and background have to be already loaded (id, backid)
- arf and rmf have to be already loaded and assigned

__See also__: load_data,assign_rmf,assign_arf

----

#### get_struct_fields
##### Synopsis
 returns several fields of a structure

##### Usage
```c
 (Any_Type val1, val2, ...) = get_struct_fields(Struct_Type s, String_Type fieldname1, fieldname2, ...);
```

##### Qualifiers

* i: indices used for filtering array fields

##### Description

Each value corresponds to the according field of the structure.
If an <code>i</code> qualifier is given, array-typed field values
are filtered with these indices, i.e.,
<pre>
       val = get_struct_feld(s, fieldname)[i];
</pre>
It also possible to create lists of structure field values,
by just passing lists (or, equivalently, arrays) as arguments.
##### Examples

<pre>
    variable table = struct { x=[1:5], y=[1:5]^2, err1=[1:5], err2=[1:5]\\*2 };

    plot_with_err( get_struct_fields(table, "x", "y", "err1"; i=[1,0,4,2,3]) ; connect_points);
    % equivalent to:
    % plot_with_err( table.x[1,0,4,2,3], table.y[1,0,4,2,3], table.err1[1,0,4,2,3] ; connect_points);

    plot_with_err( get_struct_fields(table, "x", "y", {"err1", "err2"}) );
    % or (even less redundant):
    plot_with_err( get_struct_fields(table, "x", "y", "err"+["1", "2"]) );
    % equivalent to:
    % plot_with_err( table.x, table.y, {table.err1, table.err2} );
</pre>

__See also__: get_struct_field

----

#### get_unpiled_fit_fun
##### Synopsis
 return the currently defined fit function without simple_gpile\*

##### Usage
```c
 String_Type get_unpiled_fit_fun()
```

##### Description

<code>simple_gpile\*(Isis_Active_Dataset, </code> is replaced by <code>(</code>.

__See also__: get_fit_fun

----

#### get_variable_name
##### Synopsis
 returns the namespace and name of a given reference

##### Usage
```c
 (namespace, name) = get_variable_name(&var);
```

##### Description

The name of the variable or function the given
reference points to will be returned as a string.
The namespace where it is defined is returned as
well. In case of a private namespace, however,
NULL will be returned instead.

__See also__: current_namespace

----

#### get_warmabs_model
##### Synopsis
 computes the contribution of separate elements in a warmabs-model

##### Usage
```c
 Struct_Type data = get_warmabs_model();
```

----

#### get_xydata
##### Synopsis
 provides the xy-data, which has been defined with <code>define_xydata</code>

<!--%{{{ -->
##### Usage
```c
 (x[],         y[], yerr[]) = get_xydata(Integer_Type data_id);
```

```
or

```c
 (x[], xerr[], y[], yerr[]) = get_xydata(Integer_Type data_id);
##### Description

This function returns the xy-data of dataset # <code>data_id</code>
previously defined with <code>define_xydata</code>.
If no x-uncertainty was defined, no <code>xerr</code> is returned.

__See also__: define_xydata, get_xymodel

----

#### get_xyfit_function
##### Synopsis
 returns xy-fit-function

<!--%{{{ -->
##### Usage
```c
 String_Type get_xyfit_fun();
```

__See also__: xyfit_fun, list_xypar

----

#### get_xymodel
##### Synopsis
 provides the xy-model <code>(x_mdl[], y_mdl[])</code> given by an xy-fit

<!--%{{{ -->
##### Usage
```c
 (x_mdl[], y_mdl[]) = get_xymodel(Integer_Type data_id);
```

##### Description

This function returns the xy-model (<code>(x_mdl[],y_mdl[])</code>)
provided by the last evaluation (by <code>fit_counts</code> / <code>eval_counts</code>)
of the xy-fit-function specified with <code>xyfit_fun</code>.

__See also__: xyfit_fun, get_xydata, define_xydata

----

#### GhoshLamb79
##### Synopsis
 calculates the spin-up of a neutron star after Ghosh & Lamb (1979)

##### Usage
```c
 Double_Type GhoshLamb79(Double_Type pulse_period; disk);
or Double_Type GhoshLamb79(Double_Type pulse_period; wind);
```

##### Qualifiers

* fastness: hook into the issue of a fastness parameter >=0.9. If
this qualifier is set to "limit" then the fastness is
set to 0.9 in this case. If set to a reference
function (Ref_Type) then a hook function of the form
Double_Type fastness_hook(fastness, P, L, M, R, B)
is called, which is given the computed 'fastness' and
all neutrons star parameters. It has to return the new
value for the fastness.
* neutron star parameters:: The qualifiers L, M, R, B, mu, V0,
cs, Vorb, a, xi (see the description for details)

##### Description

This implements the accretion torque theory by
Ghosh & Lamb, 1979, ApJ 234, 296
(here after GL79) which calculates the spin-up of a neutron star
spinning with a period of 'pulse_period' (given in seconds). The
returned Pdot will be in seconds per seconds.

The theory depends on the physical parameters of the neutron star
and the accretion mode. All of these are controlled by qualifiers.

Two accretion modes are available (set as corresponding qualifier):
disk - accretion from an accretion disk (Eq. 15 of GL79)
wind - accretion from a stellar wind (Eq. 24 of GL79)

Three neutron star parameters are used independently from the mode:
L - the X-ray luminosity (in 10^37 erg/s; default: 1)
M - the neutron star mass (in solar masses; default: 1.4)
R - the neutron star radius (in km; default: 11.5)

For the disk-mode the magnetic field strength is needed. One of
the following quantities has to be given:
mu - magnetic moment (in 10^30 G cm^3; default: 1)
B  - surface magnetic field strength (in 10^12 G; overwrites mu)
For the wind-mode several parameters are needed:
V0   - the capture velocity (see Eq. 20 of GL79) (in km/s;
default: 1000)
cs   - the sound speed at the capture radius (in km/s; default: 0)
Vorb - the orbital velocity (in km/s; default related to:
V0^2 = Vorb^2 + Vwind^2 + cs^2 assuming Vwind = Vorb)
a    - the binary separation (in lt-s; default: 100)
xi   - "on the order of unity" (see Eq. 22 of GL79; default: 1)

The function should be vectorized, i.e., an array of pulse
periods can be given or the qualifiers can be arrays.

In case of disk accretion, the so-called fastness parameter is
computed after Eq. 16 of GL79. This equation is accurate by 5% for
fastnesses <0.9. For larger values a warning message is displayed.
For fastnesses >=1.0 the solution is a complex number and therefore
a _NaN value is returned and an error message is displayed. The
'fastness' qualifier can be used to hook into this issue.

__See also__: pulsarGL79

----

#### GMST
##### Synopsis
 Calculates the Greenwich sidereal time and the local siderial time

##### Usage
```c
 Double_Type GST = GMST(Double_Type JD);
```

##### Qualifiers

* hour: Return the GMST in hours, not in seconds.
* dut1: The difference UT1-UTC in seconds (see IERS Bull. A).
* mjd: Argument is in MJD, not in JD.
* gast: Return the Greenwhich Apparent Siderial Time, GAST.
* era: Return the Earth rotation angle (in rotations).
* lst: Return the local mean siderial time LST.
* lon: longitude for the calculation of the LST (east is positive;
in geodetic [ITRS] coordinates, for
practical purposes these are identical to the
WGS-84 coordinates given by GPS).
* lat: latitude for the calculation of the LST (north is positive,
only needed if xp and yp are given)
* deg: lon and lat are in degrees, not in radian.
* xp: x-coordinate of the Celestial Intermediate Pole (CIP)
ALWAYS in arcseconds, as given by the IERS bulletin.
* yp: y-coordinate of the CIP, ALWAYS in arcseconds.

##### Description

This code calculates the Greenwich Mean Siderial Time and the
Greenwhich Apparent Siderial Time in seconds.

The argument <code>JD</code> is the Julian Date in the UT1 time system.
For most applications, one can take UT1=UTC. For the most precise
applications, a correction term  DUT1=UT1-UTC can be looked up in
IERS Bulletin A
(see https://www.iers.org/IERS/EN/Publications/Bulletins/bulletins.html).

The algorithms used are described by Kaplan (2005, USNO Circular
179, Sect. 2.6.2).

This routine is array safe.

Note that contrary to the coordinate transform routines the
deg qualifier only affects the interpretation of the lon, lat
qualifiers and does NOT affect the other arguments or return
arguments!

__See also__: equation_equinoxes

----

#### gravitational_radius
##### Synopsis
 calculates the gravitational radius in Meters defined as r_g=GM/c^2,
for a mass given in units of M_sol.

##### Usage
```c
 gravitational_radius(mass_in_solar)
```

----

#### greatcircle_coordinates
##### Synopsis
 calculates the coordinates of the greatcircle between two points on a sphere

##### Usage
```c
 (Double_Type lambda[], phi[]) = greatcircle_coordinates(lambda1, phi1, lambda2, phi2);
```

##### Qualifiers

* unit: [<code>="deg"</code>] unit of the angular coordinates
* delta: [<code>=0.5</code>] angular step in degrees

##### Description

(<code>lambda</code>i, <code>phi</code>i) are the spherical coordinates of point i.

<code>unit="deg"</code>: <code>lambda</code>i and <code>phi</code>i are in degrees.

They can be scalar values or arrays of the form
<code>[deg, arcmin]</code>, <code>[deg, arcmin, arcsec]</code> or <code>[sign, deg, arcmin, arcsec]</code>.
<code>unit="rad"</code>: <code>lambda</code>i and <code>phi</code>i are scalars in radian.

<code>unit="hms"</code>: code{lambda}i are scalars hour angles (24h = 360deg)
or arrays in h:m:s format, i.e., <code>[h, m]</code> or <code>[h, m, s]</code>.
The <code>phi</code>i are nevertheless in degrees as above.

__See also__: greatcircle_distance

----

#### greatcircle_distance
##### Synopsis
 calculates the angular distance between two points on a sphere in radians

##### Usage
```c
 Double_Type greatcircle_distance(alpha1, delta1, alpha2, delta2)
```

##### Qualifiers

* unit: [<code>="deg"</code>] unit of the input angular coordinates
* alpha1_unit: [<code>="deg"</code>] unit of the alpha1
* alpha2_unit: [<code>="deg"</code>] unit of the alpha2
* delta1_unit: [<code>="deg"</code>] unit of the delta1
* delta2_unit: [<code>="deg"</code>] unit of the delta2

##### Description

DEPRECATED - please use angular_separation instead
(<code>alpha</code>i, <code>delta</code>i) are the spherical coordinates of point i.

<code>unit="deg"</code>: <code>alpha</code>i and <code>delta</code>i are in degrees.

They can be scalar values or arrays of the form
<code>[deg, arcmin]</code>, <code>[deg, arcmin, arcsec]</code> or <code>[sign, deg, arcmin, arcsec]</code>.
<code>unit="rad"</code>: <code>alpha</code>i and <code>delta</code>i are scalars in radian.

<code>unit="hms"</code>: <code>alpha</code>i are scalars hour angles (24h = 360deg)
or arrays in h:m:s format, i.e., <code>[h, m]</code> or <code>[h, m, s]</code>.
The <code>delta</code>i are in degrees as above.
The units of each coordinate can be set independently.
Note that independent of the unit setting, the returned great circle
distance will always be in radian.

__See also__: greatcircle_coordinates

----

#### GreenwichSiderealTime_from_MJD
##### Synopsis
 computes the Greenwich sidereal time

##### Usage
```c
 Double_Type GST = GreenwichSiderealTime_from_MJD(Double_Type MJD);
```

##### Description

<code>MJD</code> is the Modified Julian Date (\*in UT\*).
This routine is a wrapper around GMST(JD), and only
kept for compatibility reasons.
This function is DEPRECATED. Please do not use for future work.

__See also__: GMST

----

#### greiner_hormann
##### Synopsis
 Clipping and logical intersection of two polygons

##### Usage
```c
 List_Type polylist= greiner_hormann(src, clp);
```

```
or

```c
 List_Type polylist= greiner_hormann(sx,sy,cx,cy);
##### Qualifiers

* intersection: return the intersection of src and clp
(i.e., clip src against clp), the default
* union: return the union of src and clp
* without: remove clp from src
* perturb: slightly perturb src to reduce probability of
failure of the algorithm (see description below)

##### Description

This function implements the Greiner-Hormann algorithm for polygon
intersections (Greiner & Hormann, 1998, ACM Trans. Graph. 17(2), 71-83).
The polygons are given as structures struct {x=[], y=[]}, other structure
tags are ignored. The function returns a list of closed polygons of this
type (which may be empty!). The returned polygons also include a tag
id which is 0 if the point originates in src, 1 if the point originates in
clp, and -1 if this is a newly inserted intersection point.

Alternatively, the x- and y-coordinates of the polygon points can be
given. In this case the return will still be a list of structs.

The polygons must be closed, i.e., src.x[0]==src.x[-1], src.y[0]=src.y[-1],
and the same for clp. The polygons can self-intersect, there is almost no
limitation on their shape. In the case of intersection, the determination
that a point is inside a polygon is done using the winding number
(see help for function point_in_polygon).

The Greiner-Horman algorithm has an issue for polygons that have colinear
overlapping sides. If the qualifier "perturb" is set, the coordinates
in src are randomly perturbed at a level of 1e-8 to reduce the probability
of this happening.

##### Example

variable p=xfig_plot_new(15,15);
p.world(-1.,1.,-1.,1.);

variable src,clp;

% a complex polygon
src=struct {x=[-0.25,0.00,0.25,0.3,0.8,0.5,-0.25],
y=[ 0.80,-0.40,0.8,-0.4,0.0,0.8,0.80]};

% a square
clp=struct {x=[-0.5,0.5,0.5,-0.5,-0.5]+0.2,
y=[-0.5,-0.5,0.5,0.5,-0.5]+0.2};

p.plot(src.x,src.y;color="blue",depth=150);
p.plot(clp.x,clp.y;color="green",depth=150);

variable res=greiner_hormann(src,clp;intersection);

variable i;
_for i(0,length(res)-1,1) {
p.plot(res[i].x,res[i].y;color="red",depth=50);
}

p.render("polygons.pdf");

__See also__: point_in_polygon

----

#### gridmapping
##### Synopsis
 computes a table of a 2d mapping

##### Usage
```c
 Struct_Type data = gridmapping(&getxy, X, Xfine, Y, Yfine);
```

----

#### group_noticed_data
##### Synopsis
 groups previously noticed spectral bins by an integer factor

##### Usage
```c
 group_noticed_data(Integer_Type id, Integer_Type factor);
```

__See also__: group_data

----

#### group_pha
##### Synopsis
 Apply quality and grouping information from pha file

##### Usage
```c
 group_pha(indx)
```

__See also__: load_pha

----

#### GTIoverlap
##### Synopsis
 computes the overlap of an interval [t1, t2] with a set of good time invervals

##### Usage
```c
 Double_Type GTIopverlap(Double_Type t1, Double_Type t2, Struct_Type GTI
```

__See also__: getCommonGTIs

----

#### g_earth
##### Synopsis
 Calculates the acceleration at the Earth's surface as a function of latitude

##### Usage
```c
 Double_Type g = g_earth(Double_Type phi);
```

##### Qualifiers

* deg: phi is in degrees, not in radian.
* altitude: altitude of the observer above the geoid [m]
* mks: return g in m/s^2, not in cm/s^2
* allen: use the equation of Allen (1973, Astrophys. Quantities)
* almanac: Urban & Seidelman (2013; Expl. Suppl. Astron. Almanac)

##### Description

This code calculates the surface acceleration on the earth as
a function of the latitude (in rad). The equations used are
from a compilation of different approximations to g by
Mangum & Wallace (2015), PASP 127, 74.

The default returned is for the WGS84 geoid.

This routine is array safe in phi or altitude.

__See also__: dms2deg

----

#### Hammer_projection
##### Synopsis
 Computes the Hammer-Aitoff projection

##### Usage
```c
 (Double_Type x, y) = Hammer_projection(Double_Type l, b);
```

##### Qualifiers

* deg: <code>l</code> and <code>b</code> are in degrees, not in radian
* normalized: <code>x</code> and <code>y</code> are normalized (by <code>sqrt(2)</code>)
such that <code>abs(x) <= 2</code> and <code>abs(y) <= 1</code>.
* astronomical: flip x-axis for astronomical maps, where east is
to the left
* inverse: calculate the inverse projection, interpreting l as the x- and
b as the y-coordinate; all other qualifiers are
also interpreted as expected.

##### Description

This is the projection erroneously called the Aitoff projection by many
astronomers. It is an equal area projection. The projection equations are

<code>x = 2 \* sqrt(2) \* cos(b) \* sin(l/2) / sqrt(1 + cos(b)\*cos(l/2));</code>

<code>y = sqrt(2) \* sin(b) / sqrt(1 + cos(b)\*cos(l/2));</code>

The inverse function returns nan if the arguments given are not possible.

__See also__: Aitoff_projection, Lambert_Equal_Area_projection

----

#### hardnessratio
##### Synopsis
 calculates various X-ray hardness ratio from given count rates

##### Usage
```c
 Double_Type (HR , HR_err) = hardnessratio(Double_Type soft_count, Double_Type hard_count);
```

```
or

```c
 Double_Type (HR , HR_err_up , HR_err_down) = hardnessratio(Double_Type soft_count, Double_Type hard_count ; bayesian);
##### Qualifiers

* color: calculate the hardness ratio according to color=log10(S/H)
* hardness: calculate the hardness ratio according to hardness=(H-S)/(H+S)
* ratio: calculate the hardness ratio according to ratio=S/H (the default)
* bayesian: returns hardness calculated using the bayesian estimation, calling
the function behr()
* back_s: background counts in the soft band
* back_h: background counts in the hard band
* backscale: ratio between the extraction regions for the source and the background
* exposure: Exposure per bin in seconds. If given, interpret soft_count, hard_count and t
he backgrounds as rates. Multiply the rates with exposure to get the counts.
* backexposure: if given, the background exposure. Only taken into
account if exposure is also set. If not given, it is assumed that
the source and background exposures are identical.
* ratio_type: (DEPRECATED) Integer_Type, for hr=s/h choose 1,
for hr=(h-s)/(h+s) choose 2, for hr=log(s/h) choose 3, default = 1
* err_s: Array containing the uncertainties of the soft light curve
* err_h: Array containing the uncertainties of the hard light curve
additional qualifiers are passed to 'behr' for bayesian estimation

##### Description

This function calculates the so-called hardness ratio or color according to
the three common prescriptions used in X-ray astronomy: S/H, (H-S)/(H+S), and log10(S/H).
If given, background counts are subtracted before the calculation, taking into account
different source and background extraction regions and different source and background exposure
times if necessary (if counts are given but the background exposure was different, set the
source exposure to 1 and the background exposure to the ratio of the source and background exposure
times. If rates are given, give the exposure times.

Error bars are calculated using Gaussian error propagation. Contrary to earlier versions of
this routine they are ALWAYS calculated!

The bayesian approach or the function behr() should be used in low count regime.
If they qualifier "bayesian" is present the hardness is calcualted using the bayesian estimation
implemented in the function behr(). If the background should be taken into account the function also requires
the background scaling factors used in behr().
Requires gsl, make sure module is loaded!

__See also__: behr;

----

#### hardnessratio_error_prop
##### Synopsis
 calculates a ratio and error propagation

##### Usage
```c
 (hr, err) = hardnessratio_error_prop(h, h_err, s, s_err);
```

##### Description

<code>hr  = (h-s) / (h+s)</code>

<code>err = sqrt[ (2s/(h+s)^2 \* h_err)^2  + (2h/(h+s)^2 \* s_err)^2 ]</code>

__See also__: ratio_error_prop

----

#### hardnessratio_from_dataset
##### Synopsis
 calculates hardnessratios of the current model

##### Usage
```c
 Struct_Type hardnessratio_from_dataset(
Integer_Type data-id, Integer_Type[2] soft_ch, hard_ch
);
```

##### Qualifiers

* soft_en: Double_Type[2]
* hard_en: Double_Type[2]
* get_counts: set to '&get_model_counts' if needed, default: get_data_counts
* subtract_background: subtract background from data. Only possible if get_counts is not set.
additional qualifiers are passed to 'hardnessratio'

##### Description

- at least one dataset has to be defined (load_data)
- if energy bands are given, channels have to be set to [0,0]
- returns a structure containing: sc: soft counts, hc: hard counts, ratio: hardnessratio, err: error

__See also__: hardnessratio

----

#### hardnessratio_from_spec
##### Synopsis
 calculates hardness ratio from given spectrum

##### Usage
```c
 Struct_Type H = hardnessratio_from_spec(String_Type fits, freeze_model_comp)
```

##### Description

Calculates hardness ratio from a given spectrum using the model 'enflux'.
First argument is a fits file with data and model (from fits_save_fit).
Second argument is the model component of the continuum that has to be frozen (see enflux).
It first determines the soft and hard energy flux densities of two variable energy bands
and then derives the hardness ratio plus error.
For the hardness ratio two different definitions can be chosen (either h/s or
(h-s)/(h+s)).
##### Qualifiers

* hard_band: Double_Type[2], hard energy band, default = [7.,10.]
* soft_band: Double_Type[2], soft energy band, default = [2.,4.]
* hr_def: Integer_Type, for hr=h/s choose 1, for hr=(h-s)/(h+s) choose 2, default = 1
* roc: Integer_Type, RMF OGIP compliance, default = 2

__See also__: hardnessratio_error_prop,enflux,fits_save_fit

----

#### hardnessratio_simulate_grid
##### Synopsis
 calculates hardnessratios of the current model

##### Usage
```c
 Struct_Type[] hardnessratio_simulate_grid(String_Type/Integer_Type par1name, par2name,
Integer_Type[2] soft_ch1, hard_ch1, soft_ch2, hard_ch2);
or Struct_Type[] hardnessratio_simulate_grid(
String_Type/Integer_Type par1name, Double_Type par1min, par1max, step1,
String_Type/Integer_Type par2name, Double_Type par2min, par2max, step2,
Integer_Type soft_ch1, hard_ch1, soft_ch2, hard_ch2
);
```

##### Qualifiers

* dataindex: Integer_Type, dataset index to use, default = 1
* grid1scale: 0 = linear (default), 1 = logarithmic
* grid2scale: 0 = linear (default), 1 = logarithmic
* par1grid: Double_Type[], override value grid of paramter 1
* par2grid: Double_Type[], override value grid of paramter 2
* sample1: Integer_Type, sampling-factor along each track, default 10
* sample2: Integer_Type, sampling-factor along each track, default 10
* exposure: Double_Type, default: 1e4
* arf: String_Type, file path of arf
* rmf: String_Type, file path of rmf
* rsp: String_Type, file path of rsp (arf and rmf combined)
* soft_en1: Double_Type[2], additional qualifier, soft band for all tracks in one direction
* hard_en1: Double_Type[2], additional qualifier, hard band for all tracks in one direction
* soft_en2: Double_Type[2], additional qualifier, soft band for all tracks in other direction
* hard_en2: Double_Type[2], additional qualifier, hard band for all tracks in other direction
additional qualifiers are passed to 'hardnessratio_from_dataset' and 'hardnessratio'

##### Description

- at least one dataset has to be defined (load_data)
- a model must exist (fit_fun)
- soft_ch1, hard_ch1, soft_ch2, hard_ch2 are passed to 'hardnessratio_from_dataset'; if energy-bands
(soft_en1...)are given, the channels have to be set to [0,0] each.
- if logarithmic gridscale is chosen, be careful 'parmin' is not <= zero (be aware of the default
values of your model)
- the output consists of an array of structures of tracks, where each track contains the values of par1, par2 and the
corresponding hardnessratios hr1 and hr2, and the errors hr1err and hr2err e.g. within one struct par1 is kept constant
- either give arf AND rmf; or ONLY give rsp

__See also__: hardnessratio, hardnessratio_from_dataset, xfigplot_hardnessratio_grid

----

#### hardnessratio_simulate_grid_load
##### Synopsis
 load tracks saved with hardnessratio_simulate_grid_save

##### Usage
```c
 Struct_Type = hardnessratio_simulate_grid_save(String_Type filename);
```

__See also__: hardnessratio, hardnessratio_from_dataset,
xfigplot_hardnessratio_grid, xfigplot_hardnessratio_grid_save

----

#### hardnessratio_simulate_grid_save
##### Synopsis
 saves the output of hardnessratio_simulate_grid into a fits
file

##### Usage
```c
 hardnessratio_simulate_grid_save(Struct_Type tracks,
String_Type filename);
```

##### Description

- tracks is the output strcutute of hardnessratio_simulate_grid

__See also__: hardnessratio, hardnessratio_from_dataset,
xfigplot_hardnessratio_grid, xfigplot_hardnessratio_grid_load

----

#### hex2color
##### Synopsis
 converts hex color values to color string.

##### Usage
```c
 Integer_Type hex2color(UInt_Type color)
```

__See also__: color2hex

----

#### hist1d_confidence
<!--%{{{ -->
##### Synopsis
 Find the confidence interval for histogram

##### Usage
```c
 (Min,Max) = hist1d_confidence(lo, hi, hist);
```

##### Qualifiers

* conf: [=0.9] confidence limit (between 0 and 1)
* index: if given, return the indices of lo and hi bin

##### Description

Find the bin boundary values such that they enclose the smallest volume
equal to <code>conf</code>. The result is guaranteed to have at least <code>conf</code>
integral. Works only for unimodal dsitributions.

----

#### hist2d_confidence
<!--%{{{ -->

----

#### histogram2d_min_max
##### Synopsis
 computes a 2d histogram between minimum and maximum data values

##### Usage
```c
 h2 = histogram2d_min_max(Double_Type Y, X);
```

##### Qualifiers

* xmin: [<code>=min(X)</code>]: first value of <code>Xlo</code>-grid
* xmax: [<code>=max(X)</code>]: last value of <code>Xhi</code>-grid
* ymin: [<code>=min(Y)</code>]: first value of <code>Ylo</code>-grid
* ymax: [<code>=max(Y)</code>]: last value of <code>Yhi</code>-grid
* Nx: [=50]: number of bins of (linear) <code>Xlo</code>-grid
* Ny: [=50]: number of bins of (linear) <code>Ylo</code>-grid
* Xlo: reference to a variable to store the <code>Xlo</code> array
* Ylo: reference to a variable to store the <code>Ylo</code> array

##### Description

For 2d arrays, the order of the indices matters.
Almost all ISIS and related functions use <code>h2[iy, ix]</code>
with the first index corresponding to y, and the second to x.
For this reason, <code>histogram2d_min_max</code> -- just as
<code>histogram2d</code> (though not explicitly documented) --
needs to get the array <code>Y</code> of y-coordinates as first argument
and the array <code>X</code> of x-coordinates only as second argument,
if the resulting 2d array <code>h2</code> shall be used with functions
like <code>plot_image</code>, <code>png_write</code>, <code>ds9_view</code>, etc..

The x-grid <code>Xlo</code> starts at <code>xmin</code>, but ends before xmax,
such that <code>Xhi = make_hi_grid(Xlo)</code> would end at <code>xmax</code>.
The same is true for the y-grid <code>Ylo</code> with <code>ymin</code> and <code>ymax</code>.

Unlike <code>histogram2d(Y, X, Ylo, Xlo)</code>, <code>h2</code> will not contain
overflow bins in the last column and the last row, i.e.,
<code>h2[iy,ix]</code> corresponds to the number of pairs (<code>X</code>, <code>Y</code>)
where <code>Xlo[ix] <= X < Xhi[ix]</code> and <code>Ylo[iy] <= Y < Xhi[iy]</code>.
##### Example

variable n=10000; x=2\*grand(n), y=grand(n), Xlo, Ylo;
variable h2 = histogram2d_min_max(y, x; Xlo=&Xlo, Ylo=&Ylo);
plot_image(h2, 0, Xlo+(Xlo[1]-Xlo[0])/2., Ylo+(Ylo[1]-Ylo[0])/2.);

__See also__: histogram2d

----

#### histogram3d
##### Synopsis
 bins scatter data into a 3d histogram

##### Usage
```c
 Integer_Type[,,] histogram3d(Double_Type x[], y[], z[], Xgrid[], Ygrid[], Zgrid[])
```

##### Description

<code>histogram3d</code> computes the number <code>N[i,j,k]</code> of points <code>(x[m], y[m], z[m])</code>
that fall into the 3d-cell with <code>Xgrid[i] <= x < Xgrid[i+1]</code>,
<code>Ygrid[j] <= y < Ygrid[j+1]</code> and <code>Zgrid[k] <= z < Xgrid[k+1]</code>.
The last bin in each dimension is an overflow bin,
such that its upper limit is at infinity.

__See also__: histogram, histogram2d

----

#### histogram_gaussian_probability
##### Usage
```c
 Double_Type[] histogram_gaussian_probability(Double_Type[] x, sigma, lo[, hi])
```

##### Description

While <code>histogram(x, lo[, hi])</code> increases the histogram bin <code>j</code>
where <code>lo[j] <= x[i] < hi[j]</code> by one for every <code>x[i]</code>,
<code>histogram_gaussian_probability(x, lo[, hi])</code> adds the
the Gaussian proability of events with mean <code>x[i]</code>
and standard deviation <code>sigma[i]</code> to all bins.

Note that this function acts like a convolution
and therefore introduces an additional broadening.
##### Example

variable n=10000, x=grand(n), sigma=ones(n);
variable lo=[-3:3:0.05],  hi=make_hi_grid(lo);
hplot(lo, hi, histogram(x, lo, hi));
ohplot(lo, hi, histogram_gaussian_probability(x, sigma, lo, hi));
% The first distribution follows N(0, 1),
% but the second one follows N(0, sqrt(1^2 + sigma^2)) = N(0, sqrt(2)).

__See also__: histogram

----

#### histogram_min_max
##### Synopsis
 computes a histogram between minimum and maximum value

##### Usage
```c
 Struct_Type h = histogram_min_max(Double_Type X[, Double_Type dx]);
```

##### Qualifiers

* log: use a logarithmic grid with the following number of bins:
* N: [=100] number of bins of logarithmic or linear grid

##### Description

The return value is a <code>{ bin_lo, bin_hi, value, err }</code> structure which
can directly be used with, e.g., <code>hplot_with_err</code>, <code>define_counts</code>, etc.

__See also__: histogram

----

#### history
##### Synopsis
 shows the history of commands on the interactive ISIS-shell

##### Usage
```c
 history();
```

__See also__: save_input

----

#### hist_fwhm_index
##### Usage
```c
 (lo,hi) = hist_fwhm_index(hist [, max_index]);
```

##### Synopsis
 Compute index bounds spaning FWHM of histogram

##### Description

When given a single array hist_fwhm_index tries to find the FWHM
range from the maximum. This works much better if the second argument
is given which has to be the index of the maximum (or at least close to
it). By interative stepping of the boundaries the function will stop
when the lo and hi enclose the true fwhm or has hit the array boundaries.

----

#### hms2deg
##### Synopsis
 Convert angle in hour, minute, seconds to degrees or radian

##### Usage
```c
 degree = hms2deg(h,m,s);
```

##### Qualifiers

* radian: If set, return angle in radians, not degrees

##### Description

This is a convenience routine to convert astronomical coordinates given
in hours, minutes, and seconds into a floating point number.

The routine is equivalent to calling dms2deg with the hours qualifier.

This routine is array safe (as long as h, m, s are arrays of equal length).

__See also__: dms2deg

----

#### horizon2equatorial
##### Synopsis
 convert horizon (azi,ele) coordinates to equatorial (alpha,delta)

##### Usage
```c
 (alpha,delta)=horizon2equatorial(azi,ele;qualifiers)
```

```
or

```c
 Vector_Type eqp=horizon2equatorial(hor;qualifiers)
##### Qualifiers

* JD: JD for which the calculation is to be performed. Mandatory.
* lon: geographic longitude of the observer, positive towards the east. Mandatory.
* lat: geographic latitude of the observer, positive towards the north. Mandatory.
* deg: interpret all angular arguments in degrees (default is radians!)
applies also to the return value.
* mjd: interpret date as a MJD (default: JD)

##### Description

The function  takes coordinates in the horizon (azimuth,elevation) system
and converts them into the equatorial system for the ecliptic and
elevation of the date. Alternatively the routine also accepts a
Vector_Type and then returns avector in equatorial coordinates.

See the description of the function equatorial2horizon for
references and further information. This routine is just a
wrapper around that function, with the qualifier "inverse" set.

__See also__: Vector_Type, equatorial2horizon,dms2deg,hms2deg

----

#### hplot_filled
##### Synopsis
 plot a filled histogram defined by slang arrays

##### Usage
```c
 hplot_filled(Array_Type bin_lo, Array_Type bin_hi, Array_Type values)

```

##### Qualifiers

* fill_style: [<code>=1</code>] set the fill style:

<code>FS = 1</code> <code>=></code> solid (default)

<code>FS = 2</code> <code>=></code> outline

<code>FS = 3</code> <code>=></code> hatched (cannot be used with ylog;)

<code>FS = 4</code> <code>=></code> cross-hatched (cannot be used with ylog;)

* ticks: [<code>=""</code>] set to <code>"I"</code> or <code>"P"</code> to invert or project the ticks
of both axis (additional to initial plot options)
* xopt: [<code>=get_plot_options.xopt</code>] set the plot options of the x-axis directly
* yopt: [<code>=get_plot_options.yopt</code>] set the plot options of the y-axis directly
* ymin: [<code>=min(values)</code>] set the lower y-value to which the areas are filled
* angle: [<code>=degrees</code>] sets the angle of the hatched lines for FS=3 [default = 45]

##### Description

This function plots a histogram described by three 1-D S-Lang arrays of size N.
The area below the histogram is filled. The fill style can be selected with a qualifier.
##### Examples

<code>hplot_filled([1:5],[2:6],[1:5]);</code>

<code>%</code> invert the ticks

<code>hplot_filled([1:5],[2:6],[1:5]; ticks="I");</code>

<code>%</code> change the fill style

<code>hplot_filled([1:5],[2:6],[1:5] ; fill_style=4);</code>

__See also__: ohplot_filled, hplot

----

#### hplot_with_err
##### Synopsis
 plots histogram data points with errorbars

##### Description

This function passes all its arguments and qualifiers to the
<code>plot_with_err</code> function, but adds the <code>histogram</code> and <code>xminmax</code> qualifiers.

__See also__: [o][h]plot_with_err, [o][h]plot

----

#### hpluv2rgb
##### Usage
```c
 Int_Type r, g, b = hpluv2rgb(Double_Type h, s, l);
```

##### Synopsis
 Calculate RGB triplet from HPLuv space

##### Description

This function returns the RGB colors (as 8 bit values) of
the corresponding HPLuv color (see https://www.hsluv.org/).
The inputs range from 0 to 1.

This colorpsace is useful to generate custom color maps and
palettes as it attemps to give the same perceived lightness (l)
and saturation (s) for different hues (h). Compared to HSLuv
it tries to maximize the used color range.

__See also__: rgb2hpluv, hsluv2rgb

----

#### hsl2rgb
##### Synopsis
 converts a (hue, saturation, lightness) color to (red, green, blue)

##### Usage
```c
 Integer_Type rgb = hsl2rgb(Double_Type h, s, l);
```

##### Description

The hue <code>h</code> is an angle in color-space. Here, <code>h</code> is between 0 and 1.
<code>h</code> of red is 0, <code>h</code> of green is 1/3, and <code>h</code> of blue is 2/3.
The lightness <code>l</code> of black is 0, and <code>l</code> of white is 1.
Like the hue, the saturation <code>0<=s<=1</code> matters only for <code>0<l<1</code>.

The return value is a(n array of) 24 bit RGB value(s).

__See also__: rgb2hsl

----

#### hsluv2rgb
##### Usage
```c
 Int_Type r, g, b = hsluv2rgb(Double_Type h, s, l);
```

##### Synopsis
 Calculate RGB triplet from HSLuv space

##### Description

This function returns the RGB colors (as 8 bit values) of
the corresponding HSLuv color (see https://www.hsluv.org/).
The inputs range from 0 to 1.

This colorpsace is useful to generate custom color maps and
palettes as it attemps to give the same perceived lightness (l)
and saturation (s) for different hues (h). It does not contain
the full RGB space, however.

__See also__: rgb2hsluv

----

#### hsv2rgb
##### Synopsis
 Convert HSV color to RGB

##### Usage
```c
 (Int_Type r,g,b) = hsv2rgb(Double_Type h,s,v);
```

##### Description

HSV (Hue, Saturation, Value) as doubles (0-1) are
converted to RGB values (defined as [0-255] 8 bit
values). Works for array values two (lengths must
match).

----

#### ignore_large_bins
##### Synopsis
 ignores those bins of a spectral dataset exceeding a maximal size

##### Usage
```c
 ignore_large_bis(Integer_Type id[], Double_Type maxsize);
```

##### Qualifiers

* verbose:
* unit: [=<code>"A"</code>]: maxsize may be in A or keV

----

#### ignore_xy
##### Synopsis
 ignore points from xy-dataset

c
##### Usage
```c
 ignore_xy (index [, low, high]);
```

##### Description

Wraper function of the ignore function for datasets defined with
define_xydata. Ignores data points of dataset <code>index</code>
(in the range low to high) for fitting.

__See also__: notice_xy, ignore, ignore_en, define_xydata

----

#### image2rgb
##### Synopsis
 converts an image (2d array) to a 24bit RGB image

##### Usage
```c
 Integer_Type rgb[] = image2rgb(Double_Type img[]);
```
or

```c
 Integer_Type rgb[] = image2rgb(Double_Type R[], G[], B[]);

```

##### Description

<code>min(img)</code> will be mapped to black, <code>max(img)</code> to white,
and other values to their linear gray scale.

This function can be used for <code>png_write</code>(<code>_flipped</code>).

__See also__: png_write

----

#### init_histo
##### Synopsis
 initialize a struct with histogram fields

##### Usage
```c
 init_histo([Integer_Type len]);
```

##### Description

Return a new struct with the typical fields of a histogram:
bin_lo, bin_hi, value, err. If the optional argument is present,
the fields are initialized with a Double_Type array of that
length. Else the fields are empty.

__See also__: read_histo, init_histo, add_hist, shift_hist,
scale_hist, stretch_hist

----

#### init_jet_fit
##### Synopsis
 inititialize the fit function for the speed of jet components

##### Usage
```c
 init_jet_fit (Ref_Type jet_component_structure);
```

##### Qualifiers

* pa: [=90] position angle of the jet in degrees (required)
* recalc_distance: set to 1 in order to recalculate the distance
of each component based on deltax and deltay

##### Description

This function initializes the fit function <code>jet_speed</code>, which
can fit a linear function of the form:
dist (t)  = (t - t_0) \* v
to each component, where t_0 is the ejection time of the component in
MJD and v is its speed in mas/year. For each epoch an offset (in mas)
can be fitted, allowing to correct for shifts of the image (along the
line in which the distance is measured).
For the initialization a structure with the name "jet_speed_struct"
is REQUIRED, which has to contain the fields <code>time</code> (date of epoch in MJD),
<code>distance</code> (in mas),  <code>derr</code> (uncertainty of the distance), and
<code>component</code> (integer values identifying the components).
The function extends this structure, and sets the initialized fit function.
##### Example

variable jet_speed_struct = struct {
mjd       = [55500, 55550, 55600, 55650, 55500, 55600, 55650],
deltax    = [  0.2,   0.4,   0.5,   0.7,   0.6,   1.2,   1.5],
deltay    = [  0.0,   0.0,   0.0,   0.0,   0.0,   0.0,   0.0],
derr      = [ 0.01,  0.05,  0.01,   0.1,  0.02,   0.1,   0.1],
component = [    1,     1,     1,     1,     2,     2,     2],
};
init_jet_fit(&jet_speed_struct; pa = 90);
()=fit_counts;
list_par;
plot_jet_speed ( jet_speed_struct );

__See also__: plot_jet_speed

----

#### init_plot
##### Synopsis
 starts a new plot, such that other plots can be overplotted

##### Usage
```c
 init_plot();
```

##### Description

plot is used to plot a single point in the lower left corner.
Before init_plot is called, x- and yrange have to be set.

__See also__: plot, get_plot_options

----

#### init_time_structure
##### Synopsis
 creates a time structure

##### Usage
```c
 Struct_Type init_time_structure(Integer_Type Y[, m[, d[, H[, M[, S]]]]])
```

##### Description

The <code>tm_year</code> field of the returned structure
is <code>Y-1900</code>, and <code>tm_mon</code> is <code>m-1</code>.

__See also__: localtime, mktime, strftime

----

#### inner_product
##### Synopsis

##### Usage
```c
  M[n,...,j] = inner_product( A[n,...,m], B[m,...,j] );
```

##### Description

In ISIS the operator # calculates the inner product of two arrays
A, B, i.e., contracts the last and first dimension, respectively.
A and B can have an arbitrary number of dimensions, it is just required
that the last dimension of A and first dimension of B is of the same
size!
##### Example

A = _reshape( [1:2\*3], [2,3] );
B = _reshape( [1:3\*4], [3,4] );
M = inner_product( A, B );
N = A # B;
vmessage("M

"); print(M);
vmessage("N

"); print(N);

__See also__: operator #

----

#### inner_products
##### Synopsis

##### Usage
```c
  M[n,...,l] = inner_products( A[n,...,m], B[m,...,j] [, ..., Z[k,...,l] ] );
```

##### Description

In ISIS the operator # calculates the inner product of two or more arrays.
This function is basically nesting the inner_product function!

__See also__: inner_product, operator #

----

#### integral_cat2ds9
##### Synopsis
 a cat2ds9 like function for INTEGRAL catalogs

##### Usage
```c
  ()=integral_cat2ds9(String_Type inputfile,
String_Type outputfile)
```

##### Qualifiers

* source_name: name of the column with source names
(default: NAME)
* ra_name: name of the column with right ascension of the
sources (default: RA_OBJ)
* dec_name: :name of the column with declination of the
sources (default: DEC_OBJ)
* color: color to be used for the ds9 region (default:
black)
* symbol: form of the ds9 region (default:box)
* noname: only boxes, no text with source names

----

#### integrate2d
##### Synopsis
 numerical computation of an 2-dim. integral

##### Usage
```c
 Double_Type I = integrate2d( Ref_Type func, y1, y2,
Double_Type x1, x2
);

```

##### Qualifiers

* intfun[&qromb]:: Reference to the integrator
* NOTE: Qualifiers are passed to all sub-functions!

##### Description

This function numerically computes the 2-dimensional integral 'I' over the
integrant-function 'func' of the form:

I = int_x1^x2 int_y1(x)^y2(x) func(x,y) dx dy

The given limits 'x1' and 'x2' are the lower and upper integration limits
for the 'x' variable, respectively. 'y1' and 'y2', on the other hand, are
references to functions, which calculates the lower and upper limit y1(x)
and y2(x) for the 'y' variable depending on 'x'.

The implemented solution is adopted from the 'Numerical Recipes in C'
Chap. 4.6. !

The integrator can be changed by the qualifier 'intfun', which is set to
'qromb' as default (see 'help qromb). Qualifiers given to 'integrate2d'
are passed to the 'intfun' function!

##### Example

% Calculation of the area of an rectangle:
%    I = int_0^1 dx int_0^2 dy
%      = [ x ]_0^1 \* [ y ]_0^2
%      = 2

variable x1 = 0., x2 = 1.;
define y1(x){ return 0.; };
define y2(x){ return 2.; };
define func( x, y ){ return 1.; };
variable I = integrate2d( &func, &y1, &y2, x1, x2 );
vmessage("Area of rectangle is A = %g",I);

% Calculation of the area of the unit circle in cartesian coordinates:
%   I = int_-1^1 int_-sqrt(1-sqr(x))^sqrt(1-sqr(x)) dx dy
%     = int_-1^1 2 \* sqrt(1-sqr(x)) dx

define tfun( x, y ){ return 1; }
define y1(x){ return -sqrt(1-sqr(x)); }
define y2(x){ return  sqrt(1-sqr(x)); }
variable I = integrate2d( &tfun, &y1, &y2, -1., 1. ; qromb_max_iter=24, qromb_eps=1e-3 );
vmessage("Area of unite circle is A = %g, abs(A-PI)/PI = %g", I, abs(I-PI)/PI );

%

__See also__: qromb, qsimp, integrate2d_test

----

#### integrateAB5
##### Synopsis
 integrates an ordinary differential equation with the 5th order Adams-Bashforth algorithm

##### Usage
```c
 x = integrateAB5(&f, t1, t2, dt[, x0]);
```

##### Description

The integral of the ordinary differential equation

dx/dt = f(x(t), t)  with  x(t0) = x0

reads

x(t) = x0 + int_{t0}^{t} f(x(t'), t') dt'

<code>&f</code> is a reference to a function with two arguments:
<code>define f(x, t)</code>

<code>{</code>

<code>  return ...;</code>

<code>}</code>

<code>x</code> may be be a scalar as well as an array.

__See also__: integrateRK4

----

#### integrateGK
##### Synopsis
 Integrate function with Gauss Kronrod method (G7K15)

##### Usage
```c
 Double_Type integrateGK(Ref_Typ fun, Double_Type a, b, ...);
```

##### Qualifiers

* max_intervals: [=5]: Maximum number of intervals to use
* quiet: : If given, do not message about non-convergence
* tolerance: [=1e-8]: Convergence tolerance
* recursive: If given, integration is done recursively. max_intervals does not apply.
* qualifier: [=NULL]: qualifier structure. Will be passed to function.

##### Description

Calculate the integral of a function <code>fun</code> from <code>a</code>
to <code>b</code>. It is expected that the first argument of <code>fun</code>
is the integration parameter. Additional arguments can be passed
after the integration boundaries. The second return value is the
estimated error from the integral value.

##### Example

(val,err) = integrateGK(&sin, 0, PI);

__See also__: integrateRK4

----

#### integrateRK4
##### Synopsis
 integrates an ordinary differential equation with the 4th order Runge-Kutta algorithm

##### Usage
```c
 x = integrateRK4(&f, t1, t2, dt[, x0]);
```

##### Description

The integral of the ordinary differential equation

dx/dt = f(x(t), t)  with  x(t0) = x0

reads

x(t) = x0 + int_{t0}^{t} f(x(t'), t') dt'

<code>&f</code> is a reference to a function with two arguments:
<code>define f(x, t)</code>

<code>{</code>

<code>  return ...;</code>

<code>}</code>

<code>x</code> may be be a scalar as well as an array.

__See also__: integrateAB5

----

#### integrateRK45_adaptive
##### Synopsis
 Integrate an ODE with an adaptive 4th/5th order Runge-Kutta algorithm

##### Usage
```c
 (t, x(t)) = integrateRK45_adaptive(&f, t0, t, [, x0]);
```

##### Description

Given an ordinary differential equation of the form

dx/dt = f(t, x(t))
(with <code>x</code> either a scalar or an array)

this function numerically computes the solution

x(t) = int_{t0}^{t} f(t', x(t')) dt' [ + x0 ]

by means of a 4th/5th order Runge-Kutta (RK) algorithm.

<code>&f</code> is a reference to a function with two arguments:

<code>define f(t, x)</code>

<code>{</code>

<code>  return ...;</code>

<code>}</code>

If x is an array, the adaptive stepsize is chosen according

to the needs of the "worst-offender" equation implying that

the desired accuracy is reached by each individual component.

Note: All qualifiers are also passed to the function f.
##### Qualifiers

* eps: [<code>=1e-12</code>] absolut error control tolerance; lower limit: 1e-15
* method: [<code>="RKCK"</code>] choose among three different RK45 methods:
"RKF": RK-Fehlberg, "RKCK": RK-Cash-Karp, "RKDP": RK-Dormand-Prince
* path: return the entire path and not only the final result
* verbose: show intermediate "times" <code>t</code>
* plus all qualifiers of the function f:

##### Example

% d/dt x(t) = -sin (t^2)\*2t; -> analytical solution: x(t) = cos(t^2) for x(0)=1
define f(t,x)
{
return -sin(t^2)\*2\*t;
};
(t, x) = integrateRK45_adaptive(&f, 0, 10, 1; path);
plot(t,x-cos(t^2));

% d/dt [x1(t),x2(t)] = [x2(t),-x1(t)]; -> analytical solution: x1(t) = cos(t) for x1(0)=1, x2(0)=0
define f(t,x)
{
[x[1],-x[0]];
}
(t, x) = integrateRK45_adaptive(&f, 0, PI, [1,0]; path);
plot(t,x[\*,0]-cos(t));

__See also__: integrateRKF45, integrateRK4, integrateAB5

----

#### integrateRKF45
##### Synopsis
 integrates an ODE with the adaptive 4th/5th order Runge-Kutta-Fehlberg algorithm

##### Usage
```c
 x = integrateRKF45(&f, t1, t2, dt[, x0]);
```

##### Qualifiers

* eps: [<code>=1e-12</code>] error control tolerance
* verbose: show intermediate "times" <code>t</code>

##### Description

This implementation of the adaptive Runge-Kutta-Fehlberg algorithm
is still considered EXPERIMENTAL and MAY REQUIRE FURTHER TESTING!

The integral of the ordinary differential equation

dx/dt = f(x(t), t)  with  x(t0) = x0

reads

x(t) = x0 + int_{t0}^{t} f(x(t'), t') dt'

<code>&f</code> is a reference to a function with two arguments:
<code>define f(x, t)</code>

<code>{</code>

<code>  return ...;</code>

<code>}</code>

<code>x</code> may be be a scalar as well as an array.

__See also__: integrateRK4, integrateAB5

----

#### integrate_trapez
##### Synopsis
 numerical integration with the trapezoidal rule

##### Usage
```c
 Double_Type int = integrate_trapez(Double_Type x[], Double_Type y[]);
alternative:
Double_Type int = integrate_trapez(Ref_Type function, Double_Type min, Double_Type max);
```

##### Description

If two arguments (<code>x[]</code> and <code>y[] = function(x[])</code>) are given the integral is calculated via:
<code>int = sum_i (y[i-1] + y[i])/2 \* (x[i]-x[i-1])</code>
An alternative usage with three arguments requires a reference to
the function and the integration limits. The function is evaluated
on an equidistant grid. The number of steps can be set with a qualifier.
The second case allows a forth argument specifying a previous result
with a smaller number of steps, which is meant for iterative usage by
the function <code>qsimp</code>.
##### Qualifiers

* steps [=100]: :    number of equidistant grid points,
on which the function is evaluated

##### Example

% Integration of the sin function from 0 to PI/3
% The result should be 0.5
variable x = [0:PI/3:#100];

% The first method: providing grid and corresponding function values
integrate_trapez (x, sin(x));

% Alternative method using reference to the function and integration limits
integrate_trapez (&sin, 0, PI/3);
integrate_trapez (&sin, 0, PI/3; steps = 5000);

__See also__: integrateRK4, qsimp

----

#### interpol2D
##### Synopsis

##### Usage
```c
 img2 = interpol2D(X2, Y2,  X, Y, img);
```

##### Description

<code>img = Double_Type[ny, nx];</code>

<code>X  = Double_Type[nx];</code>

<code>Y  = Double_Type[ny];</code>

<code>min(X) <= X2 <= max(X)</code>

<code>min(Y) <= Y2 <= max(Y)</code>

----

#### interpol_2d_table
##### Usage
```c
 Double_Type interpol_2d_table(Double_Type x, y, Struct_Type table)
```

----

#### interpol_polynomial
##### Synopsis
 interpolates a polynomial function between data points

##### Usage
```c
 Double_Type y = interpol_polynomial(Double_Type x, Double_Type X[], Double_Type Y[]);
```

##### Description

<code>X</code> and <code>Y</code> are arrays of same length <code>n</code>.
<code>y</code> is the Lagrange polynomial (of degree <code>n-1</code>) interpolating
the data points (<code>X[i]</code>, <code>Y[i]</code>), evaluated at <code>x</code>:

<code>     n-1           n-1      x - X[j]  </code>

<code>y =  sum  Y[i] \* product  ----------- </code>

<code>     i=0        j=0,j!=i   X[i]-X[j]  </code>

If <code>x</code> is an array (which doesn't need to be ordered), <code>y</code> will also be an array.

__See also__: interpol_points

----

#### inversemapping
##### Synopsis
 computes the inverse of a 2d mapping numerically

##### Usage
```c
 (x, y) = inversemapping(&getxy, cache, x_, y_);
```

##### Description

(cache.x_, cache.y_) = getxy(cache.x, cache.y);
(x_, y_) = getxy(x, y);

----

#### ionabs (fit-function)
##### Synopsis
 multiplicative fit-function for ionized photoabsorption

##### Description

Currently, the cross section is only evaluated at the center of each bin!

The first fit parameter, <code>ionabs.N_H</code>, is a dummy parameter,
which is not taken into account for the model. One can, however, use it
to relate the ionized column densities to an equivalent hydrogen column density.

__See also__: ionized_phabs_sigma

----

#### ionized_phabs_sigma
##### Synopsis
 calculates the photoabsorption cross section for ionized material

##### Usage
```c
 Double_Type sigma = ionized_phabs_sigma(Double_Type E);
```

##### Description

<code>E</code> is the energy in keV (may be a scalar or an array),
<code>sigma</code> is the corresponding cross section in cm^2.
The ion of interest is specified by the following
##### Qualifiers

* Z: atomic number (1 <= <code>Z</code> <= 30)
* Nel: number of electrons (<code>Z</code> >= <code>Nel</code> > 0)
* n: principal quantum number for the selection of a subshell (together with l)
* l: orbital angular momentum quantum number for the selection of a subshell

__See also__: Verner & Yakovlev (1995)

----

#### JD2MJD
##### Synopsis
 Convert Julian Dates to Modified Julian Dates.

##### Usage
```c
 JD2MJD(JD);
```

##### Description

Helper function to convert Julian Dates to MJD by
subtracting off 2400000.5.

__See also__: j2dmjd, mjd2jd

----

#### jd2mjd
##### Synopsis
 Convert Julian Dates to Modified Julian Dates.

##### Usage
```c
 jd2mjd(JD);
```

##### Description

Helper function to convert Julian Dates to MJD by
subtracting off 2400000.5.

__See also__: mjd2jd

----

#### jd2year
##### Synopsis
 transform a JD into a fractional year

##### Usage
```c
 Double_Type year = jd2year(Double_Type JD);
```

##### Qualifiers

* mjd: The argument is given in MJD, not in JD.

##### Description

NOTE: This routine takes into account leap years. This is good for
plotting, but this means that there are slight phase shifts that could be
problems when doing time series analysis. For such purposes best use
EpochofJD!

__See also__: EpochofJD

----

#### JDofDate
##### Synopsis
 Calculates the (modified) Julian Date

##### Usage
```c
 Double_Type JD = JDofDate( struct { year, month, day, hour, minute, second } );
```
or

```c
 Double_Type JD = JDofDate(year, month, day[, hour[, minute[, second]]]);

```

##### Qualifiers

* mjd: return the MJD, i.e., JD-2400000.5
* julian_calendar: return the JD/MJD assuming the
Julian calendar rather than the Gegorian one

##### Description

This routine calculates the Julian Date for a given Gregorian date
following the routine by Fliegel and van Flandern (1968, Comm. ACM 11, 657)
and further optimized as discussed by Pulkkinen and van Flandern (1979,
ApJ Suppl 41: 391). With the julian_calendar qualifier the date is
calculated for the Julian calendar (should be done for dates before
15 October 1582 in Germany, see
https://en.wikipedia.org/wiki/Gregorian_calendar
for a rough table and
https://de.wikipedia.org/wiki/Gregorianischer_Kalender
for a table containing the exact dates for the switch over).

The date is either given by a structure or by at least 3 integer arguments.
Fractional parts for the year and month are ignored. The default values for
hour, minute and second are 0, fractional days, hours, etc. are properly
taken into account.

The year must be larger than -4716 (4717 BC).
This function is array safe.

__See also__: MJDofDate,dateOfMJD

----

#### JDofEpoch
##### Synopsis
 Returns the (M)JD of a Julian or Besselian epoch such as J2000.0

##### Usage
```c
 jd=JDofEpoch(epochstring;qualifiers)
```

##### Qualifiers

* mjd: Return the modified julian date (default: JD)

##### Description

This function returns the julian date corresponding to a
Julian or Besselian epoch (e.g., J2000, B1950.0 etc.). For highest
precision, the most commonly used values are hardcoded, other values
are calculated using the formulae given by Lieske (1979, A&A 73, 282)
for Besselian dates and the standard definition of the Julian epoch
(based on Julian years with 365.25 days).

The epoch string must start with a "B" for a Besselian epoch and
"J" for a Julian epoch, followed by a number that designates the year
fractional values such as 2017.25 are possible.

Note that the time system in which the dates are defined is TT, for most
applications that do not require microsecond accuracy for the conversion
of positions the precise time system won't matter.

If the routine is called with a floating point number, it is assumed
that this number is the epoch and this number is returned. This greatly
simplifies functions in which the epoch is either a string or
a number.

__See also__: EpochofJD,tt2tai,tt2tdb

----

#### jpl_bineph2fits
##### Synopsis
 convert a binary JPL ephemeris to FITS

##### Usage
```c
 jpl_bineph2fits(ephfile,fitsfile);
```

##### Description

This function reads the JPL binary ephemeris in ephfile
and writes it to the fitsfile.

The JPL ephemeris must be in the "old-style" format.
SPK files are NOT supported.

The function has to be run on a machine with the same byte
sex as the ephemeris (JPL typically distributes ephemerides
for all common types of byte sex). It does not do a lot of
checking, however, it has been used to successfully
convert ALL available JPL old-style ephemerides into FITS.

Which also means you should probably ask Joern Wilms for
the location of the relevant FITS file rather than using this
function...

__See also__: jpl_eph,jpl_eph_vec

----

#### jpl_eph
##### Synopsis
 calculate planet positions using the JPL ephemeris

##### Usage
```c
 Struct_Type results = jpl_eph(jd,ta,ce);
```

##### Description

This function returns the ephemeris  of target body ta
as seen from center body ce for the time jd (the JD in the
TDB system).

NOTE: To calculate apparent planet positions for observing,
use the higher level function planetpos.

NOTE2: If you want a routine that is compatible with
function vsop87, uses TT and is vector safe, use  jpl_eph_vec

jd is either a Double or a 2-element array (to avoid roundoff
errors the array can include, e.g., the integer and fractional
parts of the JD). It is given in in TDB. If you need to calculate
positions for a time TT (=TAI+32.184s), convert with function
tt2tdb.
Note, however, that for all practical applications except for ms
pulsar timing, you can assume that TT=TDB.

The target and center bodies ta and ce are identified as outlined
below.

By default, the routine initializes to DE430 as distributed with HEASOFT
(and found either in  $LHEA_DATA/JPLEPH.430 or in
$LHEASOFT/refdata/JPLEPH.430).
The ephemeris in HEASOFT is only a subset of DE430, valid for about 1950--2050.
For these ephemerides, the precision for the decades around AD2000 is on
the order of meters to tens of meters, and milliarcseconds (see below).
Joern provides full files for DE430, valid for the time between
AD1550 and AD2650, and for DE431, which covers years -13200 to +17191
(with lower precision for the moon).

Use the ephemeris qualifier if you want to use another ephemeris.

For planets, the function returns an array containing the xyz-position,
and the velocity components in the ICRF. For angle variables
(only contained in a few of the JPL ephemerides), the array elements are
the angles and their  derivatives, and for the difference TT-TDB, the time
difference and its derivative. Units are km and km/s, rad and deg/day [!],
or s and s/day [!].

Target bodies or angles are either identified by a number as listed
below or by the indicated case-insensitive string. Note that not all
ephemeris files contain all of the possibilities!

1 - Mercury
2 - Venus
3 - Earth
4 - Mars
5 - Jupiter
6 - Saturn
7 - Uranus
8 - Neptune
9 - Pluto
10 - Moon
11 - Sun
12 - Solar System Barycenter
13 - Earth-Moon Barycenter
14 - 1980 IAU nutation angles
15 - Lunar libration (Euler) angles
16 - Lunar angular velocity
17 - TT-TDB

where 3 is the Earth's geocenter. For planets with moons, the
position returned is with respect to the barycenter of the respective
planetary system.

TT-TDB is measured at the geocenter.

The following abbreviations are also allowed:
12: SSB
13: Earth-Moon or EMV
14: IAU1980
15: Lunar Libration

For targets 14-17 the center is ignored

See Folkner et al., 2014, IPN Progress Report 42-196 for a description
of the precision that is reached with DE430/DE431. The figures in
this publication indicate that for the timeframe from about 1970 onwards,
where precise astrometry and space probe data exist, a precision
on the order of several 10s of meters is reached (and apparent
angular positions are precise to milli-arcseconds).

This function is NOT array safe, and it CANNOT be used in
a parallel_map or other parallelized functions. This is
because global caches are used that we cannot avoid if we
want decent performance for single calls. Sorry

##### Qualifiers

* ephemeris: structure defining the ephemeris, initialized with
jpl_initeph (see there).

__See also__: jpl_eph_vec,jpl_initeph, planetpos

----

#### jpl_eph_vec
##### Synopsis
 high precision planetary positions from the JPL ephemerides, vsop87 compatible

##### Usage
```c
 Struct_Type jpl_eph_vec(JD,planet;qualifiers)
```

##### Description

This routine provides an interface to jpl_eph which allows to
calculate heliocentric ephemerides from the JPL ephemerides.
It is compatible with a subset of the functions that are also
available from function vsop87.

Use planetpos to calculate apparent planetary positions.

The routine returns high precision planetary positions for
all planets for a given (array) of times (in TT).

Depending on the qualifiers the routine can return rectangular
coordinates (X,Y,Z) or ecliptical coordinates
(longitude, latitude, distance) in a heliocentric coordinate system
for epoch J2000 (the ICRF).

Contrary to vsop87, orbital elements cannot be calculated.

By default the function returns rectangular heliocentric
coordinates in a structure with elements x, y, z, vx, vy, vz.
Here x, y, z are in an ecliptical(!) coordinate system for
the epoch J2000 (but see the equatorial qualifier), where the x-axis
is in the direction of the vernal equinox, the z-axis points
to the ecliptical North pole, and the y-axis forms
a right handed coordinate system with the x- and z-axes.
The default units are AU and AU/day (but see the mks and cgs qualifiers).

For heliocentric coordinates the planet can have the values
"Mercury", "Venus", "Earth", "Mars", "Jupiter", "Saturn",
"Uranus", "Neptune", and "Pluto" (the latter is not included
in vsop87!). The value "Earth-Moon" will return the position
of the Earth-Moon barycenter.

The default unit of time is the Julian Date in TT, to be
compatible with vsop87. Use the qualifier tdb to avoid the
conversion TT->TDB, which for pretty much all practical
applications except for ms pulsar timing results in no
appreciable difference in the results but is slightly faster.

Use the mjd qualifier to use MJD rather than JD as input.

The default function uses DE430 from HEASOFT, which is valid
for the time between 1950 and 2050. Joern can provide ephemeris
files for the full DE430, valid AD1550 and AD2650, and
also for DE431, which covers years -13200 to +17191
(with lower precision for the moon). See the ephemeris qualifier.

When using JPL ephemerides, do NOT use this function in
a parallel_map or other parallelized computations. This is
because global caches are used that we cannot avoid if we
want decent performance for single calls. Sorry.

##### Qualifiers

* tdb: The time argument is in TDB, not TT
* mjd: The time argument is in MJD, not in JD
* barycentric: Return coordinates with respect to the solar system barycenter rather
than heliocentric coordinates.
* spherical: Return spherical coordinates in the ecliptical coordinate system.
In this case the structure returned contains the elements
lat, lon, r, latdot, londot, rdot, where lat and lon are the ecliptical
latitude and longitude (in rad), r is the distance in AU, and
latdot, londot, rdot are their time derivatives (in rad/day or
AU/day, respectively.)
* equatorial: return coordinates in the ICRS2 coordinate system, not the
equatorial one (vsop87 does not have this option)
* mean_equinox: Coordinates are given in the frame defined by the
mean equinox and ecliptic of the date.
The default is to return J2000 coordinates.
* deg: All angle quantities to be returned are in deg, or deg/day.
* mks: All distances returned by the function are given in meters or m/s, depending
on the deg qualifier, angles are returned in rad and rad/s or deg and deg/s.
* cgs: Dito, but use centimeters instead of meters.
* ephemeris: Ephemeris structure initialized with jpl_initeph.
* forcearray: Force the tags in the returned struct to be arrays.
The default is that they are arrays only if JD
is an array.

__See also__: vsop87,jpl_initeph,jpl_eph

----

#### jpl_initeph
##### Synopsis
 initialize a JPL ephemeris

##### Usage
```c
 Struct_Type results = jpl_initeph(file);
```

##### Description

This function initializes a JPL ephemeris for later use with
function jpl_eph.

For an empty argument, the function defaults to DE430 as distributed
with HEASOFT. This is probably what you want (and since jpl_eph
initializes to that ephemeris, this means that you probably do NOT
want to call this function in the first place).

The ephemeris file must be in FITS format, using the HEASOFT
convention (see function jpl_bineph2fits if you need to generate
such a file from one of the older JPL ephemeris distributions).

The function first searches for the ephemeris file as given,
and then searches for the file by prepending ${LHEA_DATA}/
or ${LHEASOFT}/refdata/.

##### Qualifiers

* nocache: Do not cache the ephemeris data in memory,
i.e., keep the FITS file open and seek on it.
This is faster if calculating just a few positions
(e.g., for a few weeks), otherwise, reading the
whole ephemeris first [the default] is faster,
but a memory hog, i.e., it won't work for DE431.

__See also__: jpl_eph,jpl_bineph2fits

----

#### j_ff
##### Synopsis
 Calculates the emission coefficient for free-free emission (bremsstrahlung)

##### Usage
```c
 Double_Type j = j_ff(nu,T);
```

##### Qualifiers

* Z: average nuclear charge (default=1)
* ne: electron particle density (cm^-3; default: 1e10)
* np: proton particle density (cm^-3; default: 1e10)

##### Description

This function returns the emission coefficient for free-free radiation
(bremsstrahlung). The frequency, nu, is measured in Hz and can be an array,
the temperature T is measured in K.

Note: per Kirchhoff's law the total bremsstrahlung spectrum from
a slab of size R is
B_nu(nu,T)\*(1.-exp(-R\*alpha_ff(nu,T)))

__See also__: alpha_ff

----

#### kaastra_cstat_goodness
##### Synopsis
 computes the theoretical Cash-statistics for a Poisson process

##### Usage
```c
 (Array_Type ce, Array_Type cn) = kaastra_cstat_goodness(Array_Type mu);
```

##### Description

Given an array of predicted counts, mu, this function uses the
expressions given by Kaastra (2017, A&A 605, A51) to compute the expected
value of the contribution to the C-statistic for this bin, ce, and its
variance, cn.

This can be used to evaluate the expected value of the C-statistic of
a fit (see function cstat_goodness()), or to show the expected model
contribution in a plot of the cash statistics residuals.

The function uses Kaastra's approximation to the exact formulae (his
Eqs. 8-22), which are better than a few times 1e-4. Use the exact
qualifier if you cannot live with this (it is unclear why you would
want to do this).

##### Qualifiers

* exact: use Kaastra's exact equations 4-6 (slow; use only
for testing, not necessary for practical work)

__See also__: cstat_goodness

----

#### kendall_tau_censored
##### Synopsis
 calculation of Kendall rank correlation coefficient

##### Usage
```c
 Struct_Type cc = kendall_tau(Double_Type x[], Double_Type y[]);
```

```
or

```c
 Struct_Type cc = kendall_tau(Double_Type x[], Double_Type y[], Char_Type y_is_upper_limit[]);
```
or

```c
 Struct_Type cc = kendall_tau(Double_Type x[], Char_Type x_is_upper_limit[], Double_Type y[], Char_Type y_is_upper_limit[]);
##### Description

This function calculates the Kendall rank correlation coefficient <code>tau</code>,
as defined by M. G. Kendall (1938, Biometrika, 30, 81), between two
arrays of equal length.
The result <code>tau</code> is within the interval [-1,1], where 1 means a perfect
agreement between both rankings, -1 means perfect disagreement, and values
around 0 indicate that both arrays are independent.
The value of <code>tau</code> is the difference of concordant and discordant pairs
divided by the total number of pairs.
In the definition of Helser (Dennis R. Helsel, "Nondetects and Data Analysis",
Wiley, 2005) only the number of determined (valid) pairs is used instead of
the total number. The structure returned by this function includes the values
of <code>tau</code>, <code>sigma</code>, and <code>pval</code> in both ways.

The value <code>sigma</code> characterizes the expected width of the distribution of <code>tau</code>
for random data. (If the "gsl" module is not available, the p-value is not calculated.
It can be obtained from <code>tau</code> and <code>sigma</code>.)

See statistic module for further functions: require("stats");
##### Examples

variable x = [1:2:#100];
variable y = grand(100)+x;
variable cc_no_limits   = kendall_tau_censored(x,y);
variable cc_incl_limits = kendall_tau_censored(x,y,nint(urand(100)));

__See also__: kendall_tau, pearson_r, spearman_r, spearmanrho, correlation_coefficient

----

#### KeplerEquation
##### Synopsis
 solves Kepler's Equation  E - e sin E  =  M

##### Usage
```c
 Double_Type E = KeplerEquation(Double_Type M, e)
```

##### Description

Solve Kepler's Equation by using the result of the method
by S. Mikkola (1987) Celestial Mechanics, 40, 329-334
as starting value for a Newton-Raphson iteration
to extend the applicability of this function to higher eccentricities.
##### Qualifiers

* threshold: stopping criterion for the Newton Raphson iteration, default = 1e-5

----

#### kerr_lp_energyshift_observer
##### Synopsis
 calculates the energyshift from a Lamp Post source (point-like)
on the rotational axis of a spining black hole (spin a) to the
observer. It follows the relxill definition that if the height is in
negative units, it is interpreted as given in units of the event
horizon.

##### Usage
```c
 kerr_lp_energyshift_observer(height, a)
```

##### Description

g = E_obs / E_emit =  sqrt( 1 - 2\*h/(h^2 + a^2)

----

#### kerr_lp_redshift
##### Synopsis
 calculates the redshift from a Lamp Post source (point-like)
on the rotational axis of a spining black hole (spin a) to the  observer

##### Usage
```c
 kerr_lp_redshift(height, a)
```

##### Description

z_obs = 1 / ( sqrt( 1 - 2\*h/(h^2 + a^2) )  - 1

----

#### kerr_rms
##### Synopsis
 calculates the radius of marginal stability of a black hole
in units of GM/c^2

##### Usage
```c
 kerr_rms(a)
```

----

#### kerr_rplus
##### Synopsis
 calculates the event horizon of a black hole in units of GM/c^2

##### Usage
```c
 kerr_rplus(a)
```

----

#### keV2erg
##### Synopsis
 convert flux to erg

##### Usage
```c
 Double_Type new_value = kev2erg(Double_Type old_value)
```

##### Qualifiers

* y_fac: : divide the value by 10^{y_fac}

__See also__: plot_unfold

----

#### keyinput
##### Synopsis
 reads input from the keyboard

##### Usage
```c
 String_Type = keyinput([String_Type message]);
```

##### Qualifiers

* silent: characters are not echoed, e.g. useful for password input
* time: read timout after given seconds. Returns an empty string
* nchr: returns automatically after given number
of chars have been read
* prompt: output the given string before reading
* default: initial text to be read

##### Description

Prompts the user to input a line, which is ended
with return. If a limited number of chars is given
using the `nchr' qualifier, the line is automatically
ended after reaching this number without pressing return.
It is also possbile to limit the time for an input with the
`time' qualifier and to disable echoing the input using
the `silent' qualifier. The latter is useful, e.g., for password
inputs or for single key events.
If `nchr==1', the returned keycode is
checked against special keys such as the arrow keys.
If one of these is detected, the returned string contains
the name if the pressed key.

----

#### keynote_size
##### Synopsis
 Set the pgplot output size to something suitable for Keynoe presentations (isis_fancy_plots package)

##### Usage
```c
 apj_size;
```

##### Description

Use as:
isis> id = open_print("fig1.ps/vcps"); keynote_size; nice_width;
isis> plot(x,y);
isis> close_print(id,"gv");

__See also__: sov, apj_size, nice_width, open_print, close_print, pg_color, pg_info

----

#### KS_test
##### Synopsis
 computes the test statistics of a two sample Kolmogorov-Smirnov test

##### Usage
```c
 test_statistics = KS_test(Double_Type x1, Double_Type x2);
```

##### Description

The null hypothesis of the KS test is that two samples are
distributed according to the same distribution. It is rejected if
the test statistic D=max(F_1(x),F_2(x)) is greater than a certain
value

----

#### lagrange_poly
##### Synopsis
 Interpolate points with Lagrange polynomial

##### Usage
```c
 Double_Type[] lagrange_poly(Double_Type[] x, x0, y0);
```

##### Qualifiers

* w: calculated weights can be passed directly

##### Description

Calculate the Lagrange interpolation at points <code>x</code> given
points <code>x0</code>,<code>y0</code>.

If multiple invocations of the interpolation for the same pair
<code>x0</code>,<code>y0</code> are required it is better to calculate the
weights beforehand (see <code>lagrange_weights</code>) and pass them
via the <code>w</code> qualifier.

The Lagrange interpolation is quite powerfull, however, as any
polynomial interpolation scheme it suffers from Runges phenomenon.
It can be shown that the interpolation of a function on a uniform
grid is close to the worst case, while the evaluation on a grid
given by the Chebyshev nodes is close to optimal. Therefore, when
interpolating a function not restircted to a specific grid you'd
be best advised to use <code>chebyshev_nodes</code> and
<code>chebyshev_lagrange_weights</code>.

##### Example

variable x = chebyshev_nodes(20; min=-2, max=2);
variable w = chebyshev_lagrange_weights(20);
variable f = sin(x);
% we can extrapolate, but this will diverge quickly
variable p = lagrange_poly([-5:5:#100], x, f; w=w);

__See also__: lagrange_weights,chebyshev_nodes,chebyshev_lagrange_weights

----

#### lagrange_poly_deriv
##### Synopsis
 Calculate y values of the derivative of a Lagrange polynomial

##### Usage
```c
 dy = lagrange_poly_deriv(x, y);
```

##### Qualifiers

* w: calculated weights can be passed directly

##### Description

Returns the y values of the derivative of the lagrange polynomial at the
given points x according to Berrut & Trefethen 2004. Interpolating those
points with the same weights gives the full derivative function.

##### Example

variable x = chebyshev_nodes(20; min=-2, max=2);
variable w = chebyshev_lagrange_weights(20);
variable f = sin(x);
variable p = lagrange_poly([-5:5:#100], x, f; w=w);
variable df = lagrange_poly_deriv(x, f);
variable dp = lagrange_poly([-5:5:#100], x, df; w=w);

__See also__: lagrange_poly,lagrange_weights

----

#### lagrange_weights
##### Synopsis
 Get Lagrange polynomial weights

##### Usage
```c
 Double_Type[] lagrange_weights(Double_Type[] x0);
```

##### Description

Given an array of evaluation points <code>x0</code> this function
calculates the weights for the barycentric Lagrange polynomial.

__See also__: lagrange_poly

----

#### lag_energy_spectrum
##### Synopsis
 Calculates the time lag of energy-resolved lightcurves

##### Usage
```c
 Struct_Type les = lag_energy_spectrum(String_Type[lcs], dimseg)
```

##### Description

\* lc_list: Array of file names of the energy-resolved
lightcurves (must have same length and time binning)
\* dimseg:  Segmentation length in bins, needed to segment the
lightcurve and do the Fourier calculation

returns: lag-energy-spectrum as a struct with fields lag, errlag
##### Qualifiers

* dt: Time resolution of the lightcurve in seconds
[default: TIMEDEL keyword]
* deadtime: Detector deadtime in seconds [default: 0.0s]
* f_lo: Array_Type. For frequency-resolved lag-energy
spectra. Default: lowest sampled frequency [an array
containing only fmin=1/(dt\*dimseg)]. Unit: Hz
* f_hi: See f_lo. Default: Nyquist frequency [1/(2\*dt)]. Unit: Hz
* verbose: Increase verbosity [default=0]
* outfile: String_Type. If set, write various timing products
into a FITS file.
* elo, ehi: Double_Type: Energy grid
* elo_ref, ehi_ref: Boundaries of reference lightcurve

##### Notes

\* The default error computation is Nowak et al., 1999, ApJ, 510,
874 (Sect. 4).
\* All input lightcurves are accounted for their gaps and segmented
by segment_lc_for_psd.
\* The cross-spectrum (CPD) and lags are calculated with foucalc.
\* The PSD normalization is fixed to Miyamoto.
\* The average time lag in the frequency interval is calculated by
the normal mean on the imaginary and real part of the
cross-spectrum:
atan2(mean(Imag(CPD)), mean(Real(CPD)))/(PI\*(fmin+fmax))
\* Reference lightcurve: For each energy bin, the function takes the
summed lightcurves of all but the current energy bands (always
excluding the lightcurve for the cross-spectrum).
\* The function does \*not\* use any information about the energy
grid. This has to be created by yourself (and must be the same as
the lightcurves in lc_list)! The elo, ehi qualifiers are only
for the records in the output file

If you want to add energy information to the output FITS file,
you can pass two Double_Type arrays (same length as lc_list) via
the elo, ehi qualifiers. The columns of the created extension,
called BAND_<f_lo>_<f_hi>Hz, are:

ENERGY_LO           - Energy channel (keV), taken from elo qualifier
ENERGY_HI           - Energy channel (keV), taken from ehi qualifier
MEAN_PHASE          - Phase (radians), computed as atan2(mean(Im(CPD)), mean(Re(CPD)))
LAG                 - Time lag (s), computed as phase/(PI\*(fmin+fmax))
LAG_ERR             - Error computed as in Nowak et al., 1999, ApJ, 510, 874 Eq. 16
LAG_ERR_PROPERR     - Error computed from Gaussian error propagation
MEAN_REAL/IMAG_CPD  - real/imaginary part of the mean of the
segment-averaged cross-spectrum
MEAN_REAL/IMAG_CPD_ERR - standard error on the mean of the
real/imaginary segment-averaged cross-spectrum
RMS/RMS_ERR         - Root Mean Squared variability of the channel-of-interest
lightcurve. The error is calculated using
Vaughan et al., MNRAS 345, 1271, 2003 Eq. 11.

Following keywords are written into each extension:

N_SEGS              - Number of segments averaged over (foucalc.numavgall)
N_FREQS             - Number of frequencies averaged over (as in
"mean of the CPD")
F_MIN/F_MAX         - Minimum and maximum frequency as given by
f_lo, f_hi qualifiers
FMIN_DFT/FMAX_DFT   - Minimal/Maximal frequency of the frequency-filtered
Fourier products - this can be different from
F_MIN/F_MAX due to the discretization of the
\*Discrete\* Fourier Transform

If you find any bugs or have questions, please contact ole.koenig@fau.de

The function also accepts all qualifiers of segment_lc_for_psd.

##### Example

%% Example for frequency-resolved lag-energy spectrum
(f_lo, f_hi) = log_grid(1, 50, n_freqs);  % (Hz)
% Energy grid must be the same as extracted lightcurves
(elo, ehi) = log_grid(0.5, 10, n_energies);  % (keV)
variable les = lag_energy_spectrum(lc_names, dimseg
; f_lo = f_lo, f_hi=f_hi,
verbose=2, outfile="test.fits", elo=elo, ehi=ehi);
_for ii (0, n_freqs-1, 1) {
ohplot_with_err(elo, ehi, les.lag[\*,ii], les.errlag[\*,ii]);
}

__See also__: segment_lc_for_psd, foucalc, colacal

----

#### Lamberg_Equal_Area_projection
##### Synopsis
 Computes the Lambert_Equal_Area_projection

##### Usage
```c
 (Double_Type x, y) = Lambert_Equal_Area_projection(Double_Type phi,theta);
```

##### Qualifiers

* deg: <code>phi</code> and <code>theta</code> are in degrees, not in radian
* inverse: calculate the inverse projection, interpreting phi as the x- and
theta as the y-coordinate; all other qualifiers are
also interpreted as expected.

##### Description

This is an equal area projection centered on the North Pole (when plotting
southern objects, flip the sign of theta!). phi is the angle along the
equator, theta is measured from the equator.

<code>R =sin((pi/2 - theta)/2);</code>

<code>x = R \* sin(phi);</code>

<code>y = R \* cos(phi);</code>

The inverse function returns nan if the arguments given are not possible.

__See also__: Aitoff_projection, Hammer_projection

----

#### lc_from_events
##### Synopsis
 extracts light curves from an event list

##### Usage
```c
 Struct_Type dat = lc_from_events(Struct_Type evts [, Array_Type bands]);
```

##### Qualifiers

* dt: time resolution in sec [default: 100]
* back: Struct_Type b_evts : subtract background events
* gti: struct { Double_Type start, stop } : GTIs for events
* minfracexp: minimum allowed fractional exposure of a time bin, requires GTIs to be set

##### Description

This function extracts light curves from an event list given as the
following structure:
Double_Type[] time - the event arrival times (in seconds)
Double_Type[] pi   - the associated event energies (in eV)
If <code>bands</code>
is given, an array of structures containing light curves of each band
is returned. The energy bands have to be given in eV. To receive
two lightcurves with energies between 1-2keV and 2-3keV, e.g.,

If GTIs are provided, the fractional exposure 'fracexp' will be added
to the output structure.

<code>dat = lc_from_events(evts, [1000,2000,3000]);</code>

__See also__: color_color_data, histogram

----

#### leapyear
##### Synopsis
 tells whether a year is a leapyear in the Gregorian calendar

##### Usage
```c
 Char_Type leapyear(Integer_Type y)
```

##### Description

For a leapyear in the Gregorian calendar, <code>y</code> is either
divisible by 4 but not by 100,
or <code>y</code> is divisible by 400.

__See also__: daysPerMonth

----

#### linear_fit_xerr_yerr_data
##### Synopsis
 fits a linear function to data points with both x- and y-errors

##### Usage
```c
 (Double_Type a, b) = linear_fit_xerr_yerr_data(Double_Type X[], Xerr[], Y[], Yerr[][, Double_Type b0]);
```
or

```c
 (Double_Type a, aerr, b, berr) = linear_fit_xerr_yerr_data(Double_Type X[], Xerr[], Y[], Yerr[][, Double_Type b0]; with_errors);

```

##### Qualifiers

* verbose:
* n: number of iterations
* with_errors: The 90% confidence interval (Delta chi^2 = 2.7) is computed as well.

##### Description

The data points <code>(X[i]+-Xerr[i], Y[i]+-Yerr[i])</code>
are iteratively fitted with the linear function <code>y = a + b\*x</code>.
If no initial value for the slope b is specified,
<code>b0 = s \* [max(Y)-min(Y)]/[max(X)-min(X)]</code>
is used.
The best fit is found iteratively after the algorithm
by Fasano & Vio (1988), BICDS 35, p.191.

__See also__: linear_regression

----

#### linear_regression
##### Synopsis
 computes a linear regression fit

##### Usage
```c
 Struct_Type = linear_regression(Double_Type[] x, y[, err]);
```

##### Description

<code>err</code> is the uncertainty of the <code>y</code> values.
If <code>err</code> is not specified, all data points are weighted equally.

The parameters <code>a</code> and <code>b</code> of the best fit <code>y = a + b\*x</code>
are   <code>a = (Sy\*Sxx - Sx\*Sxy)/D</code>

and <code>b = (S \*Sxy - Sx\*Sy )/D</code>

where <code>S  = sum(1/err^2)</code>

<code>Sx = sum(x/err^2)</code>,  <code>Sxx = sum(x\*x/err^2)</code>

<code>Sy = sum(y/err^2)</code>,  <code>Sxy = sum(x\*y/err^2)</code>

and <code>D = S\*Sxx - Sx^2</code>.

The returned structure contains the fields <code>a</code> and <code>b</code>,
and the errors <code>da</code> and <code>db</code>, respectively,
as well as the reduced chi square <code>chisq</code> of the fit.

__See also__: linear_fit_xerr_yerr_data

----

#### linear_xyfit
##### Synopsis
 linear xy fit function to be used with xyfit_fun

##### Usage
```c
 xyfit_fun ("linear");
```

##### Description

This function is not meant to be called directly!

Calling <code>xyfit_fun ("linear");</code> sets up a linear fit
function for xy-data. It has the form <code>y = a\*x + b</code>,
where <code>a</code> and <code>b</code> are the two fit parameters.

__See also__: xyfit_fun, define_xydata, plot_xyfit, linear_regression

----

#### lines
##### Synopsis
 model for gaussian line profiles of highly ionized ions' transitions

##### Usage
```c
 fit_fun("lines(id)");
```

##### Description

The return values are the bin-averages of  1 + sum_i gauss_i(lambda) ,
i.e., lines is a multiplicative model.

__See also__: gauss, set_lines_par_fun

----

#### line_intersect
##### Synopsis
 Calculate the intersection of two lines defined by
two points each

##### Usage
```c
 res=line_intersect(P0,P1,P2,P3,&alphaP,&alphaQ);
```

```
or

```c
 res=line_intersect(P0x,P0y,P1x,P1y,P2x,P2y,P3x,P3y,&alphaP,&alphaQ);
##### Description

This function implements a fast line intersection algorithm
based on
https://stackoverflow.com/questions/563198/how-do-you-detect-where-two-line-segments-intersect
between the line segments P=P0--P1 and Q=P2--P3, where the points Pi
are defined as structures of the type struct {x,y} or through
coordinates P0x,P0y, etc.

The function returns 1 if an intersection exists and 0 if not.

If an intersection exists, the function returns the relative position
of the intersection point on the segments in variables alphaP and alphaQ.

----

#### lissajous_pattern
##### Synopsis
 calculates a Lissajous pattern for 3:4 ratio with PI/4 offset

##### Usage
```c
 variable li = lissajous_pattern();
```

##### Qualifiers

* amplitude: [1.0]: amplitude by default from -1 to 1
* tstart: [0.0]: tstart
* tstop: [1.0]: tstop
* x0: [0.0]: x0
* y0: [0.0]: y0

##### Description

An ARF is built from a mirror area, filter-,
support grid-, detector layer transmission
information. The transmission files-parameters
have to be file names of transmission tables
in the format:

----

#### lists_all_lines
##### Synopsis
 shows the parameters of a lines-model's lines in a given wavelength range

##### Usage
```c
 list_all_lines([ids][, lMin, lMax]);
```

__See also__: lines, get_lambda_parameters_of_all_lines, list_lines

----

#### list_copy
##### Synopsis
 makes a copy of a nested list

##### Usage
```c
 List_Type copy = list_copy(List_Type list);
```

##### Description

<code>list_copy</code> returns a properly dereferenced copy of an
arbitrarily nested <code>List_Type</code> with all its entries.
Depending on the Data_Type of the entries, <code>list_copy</code>
iteratively calls the according sub-function
(<code>struct_copy</code>, <code>array_copy</code> or <code>list_copy</code>).
If the Data_Type of one of its entries is not
one of privouse mentioned ones, <code>list_copy</code> returns
@(Data_Type) or respectively @(entry).
##### Example

s = Struct_Type[1]; s[0]=struct{ a=Array_Type[1,2] };
s[0].a[[0]]=[0:9];
l = [{ array_copy(s), 1., [1:10] }, {"abs"}];
copy = COPY(l); copy[0][0][0].a[[0]] = ["modified"];
print(l[0][0][0].a);

__See also__: COPY, struct_copy, array_copy, assoc_copy

----

#### list_free_bounds
##### Synopsis
 List parameter range bounds for free parameters

##### Usage
```c
 list_free_bounds();
```

##### Qualifiers

* tolerance: [=0.01] Boundary hit tolerance

##### Description

This function reports the parameter boundaries for all free parameters.
For more details see help for <code>list_par_bounds</code>.

__See also__: list_par_bounds, par_bounds

----

#### list_lines
##### Synopsis
 shows the parameters of a lines-model's used lines in a given wavelength range

##### Usage
```c
 list_lines([ids][, lMin, lMax]);
```

__See also__: lines, get_lambda_parameters_of_lines, list_all_lis

----

#### List_par
##### Synopsis
 list current fit function and parameters

##### Usage
```c
 List_par ([arg])
```

```
or

```c
 List_par ( String_Type[] pattern )
##### Description

The optional argument is used to redirect the output.  If arg
is omitted, the output goes to stdout.  If arg is of type
Ref_Type, it the output string is stored in the referenced
variable.  If arg is a file name, the output is stored in that
file.  If arg is a file pointer (File_Type) the output is
written to the corresponding file.

If the given argument is a String pattern, only parameter matching
this pattern are listed!

The parameter listing looks like this:

gauss(1) + poly(1)
idx  param        tie-to  freeze    value      min          max
1  gauss(1).area     0     0       103.6        0            0
2  gauss(1).center   0     0        12.1       10           13
3  gauss(1).sigma    0     0       0.022    0.001          0.1
4  poly(1).a0        0     0       1.2e4        0            0
5  poly(1).a1        0     1           0        0            0
6  poly(1).a2        0     1           0        0            0

The first line defines the form of the fit-function. The
parameter index idx may be used to refer to individual fit
parameters (see set_par).  freeze = 1 (0) indicates that the
corresponding parameter value is frozen (variable).  If two
parameter values are tied together, the connection is indicated
in the tie-to column.  For example, if parameter 1 has tie-to =
5, that means the value of parameter 1 is tied to the value of
parameter 5; if parameter 5 changes, parameter 1 will follow
the change exactly.  If min=max=0, the corresponding parameter
value is unconstrained.

In input parameter files (see load_par), lines beginning with a
'#' are mostly ignored and may be used to include comments.
Exceptions to this rule are "special" comment lines which are
used to support additional functionality such as, e.g. writing
some parameters as functions of other parameters (see
set_par_fun).  Note that, aside from these special cases,
comment lines are not loaded by load_par and will not be
preserved if file is later overwritten by save_par.

__See also__: list_free, edit_par, set_par, get_par, save_par, set_par_fun

----

#### list_Par
##### Synopsis
 lists parameters of the current fit-function as ISIS-commands

##### Usage
```c
 list_Par([ pars[] ]);
```

##### Qualifiers

* fit_fun: lists also the fit-function
* fmt: format statement for min/max/value

----

#### list_par_bounds
##### Synopsis
 List parameter range bounds

##### Usage
```c
 list_par_bounds();
```

##### Qualifiers

* tolerance: [=0.01] Boundary hit tolerance

##### Description

This function reports the values of the fit parameters relative to the
allowed parameter range. The value is indicated in a graphical indicator
where the parameter lies (from -0.5 to +0.5 around the center). If the
parameter value is within <tolerance> close to the range minimum or maximum
the indicator at the correspongind limit changes from '<' or '>' to '|'.
In the case of min == max both ends are displayed as '|'.

__See also__: list_free_bounds, par_bounds

----

#### list_xypar
##### Synopsis
 list current xy-parameter and xy-function

<!--%{{{ -->
##### Usage
```c
 list_xypar();
```

__See also__: get_xyfit_fun, save_xypar, xyfit_fun

----

#### loadDataset
##### Synopsis
 loads and assigns one spectrum and its detector response

##### Usage
```c
 Integer_Type id = loadDataset(phaFile[, rmfFile[, arfFile[, backFile[, row]]]]);
```

##### Description

----

#### loadHETGlcs
##### Synopsis
 Load Chandra HETG lightcurves

##### Usage
```c
 lcs = loadHETGlcs();
```

##### Qualifiers

* dir [="."]:      : path to the extracted spectra
* heg [=1]:        : load HEG spectra (=0: don't load)
* meg [=1]:        : load MEG spectra (=0: don't load)
* order [=[-1,1]]: : diffraction orders to load. Sign matters.
* energyband [=[500,10000]]: : extracted energy bands. See
description below for details.
* unit [="eV"]:    : Unit for the energyband: eV, keV, A

##### Description

Load Chandra HETG lightcurves extracted with the (new) Remeis
extraction scripts and return a structure with the results.

The new (summer 2014) Remeis Chandra gratings extraction scripts
do not longer specify observation / extraction specific
information in the file name, but only the arm, diffraction order,
and energyband of the lightcurve, e.g., heg_m1_500-1000.lc or
meg_p1_3500-10000.lc.

loadHETGlcs reads the corresponding lightcurve for each specified arm,
diffraction order, and enegeryband and stores it as a field in a
structure.
The returned structure is then in the form (in case of the defaults):
struct{
dir = ".",
orders = [-1,1],
arms = ["heg","meg"],
energyband = [500, 10000],
unit = "eV",
heg_m1_500_10000 = Struct_Type, % content of the fits file
heg_p1_500_10000 = Struct_Type,
meg_m1_500_10000 = Struct_Type,
...
}
The function returns -1 if both arms are ignored, i.e., no
lightcurves chosen.

The energyband can be specified in multiple ways:
\* a list or array of limits: [0.5,1.5,3,10] keV. In this case, the
energybands for the lightcurves are assumed to be 0.5-1.5,
1.5-3, and 3-10 keV, i.e., there are no gaps.
\* a list or an array of energy pairs: {[0.5,1.5],[3,10]} or
[{0.5,1.5},{3,10}] keV. Then the bands are taken as they are,
i.e., it is possible to have gaps between energy bands.

__See also__: loadHETGlc_sum, loadHETGspec

----

#### loadHETGlc_sum
##### Synopsis
 ADD Chandra HETG lightcurves

##### Usage
```c
 Struct_Type lcsum = loadHETGlcs( [lcs] );
```

##### Qualifiers

* dir [="."]:      : path to the extracted spectra
* heg [=1]:        : load HEG spectra (=0: don't load)
* meg [=1]:        : load MEG spectra (=0: don't load)
* order [=[-1,1]]: : diffraction orders to load. Sign matters.
* energyband [=[500,10000]]: : extracted energy bands. See
description below for details.
* unit [="eV"]:    : Unit for the energyband: eV, keV, A

##### Description

Sum multiple Chandra HETG lightcurves extracted with the (new) Remeis
extraction scripts and return a structure with the result.

The new (summer 2014) Remeis Chandra gratings extraction scripts
do not longer specify observation / extraction specific
information in the file name, but only the arm, diffraction order,
and energyband of the lightcurve, e.g., heg_m1_500-1000.lc or
meg_p1_3500-10000.lc, and only extract lightcurves on a per
arm/order basis.

Often, we are more interested in the combined lightcurve of
multiple arms / orders.
loadHETGlc_sum can be used in 2 ways:
- call the function with no arguments and use the qualifiers to
specify which lightcurves you are interested in. The
qualifiers are passed to loadHETGlcs to load the lightcurves
first.
- call the function with 1 argument: the lightcurves produced by
a previous call of loadHETGlcs. In this case, all lightcurves
contained in the structure will be summed, and the qualifiers
will have no effect [in the future, they could be used to
choose a subset of the given lightcurves, but this is not
implemented yet].

The returned structure has the same fields as simply reading a
single lightcurve file would produce. If reading of the
lightcurves fails, the return value is -1.

The function assumes that the lightcurves have not been tempered
with, i.e., that they are correctly (Chandra) formatted
lightcurves and have the same length, time grid, etc. No checks
are performed. Fields like time and exposure are taken from the
first lightcurve in the structure, since they are expected to be
the same for various extractions of the same ObsID.

The energyband can be specified in multiple ways:
\* a list or array of limits: [0.5,1.5,3,10] keV. In this case, the
energybands for the lightcurves are assumed to be 0.5-1.5,
1.5-3, and 3-10 keV, i.e., there are no gaps.
\* a list or an array of energy pairs: {[0.5,1.5],[3,10]} or
[{0.5,1.5},{3,10}] keV. Then the bands are taken as they are,
i.e., it is possible to have gaps between energy bands.

__See also__: loadHETGlcs, loadHETGspec

----

#### loadHETGspec
##### Synopsis
 Load locally extracted Chandra HETG spectra and responses

##### Usage
```c
 Struct_Type ids = loadHETGspec();
```

##### Qualifiers

* dir [="."]:      : path to the extracted spectra
* heg [=1]:        : load HEG spectra (=0: don't load)
* meg [=1]:        : load MEG spectra (=0: don't load)
* order [=[-1,1]]: : diffraction orders to load. Sign matters.

##### Description

Load Chandra HETG spectra extracted with the (new) Remeis
extraction scripts and return a structure with the dataset indices.

The new (summer 2014) Remeis Chandra gratings extraction scripts
do not longer specify observation / extraction specific information
in the file name, but only the arm and diffraction order of the
spectrum, e.g., heg_m1.pha or meg_p1.pha. The old extraction
scripts used to generate a loaddata0.sl file for convenience. With
the more generic file names, this function replaces the load
script. To ensure backwards compatibility with dataset-index
sensitive par files, the function loads the arms and orders in the
exact same order as the old load scripts used to:
heg_m1 heg_p1 meg_m1 meg_p1 heg_m2 heg_p2 meg_m2 meg_p2 ...

The returned structure is then in the form (in case of the defaults):
struct{
dir = ".",
orders = [-1,1],
arms = ["heg","meg"],
heg_m1 = 1,
heg_p1 = 2,
meg_m1 = 3,
...
}
The function returns -1 if both arms are ignored, i.e., no spectra
chosen.

Negative and positive diffraction orders can be chosen independently
of each other. However, all selected orders are applied to all
selected grating arms: You can load HEG without MEG and vice versa.
But if you load them both in a single call of loadHETGspec, the
same orders will be loaded for both of them.

If you would like to load configurations like [heg_m1, meg_p1],
where different orders are loaded for each grating arms, you have
to call the function multiple times or load the spectra by hand.

__See also__: loadHETGlcs, loadHETGlc_sum

----

#### load_1storderHETGS_datasets
##### Synopsis
 loads MEG+-1 & HEG+-1 Chandra HETGS spectra

##### Usage
```c
 Integer_Type ids[] = load_1storderHETGS_datasets(String_Type specpath, RMFpath);
```

----

#### load_atime
##### Synopsis
 loads a structure containing arrival times from a FITS-file

##### Usage
```c
 Struct_Type load_atime(String_Type filename, String_Type extname);
```

##### Description

The arrival times, which were stored previously by
'save_atime', are loaded and returned as a structure.
This structure has the fields described in the
'atime_det' function. The extension table containing
the arrival times must be specified as well as the
FITS-file itself.

__See also__: save_atime, atime_det

----

#### load_data_combined
##### Synopsis
 reads and combines the given rows from a Fits Type II pha file

##### Usage
```c
 Integer_Type load_data_combined(String_Type, pha_filename, Integer_Type[] rows);
```

##### Description

A combination of load_data and combine_datasets, with
the exception that the rows appear as a single dataset.

All qualifiers are passed to load_data.

__See also__: load_data, combine_datasets

----

#### load_data_integral
##### Synopsis
 reads an INTEGRAL spectrum from a PHA file and performs the necessary tweaks

##### Usage
```c
 Integer_Type id = load_data_integral(String_Type pha_filename);
```

##### Description

ISIS's load_data often does not work with INTEGRAL spectra for the following reasons:

- The extension of the PHA file is not called 'SPECTRUM'.

- The extensions of the RMF file are not called 'MATRIX' and 'EBOUNDS'.

- The extension of the ARF file is not called 'SPECRESP'.

- The columns ENERG_LO and ENERG_HI of the ARF file contain only zeros.

The function load_data_integral tries to make the appropriate changes
(modify the extension names, write a new ARF file) and finally uses load_data.
##### Qualifiers

* verbose: [=1] show changes

__See also__: load_data

----

#### load_fermi
##### Synopsis
 loads fermi data produced by the "Fermi-SED Script"@Remeis

##### Usage
```c
 Integer_Type data_id = load_fermi(String_Type filename);
```

##### Qualifiers

* rmf_factor: [=10]: define a fine RMF to properly evaluate the model

##### Description

Loads fermi data produced by the "Fermi-SED Script"@Remeis. Note
that special care is taken here, as the energy bins are relatively
large. Therefore the function set_bin_corr_factor is used to
calculate a correction factor. This factor is used automatically
for loading the data. In order to plot the data properly,
plot_data/unfold has to be used.
WARNING: Use clear_all to delete the correction factors (as well
as the data). This is necessary as otherwise the correction factors
are applied to a newly loaded dataset with the same ID.

This function is not working if you have computed a Fermi spectrum
with Fermipy!

__See also__: load_fermi_spectrum,load_fermi_catalog

----

#### load_fermi_catalog
##### Synopsis
 loads Fermi data from a catalog for a given source

##### Usage
```c
 Integer_Type data_id = load_fermi_catalog(String_Type sourcename);

```

##### Qualifiers

* list: return list of available sources
* ul: Load includes upper limits
* catalog: specify the catalog (default: 2FGL_point_source@Remeis)
* fgl3: Use this when reading in the 3FGL catalog, either with
the catalog qualifier or without

##### Description

WARNING: Use clear_all to delete the correction factors (as well
as the data). This is necessary as otherwise the correction factors
are applied to a newly loaded dataset with the same ID.

__See also__: load_fermi

----

#### load_fermi_spectrum
##### Synopsis
 loads fermi data produced by any fermipy script

##### Usage
```c
 Integer_Type data_id = load_fermi_spectrum(String_Type filename);
```

##### Qualifiers

* rmf_factor: [=10]: define a fine RMF to properly evaluate the model
* ts_min: [=9]: set TS threshold for spectral bins to be loaded in as data points.

##### Description

Loads fermi data produced by any Fermi spectrum produced with fermipy. Note
that special care is taken here, as the energy bins are relatively
large. Therefore the function set_bin_corr_factor is used to
calculate a correction factor. This factor is used automatically
for loading the data. In order to plot the data properly,
plot_data/unfold has to be used.

A note regarding upper limits: you can set yourself at which significance
you consider a spectral to be valid and not use the 2 sigma upper limit (UL).
The default value is TS = 9, which is ~3 sigma. The SED plot produced by
the Fermi-LAT analysis script has a lower threshold, which is why you might
get less data points in your spectrum, when you load it in isis with the
default value of 'ts_min'.
Spectral bins with a lower TS value will be treated as upper limits and
not loaded in isis. For plotting purposes, the upper limits need to be
added from the [\*]_sed.fits file (column e2dnde_ul) and multiplied by a factor
of 1.60218e-6 to convert from MeV to erg.

This function supersedes the previous function 'load_fermi', which can only
be used to load the Fermi Spectra produced by the original "Fermi-SED"
script.

WARNING: Use clear_all to delete the correction factors (as well
as the data). This is necessary as otherwise the correction factors
are applied to a newly loaded dataset with the same ID.

__See also__: load_fermi

----

#### load_grouped_xmm_data
##### Synopsis
 wrapper for load_data, which sets already a few basic options

##### Usage
```c
 Integer_Type Index = load_grouped_xmm_data([String_Type Path], [E_lo, E_hi]);
```

##### Qualifiers

* min_sn[=5]: [<code>=5</code>]: Set the minimal S/N ratio (see help("group");)
* min_chan[=2]: [<code>=2</code>]: Set the minimal number of Channels do be rebinned (see help("group");)
* delete_data: If set, any data sets loaded previously will be deleted.

##### Description

This functions loads data (by default "src_sd.pha"), groups it,
and notices the energy bins between E_lo[=1keV] and E_hi[=10keV].
When changing all default values, it can be easily used for any
other satellite.

----

#### load_HETGS_datasets
##### Synopsis
 loads Chandra HETGS spectra from a type II pha file

##### Usage
```c
 Integer_Type ids[] = load_HETGS_datasets(String_Type specpath, RMFpath[, Integer_Type ms[]]);
```

##### Description

<code>ids</code> is an array containing negative/positive MEG/HEG spectra

----

#### load_par_from_FITS_header
##### Synopsis
 loads the fit-function and parameters from a FITS file

##### Usage
```c
 load_par_from_FITS_header(String_Type filename);
```

##### Description

This function reads keywords from a FITS header
created with <code>save_par_to_FITS_header_struct</code>.

__See also__: save_par_to_FITS_header_struct, save_par, load_par

----

#### load_par_tbnew
##### Synopsis
 load a parameter file after decreasing the upper limit for tbnew.PL

##### Usage
```c
 load_par_tbnew(String_Type filename);
```

##### Description

Early versions of the <code>TBnew</code> absorption model allowed
for a too large upper limit of the <code>PL</code> parameter of 5.
This function reduces the <code>PL</code> parameter to 3.999,
rewrites the parameter file, and loads it with <code>load_par</code>.

__See also__: load_par

----

#### load_pha
##### Synopsis
 Load pha file with grouping and quality information

##### Usage
```c
 load_pha("pha_filename")
```

__See also__: group_pha

----

#### load_piled1storderHETGS_datasets
##### Synopsis
 loads 1st order Chandra-HETGS data and sets up the simple_gpile model

##### Usage
```c
 Integer_Type ids[] = load_1storderHETGS_dataset(specpath, RMFpath);
```

----

#### load_piledHETGS_datasets
##### Synopsis
 loads Chandra HETGS spectral and sets up the simple_gpile model

##### Usage
```c
 Integer_Type ids[] = load_1storderHETGS_dataset(specpath, RMFpath);
```

__See also__: load_HETGS_datasets, use_simple_gpile

----

#### load_radio2

##### Synopsis
 reads and loads radio data

##### Usage
```c
 Integer_Type data_id = load_radio (String_Type filename);
```

##### Description

Takes data an ASCII file , comprised of three  columns:
Frequency[Hz], Flux density [mJy], Error [mJy], and loads
the data as a dataset.
WARNING: The standard bin width is set to 10%

It can be changed with the qualifier binwidth (given in
fraction of the frequency). Since a log frequency grid is
used, it will not be exactly the size given.
WARNING: Bins cannot overlap, as grid needs to be continuous!

##### Qualifiers

* binwidth:    specify bin width
* use_struct:  use an ISIS structure with the
following fields: freq[Hz],
bandwidth[Hz], flux[mJy], err[mJy];
with full bandwidth given

##### Example

isis> variable data_file = "/some/path/radio_file.txt";
isis> variable radio_data = load_radio2(data_file);

example using a textfile that includes bin widths:

isis> variable abc = ascii_read_table ("radio_dat.txt",[{"%F","freq"},{"%F", "bandwidth"},{"%F","flux"},{"%F","err"}]);
isis> variable radio_data = load_radio2(abc; use_struct);

__See also__: read_radio, load_radio

----

#### load_scaled_data
##### Synopsis
 Loads a dataset with a non-unity AREASCAL keyword or column

##### Usage
```c
 id = load_scaled_data( String_Type file);
```

##### Qualifiers

* rmf: [="rmf.fits", response file if not in data header]
* arf: [="arf.fits", effective area file if not in data header]
* bkg: [="bkg.fits", background file if not in data header]

##### Description

Load a data file with a non-unity AREASCAL, rewrite the
data/background to undo the ISIS default application of this value,
create a post_model_hook to properly apply it, and rewrite the data
and background backscales to properly apply it.  The data itself
must either reference a set of responses/backgrounds, or these must
be entered via qualifiers upon initial loading of the data.

__See also__: load_data, _define_back, set_data_backscale

----

#### load_xypar
##### Synopsis
 load xy-parameter and xy-function from parameter file

<!--%{{{ -->
##### Usage
```c
 load_xypar(String_Type file);
```

##### Description

Load parameter file saved with <code>save_xypar("file.par")</code>. To display
the load parameters one should use <code>list_xypar</code> instead of
<code>list_par</code>.

__See also__: save_xypar, load_par

----

#### logging

##### Synopsis
 write a log file

##### Usage
```c
 logging ("filename.log", "Log message");
```

##### Description

This function writes output to a log file (which will be created if it does
not exist. It can also handle input in the sprintf format (see example).
By default all input to logging is also printed to stdout.
Repeated calls to the function add the new message at the end of the file. It
is therefore recommended to specify the date and time in the name of the log
file.

##### Qualifiers

* v: verbosity: [default: 1] print output also to stdout, set this
qualifier to 0 for no output to stdout

##### Example

isis> variable cutime = strftime("%Y-%m-%d_%H:%M:%S");
isis> variable l = cutime+".log";
isis> logging(l, "\* Found %.u observations for %s", length(src_info), src);
isis> logging(l, "\*\*\*Error in function %s", _function_name() );

__See also__: strftime, _function_name()

----

#### log_grid
##### Synopsis
 generate a logarithmic histogram grid

##### Usage
```c
 (bin_lo[], bin_hi[]) = log_grid(min, max, nbins);
```

##### Description

This function is an shorthand form of:

<code>(log_bin_lo, log_bin_lo) = linear_grid( log(min), log(max), nbins );</code>

<code>bin_lo = exp( log_bin_lo );</code>

<code>bin_hi = exp( log_bin_hi );</code>

__See also__: linear_grid

----

#### log_par
##### Synopsis
 log-log parabolic fit function

##### Description

Fit function of the form F(x)= exp ( a\*(log(x) - center)^2 + peak );
For fitting the function is implemented in integrated from.
<code>center</code> has to be specified in the unit in which the bins are given.
The function is a parabola in the log-log space of the unit of the bins.
Currently the function only works for negative curvature <code>a<0</code>.

For a log-parabola in the energy/frequency regime the function <code>log_par_en</code>
has to be used.

__See also__: log_par_en

----

#### log_par_en
##### Synopsis
 log-log parabolic fit function in the energy/frequency regime

##### Description

Fit function of the form F(nu)= exp ( a\*(log(nu) - center)^2 + peak );
For fitting the function is implemented in integrated from.
<code>center</code> has to be specified in Hz. The bins are expected to be
given in Angstrom (as it is typically the case in ISIS).
Currently the function only works for negative curvature <code>a<0</code>.

__See also__: log_par

----

#### lorentzmb (fit-function)
##### Synopsis
 implements a Lorentzian profile

##### Description

<code>L(f)  =  [2 rms^2 Q f0]/[pi/2 + atan(2\*Q)] \* 1/[f0^2 + 4 Q^2 (f-f0)^2]</code>

[see also Eq. (1) in Pottschmidt et al. (2003), A&A 407, 1039-1058]

where:

<code>rms</code> = contribution to the root mean square variability

<code> Q </code> = quality factor

<code> f0</code> = resonance frequency = <code>nu0/sqrt(1 + 1/[4 Q^2])</code>

<code>nu0</code> = peak frequency (maximum of <code>f \* L(f)</code>)

The parameters of the lorentzmb fit-function are
"rms" (= <code>rms</code>), "peakfr" (= <code>nu0</code>) and "quality" (= <code>Q</code>).

The integrated fit-function is:

<code>int L(f) df  =  rms^2/[pi/2 + atan(2\*Q)] \* arctan{2Q/pi\*(f/f0-1)}</code>

----

#### lorentzmb_old (fit-function)
##### Synopsis
 implements a Lorentzian profile

##### Description

<code>L(f)  =  1/pi \* [2 R^2 Q f0] / [f0^2 + 4 Q^2 (f-f0)^2]</code>

[Eq. (1) in Pottschmidt et al. (2003), A&A 407, 1039-1058]

where:

<code> R </code> = normalization constant

<code> Q </code> = quality factor

<code> f0</code> = resonance frequency = <code>nu0/sqrt(1 + 1/[4 Q^2])</code>

<code>nu0</code> = peak frequency (maximum of <code>f \* L(f)</code>)

The parameters of the lorentzmb fit-function are
"norm" (= <code>R</code>), "peakfr" (= <code>nu0</code>) and "quality" (= <code>Q</code>).

The integrated fit-function is:

<code>int L(f) df  =  R^2/pi \* arctan{2Q/pi\*(f/f0-1)}</code>

----

#### Lorentz_complex
##### Synopsis
 Compute complex Lorentz profile

##### Usage
```c
 Complex_Type[] = Lorentz_complex(z, z0, gamma);
```

----

#### lorentz_trafo
##### Synopsis
 lorentz transformation for a boost in any direction

##### Usage
```c
 lorentz_trafo( Double_Type ct,
Vector_Type x,
Vector_Type B
);

```

##### Description

This function performs a Lorentz transformation:
( ct, x ) -> ( ct', x')
ct' = gamma ( ct - B\*x )
x'  = x + ( (gamma-1)/B^2 \* B\*x - gamma \* ct ) \* B
where x is the spartial vector, gamma the Lorentz-factor
and B=v/c the velocity vector.

__See also__: Vector_Type

----

#### lorentz_xyfit
##### Synopsis
 Lorentzian xy fit function to be used with xyfit_fun

##### Usage
```c
 xyfit_fun ("lorentz");
```

##### Description

Calling <code>xyfit_fun ("lorentz");</code> sets up a Lorentzian fit
function for xy-data. It has the form
<code>y = norm \* sigma/(2pi) \* 1/((x-center)^2 + (sigma/2)^2)</code>
##### Example

variable id = define_xydata(x, y, yerr);
xyfit_fun("lorentz");
() = fit_counts;
variable xfit, yfit;
(xfit, yfit) = eval_xyfun([min(x) : max(x) : #1000]);
plot(xfit, yfit);

__See also__: xyfit_fun, define_xydata, plot_xyfit, linear_regression

----

#### lumdist
##### Synopsis
 Calculate luminosity distance (in Mpc) of an object given its redshift

##### Usage
```c
 result = lumdist(z);
```

##### Qualifiers

* silent: If set, the program will not display adopted
cosmological parameters at the terminal.
* h0: [=70] Hubble parameter in km/s/Mpc
* omega_k: curvature constant, normalized to the closure density.
Default is 0, indicating a flat universe.
* omega_m: Matter density, normalized to the closure density,
default is 0.3. Must be non-negative.
* omega_lambda: : Cosmological constant, normalized to the
closure density (default: 0.7).
* q0: [=-0.55] Deceleration parameter, numeric scalar = -R\*(R'')/(R')^2

##### Description

INPUTS:    z = redshift (positive scalar or vector)
OUTPUTS:   The result of the function is the luminosity distance (in Mpc)
for each input value of z.
The luminosity distance in the Friedmann-Robertson-Walker model is
taken from  Caroll, Press, and Turner (1992, ARAA, 30, 499), p. 511.
Uses a closed form (Mattig equation) to compute the distance when the
cosmological constant is zero.   Otherwise integrates the function using
QSIMP.
See help for cosmo_param for a description of the cosmological parameters,
note that only two out of the four parameters should be given!

The routine can fail to converge at high redshift for closed universes with
non-zero lambda. This can presumably be fixed by replacing QSIMP with
an integrator that can handle a singularity.

##### Example

%  Plot the distance of a galaxy in Mpc as a function of redshift out
%  to z = 5.0, assuming the default cosmology (Omega_m=0.3, Lambda = 0.7,
%  H0 = 70 km/s/Mpc)
variable z = [0:5:0.1];
plot (z, lumdist(z));

%  Now overplot the relation for zero cosmological constant and
%  Omega_m=0.3
oplot (z, lumdist(z ; omega_lambda=0 , omega_m=0.3) );

__See also__: cosmo_param, qsimp

----

#### luminosity
##### Synopsis
 computes a source luminosity assuming the current fit-function and a distance

##### Usage
```c
 Double_Type luminosity(Double_Type Emin, Emax, d);
```

##### Qualifiers

* factor: [=<code>1.001</code>] step of logarithmic energy grid
* Emin: minimum energy of (extended) grid
* Emax: maximum energy of (extended) grid

##### Description

returns <code>4pi (d kpc)^2 \* int_Emin^Emax E\*S_E(E) dE</code>  (in erg/s)

Use flux2lum to calculate luminosities for extragalactic sources.

__See also__: energyflux, flux2lum

----

#### makepsd
##### Synopsis
 Calculate the power density spectrum of a single energy band.

##### Usage
```c
 (psd, nipsd) = makepsd(rate, timeseg, dimseg);
```

##### Description

Input:
rate - input rate array
timeseg - real time of one segment of rate
dimseg  - number of bins in each segment of rate

Output:
psd   - unnormalized, averaged PSD
nipsd - averaged PSD, individual segments normalized
##### Qualifiers

* avgbkg: Average background count rate for Miyamoto normalization
* normtype: "Miyamoto", "Leahy", "Schlittgen" normalization type

----

#### make_fine_rmf
##### Synopsis
 creates a fine RMF

##### Usage
```c
 make_fine_rmf (Data_Id [Integer], Factor [Integer]);
```

##### Description

Creates a fine RMF. Therefore each data bin will be split into
a certain number of bins, specified by the variable "Factor".

__See also__: load_slang_rmf

----

#### make_movie_from_evtList
##### Synopsis
 makes a simple movie from a given event list

##### Usage
```c
 Double_Type total_img = make_movie_from_evtList(string eventFile, double dt, string movieFile);
```

##### Description

Make a movie from the eventlist "eventFile". The time (in
seconds) of each frame is adjusted by "dt". The output file is
written to "movieFile" (best use a mp4 file).
##### Qualifiers

* cmap: ["hot"] color map
* thres: [0.0] threshold of counts/frame, when a frame should be discarded
* fps: frames per secondswitch on the scale
* size: [10,10] size of the image in cm
* tstart: start time of the movie (sec)
* tstop: end time of the movie (sec)
* labels: draw some labels (white frame and time in ksec)

__See also__: xfig_plot_new,fitswcs_get_img_wcs

----

#### make_path
##### Synopsis
 Recursively create multiple directories

##### Usage
```c
 make_path (dirs)
```

##### Description

This function creates multiple directory paths. It is
similar to mkdir_rec, but does not internally change
directories, allows multiple path specifications, and
individual modes.

The function throws an IO error if a path component exists
and is not a directory.

##### Qualifiers

* mode: mode for the paths to be generated. If mode is an
array, it contains the mode for each individual path
specified. Default: 0777
* separator: path separator. Default is /, so you will
probably not have to use it...

##### Example

make_path(["./test1/test2","./test1/../test3"];mode=[0777,0700]);

__See also__: mkdir,mkdir_rec

----

#### make_spix
##### Synopsis
 creates a spectral index map using two .fits files (provided by DIFMAP)

##### Usage
```c
 make_spix(String_Type <code>name_lo</code>, String_Type <code>name_hi</code>);
```

##### Qualifiers

* iterations: [=1] set number of translations to average over
* cc: [=cc.fits] name of the cross correlation map.  Will generate
one if the file does not exist.
* lothreshold: [=NULL] if image has a pixel below this value it's set to
this value. also criterion for showing spectral index if
req_both_bands is set to 1
* hithreshold: [=NULL] if image has a pixel below this value it's set to
this value. also criterion for showing spectral index if
req_both_bands is set to 1
* shift: [={NULL,NULL}] define the shift of the second image wrt the first
in format {x,y} in mas
* crpix_shift: [=0.] Extra shift for converting mas in pixel. In the past, 0.5 was used,
but default is now  0., as only a relative is needed
* dec_step: [=NULL] pixel size in declination (value>0).
Default value is the largest pixel size of the two images
* dec_size: [=NULL] mapsize size in declination.
Default value is the largest map size of the two images
* ra_step: [=NULL] pixel size in right ascension (value>0).
Default value is the largest pixel size of the two images
* ra_size: [=NULL] mapsize size in right ascension
Default value is the largest map size of the two images
* beam: [=[NULL,NULL,NULL]] defines beam for restoring the two images
[semi-major axis, semi-minor axis, position angle]
in mas (major and minor axis) and degree (position angle)
* req_both_bands: [=0] only make calculations if both bands are above the
noise level
* fit_noise: [=1] set to 0 to use fits header for noise information
* lo_nsigma: [=3] number of standard deviations from mean to define
noise limit.  Only matters if fit_noise==1,
overrides lothreshold
* hi_nsigma: [=3] number of standard deviations from mean to define
noise limit.  Only matters if fit_noise==1,
overrides hithreshold
* n_beams: [=3] size of beam to exclude from core on correlation
calculation
* excl_core: [=1] set to 0 if you do not want the program to
automatically exclude the core from correlation calculations
* overwrite: overwrite the restore fits files (if already existing)

##### Description

This function creates a spectral index (F=v^a) map from two fits files provided by
DIFMAP.  A cross correlation fits image is generated and the images are shifted
by the best (iterations) translations and the spectral index, etc. are
calculated for each translations. The values are averaged with the weights
given by the corresponding value in the cc image.
If the provided images do not have the same size, resolution and beam, the
functions difmap_restore and enclosing_ellipse are used to obtain images with
these properties. It is also possible to specify a desired map size and
pixel size for both axes individually, otherwise  the default value from the comparison
of both images will be used. Note, that changing the pixel size may require changing the maps size as well.

It returns a structure that holds the information for the following values

Use the structure as an input to

struct_name.spec_map      ->   matrix of calculated spectral index values

struct_name.stdev         ->   matrix of weighted stdevs of calculated values

struct_name.avg_lum       ->   matrix of weighted average of the summed BRIGHTNESS of the images

struct_name.weights       ->   matrix of sum of weights used for calculations in each pixel

struct_name.avg_shift     ->   average shifts in a 2-element array [x_shift,y_shift]

struct_name.shift_weight  ->   weights for calculating avg shift [x_weight,y_weight]

struct_name.avg_shift_pixel -> average shift in pixel [x_shift_pixel, y_shift_pixel]

struct_name.ra_px_center  ->   x index of center pixel

struct_name.ra_steps      ->   x mas per pixel

struct_name.dec_px_center ->   y index of center pixel

struct_name.dec_steps     ->   y mas per pixel

struct_name.major         ->   semi major axis of beam in mas
struct_name.minor         ->   semi minor axis of beam in mas
struct_name.source        ->   source name
struct_name.date          ->   dates of images
struct_name.posang        ->   position angle of beam in degrees

__See also__: plot_spix, write_spix, read_spix, difmap_restore, enclosing_ellipse

----

#### mass_function
##### Synopsis
 Calculates the mass function of a binary.

##### Usage
```c
 Double_Type   mass = mass_function(Double_Type porb, asini[, error_porb, error_asini]);
or Double_Type[]    i = mass_function(Double_Type mass, Double_Type[] Mopt[, error_mass, error_Mopt]; i);
```

##### Qualifiers

* i: calculate and return the inclination (case 2a)
* Mx: neutron star mass in units of the solar mass
(default: 1.4)
* rad: return the inclination angle in radian
(default: degrees)
* chatty: set to zero to suppress output messages

##### Description

The mass function of a binary is given by
(see, e.g., Hilditch, 2001)

f(M) = (M_opt sin i)^3 / (M_x + M_opt)^2
= (4 Pi^2 (a sin i)^3) / (G P_orb^2)

with the masses of the neutron star, M_x, and its optical
ompanion star, M_opt, the inclination, i, the semi-major axis,
a, the orbital period, P_orb, and the gravitational constant, G.

There are two ways this function can be used:
1)  The orbital period (in days) and the semi-major axis (in
lt-s) are provided, which then is used to calculate the
right hand side of the above equation. The returned mass is
given in units of the solar mass.
2)  The value of the mass function, mass, and the companion
mass(es), Mopt, are provided and the i-qualifier is set.
The returned value(s) is (are) the orbital inclination(s), i.
In case of 2) the neutron star mass is assumed to be Mx = 1.4
solar masses by default, but can be changed by the Mx-qualifier.
The thirs possible case, that the companion mass is returned,
is formally solving a third order polynomial, which is yet not
implemented here.

If uncertainties for the given parameters are provided the error
propagated values are returned as well for the specific case via
(value,error) = mass_funtion(..., error(s));

----

#### matrix2array
##### Synopsis
 Transforms a matrix to an Array

##### Usage
```c
 Array_Type[] matrix2array( Any_Type[...,d,...] M, d );
```

##### Description

From the given dimension d of a matrix M an array is created,
i.e., the given dimension of the matrix is shifted into the
array which then contains matrices without this dimension.
##### Example

variable M = _reshape( [1:2\*3\*4], [2,3,4] );
variable A0 = matrix2array(M,0);
variable A2 = matrix2array(M,2);
vmessage("A0");print(A0);
vmessage("A2");print(A2);

----

#### matrix33_as_array
##### Synopsis
 return the contents of the matrix as a 3x3 matrix

##### Usage
```c
  arr=matrix33_as_array(m);
```

##### Description

Return the contents of the matrix as a 3x3 array

__See also__: vector, Vector_Type, matrix33_new

----

#### matrix33_determinant
##### Synopsis
 return the determinant of a 3x3 matrix

##### Usage
```c
  det=matrix33_determinant(m);
```

##### Description

Calculates the determinant of a 3x3 matrix.

__See also__: vector, Vector_Type, Matrix33_Type

----

#### matrix33_diag
##### Synopsis
 return a diagonal-matrix

##### Usage
```c
  Matrix33_Type=matrix33_diag(m11,m22,m33);
```

##### Description

Returns a 3x3 diagonal matrix. If m11,m22,m33 are given,
then the three diagonal values are initialized to these
three values. If only m11 is given, then a scalar
matrix where all three elements are equal to m11 is
returned.

__See also__: Vector_Type, Matrix33_Type

----

#### matrix33_identity
##### Synopsis
 return a identity-matrix

##### Usage
```c
  Matrix33_Type=matrix33_identity();
```

##### Description

Returns a 3x3 identity matrix.

__See also__: Matrix33_Type

----

#### matrix33_new
##### Synopsis
 instantiate a 3x3 matrix

##### Usage
```c
  Matrix33_Type=matrix33_new();
```

##### Description

Instantiates a new 3x3 matrix object.
The following initializers are available:
\* No arguments: a zero-Matrix is returned
\* One argument:
If the argument is of type Matrix33_Type: a copy of the argument
is returned
If the argument is a scalar: all matrix elements are initialized to
this scalar (use matrix33_diag to initialize a diagonal matrix!)
If the argument is an array with 9 elements: the matrix is initialized
to these elements
\* Nine arguments: matrix elements m11,m12,m13,m21,m22,m23,m31,m32,m33,
i.e., the elements are in row order and the matrix is:

m11 m12 m13
M =  m21 m22 m23
m31 m32 m33

__See also__: Matrix33_Type, Vector_Type

----

#### matrix33_null
##### Synopsis
 return a null-matrix

##### Usage
```c
  Matrix33_Type=matrix33_null();
```

##### Description

Returns a 3x3 null-matrix

__See also__: Matrix33_Type

----

#### matrix33_reflect
##### Synopsis
 return a 3x3 reflection matrix to change the handedness of the ith axis

##### Usage
```c
  Matrix33_Type=matrix33_reflect(i);
```

##### Description

Returns a reflection matrix, i.e., a matrix that changes the handedness
of the ith axis (where i=1: x-axis, i=2: y-axis, and i=3: z-axis)
when multipliying it with a vector.

__See also__: vector, Vector_Type, matrix33_new

----

#### matrix33_rot
##### Synopsis
 return a standard rotation matrix about the x-, y-, or z-axis

##### Usage
```c
  Matrix33_Type=matrix33_rot(i,angle;qualifiers);
```

##### Qualifiers

* deg: angle is given in deg [default: radians]

##### Description

Returns a rotation matrix to transform a column-3 vector from
one cartesian coordinate system to another. The new coordinate
system is given by rotating the original system in a counter
clockwise way around the ith axis (where i=1: x-axis,
i=2: y-axis, and i=3: z-axis)

The nomenclature follows Kaplan et al, The IAU Resolutions
on Astronomical Reference Systems, Time Scales, and Earth
Rotation Models, USNO circular 179, 2005.

__See also__: vector, Vector_Type, matrix33_new

----

#### matrix33_scalar
##### Synopsis
 return a scalar-matrix

##### Usage
```c
  Matrix33_Type=matrix33_scala(m11);
```

##### Description

Returns a 3x3 scalar matrix (a matrix where all diagonal elements have the
same value and where all other elements are zero)

__See also__: Vector_Type, Matrix33_Type

----

#### matrix33_transpose
##### Synopsis
 return the transpose of a 3x3 matrix

##### Usage
```c
  Matrix33_Type=matrix33_transpose(m);
```

##### Description

Returns the transpose of a 3x3 matrix

__See also__: vector, Vector_Type, matrix33_new

Matrix33_Type

##### Synopsis
 3x3 matrix type

##### Description

3x3 Matrix type that is compatible with Vector_Type

The following operations are defined for the Matrix33_Type:
\* M1+M2: Addition and subtraction of matrices
\* -M1: Changing sign of a matrix
\* M1\*M2: Matrix - Matrix multiplication
\* M1\*V: Matrix - Vector multiplication (V is a Vector_Type)
\* M1\*f and f\*M1: Matrix - real multiplication
\* M1/M2: Multiply M1 with the inverse of M2. Do NOT use this...

Objects of type Matrix33_Type can be instantiated with the
following functions (see there for detailed descriptions):
\* matrix33_new: general initialization
\* matrix33_diag: return a diagonal matrix
\* matrix33_scalar: return a scalar matrix
\* matrix33_null: return a null matrix
\* matrix33_identity: return an identity matrix
\* matrix33_rot: return a rotation matrix for the x-, y-, or z-axis
\* matrix33_reflect: return a reflection matrix for the x-, y-, or z-axis

Other functions operating on matrices (functions marked with + are also
available through accessor functions):
\* matrix33_determinant: calculate the determinant of the matrix (+)
\* matrix33_get_diag: return the diagonal elements of the matrix (+)
\* matrix33_get_trace: return the sum of the diagonal elements (+)
\* matrix33_transpose: return the transpose of the matrix (+)
\* matrix33_adjoint: return the adjoint of the matrix
\* matrix33_cofactors: return the matrix of cofactors

The Matrix33_Type object has the following accessors:
\* m.determinant(): return the determinant of the matrix
\* m.as_array(): return the elements of the matrix as a 3x3 array
\* m.transpose(): return the transpose of the matrix (not in place!)
\* m.diag(): return the diagonal elements as a vector
\* m.trace(): return the trace of the matrix
\* m.inverse(): return the inverse of the matrix (not in place!)

----

#### matrixmul
##### Synopsis
 Matrix multiplication

##### Usage
```c
  M[n,m] = matrixmul( A[n,j], B[j,m] );
```

##### Description

(Efficient) Calculation of the product of two matrices A and B.
If A is a (n x j)-Matrix and B a (j x m)-Matrix the resulting
Matrix has the dimensions (n x m).

If A or B is one dimensional, the neccessary second dimension
is assumed to be of length 1,
i.e., A[n]\*B[m] =  A[n,1]\*B[1,m] = M[n,m]

This function is identical to the ISIS intrinsic operator #
or the inner product and only available for backwards
compatibility!

__See also__: transpose, inner_product

----

#### _maximum
##### Synopsis
 computes the maximum of >=2 values

##### Usage
```c
 Array_Type _maximum(Array_Type x1, x2, ...)
```

##### Description

<code>x1</code>, <code>x2</code>, ... have to be arrays of the same length, or scalars.
The <code>_maximum</code> function returns an array of the maximum values
by successively calling the <code>_max</code> function.
If all <code>x1</code>, <code>x2</code>, ... are scalars, <code>_maximum</code> returns a scalar value,
in this case, <code>_maximum(x1, x2, ...)</code> is equivalent to <code>max([x1, x2, ...])</code>.

__See also__: _max, max, _minimum, _min, min

----

#### MAXI_lightcurve
##### Usage
```c
 Struct_Type MAXI_lightcurve(String_Type source);
```

##### Description

The returned structure has the following fields:

- <code>time</code>: Modified Julian Date

- <code>rate</code>  , <code>err</code>  :  2-20 keV light curve [c/s/cm^2]

- <code>rate_a</code>, <code>err_a</code>:  2- 4 keV light curve [c/s/cm^2]

- <code>rate_b</code>, <code>err_b</code>:  4-10 keV light curve [c/s/cm^2]

- <code>rate_c</code>, <code>err_c</code>: 10-20 keV light curve [c/s/cm^2]

__See also__: http://maxi.riken.jp/top/index.php?cid=000000000036, http://ads.nao.ac.jp/abs/2009PASJ...61..999M

----

#### max_time
##### Synopsis
 finds the latest time in an array of structures with a time field

##### Usage
```c
 Double_Type tmax = max_time(Struct_Type structs[]);
```

##### Description

<code>structs</code> is an array of structures containing the field <code>time</code>.
<code>tmax</code> is computed in the following way:

<code>tmax = max( array_map(Double_Type, &max, array_map(Array_Type, &get_struct_field, [structs], "time")) );</code>

__See also__: min_time, min_struct_field, max_struct_field

----

#### mbknpo_fit
##### Synopsis
 Fitting a multiplicative broken powerlaw to data in energy space

##### Usage
```c
 fit_fun("mknpo");
```

##### Description

This function can be used to cut a relxill spectrum off at low
energies (e.g., Steiner et al., ApJL 969, L30, 2024, Ubach et
al., ApJ 976, 38, 2024).

__See also__: relxill

----

#### mc_sig
##### Synopsis
 calculates the significance of a spectral component doing a Monte Carlo (MC) simulation

##### Usage
```c
 Struct_Type mc_sig(String_Type withComponent.fits, String_Type withoutComponent.fits);
or Struct_Type mc_sig(String_Type torqueDir);
```

##### Qualifiers

* mcruns: number of MC loops (default: 10)
* beforeData: script to be called before any data is loaded (default: NULL)
* afterData: script to be called after the data have been loaded (default: NULL)
* beforeFit: array of scripts to be called right before a fit of faked data to
the model without [0] and with [1] the component (default: NULL)
* id: override the dataset ID(s) after fits_load_fit with the given one(s)
* ignbinning: do not apply the same binning after faking the data
* ignnotice: do not use the same energy ranges after faking the data
* torque: calculate significance using given number of torque jobs, i.e., total
number of runs = mcruns\*torque (default: 0, i.e., don't use torque)
* walltime: walltime of each torque job in minutes (default: 3 minutes times
number of MC runs per job)
* dontSubmit: do not submit the torque job-file (implies qualifier 'dontwaint')
(default: submit)
* dontWait: do not wait on the the torque jobs to complete (implies qualifier
'dontClean') (default: wait)
* torqueDir: temporary directory to save necessary torque files
NOTE: this directory will be deleted afterwards completely!
(default: ~/.isis_mc_sig/)
* dontClean: do not delete temporary torque directory afterwards
* chatty: a number >0 means more chatty (default: 0)
*  : additional qualifiers are passed to fits_load_fit

##### Description

This function calculates the significance of a spectral component
found in real data. During each Monte Carlo loop, spectra data
without the component are simulated (for each detector) and this
data are then fitted with a model containing the component (that
needs to be tested for) and separately fitted with a model without
it.
The resulting simulated differences in chi square between these
fits are returned and compared to the measured difference: the
number of simulated chi squares below the measured one corresponds
to the significance, that the spectral component is real (i.e. in
80 cases out of 100 runs the simulated chi square difference is
below the measured chi square difference, the significance is 80%).

If two FITS-files created with fits_save_fit are provided, the
first includes the model "with" the component to be tested and
the second one "without" it.

If only one argument is given, this has to be a temporary directory
with results of a previous torque run (e.g. if "dontWait" was set).
The function tries to collect and return the results as usual.

The returned structure is defined as follows:
readdchisqr  - the measured difference in chi square
fakedchisqr  - an array of simulated differences in chi square
nfalse       - the number of detected false positives
significance - the resulting significance as defined above
##### Example

% FITS-files created by fitting a cutoffpl and iron line to
% RXTE-PCA, -HEXTE and Swift-XRT data (Rmf_OGIP_Compliance = 0 to
% load XRT data, see help of fits_load_fit)
sig = mc_sig("rxte_swift_cutoffpl_ironline.fits",
"rxte_swift_cutoffpl.fits";
mcruns = 1, ROC = [2,2,0],
beforeData = "defineMyModels.sl",
afterData = "setDataHooks.sl",
chatty = 2);

__See also__: fits_save_fit, fits_load_fit, fakeit

----

#### median_2d
##### Synopsis
 computes the median image of a list of images (2d arrays)

##### Usage
```c
 med_img = median_2d(img1, ...);
```

##### Description

----

#### merge_struct_arrays
##### Synopsis
 creates a structure whose fields are merged from all structures' fields

##### Usage
```c
 Struct_Type merged_s = merge_struct_arrays(Struct_Type s[]);
```

##### Description

All elements of s have to be structures with the same fields.
The return value merged_s is another structure of this kind, and
merged_s.field = [s[0].field, s[1].field, ..., s[-1].field];
holds for every field. (If s[i].field is NULL, it is skipped
unless "keep_null" qualifier is set.)
##### Qualifiers

* remove_excess_fields: : remove fields not present in all
structures.
* reshape = Integer_Type dim: : reshape the merged fields to the
dimensions of the original fields, using the sum of dimensiom 'dim'
to account for the increased array. Care has to be taken that the
other dimension need to have the same length in all structures.
* keep_null: : keep fields which contain NULL.

__See also__: append_struct_arrays, get_intersection, reshape

----

#### message_system
##### Usage
```c
 Integer_Type message_system(String_Type cmd)
```

##### Description

<code>message(cmd);</code>

<code>system(cmd);</code>

----

#### midas_bary_helio_corr
##### Usage
```c
 Struct_Type midas_bary_helio_corr(Y, m, d, H, M, S,  RAh, RAm, RAs,  decdeg, decmin, decsec)
```

##### Description

Y, m, d, H, M, S  specify the date in UT.

The fields of the returned structure have the following meaning:

bary_corr_time: Barycentric correction time, in days

helio_corr_time: Heliocentric correction time, in days

bary_RV_corr: Total barycentric RV correction, in km/s

helio_RV_corr: Total heliocentric RV correction, in km/s

diurnal_RV_corr: (incl.) diurnal RV correction, in km/s

----

#### _minimum
##### Synopsis
 computes the minimum of >=2 values

##### Usage
```c
 Array_Type _minimum(Array_Type x1, x2, ...)
```

##### Description

<code>x1</code>, <code>x2</code>, ... have to be arrays of the same length, or scalars.
The <code>_minimum</code> function returns an array of the minimum values
by successively calling the <code>_min</code> function.
If all <code>x1</code>, <code>x2</code>, ... are scalars, <code>_minimum</code> returns a scalar value, too,
in this case, <code>_minimum(x1, x2, ...)</code> is equivalent to <code>min([x1, x2, ...])</code>.

__See also__: _min, min, _maximum, _max, max

----

#### min_max
##### Synopsis
 returns the minimum and maximum value of an array

##### Usage
```c
 (mn, mx) = min_max(Double_Type a[]);
```
or

```c
 (mn, mx) = min_max(Double_Type a1[], a2[], ...);

```

##### Qualifiers

* pad: [=0] additive fraction to be padded on both sides:

<code>-dmin = dmax = (max-min) \* pad</code>

This qualifier may be overwritten by the following ones:
* dmin: [=0] difference added to the minimum
* dmax: [=0] difference added to the maximum

* logpad: [=0] multiplicative fraction to be padded on both sides:

<code>fmin^-1 = fmax = (max/min)^logpad</code>

All array elements must be either positive or negative.
(For negative arrays <code>-A</code>,  <code>[min_max(-A; logpad=lp)]</code>
is the same as  <code>array_reverse([min_max(A; logpad=lp))</code> .)
This qualifier may be overwritten by the following ones:
* fmin: [=1] factor to multiply the minimum
* fmax: [=1] factor to multiply the maximum

##### Description

<code>mn = min(a) \* fmin + dmin;</code>

<code>mx = max(a) \* fmax + dmax;</code>

__See also__: min, max, moment

----

#### min_struct_field
##### Synopsis
 returns the minimal field value of an array of structures

##### Usage
```c
 Double_Type mn = min_struct_field(Struct_Type structs[], String_Type fieldname);
```

##### Description

<code>structs</code> is an array of structures containing the field called <code>fieldname</code>.
<code>mn</code> can be computed in the following way:

<code>mn = min( array_map(Double_Type, &min, array_map(Array_Type, &get_struct_field, [structs], fieldname)) );</code>

__See also__: max_struct_field, min_time, max_time

----

#### min_time
##### Synopsis
 finds the earliest time in an array of structures with a time field

##### Usage
```c
 Double_Type tmin = min_time(Struct_Type structs[]);
```

##### Description

<code>structs</code> is an array of structures containing the field <code>time</code>.
<code>tmin</code> is computed in the following way:

<code>tmin = min( array_map(Double_Type, &min, array_map(Array_Type, &get_struct_field, [structs], "time")) );</code>

__See also__: max_time, min_struct_field, max_struct_field

----

#### missing_contour_trq
##### Synopsis
 calculates remaining contour points from function
contour_trq. It is used in such cases where countour_trq does
finnished before all point are calculated due to torque
issues.

##### Usage
```c
 missing_contour_trq(String_Type inputDir);
```

##### Description

-<code>inputDir</code>   directory where all torque job files are,
created by function contour_trq

It may be required to run the function several times.
The output (number of files) needs to be checked manualy.
##### Example

missing_contour_trq("torqueFiles");

__See also__: contour_trq

----

#### MJD2fermi
##### Synopsis
 calculate Fermi MET used for LC and spectral analysis

##### Usage
```c
 Double_Type = MJD2fermi (Double_Type);
```

##### Description

Calculates the Fermi Mission Elapsed Time (MET)
in seconds for a given MJD(UTC).
##### Example

variable m = 54900.345;
variable fermi_s = MJD2fermi(m);

__See also__: fermi2MJD, MJDref_satellite

----

#### MJD2JD
##### Synopsis
 Convert Modified Julian Dates to Julian Dates.

##### Usage
```c
 MJD2JD(MJD);
```

##### Description

Helper function to convert MJD to Julian Dates
by adding 2400000.5.

__See also__: jd2mjd, JD2MJD, MJD2JD

----

#### mjd2jd
##### Synopsis
 Convert Modified Julian Dates to Julian Dates.

##### Usage
```c
 mjd2jd(MJD);
```

##### Description

Helper function to convert MJD to Julian Dates
by adding 2400000.5.

__See also__: jd2mjd

----

#### MJD2UNIXtime
##### Synopsis
 converts modified Julian date to UNIX time

##### Usage
```c
 Long_Type MJD2UNIXtime(Double_Type MJD)
```

##### Description

Time formats and conversion functions:
Long_Type secs = MJD2UNIXtime(Double_Type MJD);
Double_Type MJD = UNIXtime2MJD(Long_Type secs);

Struct_Type tm = localtime(Long_Type secs);  % or gmtime
Long_Type secs = mktime(Struct_Type tm);

String_Type str = strftime(String_Type fmt, Struct_Type tm);

Current time and date:
Long_Type secs = _time();
String_Type str = time();

__See also__: UNIXtime2MJD, localtime, gmtime, mktime

----

#### MJDofDate
##### Synopsis
 calculates the modified Julian date

##### Usage
```c
 Double_Type MJD = MJDofDate( struct { year, month, day, hour, minute, second } );
```
or

```c
 Double_Type MJD = MJDofDate(year, month, day[, hour[, minute[, second]]]);

```

##### Description

The Gregorian or Julian date is either given by a structure or by at
least 3 integer arguments. Fractional parts are ignored.
The default values for hour, minute and second are 0, fractional
hours etc. are properly taken into account.

This function is array safe and equivalent to calling JDofDate with the
mjd qualifier.
##### Qualifiers

* julian_calendar: return the JD/MJD for the date in the Julian calendar rather
the Gegorian date. This does not make much sense for the MJD, which was negative
for the time when the Julian calendar was used.

__See also__: JDofDate,dateOfMJD

----

#### MJDofDateString
##### Synopsis
 calculates the MJD from a string including year, month, day [, hour [, minute [, second]]]

##### Usage
```c
 Double_Type <code>mjd</code> = MJDofDateString(String_Type <code>date_string</code>);
```

##### Qualifiers

* verbose: prints the found values for YYYY-MM-DD hh:mm:ss.sss
* no_2digit_correction: see `parseDateString`

##### Description

This function calculates the Modified Julian Date from a String
using the `parseDateString` function.
##### Example

MJDofDateString("69/07/21");
MJDofDateString("1969-07-21 02:56:30.44");
MJDofDateString("sdf1969--X07..21QQ_02/56((30,,44xyz");

__See also__: parseDateString

----

#### MJDref_satellite
##### Synopsis
 returns the reference date (MJD) of a satellite's time

##### Usage
```c
 Double_Type MJDref_satellite(String_Type satellite)
```

----

#### MJDstrftime
##### Synopsis
 formats a modified Julian date

##### Usage
```c
 String_Type MJDstrftime(String_Type fmt, Double_Type MJD);
```

__See also__: strftime, MJD2UNIXtime, localtime

----

#### mkdir_rec
##### Synopsis
 Create a new directory (recursively)

##### Usage
```c
 Int_Type mkdir_rec (String_Type dir [,Int_Type mode])
```

##### Description

Does the same as 'mkdir' with the exception that this
function creates also subdirectories.
See the help of 'mkdir' for a detailed description.

__See also__: mkdir

----

#### MN_NFW
##### Synopsis
 Evaluate equations of motion, total energy, or circular velocity derived from a
potential with a Miyamoto & Nagai bulge and disk component and a Navarro, Frenk,
& White dark matter halo

##### Usage
```c
 MN_NFW(Double_Types t, m[6,n]; qualifiers)
```

##### Qualifiers

* coords: [<code>="cyl"</code>] Use cylindrical ("cyl") or cartesian ("cart") coordinates.
* eomecd: [<code>="eom"</code>] Return equations of motion ("eom"), total energy ("energy"),
circular velocity ("circ"), or Sun-Galactic center distance ("sgcd").
* Mb: [<code>=439</code>] Mass of bulge in Galactic mass units, see Irrgang et al. 2013.
* Md: [<code>=3096</code>] Mass of disc in Galactic mass units, see Irrgang et al. 2013.
* Mh: [<code>=142200</code>] Mass scale factor of halo in Galactic mass units, see Irrgang et al. 2013.
* bb: [<code>=0.236</code>] Bulge scale length, see Irrgang et al. 2013.
* ad: [<code>=3.262</code>] Disc scale length, see Irrgang et al. 2013.
* bd: [<code>=0.289</code>] Disc scale length, see Irrgang et al. 2013.
* ah: [<code>=45.02</code>] Halo scale length, see Irrgang et al. 2013.

##### Description

Evaluate the equations of motion, the total energy, or the circular velocity at time 't'
derived from a potential with a Miyamoto & Nagai bulge and disk component and a Navarro,
Frenk, & White dark matter halo (see Model III in Irrgang et al., 2013, A&A, 549, A137)
using either cylindrical coordinates (r [kpc], phi [rad], z [kpc]) and their canonical
momenta vr [kpc/Myr], Lz [kpc^2/Myr], vz [kpc/Myr]) or cartesian coordinates (x [kpc],
y [kpc], z [kpc], vx [kpc/Myr], vy [kpc/Myr], vz [kpc/Myr]), see qualifier 'coords'.
Conservation of angular momentum Lz is implemented in the equations of motion for
cylindrical coordinates only. The total energy E_total [kpc^2/Myr^2] is not used to
integrate the equations of motion although being a conserved quantity, too. Therefore,
conservation of energy, i.e., of E_total, is a measure for the precision of the numerical
methods applied.

For computing orbits with n different initial conditions, the input parameter m is
a [6,n]-matrix with (qualifier("coords")=="cyl")   or (qualifier("coords")=="cart")
m[0,\*] = r;                                        m[0,\*] = x;
m[1,\*] = phi;                                      m[1,\*] = y;
m[2,\*] = z;                                        m[2,\*] = z;
m[3,\*] = vr;                                       m[3,\*] = vx;
m[4,\*] = Lz;                                       m[4,\*] = vy;
m[5,\*] = vz;                                       m[5,\*] = vz;
If the qualifier 'eomecd' is set to "eom", the function returns a [6,n]-matrix delta with
delta[0,\*] = vr;                                   delta[0,\*] = vx;
delta[1,\*] = Lz/r^2; % = vphi                      delta[1,\*] = vy;
delta[2,\*] = vz;                                   delta[2,\*] = vz;
delta[3,\*] = -d/dr (Potential(r,z) + Lz^2/r^2);    delta[3,\*] = -d/dx Potential(x,y,z);
delta[4,\*] = 0; % -d/dphi Potential(r,z)           delta[4,\*] = -d/dy Potential(x,y,z);
delta[5,\*] = -d/dz Potential(r,z);                 delta[5,\*] = -d/dz Potential(x,y,z);
If the qualifier 'eomecd' is set to "energy", the function returns a [1,n]-array storing
the total energy for each orbit:
E_total(r,z,vr,vz,Lz) = Double_Type[n] = 0.5\*(vr^2+vz^2+Lz^2/r^2) + Potential(r,z)
or
E_total(x,y,z,vx,vy,vz) = Double_Type[n] = 0.5\*(vx^2+vy^2+vz^2) + Potential(x,y,z)
If the qualifier 'eomecd' is set to "circ", the function returns a [1,n]-array storing
the circular velocity for each orbit:
v_circ(r,z) = Double_Type[n] = sqrt( r \* d/dr Potential(r,z) )
If the qualifier 'eomecd' is set to "sgcd", the function returns the Sun-Galactic center
distance found to fit best to this potential.
##### Example

delta = MN_NFW(0, m);
energy = MN_NFW(0, m; eomecd="energy");
v_circ = MN_NFW(0, m; eomecd="circ");
sgcd = MN_NFW(; eomecd="sgcd");

__See also__: orbit_calculator, AS, MN_TF, plummer_MW

----

#### MN_TF
##### Synopsis
 Evaluate equations of motion, total energy, or circular velocity derived from a
potential with a Miyamoto & Nagai bulge and disk component and a truncated, flat
rotation curve halo model

##### Usage
```c
 MN_TF(Double_Types t, m[6,n]; qualifiers)
```

##### Qualifiers

* coords: [<code>="cyl"</code>] Use cylindrical ("cyl") or cartesian ("cart") coordinates.
* eomecd: [<code>="eom"</code>] Return equations of motion ("eom"), total energy ("energy"),
circular velocity ("circ"), or Sun-Galactic center distance ("sgcd").
* Mb: [<code>=175</code>] Mass of bulge in Galactic mass units, see Irrgang et al. 2013.
* Md: [<code>=2829</code>] Mass of disc in Galactic mass units, see Irrgang et al. 2013.
* Mh: [<code>=69725</code>] Mass of halo in Galactic mass units, see Irrgang et al. 2013.
* bb: [<code>=0.184</code>] Bulge scale length, see Irrgang et al. 2013.
* ad: [<code>=4.85</code>] Disc scale length, see Irrgang et al. 2013.
* bd: [<code>=0.305</code>] Disc scale length, see Irrgang et al. 2013.
* ah: [<code>=200</code>] Halo scale length, see Irrgang et al. 2013.

##### Description

Evaluate the equations of motion, the total energy, or the circular velocity at time 't'
derived from a potential with a Miyamoto & Nagai bulge and disk component and a truncated,
flat rotation curve dark matter halo model (see Model II in Irrgang et al., 2013, A&A,
549, A137) using either cylindrical coordinates (r [kpc], phi [rad], z [kpc]) and their
canonical momenta vr [kpc/Myr], Lz [kpc^2/Myr], vz [kpc/Myr]) or cartesian coordinates
(x [kpc], y [kpc], z [kpc], vx [kpc/Myr], vy [kpc/Myr], vz [kpc/Myr]), see qualifier
'coords'. Conservation of angular momentum Lz is implemented in the equations of motion
for cylindrical coordinates only. The total energy E_total [kpc^2/Myr^2] is not used to
integrate the equations of motion although being a conserved quantity, too. Therefore,
conservation of energy, i.e., of E_total, is a measure for the precision of the numerical
methods applied.

For computing orbits with n different initial conditions, the input parameter m is
a [6,n]-matrix with (qualifier("coords")=="cyl")   or (qualifier("coords")=="cart")
m[0,\*] = r;                                        m[0,\*] = x;
m[1,\*] = phi;                                      m[1,\*] = y;
m[2,\*] = z;                                        m[2,\*] = z;
m[3,\*] = vr;                                       m[3,\*] = vx;
m[4,\*] = Lz;                                       m[4,\*] = vy;
m[5,\*] = vz;                                       m[5,\*] = vz;
If the qualifier 'eomecd' is set to "eom", the function returns a [6,n]-matrix delta with
delta[0,\*] = vr;                                   delta[0,\*] = vx;
delta[1,\*] = Lz/r^2; % = vphi                      delta[1,\*] = vy;
delta[2,\*] = vz;                                   delta[2,\*] = vz;
delta[3,\*] = -d/dr (Potential(r,z) + Lz^2/r^2);    delta[3,\*] = -d/dx Potential(x,y,z);
delta[4,\*] = 0; % -d/dphi Potential(r,z)           delta[4,\*] = -d/dy Potential(x,y,z);
delta[5,\*] = -d/dz Potential(r,z);                 delta[5,\*] = -d/dz Potential(x,y,z);
If the qualifier 'eomecd' is set to "energy", the function returns a [1,n]-array storing
the total energy for each orbit:
E_total(r,z,vr,vz,Lz) = Double_Type[n] = 0.5\*(vr^2+vz^2+Lz^2/r^2) + Potential(r,z)
or
E_total(x,y,z,vx,vy,vz) = Double_Type[n] = 0.5\*(vx^2+vy^2+vz^2) + Potential(x,y,z)
If the qualifier 'eomecd' is set to "circ", the function returns a [1,n]-array storing
the circular velocity for each orbit:
v_circ(r,z) = Double_Type[n] = sqrt( r \* d/dr Potential(r,z) )
If the qualifier 'eomecd' is set to "sgcd", the function returns the Sun-Galactic center
distance found to fit best to this potential.
##### Example

delta = MN_TF(0, m);
energy = MN_TF(0, m; eomecd="energy");
v_circ = MN_TF(0, m; eomecd="circ");
sgcd = MN_TF(; eomecd="sgcd");

__See also__: orbit_calculator, AS, MN_NFW, plummer_MW

----

#### mpi_fit_pars
##### Synopsis
 computes confidence intervals using MPI

##### Usage
```c
 Struct_Type results = mpi_fit_pars([Integer_Type pars[]]);
```

##### Description

The function <code>mpi_fit_pars</code> is designed to provide a similar
interface then <code>pvm_fit_pars</code>, written by M. Hanke for the
isis-scripts. Please pay special attention to the notes marked IMPORTANT
below.

<code>pars</code> is an array of parameters, for which the confidence levels are to be fitted.
If <code>pars</code> is not specified, all free parameters of the current model are used.
The best fit which is eventually found is always saved in
<<code>dir</code>>/<<code>basefilename</code>><code>_best.par</code>; the confidence limits are
written in plain-text to <<code>dir</code>>/<<code>basefilename</code>><code>_conf.txt</code> and as a
FITS table to <<code>dir</code>>/<<code>basefilename</code>><code>_conf.fits</code>.

The verbosity of <code>mpi_fit_pars</code> is controlled by the intrinsic variable <code>Fit_Verbose</code>.

The return value <code>results = struct { index, name, value, min, max, conf_min, conf_max, buf_below, buf_above, tex }</code>
is a table with the following information for each parameter:

<code>min</code> and <code>max</code> are the minimum/maximum values allowed.
<code>conf_min</code> and <code>conf_max</code> are the confidence limits.
<code>buf_below</code> (<code>buf_above</code>) is the fraction of the allowed range <code>[min:max]</code>
which seperates the lower (upper) confidence limit from <code>min</code> (<code>max</code>).
If one of these buffers is 0, your confidence interval has bounced.

Perhaps more usefully, this information is written to the files
<<code>dir</code>>/<<code>basefilename</code>><code>_conf.txt</code> and
<<code>dir</code>>/<<code>basefilename</code>><code>_conf.fits</code>.  In case of any
error, the return value is <code>NULL</code>. If run via slurm/torque, these
files will only be written by the host node once all threads have
completed - i.e., there's no danger of the results being written by
several machines at the same time.

NOTE: The function "mpi_new_best_fit_hook()" can be defined by the
user. This function will be called whenever a new best fit is found. This
can be used to, e.g, store the newly found best fit (although the usual
caveats about writing files to disk while running via MPI still apply...).

IMPORTANT: Rember that the whole script containing the call
"mpi_fit_pars()" is typically run on N > 1 computers. Therefore only the
\*minimum\* amount of code necessary to run mpi_fit_pars() should be
included in the script.

IMPORTANT: This function relies on MPI. This means that it only
works when started externally via, e.g., <code>mpiexec isis-script
my_script.sl</code> or via a slurm jobfile. Slurm or mpiexec must be able to
start as many processes as you have parameters for which you want to
calculate confidence limits (e.g., if you want error bars on four
parameters, you need four tasks - no more, no less).

IMPORTANT: This code is still in <beta> test. It might happen
that the function ends unexpectedly.
##### Qualifiers

* level: confidence level to be computed.
As for conf, 0 means 68%, 1 means 90% [default], and 2 means 99% confidence level.
* tolerance: the tolerance for chi^2 improvements without interrupting the search
for the confidence intervals, see <code>help("conf");</code>. The default is <code>1e-3</code>.
* fitmethod: fit-method to be used, see <code>help("set_fit_method");</code>
Default is the currently used fit-method returned by <code>get_fit_method()</code>.
* dir: [="."] specifies the directory in which the logfiles shall be stored.
It may be a relative path to the current working directory.
* basefilename: [=startdate]
* verbose: Files with the stdout and the inital parameters are kept after program
is finished.
* forked: [=0] Use a separate (forked) process to
calculate the confidence levels. It speeds up the calculation, but
might cause troubles for models which write files to disk, as this
process is killed  immediatelly when asked to restart
calculation and not stopped smoothly. This option can also
cause your job to be killed if run via slurm, as it requests
additional threads beyond those allocated by slurm.
* do_not_finalize: if set, "mpi_finalize()" is not called
within the routine. In this case the code following the
mpi_fit_pars() call will be executed on \*all\* nodes. Only the
master process will return the confidence structure (see above);
all other processes will return NULL. This can be used to start
more than one mpi_fit_pars() in one script. Only use it for very
quick evaluations and if you \*know that you're doing\*. At the end
of such an script, it is important to call "mpi_finalize()" manually.
##### Example

% EXAMPLE 1
% Simple script for confidence level calcualtion with mpi_fit_pars()
variable id = load_data("my_data.pha");   % load the data
xnotice_en(id,0.5,16);                    % initialize data
load_par("my_best_fit.par");

variable result = mpi_fit_pars(pars);     % do calculation for pars[]
fits_save_fit("result.fits",result);      % save all information
% to disk
% Note that mpi_fit_pars() alone will save information to disk,
% by default in files named <date>_best.par, <date>_conf.txt,
% and <date>_conf.fits

% EXAMPLE 2 - Uses slurm to schedule jobs on the Remeis cluster.
% This requires two files - mpi_fit.sl, containing the ISIS code to be
% executed, and mpi_fit.slurm, containing the job specification for slurm.
% This would be run by calling "sbatch mpi_fit.slurm" at the command line.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ISIS script (mpi_fit.sl)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
variable id = load_data("my_data.pha");   % load the data
xnotice_en(id,0.5,16);                    % initialize data
load_par("my_best_fit.par");
variable pars = [1,2];                    % obviously you will pick whatever parameters you need here
() = mpi_fit_pars(pars;                   % Do the confidence limit calculations. Results will be saved to
basefilename="my_fit");                 % "my_fit_conf.fits","my_fit_conf.txt", and "my_fit_best.par".
% Note that unlike the above example, we do not manually save
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%            % the results to a file - mpi_fit_pars does this on its own.
% Jobfile (mpi_fit.slurm)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
#!/bin/bash
#SBATCH --job-name my_fit                 # name of the job to be run by slurm
#SBATCH --time 00:10:00                   # You might need more (or less) time.
#SBATCH --ntasks 2                        # we want erors on two parameters (see above), so we need 2 cores
#SBATCH --mem-per-cpu 1G                  # 1 gig of memory per core (tweak to your liking)
srun /usr/bin/nice -n +19 isis mpi_fit.sl # run the script with srun (and nice +19 because you don't
# want to bog down someone else's machine)

__See also__: fit_pars; conf, set_fit_method, pvm_fit_pars

----

#### mpi_fit_pars_trqscript_gen
##### Synopsis
 Creates torque scripts for derivation of confidence intervals

##### Usage
```c
 mpi_fit_pars_trqscript_gen(String_Type fitfile, String_Type resultfile, String_Type scriptfile)
```

##### Description

This function generates 1) an executable S-Lang file
that is loading a previous fit saved with <code>fits_save_fit</code>,
calling <code>mpi_fit_pars</code> with the current number of free parameters
and saving the result via <code>fits_save_fit</code> and <code>save_pars</code>,
2) writing the .cmd and 3) the .cmd.job file
that can be submitted to Torque via 'qsub \*.cmd.job'.

If only two arguments are given
(the resultfile and the scriptfile), the function expects
that you want to calculate the uncertainties out of isis
In that case the function will itself save the fit to a
file in the results-directory. When mpi_fit_pars is finished,
you have to delete it by your own.

ATTENTION: make sure that the min/max parameter borders
are set wide enough in your previous fit but still with
a reasonable width to allow mpi to find the best fit and
ncertainties in a reasonable amount of time.

NOTE: All given qualifiers are passed to the function
fits_load_fit.
##### Qualifiers

* walltime: [="00:30:00"]: String_Type, wallime for the torque
* ROC: Rmf OGIP Compliance (see fits_load_fit
* submit: 1-submit to torque, 0-only create job files%

##### Example

isis>

isis> mpi_fit_pars_trqscript_gen("input.fits","result.fits","trq_scripts/mpi_script.sl";
walltime="01:00:00")
OR
isis> mpi_fit_pars_trqscript_gen("result.fits","trq_scripts/mpi_script.sl";
walltime="01:00:00")

THEN

qsub trq_scripts/mpi_script.cmd.job

__See also__: fits_save_fit, mpi_fit_pars, fits_list_fit_pars

----

#### mpi_master_only
##### Synopsis
 Use function with on one host only in an MPI job

##### Usage
```c
 mpi_master_only (Reference_Type function, arg1, arg2, ...)
```

##### Qualifiers

* verbose: show name of host which acts as MPI master
* veryverbose: show name of host which acts as MPI master, PID and parent PID (overwrites verbose)

##### Description

Sometimes, for example by saving files, it is required that a function is only called once
in an MPI job. mpi_master_only does this for a function with an arbitrary number of arguments.
The function has to be passed by reference, the arguments simply as arguments.
##### Example

mpi_master_only(&sprintf, "Pi is approximately %f and Eulers number is %f", PI, E);
output:
Pi is approximately 3.141593 and Eulers number is 2.718281828459045
But this only once

----

#### mpi_mc_sig
##### Synopsis
 calculates the significance of a spectral component doing a Monte Carlo (MC) simulation

##### Usage
```c
 Struct_Type mpi_mc_sig(String_Type withComponent.fits, String_Type withoutComponent.fits [, String_Type results.fits]);
```

##### Qualifiers

* mcruns: number of MC loops (default: 10)
* beforeData: script to be called before any data is loaded (default: NULL)
* afterData: script to be called after the data have been loaded (default: NULL)
* beforeFit: array of scripts to be called right before a fit of faked data to
the model without [0] and with [1] the component (default: NULL)
* id: override the dataset ID(s) after fits_load_fit with the given one(s)
* ignbinning: do not apply the same binning after faking the data
* ignnotice: do not use the same energy ranges after faking the data
* chatty: a number >0 means more chatty (default: 0)
* seed: seed for random number generator
*  : additional qualifiers are passed to fits_load_fit

##### Description

This function calculates the significance of a spectral component
found in real data. During each Monte Carlo loop, spectra data
without the component are simulated (for each detector) and these
data are then fitted with a model containing the component (that
needs to be tested for) and separately fitted with a model without
it.
The resulting simulated differences in chi-square between these
fits are returned and compared to the measured difference: the
number of simulated chi squares below the measured one corresponds
to the significance, that the spectral component is real (i.e. in
80 cases out of 100 runs the simulated chi square difference is
below the measured chi square difference, the significance is 80%).

Two FITS-files created with fits_save_fit must be provided, the
first includes the model "with" the component to be tested and
the second one "without" it. An optional third filename may be given
to store the results to. Otherwise, a default file will be created.

This function is supposed to be used for parallel computation with
MPI. The mcruns qualifier specifies the total number of MC runs which
is split accordingly among the available nodes.

The function will create a FITS file containing the following extensions:
realdeltachisquare - the measured difference in chi square
fakedeltachisquare - an array of simulated differences in chi square
falsepositives     - the number of detected false positives
significance       - the resulting significance as defined above
##### Example

% FITS-files created by fitting a cutoffpl and iron line to
% RXTE-PCA, -HEXTE and Swift-XRT data (Rmf_OGIP_Compliance = 0 to
% load XRT data, see help of fits_load_fit)

mpi_mc_sig("rxte_swift_cutoffpl_ironline.fits",
"rxte_swift_cutoffpl.fits",
"significance.fits";
mcruns = 100, ROC = [2,2,0],
beforeData = "defineMyModels.sl",
afterData = "setDataHooks.sl",
chatty = 2);
% A typical call from the command line could look like this

mpiexec -n 4 isis <script>

to use 4 cores for the MC run. However, it is highly
recommended to use a job scheduling system (e.g., SLURM)
for these kind of simulations.

__See also__: fits_save_fit, fits_load_fit, fakeit, mc_sig

----

#### multibknpower (fit-function)
##### Synopsis
 implements a multiply-broken powerlaw

##### Description

Only break energies >0 and the corresponding photon indices are considered.
<code>PhoIndx0</code> applies for energies below the first break.
Each <code>PhoIndex</code>i applies for energies above <code>BreakE</code>i, but below the next break.
As for <code>bknpower</code>, the normalization is the flux of the first power law at 1 keV
(not necessarily the broken power law model)  in ph/s/cm^2/keV.

----

#### multiplot_flux_counts_res
##### Synopsis
 creates a plot of model flux, data counts and residuals in 3 panels

##### Usage
```c
 multiplot_flux_counts_res(data_ind[, rel_size]);
```

##### Description

If data_ind is an array of data-indices, the data will be rebinned
to the grid of the first index.

----

#### narrowline (fit-function)
##### Synopsis
 multiplicative model; implements unresolved absorption/emission line

##### Description

simple multiplicative line-function to efficiently model
unresolved absorption and emission lines. Allows to direclty fit
the equivalent width of the line.

Caution: the function does not check whether the line is
unresolved; user needs to take care of that before using the
function. In particular, for absorption lines the absolute value
of the equivalent width should be smaller than the resolution of
the data.

The fit parameters are

center [A]   line position
eqw    [A]   equivalent width of the line

----

#### new_plot_labels
##### Synopsis
 Create new plot labels for routines in isis_fancy_plots package.

##### Usage
```c
 new_plot_labels(String_Type [, String_Type]);
```

##### Qualifiers

* xlabel: New X-axis label
* ylabel: String array with new Y-axis labels for data
* rlabel: String array with new Y-axis labels for residuals
* clabel: String array with new Y-axis residual labels for Cash statistics
* mllabel: String array with new Y-axis residual labels for Maximum Likelihood statistics
* vlabel: String with new Doppler velocity X-axis label
* zlabel: String with new redshift X-axis label
* pg_font: PGPLOT font type (default is \\fr)

##### Description

new_plot_labels(x_unit [,y_unit];xlabel=string,ylabel=[string],...,
pg_font=string);

Changes the default labels for plot_counts, plot_data, plot_unfold
for the different units set by fancy_plot_unit. pg_font string will
be \*prepended\* to all inputs. Use any valid pair of units to set residual,
Cash statistic, or velocity/redshift axis labels.

Use:

set_plot_labels(;pg_font="\\fr") -or- set_plot_labels(;pg_font=``\\fr``)

to restore defaults.

Inputs:

x_unit : angstrom,a,nm,um,micron,cm,mm,m, ev,kev,mev,gev,tev,
hz,khz,mhz,ghz, psd
y_unit : photons (=default), ergs, watts, mjy, psd_leahy, or psd_rms
xlabel : String with new X-axis label
ylabel : String \*array\* (up to 9 elements) with new Y-axis labels.
Order of the array \*must\* be:
[plot_data, plot_unfold(power=0->3),plot_counts(power=0->3)]
rlabel : String \*array\* (up to 3 elements) with new Y-axis labels for
residuals.  Order of the the array \*must\* be:
[chi, chi^2, ratio]
clabel : String Array with new Cash statistic labels [res=1 or 4, 2 or 5,
which yield +/-sqrt(|Delta C|), Delta C, respectively]
mllabel: String Array with new Maximum Likelihood statistic labels [res=1 or 4,
2 or 5, which yield +/-sqrt(|Delta ML|), Delta ML, respectively]
vlabel : String with new Doppler velocity X-axis label
zlabel : String with new Redshift X-axis label
pg_font: "\\fn", "\\fr", "\\fi", "\\fs" = normal, roman, italic,
or script fonts will be used on the labels (Default is \\fr.)

__See also__: set_plot_labels, fancy_plot_unit, add_plot_unit

----

#### new_printplot
##### Synopsis
 returns a new printplot-structure

##### Usage
```c
 Struct_Type new_printplot(Double_Type x0, x1, y0, y1);
```

##### Qualifiers

* W, H: the width, i.e. the number of columns,
and the height, i.e. the number of rows,
of the plotting area without any axes or
ticmarks (default: 60 and 10)
* [x,y]axis: if set to zero do not draw the axis
* [x,y]tics: if set to zero do not draw the ticmark
* [x,y]format: sprintf format of the tics
(default: "%f")
* [x,y]strlen: maximum string length of the ticmarks
(default: 4)

##### Description

For printing a simple plot into the terminal a char
matrix is returned by this function, which can be
later printed by 'printplot_out'.
Per default, the matrix is 20x4 in size. Changing its
size can be done by the W- and H-qualifiers. The
arguments specify the x- and y-ranges of the plotting
area. The minimum and maximum values are the only
ticmarks which are added. Note that the char-matrix
is enlarged to fit the axes and ticmarks.

__See also__: printplot_out, printplot, printhplot

----

#### new_table_model
##### Synopsis
 Initialize object and file to create table model

##### Usage
```c
 Struct_Type model = new_table_model(String_Type filename)
```

<!--%{{{ -->
##### Qualifiers

* name: [=<filename-no-ext>] set model name
* double: if set, stores all values as doubles instead of floats
* overwrite: if set, ignores existing file with same name

##### Description

Giving a file name the function creates a fits file with the given
name and returns a handle that eases the process of creating a
table model according to the XSPEC format
OGIP Memo 92-009 (XSPEC Table Model File Format)

To create a file one has to give the interpolation points of the
model, the additional contributions and the model spectra.

##### Example

variable table = new_table_model("test_model.fits");

% create "parameter1" with given interpolation points
table.add_parameter("parameter1", [0:2:0.1]);
table.add_parameter("parameter2", [-1:1:0.001]); % create "parameter2"
% create additional parameter "additional"
table.add_additional("additional");

table.set_grid(bin_lo, bin_hi); % define the valid energy grid for the model
table.set_function(&my_fancy_model); % set the model function
% set additional contributions
% (only necessary if additional parameters are given)
table.set_additional(&my_fancy_contributions);

table.write(); % fill table
table.close(); % finish table

__See also__: table_model.add_parameter, table_model.add_additional,
table_model.set_grid, table_model.set_function, table_model.set_additional,
table_model.write, table_model.close

----

#### nice_width
##### Synopsis
 Sets reasonable defaults for plot line widths.

##### Usage
```c
 nice_width;
```

##### Description

Equivalent to:
isis> set_plot_widths(;d_width=2, de_width=2, r_width=2, re_width=2, m_width=2);

__See also__: set_plot_widths, apj_size, keynote_size, open_print, close_print

----

#### normalized_in_0_1
##### Synopsis
 computes a normalized array with min=0, max=1

##### Usage
```c
 Double_Type a_norm[] = normalized_in_0_1(Double_Type a[]);
```

##### Description

<code>a_norm = (a - min(a)) / (max(a)-min(a));</code>

----

#### normpsd
##### Usage
```c
 psd_norm = normpsd(psd, normtype, avrate, avbackrate, timeseg, dimseg);
```

##### Description

<code>psd</code> is the unnormalized power spectrum.
<code>avrate</code> is the average countrate of corresponding lightcurve.
<code>avbackrate</code> is the average background countrate of corresponding lightcurve.
<code>timeseg</code> is the real time of one corresponding lightcurve segment.
<code>dimseg</code> is the number of bins in one lightcurve segment.

String_Type <code>normtype</code> can be:

- "Miaymoto" (default) [Miyamoto et al. (1991), ApJ 383, 784]

<code>psd \*= 2 \* timeseg / (dimseg \* [avrate-avbackrate]^2)</code>

- "Leahy" [Leahy et al. (1983), ApJ 266, 160]

<code>psd \*= 2 \* timeseg / (dimseg^2 \* avrate)</code>

- "Schlittgen" [Schlittgen, H.J., Streitberg, B. (1995), Zeitreihenanalyse, R. Oldenbourg]
<code>psd /= dimseg</code>

----

#### notice_human2isis
##### Synopsis
 create isis notice_list from str = notice_isis2human

##### Usage
```c
 Array_Type notice_list = notice_human2isis(String_Type str);
```

##### Description

This routine converts a notice_list string created with
notice_isis2human back to the ISIS conform binning array
(see e.g. get_data_info(idx).notice_list). It can be used to
restore the otcing of data directly, by using it as argument
in the function notice_list(...).

__See also__: fits_save_fit, get_data_info, notice_isis2human

----

#### notice_isis2human
##### Synopsis
 converts isis notice_list in a human readable string

##### Usage
```c
 String_Type str = notice_isis2human(Array_Type notice_list);
```

##### Description

This routine converts the notice_list as used by ISIS (see e.g.
get_data_info(idx).notice_list) to a string which is easy to read.

The routine fits_save_fit() uses this string to save the noticed
bins of the data. It can be converted back by using
notice_human2isis().

__See also__: fits_save_fit, get_data_info, notice_human2isis

----

#### notice_listFromString
##### Synopsis
 creates a isis notice_list from a string containing the
noticed bins separated with ",".

##### Usage
```c
 Array_Type notice = notice_listFromString(String_Type str);
```

__See also__: notice_list, notice_listToString, get_data_info, fits_save_fit

----

#### notice_listToString
##### Synopsis
 converts an isis notice_list to a string

##### Usage
```c
 String_Type str = notice_listToString(Array_Type notice_list);
```

__See also__: notice_list, notice_listFromString, get_data_info, fits_save_fit

----

#### notice_xy
##### Synopsis
 notice points from xy-dataset

<!--%{{{ -->
##### Usage
```c
 notice_xy (index [, low, high]);
```

##### Description

Wraper function of the notice function for datasets defined with
define_xydata. Include data points of dataset <code>index</code>
(in the range low to high) for fitting.

__See also__: ignore_xy, notice, notice_en, define_xydata

----

#### ntree
##### Synopsis
 creates a new node of a tree with n children

##### Usage
```c
 Struct_Type ntree(DataType_Type objectType[, Struct_Type ntreeType]);
or Struct_Type ntree(DataType_Type objectType[, Integer_Type numChilds]);
```

##### Description

An n-tree is a special kind of a tree data structure.
Each node has exactly n children, which are n-tree
nodes themselves. The number of children is specified,
e.g., by the 'numChilds' parameter, which is 2 by
default. Initially, all children are null pointers.
Most importantly, a node contains a list of objects,
which is an array of the type specified by the
'objectType' parameter. Using the functions provided
in the n-tree structure, objects can be inserted or
removed.

The n-tree structure contains the following functions:
insert    - appends an object to the list.
Usage: ntree.insert(objectType object);
remove    - removes an object from the list and
returns 1 on success, 0 otherwise.
Usage: Integer_Typer ntree.remove(objectType object);
get       - returns all objects stored in the node.
Usage: objectType[] ntree.get();
getChilds - returns all objects stored in the children.
Usage: objectType[] ntree.getChilds();
getAll    - iterates over all nodes recursively to
return all objects stored in the tree.
Usage: objectType[] ntree.getAll();
childN    - returns the N's child of the actual node.
If the child does not exist, NULL will be
returned. The function names can be
overwritten by the type definition (see
below).
Usage: Struct_Type ntree.childN();
Qualifiers:
new    - creates the child if it does
not exist
renew  - creates a new child no matter
if it exists already
delete - deletes the child

In addition, the following fields exist:
objects   - array of objects stored in the node
childs    - array of length N containing the
children of the node
type      - structure describing the type of the
n-tree (see below)

The type of the n-tree can be specified by the
optional 'ntreeType' parameter. This structure
defines additional behaviours of the n-tree, and
the number of children and their the return function
names eventually. The default type sets these names
to the ones described above (childN). Additional
informations about the usage of n-tree types can
be found in the help of the 'ntree_type' function.
##### Example

% creates an 4-tree (called quad tree) with one
% initial node and an object array of Integer_Type
tree = ntree(Integer_Type, 4);

% insert '5' into the initial node
tree.insert(5);

% create and insert '10' into the third child
tree.child3(; new).insert(10);

% checks if child2 exists
if (tree.child2() == NULL)
message("child2 does not exist");

% insert '8' into child3, but it is not
% created again since it exists already
tree.child3(; new).insert(8);

% get all objects of the children
% (will return [10,8])
print(tree.getChilds());

__See also__: ntree_type

----

#### ntree_type
##### Synopsis
 returns a specific stucture defining an n-tree type

##### Usage
```c
 Struct_Type ntree_type(String_Type typeName);
```

##### Description

This functions returns the structure defining
the specific n-tree type named 'typeName'. A
list of all available types is shown if no
name is passed. The 'help' qualifier shows
additional information about the given type.

The type of an n-tree is specified and can be
extended by a structure with the following
fields:

numChilds
Defines the number of children of each node.
node. It has the same effect as the
'numChilds' parameter of the 'ntree' function.

childNames (optional)
Array of strings defining the return function
names for each children. The default names are
"child1" to "childN".

new (optional)
Reference to a callback function, which gets
called right before a new node created by
'ntree()' is returned. Parameters passed are
(1) the new node as a structur, (2) as which
child number it is created (starting at 1,
NULL if it is the root) and (3) the parent
node it belongs to (NULL if there is none).
The function has to return the new node.

insert (optional)
Reference to a callback function, which gets
called before an object is inserted into a
node by 'node.insert()'. Parameters passed are
(1) the node as a structure and (2) the object,
which should be inserted. The function has to
return the node. If NULL is returned, the
object will not be inserted into the node.

remove (optional)
Reference to a callback function, which gets
called before an object is removed from a node
by 'node.remove()'. Parameters passed are (1)
the node as a structure and (2) the object,
which should be removed. The function has to
return the node. If NULL is returned, the
object will not be removed from the node.
##### Example

% first define a callback function, which
% prevents inserting negative numbers
define ntree_myType_insert(node, object) {
if (object < 0) return NULL;
else return node;
}

% structure defining a 4-tree (called quadtree)
% and the children return functions are renamed
% to match directions. The insert callback
% function defined above is assigned also.
variable myType = struct {
numChilds = 4,
childNames = ["left","right","top","bottom"],
insert = &ntree_myType_insert
};

% create a new n-tree of myType
variable tree = ntree(Double_Type, myType);

__See also__: ntree

----

#### ntree_type_mapQuad
##### Synopsis
 returns the n-tree definition of a map quadtree

##### Usage
```c
 Struct_Type ntree(DataType_Type objectType, ntree_type("mapQuad"), Double_Type size[, Double_Type x0, y0]);
```

##### Description

A map quadtree is a 4-tree, which divides a 2d-space
into squares with an edge length of 'size'. Therefore,
each node of the tree is identified by a certain
coordinate x,y. The coordinate of the tree's root can
be specified by the x0 and y0 parameters and are (0|0)
by default. The children are named "top", "right",
"bottom" and "left". Due to that structure the tree
will be an undirected graph, meaning that, e.g., the
left node is connected to the right node and vise versa:

-------            ----            -------
|x0-size| -right-> | x0 | -right-> |x0+size|
|  y0   | <--left- | y0 | <--left- |  y0   |
-------            ----            -------
^|
top || bottom
|v
-------
|   x0  |
|y0-size|
-------

The map quadtree extends the n-tree structure by the
following functions:
lookup(x,y) - returns the node fitting the given
x and y coordinates
insert(object[,x,y]) - overwrites the usual insert
function such, that the object is inserted into
the node fitting the optional x and y coordinates

Note: deleting a child by the 'delete' qualifier,
e.g. tree.left(; delete) does NOT cascade! That is,
the left node still points to the right one (here
called tree). It might still be accessable via
tree.top().left().bottom()
##### Example

__See also__: ntree, ntree_type

----

#### nuFnu

##### Synopsis
 changes an Energy/Flux Spectrum to a Frequency/Flux\*Frequency Spectrum

##### Usage
```c
 Struct_Type = nuFnu (hist_index, E_min(keV), E_max(keV));
```

##### Description

Use this function on a dataset that has been modeled.
This function uses get_data_flux/eval_fun_keV to load
spectral data into isis and convert energy bins in a
given range to frequency (s^-1) bins as well as Flux
to flux\*frequency.
If no range specified: E_min=0.5 keV, E_max=10 keV.
Values and Errors are given in erg s^-1 cm^-2.

WARNING: Currently only frequency has been implemented
as x-unit.

For the evaluation of a deabsorbed component use the
qualifier "deabs". deabs will try to calculate the
factor between absorbed and deabsorbed model
components and correct the data.

WARNING: This does not work when a convolution
normalization (e.g., cflux, enflux, phflux)
is part of the model!

The "numbin" qualifier allows to specify the number
of output bins. Currently only a logarithmic grid
has been implemented. If numbin is not specified
the flux for the current grid will be returned.

The "group" qualifier allows to specify the S/N that
will be used for the flux calculation. Flux calculations
are only correct for large number of bins. The final
grid can be smaller (qualifier: numbin).

WARNING: Currently tested only on low counts spectra.
S/N might have to be increased for large
number of counts.

##### Qualifiers

* deabs:    evaluate deabsorbed flux
* ff:       define deabsorbed fit function
* numbin:   define number of bins
* group:   define S/N for grouping

##### Example

isis>xray = load_data("data.pha");
isis>load_par("x.par");
isis>() = fit_counts;
isis>new=nuFnu(xray,2,10);	 %change spectrum (2-10 keV) into frequency spectrum

%Plot data:
isis>hplot(new.lo, new.hi, new.val);

% Evaluate Function for deabsorbed model
% (WARNING: DOES NOT WORK IF ENFLUX IS USED IN FIT FUNCTION)

isis>xray = load_data("data.pha");
isis>fit_fun("tbnew_simple_z(1)\*powerlaw(1)");
isis>() = fit_counts;
isis>new = nuFnu(xray,2,10; deabs, ff="powerlaw(1)");
isis>%Calculate a deabsorbed powerlaw

__See also__: get_data_flux, rebin_mean, eval_fun_keV, group

----

#### num_bin

##### Synopsis
 Number of noticed bins

##### Usage
```c
 Double_Type = num_bin (hist_index);
```

##### Description

Use this function to retrieve number of
noticed bins.
##### Qualifiers

* dof: gives degrees of freedom instead of number of bins

##### Example

isis>xray = load_data("data.pha");
isis>variable num = num_bin(1);

__See also__: dof

----

#### nutation_angles
##### Synopsis
 calculate the nutation in longitude and obliquity for a given date

##### Usage
```c
  (dpsi,deps)=nutation_angles(JD;qualifiers)
```

##### Qualifiers

* JD_frac: fractional part of the Julian Date (for highest precision)
* theory: nutation theory to use. Possible string values are
IAU2000A - full IAU2000A theory, i.e., an implementation of the
theory of Matthews et al. (2002, J. Geophys. Res, 107, 2068)
IAU2000B - truncated IAU2000A theory per McCarthy & Luzum (2003,
Cel. Mech. Dyn. Astron, 85, 37); accuracy is
1 mas in 1995-2050
NU2000K  - truncated IAU2000A theory from Kaplan (2009, USNO
circular 181); accuracy is 0.1mas in 1700-2300
[the default]
* mjd: the time argument is in MJD, not in JD
* JD_frac: fractional part of the time argument. Use this if
highest precision is needed. The nutation angles are then
returned for the date JD+JD_frac.
* deg: return nutation angles in degrees
* arcsec: return nutation angles in arcseconds
* mas: return nutation angles in milliarcseconds
* iaufile: FITS file containing the theory coefficients
(usually found in ISISSCRIPTS_REFPATH)

##### Description

This routine calculates the nutation angles for the forced nutation
of the non-rigid earth according to one of the nutation theories described
above for date given by the JD-argument (which is interpreted as TT).
For most applications, usage of the NU2000K or IAU2000B routines
is fully sufficient.

This routine is array safe (but JD_frac MUST be a scalar in this case!),
the angles returned are in radians unless one of the deg, arcsec, or mas
keywords is given.

The routine is based on the NOVAS 3.1 C-code (Bangert et al., 2011, see
http://aa.usno.navy.mil/software/novas/novas_info.php )

__See also__: precess

----

#### nutation_matrix
##### Synopsis
 Calculate the nutation matrix for the mean equinox JD

##### Usage
```c
 Matrix33_Type N=nutation_matrix(JD)
```

##### Qualifiers

* theory: nutation theory to use, see help for
function nutation_angles for details.
Default: NU2000K

##### Description

This function returns the nutation matrix to convert coordinates
for the mean equinox of JD to the true equinox of JD.

Note: This is mainly an internal function, it therefore does NOT
have the usual qualifiers such as mjd, however, for some applications
it is useful to have direct access to the nutation matrix

----

#### N_body_simulation
##### Synopsis
 Compute orbits for N interacting particles

##### Usage
```c
 Struct_Type ret = N_body_simulation(Struct_Type in, Double_Type t_end; qualifiers)
```

##### Description

By numerical integration and without any simplifying approximations, this function
directly solves the equations of motion of a system of N particles under the
influence of their mutual forces (The interaction is specified in a separate
function, see qualifier 'kernel'.) from time t=0 to time t=t_end. Negative values
for t_end imply backward integration. Cartesian coordinates are used throughout.

The input structure 'in' has to contain the fields "x", "y", "z", "vx", "vy", "vz".
Each of these fields has to be an array of length N. The corresponding index gives
the particle id, i.e., particle 0 refers to x[0], y[0], z[0], vx[0], vy[0], vz[0].
The return structure 'ret' contains for each particle a field, e.g., for particle 0
a field named "o0". This field is again a structure with fields "t", "x", "y", "z",
"vx", "vy", and "vz" giving the time-dependent coordinates of the respective particle.
##### Notes

An adaptive Runge-Kutta-Fehlberg method of fourth/fifth order is applied to solve the
coupled system of first-order differential equations. The stepsize is hereby controlled
such that for each step an absolute accuracy in coordinates and velocity components is
achieved that is smaller than given by the qualifier 'tolerance'.
##### Qualifiers

* kernel: [<code>="N_body_simulation_std_kernel"</code>] Name of the function which describes the
mutual interaction. Note that all qualifiers are passed to this function as well.
* threshold: [<code>=0</code>] Lower limit on the time difference of two consecutive moments of time
that will be saved.
* tolerance: [<code>=1e-10</code>] Absolut error control tolerance; lower limit: 1e-15.
* verbose: Show intermediate times t.

##### Example

% Four interacting particles:
s = struct{x, y, z, vx, vy, vz};
s.x = [-10,0,10,0];
s.y = [0,10,0,-10];
s.z = [0,0,0,0];
s.vx = [0,-1,0,1];
s.vy = [-1,0,1,0];
s.vz = [0,0,0,0];
r = N_body_simulation(s, 50; kernel="N_body_simulation_std_kernel", psa=10\*[1,1,1,1], psb=0.1\*[1,1,1,1]);
xrange(min_max([r.o0.x,r.o1.x,r.o2.x,r.o3.x]));
yrange(min_max([r.o0.y,r.o1.y,r.o2.y,r.o3.y]));
plot(r.o0.x,r.o0.y); oplot(r.o1.x,r.o1.y); oplot(r.o2.x,r.o2.y); oplot(r.o3.x,r.o3.y);

__See also__: N_body_simulation_std_kernel, N_body_simulation_MW_kernel

----

#### N_body_simulation_MW_kernel
##### Synopsis
 Alternative interaction kernel for the function 'N_body_simulation'

##### Usage
```c
 Double_Type r[6,N] = N_body_simulation_MW_kernel(Double_Types t, m[6,N]; qualifiers)
```

##### Description

This function is an alternative interaction kernel for the function 'N_body_simulation'.
It combines the mutual N-nody interactions of the standard interaction kernel
'N_body_simulation_std_kernel' with the external forces stemming from an analytical
model for the gravitational potential of the Milky Way (see qualifier 'model').
##### Notes

Because of the unit convention used for the potentials of the Milky Way, 'psa', which
is a qualifier of the function 'N_body_simulation_std_kernel' and which is assumed to
be the mass of the Plummer spheres in solar masses, has to be converted to Galactic
mass units and then multiplied with a constant accounting for the remaining unit
conversions (see example below). The units of 'psb' have to be kpc^2.
##### Qualifiers

* model: [<code>="AS"</code>]: Function ("AS", "MN_NFW", or "MN_TF"), which evaluates the equations of
motion that result from a model for the gravitational potential of the Milky Way.
* All qualifiers from the model potential function except 'coords'.:
* All qualifiers from the function 'N_body_simulation_std_kernel'.:

##### Example

% Interacting satellite galaxies in the Milky Way:
s = properties_satellite_galaxies();
i = struct{ x, y, z, vx, vy, vz, psa, psb };
model = "AS"; % Milky Way mass model
SunGCDist = (@(__get_reference(model)))(; eomecd="sgcd"); % Sun-GC distance of chosen mass model
temp = [SunGCDist,0,0,0,0,0]; reshape(temp, [6,1]);
vlsr = (@(__get_reference(model)))(0, temp; eomecd="circ")[0]; % Local standard of rest velocity of chosen mass model
(i.x, i.y, i.z, i.vx, i.vy, i.vz) = cel2gal(s.ah, s.am, s.as, s.dd, s.dm, s.ds, s.dist, s.vrad, s.pma_cos_d, s.pmd; SunGCDist=SunGCDist, vlsr=vlsr);
kpcmyr_to_kms = 977.7736364875057; % = conversion factor from kpc/myr to km/s = 3.0856775975\*10^16 / (10^6 \* 3.15582 \* 10^7);
i.vx /= kpcmyr_to_kms;
i.vy /= kpcmyr_to_kms;
i.vz /= kpcmyr_to_kms;
i.psa = s.Pl_mass/2.325131802556774e+07; % conversion from solar masses to Galactic mass units Mgal to have G=1
% Mgal = 2.325131802556774e+07 = 1e8\*3.0856775975\*1e19/6.6742/1e-11/1.9884/1e30, see Irrgang et al., 2013, A&A, 549, A137
const = 100./kpcmyr_to_kms^2; % factor 100 because potential is given in 100 km^2/s^2, see Irrgang et al. 2013
i.psa \*= const;
i.psb = (s.Pl_radius)^2;
r = N_body_simulation(i, -1000; kernel="N_body_simulation_MW_kernel", psa=i.psa, psb=i.psb, model=model);
xrange(min_max([r.o0.x,r.o1.x])); yrange(min_max([r.o0.y,r.o1.y]));
plot(r.o0.x,r.o0.y); oplot(r.o1.x,r.o1.y);

__See also__: N_body_simulation, N_body_simulation_std_kernel, AS, MN_NFW, MN_TF

----

#### N_body_simulation_std_kernel
##### Synopsis
 Default interaction kernel for the function 'N_body_simulation'

##### Usage
```c
 Double_Type r[6,N] = N_body_simulation_std_kernel(Double_Types t, m[6,N]; qualifiers)
```

##### Description

This function is the default interaction kernel of the function 'N_body_simulation'.
It computes the equations of motion of N interacting particles at time t.
The input parameter 'm' is a [6,N]-matrix with
m[0,j] = x_j;
m[1,j] = y_j;
m[2,j] = z_j;
m[3,j] = vx_j;
m[4,j] = vy_j;
m[5,j] = vz_j;

For each particle, the potential of particle i (at position (x_i,y_i,z_i)) exerted
on particle j (at position (x_j,y_j,z_j)) is a Plummer sphere of the form
Phi(x_i,y_i,z_i,x_j,y_j,z_j) = -psa_i\*(psb_i+dis^2)^(-1/2)
with
dis^2 = (x_i-x_j)^2+(y_i-y_j)^2+(z_i-z_j)^2
and psa_i and psb_i model constants (see qualifiers).
The resulting acceleration of particle j is then
d^2/dt^2 x_j = -d/dx_j Phi = sum( psa_i\*(psb_i+dis^2)^(-3/2)\*(x_i-x_j), i!=j)
d^2/dt^2 y_j = -d/dy_j Phi = sum( psa_i\*(psb_i+dis^2)^(-3/2)\*(y_i-y_j), i!=j)
d^2/dt^2 z_j = -d/dz_j Phi = sum( psa_i\*(psb_i+dis^2)^(-3/2)\*(z_i-z_j), i!=j)
yielding the following system of first-order differential equations, which are the
equations of motion of this system and which are returned as a [6,N]-matrix 'r'
d/dt x_j  = r[0,j] = vx_j
d/dt y_j  = r[1,j] = vy_j
d/dt z_j  = r[2,j] = vz_j
d/dt vx_j = r[3,j] = -d/dx_j Phi = sum( psa_i\*(psb_i+dis^2)^(-3/2)\*(x_i-x_j), i!=j)
d/dt vy_j = r[4,j] = -d/dy_j Phi = sum( psa_i\*(psb_i+dis^2)^(-3/2)\*(y_i-y_j), i!=j)
d/dt vz_j = r[5,j] = -d/dz_j Phi = sum( psa_i\*(psb_i+dis^2)^(-3/2)\*(z_i-z_j), i!=j)
##### Qualifiers

* psa: [<code>=Double_Type[N]+1</code>] Parameter used to parametrize the interaction potential.
* psb: [<code>=Double_Type[N]+0</code>] Parameter used to parametrize the interaction potential.

##### Example

N = 4;
m = Double_Type[6,N];
r = N_body_simulation_std_kernel(0,m; psa=Double_Type[N]+1, psb=Double_Type[N]+1);

__See also__: N_body_simulation

----

#### object_visibility_satellite
##### Synopsis
 Calculate the time intervals when an object is observable with an astronomical satellite

##### Usage
```c
 visibility=object_visibility_satellite(ra,dec,mjdstart,mjdstop);
```

##### Qualifiers

* dt: Time resolution of the visibility calculation (days, default: 1)
* numerical: see below

Qualifiers to select the satellite. Constraints are ANDed if multiple
satellite qualifiers are given, i.e., the joint visibility is returned
* swift: 46-180 deg from Sun; so far ignores lunar constraint (>23deg)
* suzaku: 70-110 deg from Sun
* xmm: 70-110 deg from Sun
* chandra: >46deg from Sun; ignores lunar constraint (>6deg)
* hst: >50deg from Sun
* nustar: no solar avoidance constraints(!)

##### Description

This routine calculates the time intervals during which an astronomical
source with position ra, dec (both given in degrees) is visible to a given
astronomical satellite. Most popular facilities are supported (see above).
For each time between mjdstart and mjdstop the routine calculates the
angular separation between the source and the Sun. By default it returns
an array of structures giving the time intervals during which a source is
visible. The tags of the structure describing each interval are
MJDstart and MJDstop: start and stop MJD of the visibility interval
MJDstring           : human readable string of the above
An empty array is returned if the object is not visible during the time
interval specified by mjdstart and mjdstop.

If the qualifier "numerical" is set, the function returns a structure with
the following tags
mjd: MJD
theta: separation betwee source and Sun (deg)
visible: boolean visibility (0: no, 1: visible)
instead of the array of time intervals

Note: if the visibility interval starts before mjdstart or extends beyond
mjdend, the start and stop times of the search interval are shown instead.
Note 2: several satellites also have moon avoidance angles, or avoidance
angles for the Earth. Both are NOT (yet) taken into account.

##### Example

% convert source position into degrees
variable ra=hms2deg(19,49,35.49);
variable dec=dms2deg(+30,12,31.8);

% visibility during the year 2013
variable tstart=MJDofDate(2013,1,1);
variable tstop=tstart+365;

variable vis=object_visibility_satellite(ra,dec,tstart,tstop;suzaku,dt=0.1);

variable i;
for(i=0;i<length(vis);i++) {
printf("%s

",vis[i].MJDstring);
}

----

#### obliquity
##### Synopsis
 calculate the obliquity of the ecliptic

##### Usage
```c
 eps=obliquity(JD;mjd);
```

##### Qualifiers

* mjd: if set, the argument is in MJD, not in JD
* laskar: use the polynomial expression by Laskar (1986,
Astron. Astrophys. 157, 59), which is valid for a time
span of around 10000 years around J2000, rather than
the IAU 2006 expression.
* true: return the true obliquity for the date by applying
nutation
* theory: nutation theory to use, see help for
function nutation_angles; default: NU2000K
* deg: return the obliquity in degrees
* arcsec: return the obliquity in arcseconds

##### Description

This routine calculates the obliquity of the ecliptic for
the Julian Date(s) JD using the IAU 2006 resolutions, which
are based on Hilton et al., (2006, Cel. Mech. Dyn. Astron. 94, 351).
JD can be an array, it is formally measured in TT.

The IAU 2006 expression is good to better than 1 arcsecond
for +/-500 years around J2000. Outside of this interval
use the polynomial expression by Laskar (laskar keyword).

The angles returned are in rad, use the deg or arcsec qualifiers
if you want them in degrees or arc seconds.

__See also__: nutation_angles

----

#### ohplot_filled
##### Synopsis
 over-plot a filled histogram defined by slang arrays

##### Usage
```c
 ohplot_filled(Array_Type bin_lo, Array_Type bin_hi, Array_Type values)

```

##### Qualifiers

* fill_style: [<code>=1</code>] set the fill style:

<code>FS = 1</code> <code>=></code> solid (default)

<code>FS = 2</code> <code>=></code> outline

<code>FS = 3</code> <code>=></code> hatched (cannot be used with ylog;)

<code>FS = 4</code> <code>=></code> cross-hatched (cannot be used with ylog;)

* ymin: [<code>=min(values)</code>] set the lower y-value to which the areas are filled
* angle: [<code>=degrees</code>] sets the angle of the hatched lines for FS=3 [default = 45]

##### Description

This function overplots a histogram described by three 1-D S-Lang arrays of size N.
The area below the histogram is filled. The fill style can be selected with a qualifier.
##### Examples

<code>ohplot_filled([1:5],[2:6],[1:5]);</code>

__See also__: hplot_filled, hplot

----

#### ohplot_with_err
##### Synopsis
 overplots histogram data points with errorbars

##### Description

This function passes all its arguments and qualifiers to the
<code>hplot_with_err</code> function, but adds the <code>overplot</code> qualifier.

__See also__: [o][h]plot_with_err, [o][h]plot

----

#### open_plot_ps2eps
##### Synopsis
 opens a plot and saves .ps filename for latter use of ps2eps

##### Usage
```c
 Integer_Type id = open_plot_ps2eps(device[, nxpanes[, nypanes]]);
```

##### Description

<code>open_plot_ps2eps</code> passes its arguments to <code>open_plot</code>.
If used together with <code>close_plot_ps2eps</code>, an .eps file
is finally produced from an usual PGPLOT .ps output
through the external tool ps2eps. Therefore, <code>device</code> has to be
a <code>.ps</code> file with <code>/</code>[<code>v</code>][<code>c</code>]<code>ps</code> specification.
##### Qualifiers

* ps2epsopt:  [="-R=+ -B -f"]: option for ps2eps
* noremoveps: the .ps file will not be removed after conversion
* pre_enlargeBB: enlarge bounding box by specified value [=1, if none specified] before ps2eps
* pre_run_cmd=cmd: command to run before ps2eps.
The ps-file is passed to <code>cmd</code> as an argument.
<code>cmd</code> is expected to write the modified ps file to <code>stdout</code>.
* enlargeBB: enlarge bounding box by specified value [=1, if none specified] after ps2eps

__See also__: open_plot, close_plot_ps2eps

----

#### open_print
##### Synopsis
 Wrapper around open_plot (and pg_color) to allow a system function to call the output file (isis_fancy_plots package)

##### Usage
```c
 id = open_print(String_Type);
```

##### Description

Use as:
isis> id = open_print("fig1.ps/vcps"); keynote_size; nice_width;
isis> plot(x,y);
isis> close_print(id,"gv");

__See also__: close_print, sov, open_plot, close_plot, apj_size, keynote_size, nice_width, pg_color, pg_info

----

#### oplotGTIs
##### Synopsis
 visualizes Good Time Intervals

##### Usage
```c
 oplotGTIs(Struct_Type gti[, Double_Type offset]);
```

----

#### oplot_contour_lines
##### Synopsis
 overplots contour lines of a 2d array (image)

##### Usage
```c
 oplot_contour_lines(f, f0[, X, Y]);
```

##### Qualifiers

* save: =filename: saves/restores the contour lines in a FITS file
* pgplot: uses <code>_pgline</code> instead of <code>oplot</code>

##### Description

<code>f</code> has to be a two-dimensional array (an image).
<code>f0</code> is the value of the contour lines <code>f[y,x] = f0</code>.
The arrays <code>X</code> and <code>Y</code>, if present, transform the array-indices <code>x</code> and <code>y</code>
to the coordinate system used for plotting.

__See also__: get_contour_lines

----

#### oplot_rect
##### Synopsis
 overplots a rectangle

##### Usage
```c
 oplot_rect(Double_Type x1, y1, x2, y2);
```
or

```c
 oplot_rect(Double_Type [x1, x2], [y1, y2]);

```

----

#### oplot_struct_arrays
##### Synopsis
 overplots the fields of a structure agains each other

##### Usage
```c
 oplot_struct_arrays(Struct_Type s, String_Type fieldnameX, String_Type fieldnameY);
```

##### Qualifiers

* xoffset:
* yoffset:

##### Description

<code>oplot(s.fieldnameX - xoffset,  s.fieldnameY - yoffset);</code>

----

#### oplot_with_err
##### Synopsis
 overplots data points with errorbars

##### Description

This function passes all its arguments and qualifiers to the
<code>plot_with_err</code> function, but adds the <code>overplot</code> qualifier.

__See also__: [o][h]plot_with_err, [o][h]plot

----

#### oplot_xline
##### Synopsis
 overplots one or more vertical line(s)

##### Usage
```c
 oplot_xline(Double_Type x1[, x2, ...]);
```

##### Qualifiers

* ymin: [=<minimum of current <code>yrange</code>>]
* ymax: [=<maximum of current <code>yrange</code>>]
* color: number of the color to use

##### Description

For each <code>x</code> of <code>x1</code>[, <code>x2</code>, ...] (which may be arrays, too),
a line is overplotted from <code>ymin</code> to <code>ymax</code> with the same <code>color</code>.

----

#### oplot_yline
##### Synopsis
 overplots one or more horizontal line(s)

##### Usage
```c
 oplot_yline(Double_Type y1[, y2, ...]);
```

##### Qualifiers

* xmin: [=<minimum of current <code>xrange</code>>]
* xmax: [=<maximum of current <code>xrange</code>>]
* color: number of the color to use

##### Description

For each <code>y</code> of <code>y1</code>[, <code>y2</code>, ...] (which may be arrays, too),
a line is overplotted from <code>xmin</code> to <code>xmax</code> with the same <code>color</code>.

----

#### orbitalphase
##### Synopsis
 calculates an orbital phase at a given MJD time from an ephemeris

##### Usage
```c
 Double_Type phi = orbitalphase(Double_Type MJD, T0, P0, [Pdot, [Pddot ]]);
```
or

```c
 Double_Type phi = orbitalphase(Double_Type MJD, String_Type ephemeris);

```

##### Description

<code>phi = (MJD-T0)/P - floor( (MJD-T0)/P );</code>
where P = P0 + ( Pdot/2. + Pddot\*MJD/6. )\*MJD ;
The string <code>ephemeris</code> can be used to refer to an internally
stored (T0, P) pair or, if available, (T0, P, Pdot, Pddot) quadruple.

If <code>orbitalphase</code> is called with an unknown <code>ephemeris</code>,
the allowed values are shown by <code>get_ephemeris</code>.
##### Qualifiers

* numpulse: return pulse number instead of phase

__See also__: get_ephemeris

----

#### orbit_calculator
##### Synopsis
 Calculate orbits of test particles in a Galactic gravitational potential

##### Usage
```c
 orbit_calculator(Double_Types ah[], am[], as[], dd[], dm[], ds[], dist[], vrad[], pma_cos_d[], pmd[], t_end; qualifiers)
% or (for error propagation)
orbit_calculator(Double_Types ah, am, as, dd, dm, ds, dist, dist_sigma[], vrad, vrad_sigma[], pma_cos_d, pma_cos_d_sigma[], pmd, pmd_sigma[], t_end; qualifiers)
```

```
or

```c
 orbit_calculator(Double_Types x[], y[], z[], vx[], vy[], vz[], t_end; qualifiers)
##### Qualifiers

* coords: [<code>="cyl"</code>]: Use cylindrical ("cyl") or cartesian ("cart") coordinates for the internal
computations. Note that circular orbits like that of the Sun are computed faster in cylindrical
coordinates whereas cartesian coordinates are much more efficient for straight-line trajectories
or those that come very close to the z-axis where angular momentum terms slow down cylindrical
calculations.
* dt: Deactivate adaptive mode and use this fixed stepsize instead.
* model: [<code>="AS"</code>]: Function ("AS", "MN_NFW", "MN_TF", or "plummer_MW") evaluating the equations
of motion, circular velocity, and energy of the model potential.
* MC_runs: [<code>=nint(10^5)</code>]: Number of Monte Carlo realizations in the case that 1-sigma errors are given.
* ODE_solver: [<code>="RKCK"</code>]: Choose among three different Runge-Kutta (RK) integration methods:
"RKF": RK-Fehlberg, "RKCK": RK-Cash-Karp, "RKDP": RK-Dormand-Prince.
* parallax_pma_corr: [<code>=0</code>]: Correlation between parallax and proper motion in right ascension.
* parallax_pmd_corr: [<code>=0</code>]: Correlation between parallax and proper motion in declination.
* pma_pmd_corr: [<code>=0</code>]: Correlation between proper motion in right ascension and in declination.
* disk: [<code>=struct{radius = 0, height = 0.1, x = 0, y = 0, z = 0, crossings = 1}</code>]: If disk.radius > 0,
orbit integration will be stopped at the moment a trajectory has crossed a horizontal plane
located at z = disk.z + disk.height \* Gaussian-random-number inside a circle of radius
disk.radius centered at (disk.x, disk.y) for the disk.crossings-th time.
* seed: [<code>=_time()</code>]: Seed the random number generator via the function 'seed_random'.
* set: [<code>=0</code>]: If present, trajectories will be saved ("Save entire trajectories"). As
this can be very memory-consuming for a large number of orbits, one can additionally
use the value of this qualifier to specify a lower limit on the time difference of
two consecutive moments of time that will be saved.
* stff: "Save to fits files": Prefix of fits files to which initial and final structures are written.
* SunGCDist: By default, the Sun-Galactic center distance is taken from the current model.
Use this qualifier to explicitly set a distance in kpc.
* tolerance: [<code>=1e-8</code>]: Absolute error control tolerance; lower limit: 1e-15.
* verbose: Show intermediate times t.
* Any qualifiers from 'cel2gal' and the model potential function except 'vlsr' and 'eomecd'.:
Important note: for consistency, the local standard of rest velocity vlsr is calculated from the
circular velocity of the current model potential evaluated at (r=SunGCDist, z=0).

##### Description

Calculate orbits of test particles in a Galactic gravitational potential from given
initial conditions. The latter can be given either in celestial or Galactic cartesian
coordinates (see the help on the function 'cel2gal' for format and unit conventions).
Integration starts at time t=0 and ends at t=t_end [Myr], which is the last input
parameter. A negative t_end implies backward integration, which is e.g. useful to
trace back orbits in time. The potential and its equations of motion are outsourced
to a function specified by the qualifier 'model'. In this way, switching from one model
to another one is simply done by changing the before mentioned qualifier. Make always
use of cylindrical coordinates (r [kpc], phi [rad], z [kpc]) and their canonical momenta
(vr [kpc/Myr], Lz [kpc^2/Myr], vz [kpc/Myr]) as well as of cartesian coordinates (x [kpc],
y [kpc], z [kpc], vx [kpc/Myr], vy [kpc/Myr], vz [kpc/Myr]) to set up the equations of
motion (see the qualifier 'coords'). To numerically integrate the coupled differential
equations, an adaptive Runge-Kutta method of fourth/fifth order is used (see qualifier
'ODE_solver'). The stepsize is hereby controlled such that for each step an absolute
accuracy in coordinates (in units of kpc) and velocity components (in units of km/s) is
achieved that is smaller than given by the qualifier 'tolerance'. The function is optimized
for multi-orbit calculations, i.e., when the input parameters are either arrays or 1-sigma
uncertainties are given in addition. The latter are used to create Gaussian distributed
initial conditions to perform error propagation based on a number of Monte Carlo runs as
specified by the qualifier 'MC_runs'. To assign asymmetric uncertainties, use an array
of length two, i.e., [sigma_plus, sigma_minus], instead of a single number. The Gaussian
distribution is then split up into two Gaussian distributions, one with standard deviation
sigma_plus (for values larger than the respective input parameter) and one with sigma_minus
(else). To account for correlations between the distance (or alternatively the parallax,
see the qualifier 'parallax' in the function 'cel2gal'), proper motions in right ascension,
and proper motion in declination, make use of the qualifiers 'parallax_pma_corr',
'parallax_pmd_corr', and 'pma_pmd_corr'. Note that asymmetric uncertainties and
parameter correlations are mutually exclusive for individual parameters. All orbits are
computed simultaneously and on the same time grid. Stepsize control is hereby based on
the worst-offender principle. The function returns one structure with the two fields
"i" (initial) and "f" (final) (both again structures) containing the initial and final
Galactic cartesian coordinates (in kpc) and velocities (in km/s) as well as the z-component
of angular momentum Lz (in kpc^2/Myr) and total energy E_total = E_kin + E_pot (in kpc^2/Myr^2).
To see whether conservation of energy or conservation of angular momentum is implemented
in the equations of motion or not, have a look at the help of the outsourced potential
function. The final structure contains also the minimum and maximum Galactocentric distances
Rmin = min(R(t)) and Rmax = max(R(t)) with R(t) = sqrt(x(t)^2+y(t)^2+z(t)^2) and - if the
qualifier 'coords' is set to "cyl" - the number of revolutions about the Galactic z-axis
(negative values imply a motion in direction of Galactic rotation, i.e. prograde orbits,
while positive ones imply retrograde orbits). To save the initial and final structures to
fits files, set the qualifier 'stff' to the desired prefix of the filename. If not only
the initial and final situation is of interest, but rather the entire trajectories, use
the qualifier 'set'. In this case, the additional field "tr" (trajectory) (again a structure,
one field per orbit ("o1", "o2", ...)) is added to the returned structure containing all
orbits. For tracing back orbits to the Galactic disk, use the 'disk' qualifier to stop
individual calculations at the moment a trajectory has crossed the disk for a certain
number of times.
##### Example

s = orbit_calculator(12,22,29.6,40,49,36,3.078,262,-13.52,16.34,-1000; disk = struct{radius=50, height=0.2, x=0, y=0, z=0, crossings=1});
s = orbit_calculator(12,22,29.6,40,49,36,3.078,[0.6,0.3],262,5,-13.52,1.31,16.34,1.37,-1000; disk = struct{radius=50, height=0.2, x=0, y=0, z=0, crossings=1}, stff="HIP60350", MC_runs=100);
s = orbit_calculator(-8.4,0,0,0,242,0,250; set, model="MN_TF");
plot(s.tr.o0.x, s.tr.o0.y);
s = orbit_calculator([8:10:#500], [0:1:#500], [4:5:#500], [0:0:#500], [210:230:#500], [-10:-50:#500], 1000);

% Example using parallax, proper motions, and correlation parameters from Gaia:
s = orbit_calculator(12,22,29.6,40,49,36,0.325,0.3,262,5,-13.52,1.31,16.34,1.37,-1; parallax, parallax_pma_corr=0.1, parallax_pmd_corr=0.2, pma_pmd_corr=0.75);

% Example using the spectroscopic distance and only proper motions from Gaia:
s = orbit_calculator(12,22,29.6,40,49,36,3.077,[0.6,0.3],262,5,-13.52,1.31,16.34,1.37,-1; pma_pmd_corr=0.75);

__See also__: cel2gal, AS, MN_NFW, MN_TF, plummer_MW, xfig_3d_orbit_on_cube

----

#### outer_product
##### Synopsis
 computes the outer product of a number of vectors

##### Usage
```c
 Double_Type P[] = outer_product(Double_Type f1[], f2[], ..., fn[]);
```

##### Description

The <code>n</code> arguments <code>f1</code>, <code>f2</code>, ..., <code>fn</code> have to be one-dimensional arrays.
The return value <code>P</code> is an <code>n</code>-dimensional array with
<code>P[i1, i2, ..., in] = f1[i1] \* f2[i2] \* ... fn[in]</code>.

----

#### outer_products
##### Synopsis
 computes multi-dimensional arrays from one-dimensional ones

##### Usage
```c
 (Double_Type P1[], P2[], ...) = outer_products(Double_Type f1[], f2[], ..., fn[]);
```

##### Description

<code>P1[i1, i2, ..., in] = f1[i1];</code>

<code>P2[i1, i2, ..., in] = f2[i2];</code>

...

<code>Pn[i1, i2, ..., in] = fn[i1];</code>

The return value <code>Pj</code> is calculated as outer product of <code>x1, x2, ..., xn</code>,
where <code>xj</code> = <code>fj</code> and
<code>xi = [1, 1, ..., 1]</code> (same length as <code>fi</code>) for <code>i!=j</code>.

__See also__: outer_product

----

#### overplot_clean_model
##### Synopsis
 creates an overlay of an clean VLBI image and the modelfit components

##### Usage
```c
 overplot_clean_model(String_Type <code>cleanfile</code>, String_Type <code>modfile</code>, String_Type <code>outputfile</code>);
```

##### Qualifiers

* ra_mas: [={20,-20}] {left,right} limits of image in mas
* dec_mas: [={-20,20}] {top,bottom} limits of image in mas
* plot_size: [=15] size of plot
* n_sigma: [=3.0] lowest contour of clean image
* sourcename: [=default] name of the source, by default the name is read from the .fits file,

set to NULL for not plotting a source name
* obs_date: [=default] the observation date, by default the observation date is read from the .fits file,

set to NULL for not plotting a observation date, set to "mjd" when MJD format required
* cont_color: [="gray"] color of contours of clean image
* cont_scl: [="2"] set factor to change the separation between contour levels
* cont_lvl: [=[c1,c2,..] set contour levels [Jy] manually, overwrites other contour parameters
* model_color: [="black"] color of Gaussian ellipses
* center_symbol: [="+"] symbol stating the ellipse center, set to NULL for no symbol
* comp_label: [=0] set to 1 when labelling of components depending on distance from [0,0]
is requested
* ind_inverse: [=0] if the labels should be in inverse order set to 1
* label_alt: [=NULL] give list of alternative labels
* label_color: [="red"] color of component labels
* ex_counterjet: [=0]	set to 1 if counterjet components (and core) should be excluded and define
the corresponding quadrant of the plot via the CJ-coordinates
* counterjet_ra: [=NULL] define counterjet coordinates in mas
* counterjet_dec: [=NULL] define counterjet coordinates in mas

##### Description

This function creates an overlay of a VLBI-clean image and the corresponding

model of Gaussian components which are over-plotted as ellipses.

The required input format are fits-file for both the clean and the modelfit images.
The format of the output file depends on the suffix of the given

<code>filename</code>. Possible formats of the output file are PDF, EPS,

PNG, GIF, etc.
If labelling = 1 is set, the components are labeled with J0,J1,J2,... depending on
their distance to [0,0].
The counterjet components (and core) can be excluded by defining the corresponding
quadrant of the the plot via counterjet_ra and _dec.

----

#### pack_obj
##### Synopsis
 converts an SLang object into a binary string

##### Usage
```c
 BString_Type[] pack_obj(Any_Type obj);
```

##### Description

Uses the `pack' function to convert a single SLang object into
an array of binary strings (BString_Type). The format specifier
is included as first character of the strings.

If the object is a single number or string then the returned
array consists of a single item only. In case the given object
is an array or a structure, the returned array starts with the
type of the input array and its length or the field structure
definition, respectively. The remaining items are the input
array items or the structure items. For structures, the
contained objects are converted recursively.

The following data-types are supported:
Int16_Type, Int32_Type, Int64_Type, Float_Type, Double_Type,
Char_Type, String_Type, Array_Type, Struct_Type
and its aliases.
##### Example

<pre>

    s = pack_obj(PI);        % s[0] = "d\030-DT\373!\011@"

    s = pack_obj([1:3] + 4); % s[0] = "ak\003\000\000\000"
                             % s[1] = "\005\000\000\000"
                             % s[2] = "\006\000\000\000"
                             % s[3] = "\007\000\000\000"

    variable obj = struct {
      number = 598105,
      float  = 341.12e8,
      more   = struct {
        msg    = "hello"
      }
    };
    s = pack_obj(obj);
    print(s);

</pre>

__See also__: unpack_obj, pack, unpack

----

#### palette--blend
##### Synopsis
 Blend one or more colors linearly (in RGB space).

##### Usage
```c
 UInt_Type get_color_palette("blend", UInt_Type n);
```

##### Qualifiers

* colors[=[red,gray,blue]]: The colors to interpolate, must be given as HEX
* set[=[0:1:#length(colors)]]: The setpoints of the colors. Can be unsorted.
* space[="hsluv"]: The color space in which interpolation is done.

##### Description

Blend colors to a palette from given colors. The setpoints can be
used to shift the color at the same position to higher or lower
interpolation values.

The qualifier <code>space</code> allows to control in what space the interpolation
is done. This either must be one of the known color spaces "hsl", "hsluv",
"hpluv", or "rgb", or a tuple (list with 2 elements) with references
to two functions. The first must take three arguments (R,G,B) as 8 bit
encoded colors and convert it to the color space variables (x,y,z). The
second converts back (x,y,z) -> (R,G,B).

----

#### palette--cubehelix
##### Synopsis
 Create palette using 'cubehelix' description

##### Usage
```c
 UInt_Type[] pattern = get_color_palette("cubehelix", UInt_Type n);
```

##### Qualifiers

* start[=0.0]: Start color of the palette
* s[=0.8]: Saturation of the colors
* rot[=0.4]: How far the scale rotates in color (hue)
* dark[=0.15]: Dark end of the palette
* light[=0.85]: Light end of the palette

##### Description

Calculates a color palette according to the description
in D. A. Green's, 'A colour scheme for the display of
astronomical intensity images', (Bull. Astr. Soc. India (2011)).

----

#### palette--dark
##### Synopsis
 Get dark blend palette with given color

##### Usage
```c
 UInt_Type[] palette = get_color_palette("dark", UInt_Type n);
```

##### Qualifiers

* color[=red]: Color to blend with dark pattern (as HEX value).
* reverse: If given, blend from color to dark

##### Description

Get a color palette from the chosen color fading in from
a dark tone.

----

#### palette--diverging
##### Synopsis
 Create a diverging palette between two colors

##### Usage
```c
 UInt_Type palette = get_color_palette("diverging", UInt_Type n);
```

##### Qualifiers

* dark: If given, midpoint is a dark tone
* h_pos[=0.7]: Hue of positive color
* h_neg[=0.2]: Hue of negative color
* sep[=0.01]: Size of midpoint region
* s[=0.75]: Saturation of both colors
* l[=0.5]: Luminosity of both colors

##### Description

Create a color palette useful to represent diverging data.

__See also__: hsluv2rgb

----

#### palette--hpluv
##### Synopsis
 Generate palette from HSLuv space

##### Usage
```c
 UInt_Type[] palette = get_color_palette ("hpluv", UInt_Type n);
```

##### Qualifiers

* h[=0.01]: Starting hue
* s[=0.90]: Saturation
* l[=0.60]: Lightness

##### Description

Create a color palette with <code>n</code> entries. Control the
appearence with the HSL qualifiers.

__See also__: hpluv2rgb

----

#### palette--hsl
##### Synopsis
 Generate palette from HSL space

##### Usage
```c
 UInt_Type[] palette = get_color_palette ("hsl", UInt_Type n);
```

##### Qualifiers

* h[=0.01]: Starting hue
* s[=0.65]: Saturation
* l[=0.60]: Lightness

##### Description

Create a color palette with <code>n</code> entries. Control the
appearence with the HSL qualifiers.

__See also__: hsl2rgb

----

#### palette--hsluv
##### Synopsis
 Generate palette from HSLuv space

##### Usage
```c
 UInt_Type[] palette = get_color_palette ("hsluv", UInt_Type n);
```

##### Qualifiers

* h[=0.01]: Starting hue
* s[=0.90]: Saturation
* l[=0.60]: Lightness

##### Description

Create a color palette with <code>n</code> entries. Control the
appearence with the HSL qualifiers.

__See also__: hsluv2rgb

----

#### palette--light
##### Synopsis
 Get light blend palette with given color

##### Usage
```c
 UInt_Type[] palette = get_color_palette("light", UInt_Type n);
```

##### Qualifiers

* color[=red]: Color to blend with dark pattern (as HEX value).
* reverse: If given, blend from color to light

##### Description

Get a color palette from the chosen color fading in from
a light tone.

----

#### palette--map
##### Synopsis
 Retrieve a set of colors from a colormap

##### Usage
```c
 UInt_Type[] palette = get_color_palette (String_Type name, UInt_Type len);
```

##### Qualifiers

* start[=0.0]: Starting "color" (lowest value)
* range[=1.0]: Range of "color", larger than one causes repetitions

##### Description

This function is useful if a range of colors is required.
It returns <code>len</code> values from a linear mapping of the
given colormap. The colors are constructed from palette--blend
and forwards all qualifiers to this constructor.

Note: This function is used only if the given <code>name</code> is
a colormap (and does not match a palette name, see <code>png_get_colormap_names</code>),
to construct a %  set of colors from a color array see
palette--blend.

__See also__: png_get_colormap_names, palette--name

----

#### palette--sb
##### Synopsis
 Get Seaborn color paletts

##### Usage
```c
 UInt_Type[] get_color_paletts("sb:"+name, UInt_Type n);
```

##### Description

The seaborn paletts are a very good set of colors for qualitative
representation of data (like lines, points, etc.).

----

#### palette--sron
##### Synopsis
 Get SRON palettes

##### Usage
```c
 UInt_Type[] get_color_palette("sron:"+name, UInt_Type n);
```

##### Description

The SRON colors are defined in Paul Tol's technical note (<code>https://personal.sron.nl/~pault/data/colourschemes.pdf</code>)
and provides a set of colors for qualitative, diverging, and sequential
representations.

Note: To get the original set of colors (was provided by <code>get_sron_colors</code>)
use <code>get_color_palette("sron-rainbow", n);</code> for diverging and sequential
there are no direct matches. See the other color palette options.

__See also__: get_color_palette_names, palette--sron-rainbow

----

#### palette--sron-rainbow
##### Synopsis
 Get SRON rainbow palette from Paul Tol

##### Usage
```c
 UInt_Type[] palette = get_color_palette("sron-rainbow", UInt_Type n);
```

##### Description

Returns a set of colors more or less like rainbow colors with good contrast.
<code>n</code> makes a smart subset up to 23.

----

#### palette--tab
##### Synopsis
 Get Tableau10 color palettes

##### Usage
```c
 UInt_Type[] palette = get_color_palette("tab:"+name, UInt_Type n);
```

##### Description

Color palettes used by the Tableau10 software for visualization. Usuall only
good for qualitative data.

----

#### panstarrsImageDownload
##### Synopsis
 Download PanSTARRS image cutouts

##### Usage
```c
 Assoc_Type fileNames = panstarrsImageDownload(String_Type position, Double_Type size, String_Type outdir)
Assoc_Type fileNames = panstarrsImageDownload(Double_Type ra, Double_Type dec, Double_Type size, String_Type outdir)
```

##### Qualifiers

* g: Download images taken with the g filter
* r: Download images taken with the r filter
* i: Download images taken with the i filter
* z: Download images taken with the z filter
* y: Download images taken with the y filter
* stack: Download final stacks
* warp: Download individual warps (single epoch images)
* data: Download main data products
* mask: Download masks
* wt: Download weight images
* exp: Download exposure maps
* expwt: Download weighted exposure maps (undocumented)
* num: Download num images (undocumented)

##### Notes

Please note that PanSTARRS only covers the sky north of DEC=-30 deg.
At least one filter is required.
At least one of stack or warp is required.
At least one of data, mask, wt, exp, expwt or num is required.
The function only throws an exception on real runtime errors. If some data
just aren't available no exceptions is thrown, the images just don't exist
and are therefore not downloaded and not entered into the returned assoc.
##### Description

Access the PanSTARRS DR1 image cutout server located at
http://plpsipp1v.stsci.edu/cgi-bin/ps1cutouts to
download different combinations of data products and filters.
The usage of this function is analogous to the usage of this website.
position can be a generic string which is resolved by the server itself
using Simbad or other means. Alternatively RA and DEC can be supplied
directly to the function in degrees.
outdir must supply a directory where the output files shall be written.
The function returns an Assoc_Type which contains the information about
the downloaded files. If all options are set the assoc looks like this:
<pre>

    assoc
     stack
      aux
       exp
        g=path
        ...
       expwt
        g=path
        ...
       mask
        g=path
        ...
       num
        g=path
        ...
       wt
           g=path
           ...
      colors
          g=path
          ...
     warp
         aux
          mask
           g
            55860.59225=path
            ...
           i
            55200.51443=path
            ...
           r
            55911.49788=path
            ...
           y
            55518.62770=path
            ...
           z
               55302.23917=path
               ...
          wt
              g
               55860.59225=path
               ...
              i
               55200.51443=path
               ...
              r
               55911.49788=path
               ...
              y
               55518.62770=path
               ...
              z
                  55302.23917=path
                  ...
         colors
             g
              55860.59225=path
              ...
             i
              55200.51443=path
              ...
             r
              55911.49788=path
              ...
             y
              55518.62770=path
              ...
             z
                 55302.23917=path
                 ...

</pre>
The structure should be self explanatory, except the set of numbers at
the lowest level of the warps. These are the MJDs when the exposure
was completed.

----

#### __panstarrsRetrieveSite
##### Synopsis
 Download a html page of the PanSTARRS cutout server

##### Usage
```c
 String_Type __panstarrsRetrieveSite(String_Type URL)
```

##### Description

Simply takes a url and downloads the html content of the site using curl,
returning it as a string. Throws an exception upon error.

----

#### parseDateString
##### Synopsis
 parses a string including year, month, day [, hour [, minute [, second]]]

##### Usage
```c
 Struct_Type parseDateString(String_Type date_string);
```

##### Qualifiers

* no_2digit_correction: prevents the correction of two digit year specification,
e.g., 83/12/13 instead of 1983/12/13. If this qualifier
is not set, 2000 is added to years from 00-19 and
1900 to years 20-99.

##### Description

This function tries to interprete the given string as a data and returns
a structure consistent with the return value of `localtime'. It is
assumed that the first number occuring in the string specifies the year,
the second the month, and the third the day. If further numbers are found,
they are interpreted as hour, minute, second and fraction of seconds. Note
that the seconds contained in the structure as defined in `localtime' has
to be an integer, while here a double is used in case of fraction of
seconds. There can be any separators between the numbers (except numbers).
##### Example

parseDateString("69/07/21");
parseDateString("1969-07-21 02:56:30.44");
parseDateString("sdf1969--X07..21QQ_02/56((30,,44xyz");

__See also__: localtime

----

#### __parsePanstarrsPage
##### Synopsis
 Parse the html of a PanSTARRS cutout server page

##### Usage
```c
 Assoc_Type __parsePanstarrsPage(String_Type html)
```

##### Description

Takes the result of __panstarrsRetrieveSite() and parses it in order to
determine which images are available and what their specific download
URLs are

----

#### partial_correlation
##### Synopsis
 Tests two luminosities for partial correlation due to redshift

##### Usage
```c
 partial_correlations(String_Type filename);
```

##### Description

This function tests if a correlation of two parameters is due to
the redshift. Description of method and code adapted from
Akritas & Siebert, 1996, MNRAS, 278, 919.
Works with FITS and ASCII files.

The input file needs 6 columns with luminosity1, UL,
luminosity2, UL, redshift, UL. The upper limit columns should
have a 1 for a detection, and a 0 for an upper limit.

##### Examples

partial_correlation("data.txt")

partial_correlation("data.fits")

__See also__:

----

#### par_bounds
##### Synopsis
 Return parameter index of parameters hitting bounds

##### Usage
```c
 Int_Type[] par_bounds();
```

##### Qualifiers

* tolerance: [=0.01] Boundary hit tolerance

##### Description

This function returns the parameter index for every parameter with satisfies
(par.max-par.value)/(par.max-par.min) <= tolerance or
(par.value-par.min)/(par.max-par.min) <= tolerance.

__See also__: list_par_bounds, list_free_bounds

----

#### par_list
##### Synopsis
 Print a parameter file listing

##### Usage
```c
 Int_Type par_list([String_Type filename | Ref_Type buffer | File_Type fd]);
```

##### Qualifiers

* tex: [=0]: Format parameter listing in form of a LATEX tabular
environment. This does currently not work for a Ref_Type
argument.
* pdf: [=0]: Compile a pdf file containing the parameter listing
as a table.
* all: [=0]: Add all parameters to tex and pdf file. By default
parameters with the following name - value combinations
are excluded:
norm    1
* exclude: [=0]: Array or list of parameters to be excluded in
tex and pdf listings. These are even excluded if the
"all" qualifier above is set.
* include: [=0]: Array or list of additional parameters to be
included in tex and pdf listings.

##### Description

Prints all internally stores parameter file lines to screen. This includes
out-commented fit functions and parameter lines, which are only loaded if
par_load is used instead of load_par. Writes parameter listing to file if
a String_Type parameter is given, which will be interpreted as filename.
If a File_Type parameter is given the listing will be written to this
file. If the argument is of Ref_Type, the listing will be returned in this
buffer. This argument functionality works analog to the default list_par
function.

__See also__: par_load, par_save, save_par, load_par, list_par

----

#### par_load
##### Synopsis
 Loads fit function and parameters for given component from file

##### Usage
```c
 par_load(String_Type filename [, String_Type component]);
```

##### Qualifiers

* clean: [=1]:   Remove temporary parameter files for individual
components after calling load_par.
* dryrun: [=0]:  Generate parameter file for component but
do not load it, i.e., do not call load_par.
Implies clean=0.
* iterate: [=0]: Iterate through components. Returns the name of
the current component or NULL if no more components
are available.

##### Description

Creates a copy of the given parameter file and modifies it such that only
the fit function associated with the given component is active. This file
is then loaded using the standart load_par function.
This way individual model components, or alternative fit functions, can
be defined in the same parameter file using the following format:
#[name1] fitFunction1
#[name2] fitFunction2
defaultFitFunction
The rest of the file contains the parameters in the usual format used by
list_par. The name "DEFAULT" is reserved for the (uncommented) default
fit function. The function returns the name of the loaded component. It
returns NULL if the desired component does not exist or if no more
components are available during iteration.

__See also__: par_save, load_par, list_par

----

#### par_save
##### Synopsis
 Save fit function and parameters to labeled component in file

##### Usage
```c
 Int_Type par_save(String_Type filename [, String_Type component]);
```

##### Qualifiers

* dryrun: [=0]: generate parameter file for component but
do not load it, i.e., do not call load_par.
Implies clean=0.

##### Description

Saves the current fit function and parameter list
to the given parameter file. If a component name is given, the current fit
function will be saved as a named and commented out component, which can
loaded using par_load. Otherwise the main difference to save_par is that
comment lines, which are only loaded if par_load is used, are saved to the
parameter file as well. Calling this function is equivalent to calling
save_par if no comment lines are present or if the parameter file has been
loaded using load_par.
The function returns the number of components written to the file, or -1
upon error.

__See also__: par_load, save_par, load_par, list_par

----

#### path_realpath
##### Synopsis
 Get full path of specified path

##### Usage
```c
 String_Type realpath = path_realpath(String_Type path);
```

##### Description

Turn the given path into an asbolute path (replacing '..' and '.').

__See also__: path_concat,path_is_absolut

----

#### period_search_via_string_length
##### Synopsis
 A period-finding method for sparse randomly spaced observations

##### Usage
```c
 (Double_Type p[], SL[]) = period_search_via_string_length(Double_Type t[], s[], pmin, pmax; qualifiers)
```

##### Description

This function may be useful to determine the period of a variable
signal 's' observed at a relatively small number 'N' of randomly
spaced observations at times 't' possibly taken many periods apart.

To identify candidate periods in the given range between 'pmin' and
'pmax', string-lengths 'SL' for trial periods 'p' (sampled in equal
frequency steps, see qualifier "delta_phi_max") are computed and
tabulated. The trial period giving the lowest string-length results
in the most smooth-looking curve and is thus the most likely period.
##### Notes

The underlying idea is to minimize the so-called "string-length" in
a phase diagram. The phase diagram for a trial period 'p' is created
by computing the phase 'phi' according to
phi = (t-min(t))/p mod 1.
The string-length 'SL' is then simply the sum of the lengths of line
segments joining successive points (phi_i, s_i) in a phase diagram:
SL = sum ( ((s_i-s_i-1)^2+(phi_i-phi_i-1)^2)^(1/2) )
+ ((s_1-s_N)^2+(phi_1-phi_N+1)^2)^(1/2).
To get rid of different scales caused by different units in ordinate
(e.g., km/s or magnitude) and abscissa (unit = trial period), the
observations are scaled so that
s' = 0.5\*(s-min(s))/(max(s)-min(s))-0.25
in order to give equal weight to measures and phases (for details,
see Dworetsky 1983, MNRAS, 203, 917).

For reference: the string-length of a sinusoidal string is 1.4637.
##### Qualifiers

* delta_phi_max [=0.01]: : Trial periods 'p' are sampled in equal
frequency steps of
delta_freq = delta_phi_max/(max(t)-min(t)).
This ensures that phase errors are always less than 'delta_phi_max'
since
phi = (t-min(t))/p mod 1 = (t-min(t))\*freq mod 1
-> delta_phi = (t-min(t))\*delta_freq
-> delta_phi_max = (max(t)-min(t))\*delta_freq.

##### Example

t = 1000\*urand(50); % time of observations
s = sin(t)+0.05\*grand(length(t)); % signal of observations; true period is 2\*PI
connect_points(0); point_style(2); plot(t, s);
(p, SL) = period_search_via_string_length(t, s, 1, 10; delta_phi_max=0.01);
connect_points(-1); point_style(-1); plot(p, SL);
ind = where(SL==min(SL)); SL[ind[0]]; p[ind[0]]; % index, value, and period of minimum string-length
connect_points(0); point_style(2); plot((t-min(t))/p[ind[0]] mod 1, s); % phase diagram

__See also__:

----

#### pfold
##### Synopsis
 folds a lightcurve or event list on a given period

##### Usage
```c
 Struct_Type pp = pfold(Double_Type t, r, p);
```
or

```c
 Struct_Type pp = pfold(Double_Type t, r, p, e);
```
or

```c
 Struct_Type pp = pfold(Double_Type t, p);
```

##### Qualifiers

* nbins: [=30] number of bins for the pulse profile
* exact: take finite lightcurve bins into account (LC case).
take differantial phase grid into account (Events case).
* dt: lightcurve bin size.
* fracexp: fractional exposure per lightcurve bin.
* t0: set reference time.
* pdot: [=0] first derivative of pulse period p.
* pddot: [=0] second derivative of pulse period p.
* gti: GTIs for event data, given as struct{start=Double_Type, stop=Double_Type}

##### Description

Calculates the pulse profile of a given lightcurve or event list
for times <code>t</code> and rate <code>r</code>. In case of an event list
normally the use of GTIs is necessary to ensure correct results.

If the qualifiers <code>pdot</code> or <code>pddot</code> are given and not
zero a taylor expansion of the period evolution is used to
calculate the mapping to phase (from <code>t0</code>). If <code>pddot</code>
is non-zero the result is only approximately correct. See
<code>phaseOfTime</code>.

The input arrays <code>t</code>, <code>r</code>, and <code>e</code> can also be
given as qualifiers.

If the <code>exact</code> qualifier is given the finite size of lightcurve
bins is taken into account by linear interpolation. However, the
computation time is increased. For event lists, the code will take the
differentail phase grid change into account. Otherwise the exposure
time is approximated assuming a constant period over one GTI frame.

The returned structure contains the fields bin_lo, bin_hi, value
and err, ready for plotting the pulse profile (as rate). For further
diagnostics the <code>counts</code> (counts) and <code>ttot</code> (per-bin exposure)
are given. The field <code>npts</code> contains the number of lightcurve bins
starting in each bin.

__See also__: phaseOfTime, timeOfPhase

----

#### pfold_map
##### Synopsis
 folds a lightcurve or event list on a given period map

##### Usage
```c
 Struct_Type ppmap = pfold_map(Double_Type t, r, p);
```
or

```c
 Struct_Type ppmap = pfold_map(Double_Type t, r, p, e);
```
or

```c
 Struct_Type ppmap = pfold_map(Double_Type t, p);
```

##### Qualifiers

* nbins: [=30] number of bins for the pulse profile
* exact: take finite lightcurve bins into account (LC case).
take differantial phase grid into account (Events case).
* dt: lightcurve bin size.
* fracexp: fractional exposure per lightcurve bin.
* t0: set reference time.
* pdot: [=0] first derivative of pulse period p.
* pddot: [=0] second derivative of pulse period p.
* gti: GTIs for event data, given as struct{start=Double_Type, stop=Double_Type}

##### Description

This function acts identical to <code>pfold</code> except that a two
dimensional array is calculated, where the first dimension runs
over the cycles and the second over the period.

The returned structure has the following fields
bin_lo, bin_hi  Phase grid of pulses (from 0 to 1)
phase_lo, phase_hi  Cycle grid, continuously
counts  2D map of counts
exposure  2D map of exposure time
rate  2D map of rate
p  struct returned by pfold

For illustration: The returned map can be collapsed to the pulse
profile via <code>sum(ppmap.counts, 0)</code> or <code>mean(ppmap.rate, 0)</code>.

__See also__: pfold, phaseOfTime, timeOfPhase

----

#### _pgaxis
##### Synopsis
 draw a labelled graph axis

##### Usage
```c
 _pgaxis(opt, x1, y1, x2, y2, v1, v2, step, nsub, dmajl dmajr, fmin, disp, orient);
```

##### Description

Besides <code>String_Type opt</code> and <code>Integer_Type nsub</code>,
all parameters are of <code>Double_Type</code>.

<code>_pgaxis</code> draws an axis from world-coordinate position (<code>x1</code>,<code>y1</code>) to (<code>x2</code>,<code>y2</code>).

Normally, this routine draws a standard linear axis with equal subdivisions.
The quantity described by the axis runs from <code>v1</code> to <code>v2</code>.
If the '<code>L</code>' option is specified, the routine draws a logarithmic axis.
In this case, the quantity described by the axis runs from <code>10^v1</code> to <code>10^v2</code>.
A log. axis always has major, labeled, tick marks spaced by one or more decades.
If the major tick marks are spaced by one decade (as specified by the <code>step</code> argument),
then minor tick marks are placed at 2, 3, ..., 9 times each power of 10;
otherwise minor tick marks are spaced by one decade.  If the axis spans
less than two decades, numeric labels are placed at 1, 2, and 5 times each
power of ten.  If the axis spans less than one decade, or if it spans many decades,
it is preferable to use a linear axis labeled with log(quantity of interest).

Arguments:

<code>opt</code>    : a string containing single-letter codes for various options.

The options currently recognized are:

<code>L</code> : draw a logarithmic axis

<code>N</code> : write numeric labels

<code>1</code> : force decimal labelling, instead of automatic choice

<code>2</code> : force exponential labelling, instead of automatic.

<code>x1</code>, <code>y1</code> : world coordinates of one endpoint of the axis.

<code>x2</code>, <code>y2</code> : world coordinates of the other endpoint of the axis.

<code>v1</code>     : axis value at first endpoint.

<code>v2</code>     : axis value at second endpoint.

<code>step</code>   : major tick marks are drawn at axis value <code>0.0</code> plus or minus
integer multiples of step.  If <code>step==0.0</code>, a value is chosen automatically.

<code>nsub</code>   : minor tick marks are drawn to divide the major divisions into <code>nsub</code> equal
subdivisions (ignored if <code>step==0.0</code>).   If <code>nsub <= 1</code>,
no minor tick marks are drawn. <code>nsub</code> is ignored for a logarithmic axis.

<code>dmajl</code>  : length of major tick marks drawn to left of axis
(as seen looking from first endpoint to second),
in units of the character height.

<code>dmajr</code>  : length of major tick marks drawn to right of axis,
in units of the character height.

<code>fmin</code>   : length of minor tick marks, as fraction of major.

<code>disp</code>   : displacement of baseline of tick labels to right of axis,
in units of the character height.

<code>orient</code> : orientation of label text, in degrees;
angle between baseline of text and direction of axis (0-360 deg).

__See also__: http://www.astro.caltech.edu/~tjp/pgplot/subroutines.html#PGAXIS

----

#### _pgbox
##### Synopsis
 annotate the viewport with frame, axes, numeric labels, etc.

##### Usage
```c
 _pgbox(xopt, xtick, nxsub,  yopt, ytick, nysub);
```

##### Description

<code>x</code>/<code>yopt</code>: string of options for X (horizontal) / Y (vertical) axis of plot.
Options are single letters, and may be in any order:

"A": draw Axis (X axis is horizontal line Y=0, Y axis is vertical line X=0).
"B": draw bottom (X) or left (Y) edge of frame.
"C": draw top (X) or right (Y) edge of frame.
"G": draw Grid of vertical (X) or horizontal (Y) lines.
"I": Invert the tick marks; ie draw them outside the viewport instead of inside.
"L": label axis Logarithmically (see below).
"N": write Numeric labels in the conventional location
-- below the viewport (X) or to the left of the viewport (Y).
"P": extend ("Project") major tick marks outside the box
(ignored if option I is specified).
"M": write numeric labels in the unconventional location
-- above the viewport (X) or to the right of the viewport (Y).
"T": draw major Tick marks at the major coordinate interval.
"S": draw minor tick marks (Subticks).
"V": orient numeric labels Vertically. This is only applicable to Y.
The default is to write Y-labels parallel to the axis.
"1": force decimal labelling, instead of automatic choice (see PGNUMB).
"2": force exponential labelling, instead of automatic.

<code>x</code>/<code>ytick</code>: world coordinate interval between major tick marks on X/Y axis.
If <code>x</code>/<code>ytick==0</code>, the interval is chosen by _pgbox,
so that there will be at least 3 major tick marks along the axis.

<code>n</code>{<code>x</code>/<code>y</code>}<code>sub</code>: number of subintervals to divide the major coordinate interval into.
If <code>x</code>/<code>ytick==0</code> or <code>nx/ysub==0</code>,the number is chosen by _pgbox.

To get a complete frame, specify BC in both <code>xopt</code> and <code>yopt</code>.
Tick marks, if requested, are drawn on the axes or frame or both,
depending which are requested. If none of ABC is specified,
tick marks will not be drawn.

For a logarithmic axis, the major tick interval is always 1.0.
The numeric label is 10^x where x is the world coordinate at the tick mark.
If subticks are requested, 8 subticks are drawn between each major tick at equal logarithmic intervals.

__See also__: http://www.astro.caltech.edu/~tjp/pgplot/subroutines.html#PGBOX

----

#### pgcolor
##### Synopsis
 Set pgplot colors 17, 18, 19, 20 to a green, brown, pink, dark yellow (isis_fancy_plots package)

##### Usage
```c
 pg_color; -or- pgcolor;
```

##### Description

__See also__: pg_info, pginfo

----

#### pginfo
##### Synopsis
 Print a core dump of some useful pgplot and isis_fancy_plots information.

##### Usage
```c
 pg_info; -or- pginfo;
```

##### Description

__See also__: Nearly all isis_fancy_plot functions return a use message if invoked without arguments

----

#### _pgsls (set line style)
##### Synopsis
 set the line style attribute for subsequent plotting

##### Usage
```c
 _pgsls(Integer_Type linestyle);
```

##### Description

This attribute affects line primitives only;
it does not affect graph  markers, text, or area fill.
Five different line styles are available, with the following codes:
1 (full line), 2 (dashed), 3 (dot-dash-dot-dash), 4 (dotted),
5 (dash-dot-dot-dot). The default is 1 (normal full line).

----

#### pg_color
##### Synopsis
 Set pgplot colors 17, 18, 19, 20 to a green, brown, pink, dark yellow (isis_fancy_plots package)

##### Usage
```c
 pg_color; -or- pgcolor;
```

##### Description

__See also__: pg_info, pginfo

----

#### PG_function
##### Synopsis
 sets fitting statistic for poisson source counts and already subtracted gaussian background

##### Usage
```c
 set_fit_statistic("PG");
```

##### Description

This fitting statistic can be used when dealing with
low count spectra that have already been subtracted
by the instrumental background. Cash statistics are
not suited for this task since purely poisson distri-
buted counts are assumed in that case.
This version of the fitting statistic has been derived
from the profile likelihood statistic for zero back-
ground counts from:

https://heasarc.gsfc.nasa.gov/xanadu/xspec/manual/XSappendixStatistics.html

The statistic should be used when fitting low count
spectra of the Swift/BAT instrument.
IMPORTANT: the statistic can only be used when fitting
count rate spectra since the exposure times for each
channel have dummy values of 1s.

__See also__: set_fit_statistic

----

#### pg_info
##### Synopsis
 Print a core dump of some useful pgplot and isis_fancy_plots information.

##### Usage
```c
 pg_info; -or- pginfo;
```

##### Description

__See also__: Nearly all isis_fancy_plot functions return a use message if invoked without arguments

----

#### phasebin_GTIs
##### Synopsis
 computes the GTI time in phase bins

##### Usage
```c
 Double_Type dt[] = phasebin_GTIs(tstart, tstop, T0, P, n);
```

----

#### phaseOfTime
##### Synopsis
 Compute the phase corresponding to given time

##### Usage
```c
 Double_Type[] phaseOfTime(Double_Type[] time, Double_Type, p, dp, ddp);
```

##### Description

Given a time and a period evolution by the period P <code>p</code>,
first, and second derivative of P, <code>dp</code> and <code>ddp</code>,
respectively, calculate the phase.

Note: This function does a simple taylor expansion of the phase
dphi = 1./P(t)dt. Time zero correpsonds to phase zero. For
long time arrays this function suffers from precision errors.

Since it is expected that the period changes monotonically, this
function throws an error if the given time is outside of the extrema
(if any). This only applies to non-zero <code>ddp</code>.

__See also__: timeOfPhase

----

#### phflux (fit-function)
##### Synopsis
 fits the photon flux in a given energy range

##### Description

This function can be used as a convolution model to determine
the photon flux [ph/s/cm^2] of the model in the energy range
given by <code>E_min</code> and <code>E_max</code>. Only bins within(!) this energy range
are considered for the calculation of the flux, thus the model
should be evaluated on a grid including the values defining the
energy range, i.e. <code>E_min</code> and <code>E_max</code> are elements
of <code>[bin_lo, bin_hi]</code> of the grid. A user grid can be used
for this purpose.
As this function fits the normalization of the total convolved
model, the normalizations of its components are not defined
absolutely, but only relativ to each others. For that reason it
is meaningful to freeze the normalization of one component, at
best the one of the continuum to avoid ambiguities during
fitting.

##### Examples

% data definition:
<code>variable lo = _A([1:10]);</code>
<code>variable hi = make_hi_grid(lo);</code>
<code>variable my_data = define_counts(lo,hi,lo,sqrt(lo));</code>

<code>variable my_emin = 2.5;</code>
<code>variable my_emax = 6.5;</code>
% defining a grid containing the energy limits for the flux:
% (in this way only valid if energy range is covered by the grid
% and if these values are not already element of bin_lo, bin_hi)
<code>define my_grid(id, s)</code>
<code>{</code>
<code>   variable mygdc = get_data_counts(id);</code>
<code>   mygdc.bin_lo = [mygdc.bin_lo,_A(my_emax),_A(my_emin)];</code>
<code>   mygdc.bin_hi = [mygdc.bin_hi,_A(my_emax),_A(my_emin)];</code>
<code>   s.bin_lo = mygdc.bin_lo[array_sort(mygdc.bin_lo)];</code>
<code>   s.bin_hi = mygdc.bin_hi[array_sort(mygdc.bin_hi)];</code>
<code>   return s;</code>
<code>}</code>

<code>set_eval_grid_method (USER_GRID, my_data, &my_grid);</code>

<code>fit_fun("phflux(1,powerlaw(1))");</code>

<code>set_par("phflux(1).E_min",  my_emin,  1); % keV</code>
<code>set_par("phflux(1).E_max",  my_emax,  1); % keV</code>
<code>freeze("powerlaw(1).norm");</code>
<code>()=fit_counts();</code>
<code>list_par;</code>

% It is also possible to determine only the flux of certain
% model components, e.g., the unabsorbed flux:
<code>fit_fun(phabs(1)\*phflux(1, powerlaw(1)));</code>

__See also__: enflux, set_eval_grid_method

----

#### photon_flux

##### Synopsis

##### Usage
```c
 String_Type = photon_flux (hist_index, E_min, E_max);
```

##### Description

This function returns the integrated photon flux of
a defined Energy range.
If no energy range specified E_min=0.5, E_max=10.

__See also__: get_data_flux;

----

#### physical_quantity
##### Synopsis
 initializes a physical quantity with number and units

##### Usage
```c
 PhysicalQuantity_Type physical_quantity(Double_Type number)
```

##### Qualifiers

* leng: length unit and dimension
* time: time unit and dimension
* mass: mass unit and dimension
* curr: electrical current unit and dimension
* temp: temperature unit and dimension
* unit: array of compound units (see <code>physical_quantity_unit</code>)

##### Description

The units are specified as strings with their dimensionality
indicated by "^" as powers, i.e., "[unit]^[dim]".
[dim] can be a negative number as well.
For dim==1, "^1" can be omitted.
##### Example

variable c = physical_quantity(299792.458; length="km", time="s^-1");

__See also__: physical_quantity_unit

----

#### physical_quantity_current_in_A
##### Synopsis
 defines a new current unit or gets the conversion for an existing one

##### Usage
```c
 physical_quantity_current_in_A(String_Type name, Double_Type value);
```
or

```c
 Double_Type value = physical_quantity_current_in_A(String_Type name);

```

##### Description

The unit  <code>name</code> = <code>value</code> A  can be used in
<code>physical_quantity(x; curr=name);  % = x \* value</code> A

__See also__: physical_quantity

----

#### physical_quantity_length_in_m
##### Synopsis
 defines a new length unit or gets the conversion for an existing one

##### Usage
```c
 physical_quantity_length_in_m(String_Type name, Double_Type value);
```
or

```c
 Double_Type value = physical_quantity_length_in_m(String_Type name);

```

##### Description

The unit  <code>name</code> = <code>value</code> m  can be used in
<code>physical_quantity(x; leng=name);  % = x \* value</code> m

__See also__: physical_quantity

----

#### physical_quantity_mass_in_kg
##### Synopsis
 defines a new mass unit or gets the conversion for an existing one

##### Usage
```c
 physical_quantity_mass_in_kg(String_Type name, Double_Type value);
```
or

```c
 Double_Type value = physical_quantity_mass_in_kg(String_Type name);

```

##### Description

The unit  <code>name</code> = <code>value</code> kg  can be used in
<code>physical_quantity(x; mass=name);  % = x \* value</code> kg

__See also__: physical_quantity

----

#### physical_quantity_temperature_in_K
##### Synopsis
 defines a new temperature unit or gets the conversion for an existing one

##### Usage
```c
 physical_quantity_temperature_in_K(String_Type name, Double_Type value);
```
or

```c
 Double_Type value = physical_quantity_temperature_in_K(String_Type name);

```

##### Description

The unit  <code>name</code> = <code>value</code> K  can be used in
<code>physical_quantity(x; curr=name);  % = x \* value</code> K

__See also__: physical_quantity

----

#### physical_quantity_time_in_s
##### Synopsis
 defines a new time unit or gets the conversion for an existing one

##### Usage
```c
 physical_quantity_time_in_s(String_Type name, Double_Type value);
```
or

```c
 Double_Type value = physical_quantity_time_in_s(String_Type name);

```

##### Description

The unit  <code>name</code> = <code>value</code> s  can be used in
<code>physical_quantity(x; time=name);  % = x \* value</code> s

__See also__: physical_quantity

----

#### physical_quantity_unit
##### Synopsis
 defines a new compound unit or gets the value of an existing one

##### Usage
```c
 physical_quantity_unit(String_Type name, Double_Type value;; qualifiers);
```
or

```c
 physical_quantity_unit(String_Type name, PhysicalQuantity_Type value);
```
or

```c
 PhysicalQuantity_Type value = physical_quantity_unit(String_Type name);

```

##### Description

If the second argument of the <code>physical_quantity_unit</code> function
is a double value, the value of the unit is
constructed with the <code>physical_quantity</code> function,
i.e., all its qualifiers can be applied.

The unit  <code>name</code> = <code>value</code>  can be used in
<code>physical_quantity(x; unit=name);  % = x \* value</code>

__See also__: physical_quantity

----

#### planetpos
##### Synopsis
 Calculate the apparent position of the Sun, Moon, and the planets
(Mercury,..., Neptune, and Pluto).

##### Usage
```c
 (r,alp,del) = planetpos(JD;qualifiers);
```

```
or

```c
 (r,alp,del) = planetpos(JD,object;qualifiers);
##### Description

Returns the true geocentric distance (in AU), and apparent right ascension
and declination of a planet in the geocentric celestial reference system for the
date JD (in TT or TDB [the default]).

Use the center-qualifier to choose another center object.

The default coordinate system is the J2000.0 (ICRS) system, to include the
effects of precession and nutation to get "apparent" positions, use the
of_date qualifier, to get the mean equinox position (w/o nutation), use
of_date together with the mean_equinox qualifier.

The true geocentric distance is the distance the planet has at the time of the
calculation, while the apparent position is corrected for light travel time
effects. This is the default (and identical to the Astronomical Almanac).
If the lighttravel qualifier is set, the function returns the
distance the light traveled. In most cases, this is what you want.
Use the "no_apparent" to switch off the correction for light travel time
(e.g., useful for the calculation of heliocentric coordinates, where
traditionally light travel time effects are are not taken into account)

The default is the JPL ephemeris DE430 (as used in the astronomical almanac
and as distributed with HEASOFT). Use the ephemeris qualifier to switch to
another ephemeris.

Alternatively, the less precise VSOP87 can be used (but not for Pluto and
the Moon). There is no computing time advantage to doing so, however, but
vsop87 is valid for several 1000 years around AD2000, while most JPL
ephemerides are limited to less than that.

This function has been checked against the values tabulated in the
Astronomical Almanac for 2014 and 2015, which also uses DE430.
The results match exactly.

JD and object can be arrays. In this case the return value is
an array of Vectors or three arrays of distance, RA and DEC,
sorted by object first and by date next.

##### Qualifiers

* object: a string (valid values: Sun, Mercury, Venus,
Mars, Jupiter, Saturn, Uranus, Neptune, Pluto, Moon,
default: Sun).
* center: center object for the position. Default: Earth.
Either a string (same as "object"), or a
3D or 6D long double array. If 3D: position
in AU in a barycentric coordinate system in
ICRS coordinates (xyz), if 6D: position and
velocity (AU/D) in a barycentric coordinate system.
* topocentric: return topocentric positions; if this qualifier
is of type Vector_Type, then the xyz coordinates are
interpreted as the position of the observer in the
IERS 2010 coordinate system, in units of meters (see
function geographic2vector). Otherwise, a structure with
geographic coordinates is used, use tags lat, lon for
the geographic position (in degrees, east is positive),
and tag height as height (in meters) over the WGS 84
geoid (as appropriate for GPS coordinates).
* of_date: if set, return the apparent position in the geocentric
celestial reference system for the ecliptic and
equinox of date (this is what is listed in the
astronomical almanac).
* mean_equinox: if set together with of_date, return coordinates
for the mean equinox of date (i.e., ignore nutation).
* no_apparent: ignore light travel time effects
* ecliptical: return coordinates in ecliptical coordinates,
i.e., return r,lon,lat (or the xyz vector in ecliptical coords)
(also takes of_date qualifier into account)
* vector: return a geocentric/object centric direction (!) vector
for the position.
* deg: return the angles in degrees (default: radian).
* mks: return distance in m (default: AU)
* cgs: return distance in cm (default: AU)
* lighttravel: return distance the light traveled (default: true geocentric dist)
* mjd: the given date is the MJD
* tt: the given date is TT (default: TDB, difference only matters for pulsar work)
* vsop87: use the VSOP87 ephemeris rather than the JPL ephemeris, does not work
for Pluto and the Moon.

__See also__: jpl_initeph,vsop87,geographic2vector

----

#### plotGTI
##### Synopsis
 visualizes Good Time Intervals

##### Usage
```c
 plotGTI(Struct_Type gti[, Double_Type offset]);
```

##### Qualifiers

* ylevel: plot GTIs at constant y-level
* overplot:

----

#### plotxy
##### Synopsis
 Generate a simple x/y plot with error bars (isis_fancy_plots package)

##### Description

plotxy(x,dxm,dxp,y,dym,dyp, pstruct); % pstruct = struct{dcol, decol, xrng, ...}
plotxy(x,dxm,dxp,y,dym,dyp; dcol=#, decol=#, ...);

Also accepts:

plotxy(x,y [,pstruct;qualifiers]);
plotxy(x,dxm,dxp,y [,pstruct;qualifiers]);
plotxy(x,,,y,dym,dyp [,pstruct;qualifiers]);

Plot simple x,y plots with error bars: x-dxm, x+dxp, etc.

Options below refer to structure variables/associative keys/qualifiers:

dcol  = (pgplot) color value for data
decol = (pgplot) color value for data
dsym  = (pgplot) symbol value for data
Note: dsym=0 will \*not\* produce a histogram plot
xrange= List of X-limits for the data. Ranges previously input
via xrange(); will be respected if this option is not set.
yrange= List of Y-limits for the data. Ranges previously input
via yrange(); will be respected if this is not set.
xlabel= String for the X-axis label
ylabel= String for the Y-axis label
Note: xlabel(); ylabel(); commands will also work.
oplt    = 0 (default) for new plot, !=0 for overplotting

Further note: plotxy(...); will apply the choices from connect_points(#);

__See also__: plot_counts, plot_data, plot_unfold, plot_residuals, plot_fit_model, plotxy, plot_comps, plot_double

----

#### plot_atime
##### Synopsis
 plots the residuals of a pulse arrival times fit

##### Usage
```c
 plot_atime([Integer_Type[] index]);
```

##### Qualifiers

* t0: reference time of xticks
* col: array of colors for datasets
* noerrbars: do not plot errorbars
* connect_points: see 'connect_points'
* style: see 'point_style'
* xunit: used time unit (d or s)
* yunit: used residual unit (phi or s)
* xlunit: label of xunit
* ylunit: label of yunit
* xrng: time range
* yrng: residual range (default -0.5 to 0.5)
* ploteph: overplot the pulse ephemeris
* plotorb: overplot the orbital motion
* plotpnum: overplot the modelled pulse numbers
('modnum' reference must be set,
see 'define_atime')
* plotdif: overplot the meassured pulse period
('modnum' reference must be set,
see 'define_atime')
* y2rng: yrange of overplot
* y2rel: if pulse period tics are displayed
wrong, you should switch to relative
values and milliseconds
* extcol: color of overplot
* extcolY: yaxis color of overplot
* oplot: do not erase plot window
* lshift: if 'peph' and 'porb' set, shift the
labels printed at the ephemeris by
the given value in y-direction. May
be a two value array [eph,orb].
Values are interpreted as relative
coordinates.

##### Description

By default plots the residuals of all datasets
containing arrival times. The residuals are
calculated by
residuals = data - model
Using the optional
first parameter the indices of the datasets to
be plotted can be specified. Also works if
some datasets are excluded from the fit (see
'atime_xinclude').
The residuals in units of pulse phase or seconds
are plotted against the meassured pulse arrival
times in days or seconds. The units can be set
by using the accordant qualifiers. Further
informations can be overplotted, like the
pulse period in the binary barycentre.

__See also__: arrtimes, atime_dataind, atime_xinclude, plot_data

----

#### plot_combined_data_model_residuals
##### Synopsis
 plots data and model counts, and residuals for a combination of data sets

##### Usage
```c
 plot_combined_data_model_residuals([Integer_Type id[]]);
```

##### Qualifiers

* dcol: color of data [default=1]
* mcol: color of model [default=2]

##### Description

If no indices <code>id</code> of data sets are specified, <code>all_data</code> are used.

The combined data, model and residuals are plotted in a two panel multiplot.

__See also__: get_combined_data_model_residuals

----

#### plot_component
##### Synopsis
 to plot modelfit parameters of different components

##### Usage
```c
 plot_component([array of <code>struct comp</code>]);
```

##### Qualifiers

* outputfile: outputfile name and directory by hand
* mjd_min: [=53736.0] lower limit of time axis in mjd (default: 1/1/2006)
* mjd_max: [=55927.0] upper limit of time axis in mjd (default: 1/1/2012)
* date_min: [=2006.0] lower limit of time axis (default: 1/1/2006)
* date_max: [=2012.0] upper limit of time axis (default: 1/1/2012)
* distance_min: [=-2] lower limit of distance axis in mas
* distance_max: [=20] upper limit of distance axis in mas
* flux_min: [=1e-5] lower limit of flux axis in Jy
* flux_max: [=5] upper limit of flux axis in Jy
* TB_min: [=10^5] lower limit of brightness temperature axis in K
* TB_max: [=10^15] upper limit of brightness temperature axis in K
* size_min: [=1e-3] lower limit of size axis in mas^2
* size_max: [=100] upper limit of size axis in mas^2
* pos_min: [=-180] lower limit of pos angle in degrees
* pos_max: [=180] upper limit of pos angle in degrees
* labels: [=default] provide array of custom labels for the components
* sym: [=default] provide array of custom symbols for the components
* symcolor: [=default] provide array of custom colors for the components
* symsize: [=1] provide array of custom symbol sizes or one value to apply size to all
* legend: create a legend
* lpos_x: set the x position of the legend in world0 system (0 = left, 1=right)
* lpos_y: set the y position of the legend in world0 system (0 = bottom, 1=top)
* linestyle: [=default] set to 0 if the flux values should not be conntected (or to another value for
another line style
* nocomp: provide a comp structure (or array of structures) to plot not identified components in black
* plots: [=[9,10,3,4,11,12]]: provide an array of numbers to generated specified plots:
1:	distance vs mjd
2:	flux vs mjd
3:	T_B vs distance
4:	flux vs distance
5:	size vs distance
6:	pos angle vs distance
7:	size vs mjd
8:	pos angle vs mjd
9:	distance vs time
10:	flux vs time
11:	size vs time
12:	pos_angle vs time

##### Description

This functions creates overview plots for modelfit components. The required input format is the comp structure which can be obtained with get_component or an array of the comp structure.

----

#### plot_comps
##### Synopsis
 Create a data plot with model components explicitly shown (isis_fancy_plots package)

##### Usage
```c
 plot_comps({data},&plot_func;dcol={val},mcol={val},ccol={val},cstyle=val,...);
```

```
or

```c
 plot_comps({data},pstrut,&plot_func); where pstruct=struct{dcol, mcol, ...}
##### Description

Use a fancy plotting function, e.g., plot_counts or plot_data or
plot unfold, passed as a reference, and cycle through all the
components with a norm parameter.  Plot each of these as a separate
model component.  The plot functions now take two additional
optional qualifiers (which alternatively can be passed via the
pstruct structure variable): ccol and cstyle.  The ccol parameter
gives the color of the model components for each dataset, which can
be different from the color of the model for the complete model.
The cstyle allows a global change of the line_style for \*all\* of the
model components.  (I.e., only one alternate line_style can be
chosen.)  data is the usual combination of integers (=individual
data sets), arrays (=data sets to be combined), and lists (=id of
combined datasets).

##### Examples

plot_comps({1,[2,3]},popt,&plot_counts;xrange={1,10});
plot_comps({5,8},&plot_unfold);
plot_comps({{1}},popt,&plot_data);

__See also__: plot_counts, plot_data, plot_unfold, plot_residuals, plot_fit_model, plotxy, plot_comps, plot_double

----

#### plot_contour_trq
##### Synopsis
 creates a contour plot out of the results from function
contour_trq.

##### Usage
```c
 plot_contour_trq(String_Type inputDir);
```

##### Qualifiers

* out:    post script outputname
* image:  fits image outputname
* x:      x label
* y:      y label

##### Description

- <code>inputDir</code> directory where all torque job files are,
created by function contour_trq.

Be aware of the issues with the torque (look at the description
of contour_trq function), as it may not have all bins^2
values, and hence give wrong contour plot.

The default post script file name is cont_default.ps.
Output fits image file is cont_default.fits.

EXAMPLE

plot_contour_trq("fileDirectory";out="my_out",x="x_lab",y="y_lab");

creates a plot "my_out.ps" with x-axis label named "x_lab" and y_axis
label named "y_lab".

__See also__: contour_trq, missing_contour_trq

----

#### plot_counts
##### Synopsis
 Plot counts per bin (isis_fancy_plots package)

##### Description

plot_counts({indx,[arry],{cid}},pstruct);  % pstruct = struct{ dcol, mcol, rcol, ...}
plot_counts({indx,[arry],{cid}};dcol={val},mcol={val},rcol={val,[arry],val},...);

Plot background subtracted data, model, and residuals as counts/bin
Residuals are units of chi, chi2, or ratio, and will be based upon whether
one chooses sigma=model, data, or gehrels in set_fit_statistic();
(data error bars are only affected by the latter two).
set_fit_statistic("cash"); will alter the residuals to the Cash statistic.
set_fit_statistic("ml"); will alter the residuals to the Maximum Likelihood statistic.

Options below refer to structure variables/qualifiers

indx    = list of data set indices to be plotted. Any indices grouped in
an array within that list will be \*combined\* in the data plot.
Single number in list is combo id, {#} = [combination_members(#)].
dcol    = (pgplot) color value for data (or list of color values)
decol   = (pgplot) color value for data error bars (or list of color values)
mcol    = (pgplot) color value for model (or list of color values)
0 => No model plotted
rcol    = (pgplot) color value for residuals (or list of color values; arrays
within the list allow for individual color values if portions of
the data are combined, but their associated residuals are not)

recol   = color for residual error bars (or list of color values; arrays
within the list act as for residual color inputs)
dsym    = (pgplot) symbol value for data (or list of symbol values)
0 => histogram plot
rsym    = (pgplot) symbol value for residuals (or list of symbol values;
arrays within the list act as for residual color inputs)
0 => histogram plot
xrange  = List of X-limits for the data & model & residuals
Note: Any X- or Y-range set to NULL is autoscaled
yrange  = List of Y-limits for the data & model and (optionally) residuals
oplt    = 0 (default) for new plot, !=0 for overplotting
no_reset= 0 (default)- plots \*will\* be reset, i.e., next plot moves to new pane
(multiplot), next plot redraws window (single plot). no_reset=1 necessary
for overplotting multiplots (oplt=1 sufficient for single plots).
res     = 0 (default), no residuals; 1, 2, or 3 = chi, chi2, or ratio residuals
4, 5, or 6 = chi, chi2, or ratio, but combine residuals for combined data
set_fit_method("cash"); or set_fit_method("ml") will cause res=(2 or 5)
or res=(1 or 4) to plot the residual for the Cash or Maximum Likelihood
statistic or its square root, respectively
power  = 0, 1 (default), 2, or 3 for Counts/bin X
(1/Unit, 1, Unit, Unit^2), respectively
bkg     = List of 0's (subtract background-default), 1's (include backgrounds),
or -1's (plot \*only\* the background [no model plotted in this case]).
Ratio residuals will include background in data/model, other residuals
are unaffected. Indices within a combination are treated the same.)
xlabel  = String that will overwrite default X-axis label (default=NULL)
ylabel  = String or string array that will overwrite the default Y-axis labels
(second element of array applies to residuals; default=NULL)
zshift  = List of redshifts to be applied to the data (default zshift={0,0,...})
vzero   = If set, the reference X-unit value to be defined as zero velocity.
The X-axis then becomes a velocity axis (km/s) referenced to this
point (default vzero=NULL; setting vzero/zaxis supersedes zshift)
zaxis   = If not 0, use a redshift axis instead of a velocity axis \*if\* vzero
is defined (default zaxis=0)
scale   = Multiplicatively scale the Y-axis by the values in a list.
Any arrays in the list should hold the individual scalings for
data set arrays in the input index list.  \*\*Note:\*\*  these values
only scale the plots, not the fits.  (Default values are 1.)
gap     =  1 (default), models are histograms with gaps where data has gaps,
0          , model are bin-centered lines, without gaps.

__See also__: plot_data, plot_unfold, plot_residuals, plot_fit_model, plotxy, plot_comps, plot_double

----

#### plot_data
##### Synopsis
 Plot counts per unit per second (isis_fancy_plots package)

##### Description

plot_data({indx,[arry],{cid}},pstruct);  % pstruct = struct{ dcol, mcol, rcol, ...}
plot_data({indx,[arry],{cid}};dcol={val},mcol={val},rcol={val,[arry],val},...);

Plot background subtracted data, model, and residuals as counts/xunit/sec.
Residuals are units of chi, chi2, or ratio, and will be based upon whether
one chooses sigma=model, data, or gehrels in set_fit_statistic();
(data error bars are only affected by the latter two).
set_fit_statistic("cash"); will alter the residuals to the Cash statistic.
set_fit_statistic("ml"); will alter the residuals to the Maximum Likelihood statistic.

Options below refer to structure variables/qualifiers

indx    = list of data set indices to be plotted. Any indices grouped in
an array within that list will be \*combined\* in the data plot.
Single number in list is combo id, {#} = [combination_members(#)].
dcol    = (pgplot) color value for data (or list of color values)
decol   = (pgplot) color value for data error bars (or list of color values)
mcol    = (pgplot) color value for model (or list of color values)
0 => No model plotted
rcol    = (pgplot) color value for residuals (or list of color values; arrays
within the list allow for individual color values if portions of
the data are combined, but their associated residuals are not)
recol   = color for residual error bars (or list of color values; arrays
within the list act as for residual color inputs)
dsym    = (pgplot) symbol value for data (or list of symbol values)
0 => histogram plot
rsym    = (pgplot) symbol value for residuals (or list of symbol values;
arrays within the list act as for residual color inputs)
0 => histogram plot
xrange  = List of X-limits for the data & model & residuals
Note: Any X- or Y-range set to NULL is autoscaled
yrange  = List of Y-limits for the data & model and (optionally) residuals
oplt    = 0 (default) for new plot, !=0 for overplotting
no_reset= 0 (default)- plots \*will\* be reset, i.e., next plot moves to new pane
(multiplot), next plot redraws window (single plot). no_reset=1 necessary
for overplotting multiplots (oplt=1 sufficient for single plots).
res     = 0 (default), no residuals; 1, 2, or 3 = chi, chi2, or ratio residuals
4, 5, or 6 = chi, chi2, or ratio, but combine residuals for combined data
set_fit_method("cash"); or set_fit_method("ml") will cause res=(2 or 5)
or res=(1 or 4) to plot the residual for the Cash or Maximum Likelihood
statistic or its square root, respectively
bkg     = List of 0's (subtract background-default), 1's (include backgrounds),
or -1's (plot \*only\* the background [no model plotted in this case]).
Ratio residuals will include background in data/model, other residuals
are unaffected. Indices within a combination are treated the same.)
xlabel  = String that will overwrite default X-axis label (default=NULL)
ylabel  = String or string array that will overwrite the default Y-axis labels
(second element of array applies to residuals; default=NULL)
zshift  = List of redshifts to be applied to the data (default zshift={0,0,...})
vzero   = If set, the reference X-unit value to be defined as zero velocity.
The X-axis then becomes a velocity axis (km/s) referenced to this
point (default vzero=NULL; setting vzero/zaxis supersedes zshift)
zaxis   = If not 0, use a redshift axis instead of a velocity axis \*if\* vzero
is defined (default zaxis=0)
scale   = Multiplicatively scale the Y-axis by the values in a list.
Any arrays in the list should hold the individual scalings for
data set arrays in the input index list.  \*\*Note:\*\*  these values
only scale the plots, not the fits.  (Default values are 1.)
sum_exp = If==1, then when combining data sets, sum the exposure times (as
opposed to using the mean exposure time; default sum_exp=1).
gap     =  1 (default), models are histograms with gaps where data has gaps,
0          , model are bin-centered lines, without gaps.

__See also__: plot_data, plot_unfold, plot_residuals, plot_fit_model, plotxy, plot_comps, plot_double

----

#### plot_double
##### Synopsis
 Use two different plot functions in the same figure (isis_fancy_plots package)

##### Description

plot_double({data},pstruct,&plot_funcI,&plot_funcII);  % pstruct=struct{dcol, mcol, ...}
plot_double({data},&plot_funcI,&plot_funcII;dcol={val},mcol={val},ccol={val},...);

Using fancy plotting functions, e.g., plot_counts or plot_data or
plot unfold, passed as references, apply plot_funcI in the upper
panel and plot_funcII in the lower panel.  (If residuals are chosen
to be displayed, include a third panel for them beneath the first
two plots.)  In each plot, cycle through all the components with a
norm parameter.  Plot each of these as a separate model component.
The plot functions now take two additional optional qualifiers
(which alternatively can be passed via the pstruct structure
variable): ccol and cstyle.  The ccol parameter gives the color of
the model components for each dataset, which can be different from
the color of the model for the complete model.  The cstyle allows a
global change of the line_style for \*all\* of the model components.
(I.e., only one alternate line_style can be chosen.)  data is the
usual combination of integers (=individual data sets), arrays (=data
sets to be combined), and lists (=id of combined datasets). Plot
parameters retain their usual meaning, with the exception of yrange
and power.  yrange is now a list of up to 6 elements, with the first
two applying to plot_funcI, the next two applying to plot_funcII,
and the final two applying to the residuals. If power is a list of
two elements, then the first element applies to plot_funcI and the
second element applies to plot_funcII.

##### Examples

plot_double({1,[2,3]},popt,&plot_unfold,&plot_counts;xrange={1,10});
plot_double({5,8},&plot_unfold,&plot_data);
plot_double({{1}},popt,&plot_data,&plot_counts);

__See also__: plot_counts, plot_data, plot_unfold, plot_residuals, plot_fit_model, plotxy, plot_comps, plot_double

----

#### plot_fit_model
##### Synopsis
 Plot background subtracted model as counts/xunit/sec (isis_fancy_plots package).

##### Description

plot_fit_model({indx,[arry],{cid}},pstruct);  % pstruct = struct{ mcol, ...}
plot_fit_model({indx,[arry],{cid}};mcol={val},...);

Plot background subtracted model as counts/xunit/sec.

Options below refer to structure variables/qualifiers

indx    = list of data set indices to be plotted. Any indices grouped in
an array within that list will be \*combined\* in the data plot.
Single number in list is combo id, {#} = [combination_members(#)].
mcol    = (pgplot) color value for model (or list of color values)
0 => No model plotted
xrange  = List of X-limits for the data & model & residuals
Note: Any X- or Y-range set to NULL is autoscaled
yrange  = List of Y-limits for the data & model and (optionally) residuals
oplt    = 0 (default) for new plot, !=0 for overplotting
no_reset= 0 (default)- plots \*will\* be reset, i.e., next plot moves to new pane
(multiplot), next plot redraws window (single plot). no_reset=1 necessary
for overplotting multiplots (oplt=1 sufficient for single plots).
bkg     = List of 0's (subtract background-default), 1's (include backgrounds),
or -1's (plot \*only\* the background [no model plotted in this case]).
Ratio residuals will include background in data/model, other residuals
are unaffected. Indices within a combination are treated the same.)
xlabel  = String that will overwrite default X-axis label (default=NULL)
ylabel  = String or string array that will overwrite the default Y-axis labels
(second element of array applies to residuals; default=NULL)
zshift  = List of redshifts to be applied to the data (default zshift={0,0,...})
vzero   = If set, the reference X-unit value to be defined as zero velocity.
The X-axis then becomes a velocity axis (km/s) referenced to this
point (default vzero=NULL; setting vzero/zaxis supersedes zshift)
zaxis   = If not 0, use a redshift axis instead of a velocity axis \*if\* vzero
is defined (default zaxis=0)
scale   = Multiplicatively scale the Y-axis by the values in a list.
Any arrays in the list should hold the individual scalings for
data set arrays in the input index list.  \*\*Note:\*\*  these values
only scale the plots, not the fits.  (Default values are 1.)
sum_exp = If==1, then when combining data sets, sum the exposure times (as
opposed to using the mean exposure time; default sum_exp=1).
gap     =  1 (default), models are histograms with gaps where data has gaps,
0          , model are bin-centered lines, without gaps.

__See also__: plot_counts; plot_data, plot_unfold, plot_residuals, plotxy, plot_comps, plot_double

----

#### plot_jet_speed
##### Synopsis
 visualizes the jet_speed_struct used by init_jet_fit

##### Usage
```c
 plot_jet_speed (Struct_Type jet_speed_struct);
```

##### Qualifiers

* xrange: set the xrange (provide a list or array)
* yrange: set the yrange (provide a list or array)

__See also__: init_jet_fit

----

#### plot_residuals
##### Synopsis
 Plot the data residuals (isis_fancy_plots package)

##### Description

plot_residuals({indx,[arry],{cid}},pstruct);  % pstruct = struct{ rcol, rsym, ...}
plot_residuals({indx,[arry],{cid}};dcol={val},rcol={val,[arry],val},rsym=...);

Plot data residuals, without plotting the data.  Residuals related to data
indices in [arry] will appear in a single ascii file if write_plot(); is
used, and will be combined in the plot if res>3 is chosen.

Options below refer to structure variables/qualifiers

indx    = list of data set indices to be plotted. Any indices grouped in
an array within that list will be \*combined\* in the data plot.
Single number in list is combo id, {#} = [combination_members(#)].
rcol    = (pgplot) color value for residuals (or list of color values; arrays
within the list allow for individual color values if portions of
the data are combined, but their associated residuals are not)
recol   = color for residual error bars (or list of color values; arrays
within the list act as for residual color inputs)
rsym    = (pgplot) symbol value for residuals (or list of symbol values;
arrays within the list act as for residual color inputs)
0 => histogram plot
xrange  = List of X-limits for the data & model & residuals
Note: Any X- or Y-range set to NULL is autoscaled
yrange  = List of Y-limits for the data & model and (optionally) residuals
oplt    = 0 (default) for new plot, !=0 for overplotting
no_reset= 0 (default)- plots \*will\* be reset, i.e., next plot moves to new pane
(multiplot), next plot redraws window (single plot). no_reset=1 necessary
for overplotting multiplots (oplt=1 sufficient for single plots).
res     = 0 (default), no residuals; 1, 2, or 3 = chi, chi2, or ratio residuals
4, 5, or 6 = chi, chi2, or ratio, but combine residuals for combined data
set_fit_method("cash"); or set_fit_method("ml") will cause res=(2 or 5)
or res=(1 or 4) to plot the residual for the Cash or Maximum Likelihood
statistic or its square root, respectively
xlabel  = String that will overwrite default X-axis label (default=NULL)
ylabel  = String or string array that will overwrite the default Y-axis labels
(second element of array applies to residuals; default=NULL)
zshift  = List of redshifts to be applied to the data (default zshift={0,0,...})
vzero   = If set, the reference X-unit value to be defined as zero velocity.
The X-axis then becomes a velocity axis (km/s) referenced to this
point (default vzero=NULL; setting vzero/zaxis supersedes zshift)
zaxis   = If not 0, use a redshift axis instead of a velocity axis \*if\* vzero
is defined (default zaxis=0)

__See also__: plot_counts, plot_data, plot_unfold, plot_fit_model, plotxy, plot_comps, plot_double

----

#### plot_spix
##### Synopsis
 plots a spectral index map using the struct provided by make_spix

##### Usage
```c
 plot_spix(Struct_Type values, String_Type outputname);
```

##### Qualifiers

* inv_color: [=0] inverts color scale (i.e., roles of red and blue switch)
* min_spix: [=min(values.spec_map)] minimum spectral index to be plotted
* max_spix: [=max(values.spec_map)] maximum spectral index to be plotted
* lum_scale: [=1] use the sum of the intensity of both images to scale
the brightness of the spectral index map, set to 0 in order to
show the significant regions at uniform brightness
* nsigma [=0]: spectral index values are only shown for pixels where
the emission (in both bands) is above the specified
significance (e.g., nsigma=3 means that the emission
has to be 3\*sigma above the noise level)
* nsigma_lo: [=0] emission limit for low frequency  band separately
* nsigma_hi: [=0] emission limit for high frequency band separately
* low_lum_limit: [=0] number of stdevs above the median that luminosity data
begins to be displayed
* hi_lum_limit: [=0] number of (e^n) stdevs above the median at which color
is fully saturated (0 -> no limit)
* ra_frac: [={0.0,1.0}] fraction of RA to display with {left,right} limits,
will keep scaling
* dec_frac: [={0.0,1.0}] fraction of DEC to display with {left,right} limits,
will keep scaling
* ra_mas: [={NULL,NULL}] {left,right} limits of image in mas
* dec_mas: [={NULL,NULL}] {top,bottom} limits of image in mas
* size: [=14] size of plot (maximum dimension)
* print_mode: [=0] set =1 for white background
* blue_bkgr: [=0] for a dark blue background set to 1
* quadratic: create a quadratic image, by default the scaling is such that
scaling in RA and DEC is equal
* no_labels: plot no labels
* pmodecolor: [=1] color saturation decreases wth this root of luminosity
(i.e., 2=sqrt) in print mode only
* beam_color: [="gray"] beam color
* src_name: [=values.source] manually set source name in plot
* obs_date: [=values.date] manually set date in plot
* xyunit: [="mas"] unit of the x/y labels, can be changed between "mas", "arcsec", "arcmin" and "deg";
assumption: FITS header sets unit "mas"
* xfig_tmp_dir: [=xfig_get_tmp_dir] set the path for the tmp directory used by xfig
* xfig_autoeps_dir: [=xfig_get_autoeps_dir] set the path for the autoeps directory
* color_scheme: [="hot"] setting another colorscheme (lum_scale=0 is automatically set)
* h_scalebar: if given, a horizontal scalebar is plotted above the spixmap
* no_scalebar: if given, no scalebar is plotted

##### Description

This function creates a spectral image plot with xfig from the
structure generated by make_spix. The log of the average brightness
is displayed as color saturation and the spectral index as hue so
that both spectral index and brightness are apparent in the image.
It will ouput a .pdf file of the plot with a color scale bar on the
side.  For the luminosity scaling, the data below the median value
is cut out and the data above the median is fit to a gaussian. The
hi_lum_limit and low_lum_limit are based on the stdev from this fit.

__See also__: make_spix, read_spix, write_spix

----

#### plot_struct_arrays
##### Synopsis
 plots the fields of a structure agains each other

##### Usage
```c
 plot_struct_arrays(Struct_Type s, String_Type fieldnameX, String_Type fieldnameY);
```

##### Qualifiers

* xoffset:
* yoffset:

##### Description

<code>plot(s.fieldnameX - xoffset,  s.fieldnameY - yoffset);</code>

----

#### plot_table_columns
##### Synopsis
 plots columns of a table against each other

##### Usage
```c
 plot_table_columns(Struct_Type table);
```

##### Qualifiers

* x: array of columns to be used for the x-axis [default: all columns]
* y: array of columns to be used for the y-axis [default: all columns]
* path: path to save the postscript plots
* multiplot: produce one single multiplot (does not call open_plot)

----

#### plot_unfold
##### Synopsis
 Plot flux-corrected spectra (isis_fancy_plots package).

##### Description

plot_unfold({indx,[arry],{cid}},pstruct);  % pstruct = struct{ dcol, mcol, rcol, ...}
plot_unfold({indx,[arry],{cid}};dcol={val},mcol={val},rcol={val,[arry],val},...);

Plot background subtracted unfolded data, model, and residuals using a
variety of X- and Y-units set by fancy_plot_unit(xunit, [yunit]);
Residuals are units of chi, chi2, or ratio, and will be based upon whether
one chooses sigma=model, data, or gehrels in set_fit_statistic();
(data error bars are only affected by the latter two).
set_fit_statistic("cash"); will alter the residuals to the Cash statistic.
set_fit_statistic("ml"); will alter the residuals to the Maximum Likelihood statistic.

Options below refer to structure variables/qualifiers

indx    = list of data set indices to be plotted. Any indices grouped in
an array within that list will be \*combined\* in the data plot.
Single number in list is combo id, {#} = [combination_members(#)].
dcol    = (pgplot) color value for data (or list of color values)
decol   = (pgplot) color value for data error bars (or list of color values)
mcol    = (pgplot) color value for model (or list of color values)
0 => No model plotted
rcol    = (pgplot) color value for residuals (or list of color values; arrays
within the list allow for individual color values if portions of
the data are combined, but their associated residuals are not)
recol   = color for residual error bars (or list of color values; arrays
within the list act as for residual color inputs)
dsym    = (pgplot) symbol value for data (or list of symbol values)
0 => histogram plot
rsym    = (pgplot) symbol value for residuals (or list of symbol values;
arrays within the list act as for residual color inputs)
0 => histogram plot
xrange  = List of X-limits for the data & model & residuals
Note: Any X- or Y-range set to NULL is autoscaled
yrange  = List of Y-limits for the data & model and (optionally) residuals
oplt    = 0 (default) for new plot, !=0 for overplotting
no_reset= 0 (default)- plots \*will\* be reset, i.e., next plot moves to new pane
(multiplot), next plot redraws window (single plot). no_reset=1 necessary
for overplotting multiplots (oplt=1 sufficient for single plots).
res     = 0 (default), no residuals; 1, 2, or 3 = chi, chi2, or ratio residuals
4, 5, or 6 = chi, chi2, or ratio, but combine residuals for combined data
set_fit_method("cash"); or set_fit_method("ml") will cause res=(2 or 5)
or res=(1 or 4) to plot the residual for the Cash or Maximum Likelihood
statistic or its square root, respectively
power  = 0, 1 (usual default), 2 (default for mJy) or 3 (default for ergs/Watts
vs. energy units)=> photons/cm^2/s/xunit \*(1/xunit,1,xunit,xunit^2)
bkg     = List of 0's (subtract background-default), 1's (include backgrounds),
or -1's (plot \*only\* the background [no model plotted in this case]).
Ratio residuals will include background in data/model, other residuals
are unaffected. Indices within a combination are treated the same.)
xlabel  = String that will overwrite default X-axis label (default=NULL)
ylabel  = String or string array that will overwrite the default Y-axis labels
(second element of array applies to residuals; default=NULL)
zshift  = List of redshifts to be applied to the data (default zshift={0,0,...})
vzero   = If set, the reference X-unit value to be defined as zero velocity.
The X-axis then becomes a velocity axis (km/s) referenced to this
point (default vzero=NULL; setting vzero/zaxis supersedes zshift)
zaxis   = If not 0, use a redshift axis instead of a velocity axis \*if\* vzero
is defined (default zaxis=0)
scale   = Multiplicatively scale the Y-axis by the values in a list.
Any arrays in the list should hold the individual scalings for
data set arrays in the input index list.  \*\*Note:\*\*  these values
only scale the plots, not the fits.  (Default values are 1.)
gap     =  1 (default), models are histograms with gaps where data has gaps,
0          , model are bin-centered lines, without gaps.
con_mod= 1 (default), the smear the model by the detector response, otherwise
plot the unsmeared model at the internal resolution of the arf

Note: Model flux is: ( \\int dE S(E) )/dE, while data is
(C(h) - B(h))/(\\int R(h,E) A(E) dE)/dh/t, where A(E) is effective area,
R(h,E) is RMF, C(h)/B(h) are total/background counts. Thus, the data
and model will match best only in the limit of a delta function RMF,
and in fact might look different than the residuals (which is the
only proper comparison between data and model, anyhow).

__See also__: set_power_scale, plot_counts, plot_data, plot_residuals, plot_fit_model, plotxy, plot_comps, plot_double

----

#### plot_vlbi_map
##### Synopsis
 creates an image of the VLBI map with transparent background using a .fits file (provided by DIFMAP)

##### Usage
```c
 plot_vlbi_map(String_Type <code>fitsfile</code>, [String_Type <code>fitsfile (polflux)</code>], String_Type <code>filename</code>)
```

```
or

```c
 plot_vlbi_map(Struct_Type <code>img_struct</code>, String_Type <code>filename</code>)
##### Qualifiers

* color_scheme [="ds9b"]:   select a color scheme for the image
* dec_frac [={0.0,1.0}]:    declination range of the image by
selecting a fraction of the file's range
* ra_frac [={0.0,1.0}]:     right ascension range of the image by
selecting a fraction of the file's range
* dec_mas [={min,max}]:     set declination range of the image directly in mas.
overwrites <code>dec_frac</code>
* ra_mas [={min,max}]:      set right ascension range of the image directly in mas
(analog to <code>dec_mas</code>)
* fit_noise [=1]:           fit the noise of a map
* n_sigma [=3.0]:           start color scaling at <code>n_sigma\*sigma</code>
* cont_scl [=2.0]:          set factor to change the separation between

contour levels, the levels are placed at:

<code>cont_scl^[0,1,...]\*n_sigma\*sigma</code>
* cont_lvl [=[c1,c2,..]:    set contour levels [Jy] manually, overwrites

other contour parameters
* cont_width [=2]:          set width of contour lines
* plot_cont [=1]:           set to 0 in order to plot without contour lines
* cont_depth [=2]:          set contour-line depth
* plot_vec [=0]:            set to 1 in order to plot with vectors
(requires second fits file with polarized flux density)
* vec_density [=5]:         density of EVPA vectors; possible values: [1..10]
* vec_width [=1]:           width of EVPA vectors
* vec_color [="black"]:     color of EVPA vectors
* plot_clr_img [=1]:        set to 0 in order to plot without colored image
* plot_clr_key [=1]:        set to 0 in order to plot without key for color scale
* plot_scale_arrows [=1]:   set to 1 in order to plot with arrows denoting the size scalesin the map
* clrcut [=0]:              set to 1 in order to start the color scale at the
significant emission (i.e., no color scaling below)
* clrmin [=min(image)]:     set minimum value [Jy] for color scale (see png_gray_to_rgb)
* clrmax [=max(image)]:     set maximum value [Jy] for color scale (see png_gray_to_rgb)
* clrmu [from fit_gauss_to_img_noise]: set noise level of the image [Jy] for color scale
(mean value of regions without significant emission)
* clrsig [from fit_gauss_to_img_noise]: set width of noise (1-sigma) [Jy] for color scale,
for identical color scale (e.g., in order to compare
different images) the following qualifiers have to be set:
clrmin, clrmax, clrmu, clrsig
* colmap_depth:             set depth of png map
* bkg_white:                set white map below clrmin, if clrcut is set, clrmin equals
n_sigma above the mean background.
* quadratic:                create a quadratic image, by default the scaling is such that
scaling in RA and DEC is equal
* plotsize [=14]:           size of the plot (scaling of image relative to font size)
* src_name [=default]:      set the name of the source, by default the name

is read from the .fits file
set to NULL for not plotting a source name
* obs_date [=default]:      set the observation date, by default the observation

date is read from the .fits file
set to NULL for not plotting a observation date
* axis_color [="gray"]:     set axis color
* source_color [="gray"]:   set color of source name
* date_color [="gray"]:     set color of observation date
* date_depth [=1]:          set depth of observation date
* source_depth [=1]:        set depth of source name
* cont_color [="gray"]:     set color of contour lines
* neg_cont_color [="gray"]: set color of contour lines below noise level
* date_xy [=[0.95,0.95]]:   set world0 coordinates of date string
* plot_beam [=1]:           set to 1 in order to plot the beam
* plot_components:          set to plot model components on top of image
* model_circs:              set to plot model component circles on top of image
* pos_comp_color [="seagreen"]: set for color of model components with positive flux
* neg_comp_color [="seagreen"]: set for color of model components with negative flux
* beam_color [="gray"]:     set color of the beam
* no_labels: :	        plot no labels
* colmap_label: :	        set label of colormap
* neglog [=0]:              use log scale for negative flux values
* frac [=0.1]: :	        fraction to which the linear region below n_sigma\*sigma
is scaled in the color scale (if clrcut != 0)
* funit [="mJy"]:           unit of the color scale bar, can be changed from "mJy" to "Jy"
* xyunit [="mas"]:          unit of the x/y labels, can be changed between "mas", "arcsec", "arcmin" and "deg";
assumption: FITS header sets unit "mas"
* return_xfig:              set qualifier to return the xfig object(s) instead than
rendering directly

##### Description

This function creates an image of a jet using the .fits file provided
by DIFMAP.
Alternatively a structure with the required fields (as obtained
with the function <code>read_difmap_img</code>) can be given directly to
<code>plot_vlbi_map</code> instead of the name of a fits file.
The color scheme can be selected and contour lines are calculated.
The format of the output file depends on the suffix of the given
<code>filename</code>. Possible formats of the output file are PDF, EPS,
PNG, GIF, etc.

If plot_vlbi_map is called with three arguments, the first two of them beiing maps,
the code will determine the noise level of the second map and cut the first
map at the given sigma level. A typical application would be to plot the
distribution of electric vectors or the degree of polarization only where
the polarized flux is significant.

__See also__: read_difmap_fits,fit_gauss_to_img_noise

----

#### plot_vlbi_pol_map
##### Synopsis
 creates a polarimetric image of a VLBI map using according .fits files (provided by DIFMAP)

##### Usage
```c
 (Struct_Type xfig-map, Struct_Type xfig-colormap) = plot_vlbi_pol_map(String_Type <code>fitsfile flux-map-1</code>,
String_Type <code>filename flux-map-2</code>, String_Type <code>filename plot-product</code>)
```

```
or

```c
 (Struct_Type xfig-map, Struct_Type xfig-colormap, Struct_Type xfig-vectormap) =
plot_vlbi_pol_map(String_Type <code>fitsfile flux-map-1</code>, String_Type <code>fitsfile EVPA-map</code>,
String_Type <code>filename flux-map-2</code>, String_Type <code>filename plot-product</code>)
##### Qualifiers

* n_sigma_pol: [=5] start color scaling of polarized flux at <code>n_sigma\*sigma</code>
* n_sigma_vec: [=5] start plotting of EVPA vectors at <code>n_sigma\*sigma</code> in reference to the polarized flux
* colmap_pol: if set, plot most significant polarized flux (depending on n_sigma_pol),
recommended: color map "iceandfire"
* colmap_back: if set, plot polarized flux or total intensity flux, recommended: color map "ds9b"
* pol_cont: set to 1 in order to plot contours of flux-map-1
* pol_cont_col: [="white"] color of contours of flux-map-1
* pol_cont_depth: [=0] depth of contours of flux-map-1
* pol_translate: [=0.4] if plot_pol_colmap=0, the contours of polarized flux will be translated
by <code>pol_translate\*range_in_declination</code>
* render_object: [=1] set to 1 in order to render the plot object

##### Description

This function uses the existing maps flux-map-1 (polarized flux),
(the EVPA_map for the electric vector position angle) and
flux_map_2 (polarized flux or total intensity flux) to plot the polarized flux
as color-coded map (and the EVPA as vectors) - cutted at the most significant contours
depending on n_sigma_pol - on top of the total intensity contours or as contours
vertically translated to them.
One has the flexibility to plot the polarized flux distribution instead of the total
intensity flux color-coded depending on the map given for flux-map-2.
All qualifiers of <code>plot_vlbi_map</code> are forwarded to this function.

__See also__: plot_vlbi_map

----

#### plot_with_err
##### Synopsis
 plots data points with their errorbars

##### Usage
```c
 plot_with_err(x, [xErr,] y, yErr);
```
or

```c
 plot_with_err(Struct_Type s);

```

##### Qualifiers

* xerr: change 3-argument-syntax to <code>plot_with_err(x, xErr, y);</code>
* xminmax: changes the meaning of <code>xErr</code> -- and <code>x</code>, if <code>xErr</code> is not a list
* yminmax: changes the meaning of <code>yErr</code> -- and <code>y</code>, if <code>yErr</code> is not a list
* minmax: equivalent to both <code>x</code>- and <code>yminmax</code>
* i: index-array of subset of data points to be plotted
* set_xrange=frac:  (default: 0.05): set the <code>xrange</code> from the lowest to highest x-value
with additional padding (given as a fraction fo the x-range) on both sides
* set_yrange=frac:  (default: 0.05): set the <code>xrange</code> from the lowest to highest y-value
with additional padding (given as a fraction of the y-range) on both sides
* set_ranges: equivalent to both <code>set_xrange</code> and <code>set_yrange</code>
* overplot: The data will be overplotted.
* connect_points: data points are also connected
* histogram: draw histogram lines, too
* error_color: draw error bars in a different color

##### Description

In order to use asymetric errors for x and/or y,
the correspondig <code>Err</code> argument has to be a list <code>{ Err1, Err2 }</code>.
If one of the <code>minmax</code> qualifiers is used,
the corresponding <code>Err</code> list contains directly minimum and maximum values.

If one of the <code>minmax</code> qualifiers is used, but <code>Err</code> is not a list,
the value and <code>Err</code> arguments actually mean minimum and maximum values.
The actual value is infered to be the mean of minimum and maximum.
##### Examples

% examples with symmetrical errorbars:

plot_with_err(x,       y, yErr);

plot_with_err(x, xErr, y, yErr);

plot_with_err(x, xErr, y,     ; xerr);

% examples with unspecified x and/or y value:

plot_with_err(xMin, xMax, y   , yErr; xminmax);  % => x = (xMin+xMax)/2

plot_with_err(x[, xErr],  yMin, yMax; yminmax);  % => y = (yMin+yMax)/2

plot_with_err(xMin, xMax, yMin, yMax;  minmax);  % => [both inferences]

s = struct { bin_lo=x-xErr, bin_hi=x+xErr, value=y, err=yErr };

plot_with_err(s);

% examples with asymmetrical errorbars:
plot_with_err(x, {xErr1, xErr2}, y,  {yErr1, yErr2});

plot_with_err(x, {xMin,  xMax }, y,  {yMin,  yMax}; minmax);

% example combining the above features:

plot_with_err(xMin, xMax, y, {yMin, yMax}; minmax);  % => x = (xMin+xMax)/2

__See also__: [o][h]plot_with_err, [o][h]plot

----

#### plot_with_y2axis
##### Synopsis
 plot two functions with different y-axes

##### Usage
```c
 plot_with_y2axis(x1, y1, [ x2,] y2);
```

##### Qualifiers

* color: set the color of the 2nd y-axis [default: red]
* yspace: space above and below the last data point in units of the total y-range.

##### Description

This function plots two different parameters y1 and y2, which depend
on the same paramter x. By default, the same x is taken for
both parameters.

The y2-axis and the ranges are set automatically.

Additionally the function returns the rescaled y2 values, which
now lie in the range of the y1 values.

----

#### plot_xyfit
##### Synopsis
 plot xy-data and its current xy-model

<!--%{{{ -->
##### Usage
```c
 plot_xyfit(Integer_Type data_id);
```

##### Description

A simple plot function of the xy-data (given by <code>define_xydata</code>)
and -model (last evaluation of the xy-fit-function, see <code>xyfit_fun</code>).

This functions basically calls:

<code>plot_with_err( get_xydata(data_id) );</code>

<code>oplot( get_xymodel(data_id) );</code>

__See also__: get_xydata, get_xymodel, define_xydata, xyfit_fun, plot_with_err

----

#### plummer_interaction_kernel
##### Synopsis
 Evaluate equations of motion or potential energy from a number of Plummer spheres

##### Usage
```c
 Double_Type eom[3,n] = plummer_interaction_kernel(Double_Types t, m[6,n], Struct_Type ps; qualifiers)
```

```
or

```c
 Double_Type energy[n] = plummer_interaction_kernel(Double_Types t, m[6,n], Struct_Type ps; qualifiers)
##### Qualifiers

* coords: [<code>="cyl"</code>] Use cylindrical ("cyl") or cartesian ("cart") coordinates.
* eomecd: [<code>="eom"</code>] Return equations of motion ("eom") or potential energy ("energy").

##### Description

This function computes the equations of motion or potential energy of n test particles
at time 't' caused by the interaction with a number of moving Plummer spheres. Depending
on whether cylindrical coordinates (r,phi,z) and their canonical momenta (vr,Lz,vz) or
cartesian coordinates (x,y,z,vx,vy,vz; see qualifier 'coords') are used, the second
input parameter 'm' is a [6,n]-matrix with
(qualifier("coords")=="cyl")                       or (qualifier("coords")=="cart")
m[0,\*] = r;                                        m[0,\*] = x;
m[1,\*] = phi;                                      m[1,\*] = y;
m[2,\*] = z;                                        m[2,\*] = z;
m[3,\*] = vr;                                       m[3,\*] = vx;
m[4,\*] = Lz;                                       m[4,\*] = vy;
m[5,\*] = vz;                                       m[5,\*] = vz;
If the qualifier 'eomecd' is set to "eom", the function returns a [3,n]-matrix 'delta' with
delta[0,\*] = -d/dr Phi(r,phi,z);                   delta[0,\*] = -d/dx Phi(x,y,z);
delta[1,\*] = -d/dphi Phi(r,phi,z);                 delta[1,\*] = -d/dy Phi(x,y,z);
delta[2,\*] = -d/dz Phi(r,phi,z);                   delta[2,\*] = -d/dz Phi(x,y,z);
whereby Phi is the sum over all Plummer potentials.
If the qualifier 'eomecd' is set to "energy", the function returns an array of length n
storing the potential energy for each orbit:
E(r,phi,z) = Double_Type[n] = Phi(r,phi,z)
or
E(x,y,z) = Double_Type[n] = Phi(x,y,z)

For each Plummer sphere, the third input parameter 'ps', which is a structure, contains
a field which is again a structure with fields 't', 'x', 'y', and 'z' (all are arrays of
the same length) that list the time-dependent positions of the sphere. Additionally, the
shape of the respective sphere (see notes below) is given by the two fields 'psa' and
'psb' (both scalars).
##### Notes

The potential of a Plummer sphere at distance r is
Phi(r) = -psa\*(psb+r^2)^(-1/2)
The resulting acceleration in radial direction is
d^2/dt^2 r = -d/dr Phi = -psa\*(psb+r^2)^(-3/2)\*r

Cubic spline interpolation is used to determine the positions of the Plummer spheres
at time 't' if the GSL-module is available. Otherwise, linear interpolation is applied.
Extrapolation is not allowed. Always make sure that the tabulated times '.t[\*]' are in
monotonic increasing order if '.t[-1]' is positive or in monotonic decreasing order if
'.t[-1]' is negative.
##### Example

ps = struct{ o0, o1 };
ps.o0 = struct{ t=[0,1,2], x=[-1,0,1], y=[0,1,2], z=[0,1,2], psa=1, psb=4 };
ps.o1 = struct{ t=[0,1,2], x=[1,0,-1], y=[0,1,2], z=[0,1,2], psa=1, psb=4 };
m = Double_Type[6,1];
m[0,0] = 0; m[1,0] = 2; m[2,0] = 0; m[3,0] = 0; m[4,0] = 0; m[5,0] = 0;
r = plummer_interaction_kernel(0,m,ps; coords="cart");
r = plummer_interaction_kernel(0,m,ps; eomecd="energy");

__See also__: N_body_simulation_std_kernel, plummer_MW

----

#### plummer_MW
##### Synopsis
 Alternative model potential for the function 'orbit_calculator'

##### Usage
```c
 plummer_MW(Double_Types t, m[6,n]; qualifiers)
```

##### Qualifiers

* plummer_spheres: Structure whose fields are again structures with fields 't' [Myr],
'x' [kpc], 'y' [kpc], 'z' [kpc], 'psa' [Msun/Mgal\*constant] (see notes), and 'psb'
[kpc^2] describing the orbits and shapes of the Plummer spheres.
Always make sure that the tabulated times 't[\*]' are in monotonic increasing order
if 't[-1]' is positive or in monotonic decreasing order if 't[-1]' is negative.
* MW_potential: [<code>="AS"</code>]: Function ("AS", "MN_NFW", or "MN_TF"), which evaluates the
equations of motion that result from a model for the gravitational potential of
the Milky Way.
* All qualifiers from the Milky Way model potential (see qualifier 'MW_potential').:
* All qualifiers from the function 'plummer_interaction_kernel'.:

##### Description

This function provides an alternative model for the gravitational potential of the
Milky Way which can be used by the function 'orbit_calculator'. The gravitational
forces of a standard Milky Way potential (see qualifier 'model') are combined with
those arising from the interaction with a number of moving Plummer spheres (see
function 'plummer_interaction_kernel' and qualifier 'plummer_spheres') to determine
the acceleration of n independent test particles at time 't'.
##### Notes

Because of the unit convention used for the potentials of the Milky Way, the field
'psa' of the qualifier 'plummer_spheres', which is assumed to be the mass of the
respective Plummer sphere in solar masses, has to be converted to Galactic mass units
and then multiplied with a constant accounting for the remaining unit conversions
(see example below). The units of 'psb' have to be kpc^2.
##### Example

% Test particle affected by the Milky Way and satellite galaxies:
t_end = -100; % integration time in Myr
model = "AS"; % Milky Way mass model
s = properties_satellite_galaxies();
i = struct{ x, y, z, vx, vy, vz, psa, psb };
SunGCDist = (@(__get_reference(model)))(; eomecd="sgcd"); % Sun-GC distance of chosen mass model
temp = [SunGCDist,0,0,0,0,0]; reshape(temp, [6,1]);
vlsr = (@(__get_reference(model)))(0, temp; eomecd="circ")[0]; % Local standard of rest velocity of chosen mass model
(i.x, i.y, i.z, i.vx, i.vy, i.vz) = cel2gal(s.ah, s.am, s.as, s.dd, s.dm, s.ds, s.dist, s.vrad, s.pma_cos_d, s.pmd; SunGCDist=SunGCDist, vlsr=vlsr);
kpcmyr_to_kms = 977.7736364875057; % = conversion factor from kpc/myr to km/s = 3.0856775975\*10^16 / (10^6 \* 3.15582 \* 10^7);
i.vx /= kpcmyr_to_kms;
i.vy /= kpcmyr_to_kms;
i.vz /= kpcmyr_to_kms;
i.psa = s.Pl_mass/2.325131802556774e+07; % conversion from solar masses to Galactic mass units Mgal to have G=1
% Mgal = 2.325131802556774e+07 = 1e8\*3.0856775975\*1e19/6.6742/1e-11/1.9884/1e30, see Irrgang et al., 2013, A&A, 549, A137
const = 100./kpcmyr_to_kms^2; % factor 100 because potential is given in 100 km^2/s^2, see Irrgang et al. 2013
i.psa \*= const;
i.psb = (s.Pl_radius)^2;
ps = N_body_simulation(i, t_end; kernel="N_body_simulation_MW_kernel", psa=i.psa, psb=i.psb, model=model);
% ps contains time-dependent coordinates of Plummer spheres
% add information about shape of the Plummer spheres:
j = 0;
foreach field (get_struct_field_names(ps))
{
temp = struct{ psa=i.psa[j], psb=i.psb[j] };
set_struct_field(ps, field, struct_combine(get_struct_field(ps, field), temp));
j++;
};
% compute trajectories of test particles:
s = orbit_calculator(4,38,12.8,-54,33,12,61,723,0.86,0.57,t_end; set, model="plummer_MW", MW_potential=model, plummer_spheres=ps);
plot(s.tr.o0.x,s.tr.o0.y);
% without satellite galaxies:
s = orbit_calculator(4,38,12.8,-54,33,12,61,723,0.86,0.57,t_end; set, model=model);
oplot(s.tr.o0.x,s.tr.o0.y);

__See also__: orbit_calculator, plummer_interaction_kernel, AS, MN_NFW, MN_TF

----

#### png_read_curve
##### Synopsis
 reads a curve from a x-y plot in an image

##### Usage
```c
 (X, Y) = png_read_curve(filename, xpix1, xval1, xpix2, xval2, ypix1, yval1, ypix2, yval2);
```

##### Description

<code>filename</code> is a png file containing a color-defined curve.
Its <code>x</code> and <code>y</code> coordinates are calibrated by <code>pix</code>/<code>val</code> pairs
of pixel coordinate and corresponding value assuming a linear scale.
The pixel coordinates start with (0, 0) in the upper left corner.
The return values are calibrated x-values and y-values
averaged over all pixels of the curve in the corresponding column.
##### Qualifiers

* color: [<code>=0x000000</code> (black)]: considered color of the curve
* wherenot: consider any color except the one specified above

----

#### point_distance2_from_line
##### Synopsis
 Calculate the squared distance of a point from a line

##### Usage
```c
 d2=point_distance2_from_line(xp,yp,x1,y1,x2,y2)
```

##### Description

Calculate the  distance of point (xp,yp) from the line
defined by the points P1=(x1,y1) and P2=(x2,y2), where
P1!=P2. This condition is not tested for speed
reasons and will result in a division by zero.

----

#### point_in_polygon
##### Usage
```c
 ret=point_in_polygon(p0,V);
```

```
or

```c
 ret=point_in_polygon(x,y,Vx,Vy);
##### Synopsis
 determine whether a point is in a polygon

##### Qualifiers

* evenodd: use the crossing number method
* crossing: use the crossing number method
* winding: use the winding number method (the default)

##### Description

The function returns 1 if the point p0 is located inside the
polygon defined by the vertices V, and 0 if it is located
outside of the polygon.

The polygon has to be closed, i.e. V.x[n]==V.x[0] and
V.y[n]==V.y[0] where n is the number of polygon points.

Either the winding number (default) or the even-odd-rule
define what is meant by inside.

The point is either defined by a struct{x,y} and the vertices
by a struct{x[],y[]}, or the coordinates can be directly
given in the respective arrays.

See the URL below for more explanations.

Based on code by Dan Sunday,
http://geomalgorithms.com/a03-_inclusion.html

__See also__: crossing_number_polygon,point_in_polygon,simplify_polygon

----

#### point_is_left_of_line
##### Usage
```c
 ret=point_is_left_of_line(p0,p1,p2);
```

```
or

```c
 ret=point_is_left_of_line(p0x,p0y,p1x,p1y,p2x,p2y);
##### Synopsis
 determines whether point p2 is left of a line through p0 and p1

##### Description

This function tests if point p2 is to the left of an infinite line defined
by points p0 and p1. The points are defined by structs p=struct{x,y},
where x is the x-coordinate and y is the y-coordinate.

The function returns
+1 if P2 is left of the line
0 if P2 is on the line
-1 -1 if P2 is right of the line

Based on code by Dan Sunday, http://geomalgorithms.com/a03-_inclusion.html

__See also__: crossing_number_polygon,winding_number_polygon,point_in_polygon,simplify_polygon

----

#### polint
##### Synopsis
 Polynomial Interpolation and Extrapolation with error estimation

##### Usage
```c
  (Double_Type y, dy ) = polint (Double_Type[] xa, ya, Double_Type x);
```

##### Description

Returns an interpolated value <code>y</code> at the given point <code>x</code> and an
error estimate <code>dy</code> for the given arrays <code>xa</code> and <code>ya</code>.
If P(x) is the polynomial of degree n-1 such that P(xa_i) = ya_i, i=0,n-1,
then the retruned value y=P(x).
Adapted from algorithm in Numerical Recipes,
by Press et al. (1992, 2nd edition), Section 3.1.

__See also__: qromb

----

#### polytropic_standard_model
##### Synopsis
 Compute the structure of a polytropic standard model

##### Usage
```c
 Struct_Type s = polytropic_standard_model(Double_Type M, R, X, Y)
```

##### Description

Based on the stellar mass 'M' (in solar masses), stellar
radius 'R' (in solar radii), hydrogen mass fraction 'X',
and helium mass fraction 'Y', this function computes the
structure of a polytropic standard model. The output
structure 's' contains the fields "r" (radial coordinate
in solar radii), "rho" (density in g per cm^3), "P"
(pressure in dynes per cm^2), and "T" (temperature in K),
i.e., the structure of the polytrope.
##### Notes

Polytropes are gaseous spheres in hydrostatic equilibrium
which obey a polytropic equation of state
P = K rho^((n+1)/n)
where 'P' is the pressure, 'rho' the density, 'K' the
polytropic constant, and 'n' the polytropic index. The
so-called polytropic standard model is a polytropic model
of index n=3. Its structure has a surprisingly good
resemblence to those of main sequence stars and is, thus,
used as a starting point to study the internal structure
of stars. For details, see, e.g., Chapter 2.4 in the book
"Principles of Stellar Evolution and Nucleosynthesis" by
D.D. Clayton.
##### Example

s = polytropic_standard_model(1, 1, 0.73, 0.26);

__See also__: solve_Lane_Emden_equation, solve_Eddington_quartic_equation

----

#### position_angle
##### Usage
```c
  sep=position_angle(ra1,dec1,ra2,dec2);
```

##### Synopsis
 calculates the position angle of object1 with respect to object2

##### Qualifiers

* deg: if set, the input coordinates and output are in degrees (default: radian)
* radian: if set, the input coordinates and output are in radian (the default))

##### Description

This routine calculates the position angle on the sky of the point
with coordinates ra1/dec1 with respect to the object with coordinates
ra2/dec2.

Following the IAU conventions, the position angle is 0 if object1 is
directly north of 2 and it is counted in the N-E-S-W-N direction, i.e.,
it is pi/2 / 90deg if object 1 is East of object 2.

Note that per IAU convention, "position angle" always refers to the
relative position with respect to the equatorial system. This
routine is agnostic to the type of coordinate system, i.e., the
position angle can be computed in all coordinate systems, but the
term "position angle" should be avoided for other coordinate systems.

The position angle is not defined if object 2 is at one of the poles,
it is 0 if object1 and object2 are at the same position.

The position angle is returned in the units of the input coordinate system.

This function is array safe for either ra1/dec1 or for ra2/dec2.

__See also__: hms2deg,dms2deg,angle2string,greatcircle_distance

----

#### pos_modulo
##### Synopsis
 computes the modulo and ensures that it is positive

##### Usage
```c
 m = pos_modulo(a, b);
```

##### Description

<code>a</code> and <code>b</code> can either be arrays or scalars of a numerical type.

<code>m =  a mod b;  %</code> if m is positive, otherwise:

<code>m = (a mod b) + b;</code>

----

#### powerlaw_noise
##### Synopsis
 simulates a light curve with a power law distributed power spectrum

##### Usage
```c
 Double_Type rate[] = powerlaw_noise(Integer_Type n);
```

##### Qualifiers

* beta: [= 1.5]: power law index of the power spectrum
* mean: [= 0]: mean rate of the simulated light curve
* sigma: [= 1]: standard deviation of the simulated light curve

##### Description

<code>n</code> is the number of bins of the simulated lightcurve.
It should be a power of two best performance of the fast Fourier transform.

__See also__: Timmer & Koenig (1995): "On generating power law noise", A&A 300, 707-710

----

#### powerlaw_xyfit
##### Synopsis
 linear xy fit function to be used with xyfit_fun

##### Usage
```c
 xyfit_fun ("powerlaw");
```

##### Description

This function is not meant to be called directly!

Calling <code>xyfit_fun ("powerlaw");</code> sets up a powerlaw fit
function for xy-data. It has the form <code>y = norm\*x^{-index}</code>

__See also__: xyfit_fun, define_xydata, plot_xyfit, linear_regression

----

#### precess
##### Synopsis
 precess equatorial coordinates between two equinoxes

##### Usage
```c
 (alpha,delta)=precess(alpha,delta;qualifiers)
```

```
or

```c
 AstroVector3_Type ecl=precess(eqp;qualifiers)
##### Qualifiers

* fromequinox: starting equinox of the transformation.
Float: JD, string: epoch designation (e.g.,
"J2000.0" or "B1950.0";
default: J2000.0)
* toequinox: end equinox of the transformation (same interpretation)
as fromequinox; required!
* deg: interpret angular arguments in degrees (default is radians!)
applies also to the return value.
* mjd: interpret equinoxes as a MJD (default: JD)

##### Description

Precess a coordinate from one equinox to another using
the IAU 2000A model.

The default equinox is J2000.0, formally the equinoxes are in TDB.

__See also__: Vector_Type,JDofEpoch,dms2deg,hms2deg,precession_matrix,gcrs2j2000_matrix

----

#### precession_matrix
##### Synopsis
 return the precession matrix for the transform from J2000.0 to a given JD

##### Usage
```c
 Matrix33_Type mat=precession_matrix(JD)
```

##### Description

This function calculates the precession matrix for the calculation
of the precession FROM J2000.0 TO JD using the IAU 2000.0A theory
(Capitaine et al., 2003, A&A 412, 567, Sect. 7)

To get the matrix for the conversion from JD to J2000.0, transpose the
matrix returned by this function.

In most cases users will want to use the precess-function to
precess astronomical coordinates.

Note: This is mainly an internal function, it therefore does NOT
have the usual qualifiers such as mjd or any safety checks, however,
for some applications it will be useful to have direct access to the
precession matrix.

__See also__: precess,precession_matrix

----

#### precession_matrix2
##### Synopsis
 return the precession matrix for the transform between two equinoxes

##### Usage
```c
 Matrix33_Type mat=precession_matrix2(fromJD,toJD)
```

##### Description

This function calculates the precession matrix for the calculation
of the precession from fromJD TO toJD using the IAU 2000.0A theory
(Capitaine et al., 2003, A&A 412, 567, Sect. 7)

In most cases users will want to use the precess-function to
precess astronomical coordinates.

Note: This is mainly an internal function, it therefore does NOT
have the usual qualifiers such as mjd or any safety checks, however,
for some applications it will be useful to have direct access to the
precession matrix.

__See also__: precess,precession_matrix

----

#### primefactors
##### Synopsis
 factorizes an integer number into primes

##### Usage
```c
 Integer_Type factors[] = primefactors(Integer_Type x);
```

##### Description

The array of prime factors will be ordered:
<code>factor[i] <= factor[j]  %</code> for <code>i<j</code>.

----

#### principal_components
##### Synopsis
 performs a principal components analysis

##### Usage
```c
 Struct_Type PCA = principal_components(Struct_Type s);
```

##### Description

The normalized components (which are stored in <code>PCA.components.c</code>#i)
are calculated from the fields of the structure <code>s</code>
such that they have a mean of 0 and a variance of 1.
From them, the covariance matrix <code>PCA.cov_matrix</code> is calculated,
which is diagonalized (see <code>PCA.eigenvalues</code> and <code>PCA.eigenvectors</code>).
The principal components are stored in <code>PCA.components.pc</code>#i
in ascending order of their contribution to the total variance.
##### Qualifiers

* table: [="tab"]: name of the structure <code>s</code>

__See also__: cov_matrix

----

#### printhplot
##### Synopsis
 print a plot of a histogram into the terminal

##### Usage
```c
 printplot(Double_Type[] lo, hi, values[, Struct_Type printplot]);
```

##### Qualifiers

* sym: the char used for the bar (default: 'o')
* get: return the structure instead of printing

##### Description

Prints a very simple ASCII-version of plotting the
given histogram into the terminal. The x- and y-ranges
are defined automatically by the input, but can be
specified via the optional printplot-structure (see
'new_printplot'). The only drawn ticmarks represent
these ranges.

All qualifiers are also passed to new_printplot
##### Example

% plot gaussian distributed random numbers
(lo,hi) = linear_grid(-3, 3, 40);
printhplot(lo, hi, histogram(grand(10000), lo, hi); W=40);

__See also__: new_printplot, printplot

----

#### printplot
##### Synopsis
 print a plot of xy-values into the terminal

##### Usage
```c
 printplot(Double_Type[] x, y[, Struct_Type printplot]);
```

##### Qualifiers

* sym: the char used for a data point (default: 'x')
* get: return the structure instead of printing

##### Description

Prints a very simpel ASCII-version of plotting the
given xy-values into the terminal. The x- and y-ranges
are defined automatically by the input, but can be
specified via the optional printplot-structure (see
'new_printplot'). The only drawn ticmarks represent
these ranges.

All qualifiers are also passed to new_printplot.
##### Example

% plot a sin
x = [0:2\*PI:#100];
printplot(x, sin(x));

% overplot a cosin
printplot(x, .5\*cos(x), printplot(x, sin(x); get); sym = '\*');

__See also__: new_printplot, printhplot

----

#### printplot_out
##### Synopsis
 print a char-matrix into the terminal

##### Usage
```c
 printplot_out(Char_Type[] matrix);
```

__See also__: new_printplot

----

#### print_array
##### Synopsis
 Prints the entries of an array in one line.

##### Usage
```c
 print_array(Array_Type);
```

##### Description

Prints the entries of an array in one line instead of different lines.
Helpful for displaying dependent values of different arrays like a table.
##### Example

UVOT-filter names and their wavelengths.

isis> filters=["UVW2","UVM2","UVW1","U","B","V"];
isis> wave=[2078.546871,2257.186625,2659.009185,3475.482080,4359.034280,5429.548507];
isis> print_array(filters); print_array(wave);
UVW2    UVM2    UVW1    U       B       V
2078.546871     2257.186625     2659.009185     3475.482080     4359.034280     5429.548507

----

#### print_statistics
##### Synopsis
 shows statistical information on an array of numbers

##### Usage
```c
 print_statistics(Double_Type a[]);
```
or

```c
 print_statistics(Struct_Type s);

```

##### Description

If the argument of <code>print_statistics</code> is an array <code>a</code>,
its minimum, average, standard deviation and maximum
are shown. If <code>a</code> contains irregular numbers (<code>nan</code> or <code>+/-inf</code>),
the same quantities are also shown for the regular numbers only.

If <code>print_statistics</code> is called with a structure argument,
the above mentioned task is performed on all array fields.

__See also__: moment

----

#### print_struct
##### Synopsis
 prints the fields of a structure as columns of a table

##### Usage
```c
 print_struct([File_Type F,] Struct_Type s);
```

##### Description

If <code>s</code> is a structure of arrays or lists,
these are displayed as columns of a table.
The output is written to <code>stdout</code> unless another <code>F</code>
is specified, which may either be a file pointer
or a string containing the filename.
##### Qualifiers

* i: array of rows which are to be shown at all
* mark: array of rows which are to be marked
* fields: array of fieldnames (columns) which are to be shown
* fmt: format string(s) for the columns, see <code>help("sprintf");</code>
* sep: string separator between the columns (default = <code>"   "</code>)
* initial: initial separator on a line (default = <code>""</code>)
* final: final separator on a line (default = <code>""</code>)
* html: set <code>sep</code>, <code>initial</code> and <code>final</code> such that an HTML table is produced
* tex: set <code>sep</code>, <code>initial</code> and <code>final</code> such that a TeX table is produced
* nohead: don't show head line with field names

##### Examples

<code>print_struct(   s);                       %</code> The fields of <code>s</code> are printed.

<code>print_struct(F, s);                       %</code> The fields of <code>s</code> are printed to the file <code>F</code>.

<code>print_struct( , s; fmt="%.2f");           %</code> The fields are floats which are printed with 2 decimals.

<code>print_struct( , s; fmt="%.2f", sep=" ");  %</code> As before, but with smaller separation between the columns.

__See also__: writecol, sprintf

----

#### probmap
##### Synopsis
 histogram-like function for 2d-data including uncertainties

##### Usage
```c
 Struct_Type probmap([Double_Type x0, x1, y0, y1]);
```

##### Qualifiers

* xbins: number of bins in x-direction (preferred over 'bins')
* ybins: number of bins in y-direction (preferred over 'bins')
* bins: number of bins in both directions (default: 201)

##### Description

Using this object, a histogram of multiple xy-datasets
including uncertainties for both, x- and y-direction,
can be created. The uncertainties are handled as 2d-
gaussians with sigma_x and sigma_y equal to the given
errors.

Calling this function creates a structure with the
following functions among other fields:
add      - adds xy-data to the map and returns the dataset
number of the added data
Usage: probmap.add(Double_Type[] x, y[, dy]);
or probmap.add(Double_Type[] x, y[, dx, dy]);
delete   - deletes data identified by its dataset number
Usage: probmap.delete(Integer_Type number);
xrange   - sets the x-range
Usage: probmap.xrange(Double_Type xMin, xMax);
yrange   - sets the y-range
Usage: probmap.yrange(Double_Type yMin, yMax);
npoints  - count the number of xy-data added in each point
of the map. If set the density map is available
at .data.npoints, and it is passed as qualifier
'npoints' to the norm_fun (see next qualifier).
norm_fun - reference to a function used for normalization.
The parameters are an array of all datasets,
given as a structure (x,y,dx,dy), and the
histogram map resulting by adding all data.
The function has to return either a single
normalization factor or a map of factors.
Default factor: 1./max(histogram)
getmap   - calculates the histogram map from the added data
and returns it as 2d-array
Usage: probmap.getmap();
getpoint - returns the value of the histogram map at a
specific point
Usage: probmap.getpoint(x,y);
calcpath - calculates the path with the highest averaged
probability between to points using the
A\*-algorithm returning a structure with the
best path (x,y)
##### Example

% creata a new map and set x- and y-range
variable pm = probmap(0.1, 100, 0, 20);
% add two xy-datasets including uncertainties
pm.add(x1, y1, dx1, dy1);
pm.add(x2, y2, dx2, dy2);
% plot the resulting histogram
plot_image(pm.getmap());

__See also__: histogram2d, histogram_gaussian_probability, aStar

----

#### properties_satellite_galaxies
##### Synopsis
 Retrieve the properties of several satellite galaxies of the Milky Way

##### Usage
```c
 Struct_Type s = properties_satellite_galaxies()
```

##### Description

Retrieve the properties (current kinematics, spatial extent, mass) of several satellite
galaxies of the Milky Way.

The output structure contains for each object the celestial coordinates in right ascension
[h, m, s] and declination [deg, arcmin, arcsec], distance [kpc], radial velocity [km/s],
proper motion in right ascension times cosine of declination [mas/yr], proper motion in
declination [mas/yr]), half-light radius [kpc], dynamcial mass inside half-light radius
[solar masses], Plummer softening radius [kpc], and the Plummer mass [solar masses].
##### Notes

Positions, distances, radial velocities, half-light radii, and dynamcial masses are from
McConnachie 2012 when available. Proper motions (PMs) are available only for a subset of
satellites and are set to zero otherwise.

The parameters of the Plummer potentials (softening radius, mass) are determined under
the assumption that the dynamcial mass inside the half-light radius is 0.85 times the
total mass, which gives a softening radius of about one third of the half-light radius.

Main reference: McConnachie 2012, AJ, 144, 4.
Additional references or comments:
- LMC, SMC:         PMs and Plummer parameters from Kallivayalil et al. 2013, ApJ, 764, 161.
Half-light radius and mass derived from Plummer parameters.
- Canis Major:      PMs from Dinescu et al. 2005, AJ, 631, L49.
Dynamical mass assumed to be ten times stellar mass, half-light radius set to 1 kpc.
- Sagittarius dSph: PMs from Pryor et al. 2010, AJ, 139, 839.
- Fornax:           PMs from Piatek et al. 2007, AJ, 133, 818.
- Sextans:          PMs from Walker et al. 2008, ApJ, 688, L75.
- Sculptor:         PMs from Piatek et al. 2006, AJ, 131, 1445.
- Draco:            PMs from Pryor et al. 2014, AJ, submitted [arXiv:1407.3509].
- Ursa Minor:       PMs from Piatek et al. 2005, AJ, 130, 95.
- Carina:           PMs from Piatek et al. 2003, AJ, 126, 2346.
- Leo I:            PMs from Sohn et al. 2013, ApJ, 768, 139.
- Leo II:           PMs from Lepine et al. 2011, ApJ, 741, 100.
- Bootes III:       Dynamical mass assumed to be ten times stellar mass, half-light radius set to 10 pc.
##### Example

s = properties_satellite_galaxies();
print_struct(s);

__See also__: N_body_simulation_MW_kernel

----

#### psdcorr_zhang
##### Synopsis
 Timing Tools: Poisson Noise and Deadtime Correction (Zhang)

##### Usage
```c
 (freq, psd) = psdcorr_zhang(totrate, tseg, dimseg);
```

##### Qualifiers

* nonparalyzable: Set this qualifier if the deadtime is non-paralyzable

##### Description

The deadtime is assumed to be paralyzable by default.

Inputs:
totrate - total countrate of all instruments
tseg    - realtime length of the lc segments used for psd calculation
dimseg  - bincount of the lc segments used for psd calculation

Outputs:
freq    - fourier frequency array
noipsd  - array of observational noise of the psd

__See also__: Zhang et al. (1995), ApJ, 449, 930

----

#### psd_lc
##### Synopsis
 simulate a random light curve that follows a given PSD using the algorithm of Timmer and Koenig

##### Usage
```c
 Double_Type rate[] = psd_lc(Integer_Type n, Double_Type dt, Ref_Type PSD);
```
or

```c
 (rate1, rate2) = psd_lc(Integer_Type n, Double_Type dt, Ref_Type PSD; time_lag_spectrum=...);

```

##### Qualifiers

* mean: [= 100]: mean count rate of the simulated lightcurve
* sigma: [= 20]: standard deviation of the simulated lightcurve
* poisson: if Poisson noise should be applied on the lightcrurve
* nr_PCUs: [= 1]: number of PCUs
* time_lag_spectrum: spectrum of time lags (two lightcurves will be returned)
* mean_2: [= 100]: mean count rate of the second lightcurve
* sigma_2: [= 20]: standard deviation of the second lightcurve

##### Description

<code>n</code> is the number of bins of the simulated lightcurve.
It should be a power of two for best performance of the FFT.
<code>dt</code> is the time resolution.
<code>PSD</code> is a reference to a function which takes one argument
-- the frequency -- and calculates the corresponding PSD value.
The number of PCUs is needed for the calculation of Poisson noise
if a mean RXTE count rate is given in counts/PCU.

If <code>time_lag_spectrum</code> is reference to a function of one argument
-- the frequency -- that calculates the time lag spectrum,
an additional second lightcurve is returned that has
the corresponding time lag with respect to the first one.

see Timmer & Koenig (1995): "On generating power law noise",
A&A 300, 707-710

----

#### pulsar
##### Synopsis
 fit-function modelling a neutron star pulse period evolution

##### Usage
```c
 fit_fun("pulsar");
```

##### Description

Deprecated, use
fit_fun("pulsartorque");
from now on.

----

#### pulsarorbit
##### Synopsis
 fit-function modelling a neutron star pulse period evolution

##### Usage
```c
 fit_fun("pulsarorbit");
```

##### Description

DEPRECATED, use
fit_fun("dopplerorbit\*pulsartorque");
from now on.

----

#### pulsarorbit_fluxerror_mc
##### Synopsis
 estimates additional uncertainties caused by the flux measurements

##### Usage
```c
 Double_Type[] pulsarorbit_fluxerror_mc(Integer_Type dataset);
```

##### Qualifiers

* runs: number of MC loops (default: 100)
* save: save the uncertainty estimation to the
assigned FITS-filename
* collect: file-pattern used by 'glob' to read and
merge all FITS-files from previous runs
* modify: add the estimated uncertainties to the
dataset(s) assigned to this qualifier
(see below for a detailed description)
* chatty: be chatty if > 0 (default: 0)

##### Description

The flux measurements used to calculate the evolution
of the spin-period in the fit-function 'pulsarorbit'
usually have uncertainties. These uncertainties are
not taken into account during an ordinary fit. This
function performs Monte Carlo simulations to estimate
the uncertainties of the modelled period induced by
the flux uncertainties.

During each run the flux evolution associated to the
dataset 'id' is varied using
flux = flux + grand \* flux_err
such that synthetic flux evolutions are created. Then
a fit is performed using only the given dataset 'id'.
This results in many modelled period evolutions. Their
standard deviation at each time is finally considered
as an additional uncertainty in the period space.
These uncertainties are returned by the function.

If the 'modify'-qualifier is set, the dataset(s)
assigned to that qualifier or, in case of NULL, the
dataset 'id' is modified as follows:
new_error = sqrt(sqr(data_error) + sqr(mc_error))
where data_error is the current 'error'-field of the
dataset and mc_error is the estimated additional
uncertainty as calculated by this function. In case
of multiple given datasets, the time range of 'id'
should include all of these datasets to get a proper
period evolution.

__See also__: pulsarorbit

----

#### pulsartaylor
##### Synopsis
 fit-function modelling the pulse period evolution with a Taylor series

##### Usage
```c
 fit_fun("pulsartaylor");
```

altusage{fit_fun("dopplerorbit\*pulsartaylor");}
##### Description

This fit-function computes the pulse period evolution of, e.g.,
a neutron star based on a Taylor series. That is
p(t) = p0 + Pdot\*(t-t0) + .5\*Pddot\*(t-t0)^2 + ...
Here, p0 is the pulse period at the reference time t0 and
Pdot, Pddot,... are the higher order derivatives.

The parameters of the fit-function are:
p0    - spin-period at t0 (s)
t0    - reference time t0 (MJD), has to be fixed
pdot  - period derivative (s/s)
p2dot - 2nd period derivative (s/s^2)
etc.

By default the Taylor series is computed up to the second
order. If your data requires higher orders, you can change this
limit using 'pulsartaylor_set_order'.

NOTE: in case you add the Doppler shift of orbital motion to the
model using the 'dopplerorbit' fit-function, make sure that
this fit-function is calculated \*first\* in order to
transform the times ('lo' parameter of the fit-function)
into the barycenter of the binary! These corrected times
are shared among these fit-functions via the ISISscripts
caching extension. Then the reference time, t0, is
interpreted as binary corrected!

NOTE: a Taylor series describes the pulse period evolution
phenomenologically. In case of mass-accretion from a donor
star the evolution is driven by the mass accretion rate and
a Taylor series does not model this correctly. It is likely
that further fit-parameters, such as orbital parameters,
get biased due to this imperfect modelling (see, e.g., PhD
thesis of M. Bissinger)!
##### Example

% define the measured period evolution as ISIS dataset
id = define_counts(time, make_hi_grid(time), period, period_err);

% set the fit-function
fit_fun("pulsartaylor(1)");

__See also__: pulseperiod, taylor, pulsartaylor_set_order, fitfun_cache

----

#### pulsartaylor_set_order
##### Synopsis
 changes the order of the Taylor series used in 'pulsartaylor'

##### Usage
```c
 pulsartaylor_set_order(Integer_Type new_order);
```

##### Description

By default the Taylor series used in the 'pulsartaylor' fit-
function is computed up to the second order. This function allows
to change this order starting at zero up to the 7th order. The
number of fit-parameters are adapted and named accordingly.

NOTE: changing a fit-function and its parameters on the fly is
not supported by ISIS. In order to still achieve this
feature here, the fit-function is first deleted using
'del_function' and defined again using 'add_slang_function'.
Testing revealed, however, that this trick only works once!

__See also__: pulsartaylor

----

#### pulsartorque
##### Synopsis
 fit-function modelling the accretion torque of a neutron star (simple way)

##### Usage
```c
 fit_fun("pulsartorque");
```

altusage{fit_fun("dopplerorbit\*pulsartorque");}
##### Description

The spin-up of an accreting neutron star is connected with its
luminosity via
Pdot = - b \* P^2 L^alpha
as found by Ghosh & Lamb (1979). This fit-function solves this
differential equation in order to calculate the spin-evolution of
the neutron star.

The parameters of the fit-function are:
p     - spin-period at t0 (s)
t0    - reference time t0 (MJD), has to be fixed
a     - constant spin-up or -down (s/s)
b     - torque strength (s/s @ Lnorm and Pnorm)
alpha - exponent of b (try to freeze it)
Lnorm - luminosity used for normalization, has to be fixed
Pnorm - spin-period user for normaliziation, has to be fixed

In order to express the torque strength, b, in the usual unit of
a spin-change (s/s), the equation is modfied by two normalization
constants:
Pdot = - b \* (P/Pnorm)^2 (L/Lnorm)^alpha
where Pnorm is a reference spin-period and Lnorm a reference
luminosity. For instance, Pnorm could be tied to parameter p,
i.e., the period p at t0. This should be avoided, however, when
multiple dataset are fitted with the same torque strength b, but
different values for the parameter p. Here Pnorm has to be the
same among all datasets! The same applies to Lnorm, which should
be fixed to an (arbitrary) flux or rate, for instance
corresponding to the flux of the Crab.
NOTE: setting Pnorm = 0 (the default) uses Pnorm = p internally
in order to ensure backward compatibility.

The exponent, alpha, of the torque strength, b, depends on the
accretion mechanism. After Ghosh & Lamb, alpha=6/7 for disk-, and
alpha=1 for wind- accretion.

In order to calculate the spin-evolution, the count rate over
time, i.e., a light curve has to be assigned to the dataset using
'set_dataset_metadata' (see example below). The period
measurements have to be within the time range of the light
curve. The structure assigned to the dataset must contain the
following fields:
time - time (MJD, ordered)
rate - count rate at 'time'

NOTE: in case you add the Doppler shift of orbital motion to the
model using the 'dopplerorbit' fit-function, make sure that
this fit-function is calculated \*first\* in order to
transform the times ('lo' parameter of the fit-function
/and/ light curve 'time' grid) into the barycenter of the
binary! These corrected times are shared among these
fit-functions via the ISISscripts caching extension. Then
the reference time, t0, is interpreted as binary corrected!

NOTE: the full Ghosh & Lamb accretion torque theory provides
equations for the torque strength, b, as a function of the
neutron star parameters. This is not implemented here for
simplicity. The full theory is implemented in the
'pulsarGL79' fit-function.

NOTE: the model is calculated on the light curve time grid in
order to ensure that the integration includes the reference
time, t0. This model is interpolated onto the period time
grid in the end.
##### Example

% define the measured period evolution as ISIS dataset
id = define_counts(time, make_hi_grid(time), period, period_err);

% assign the light curve to this dataset
set_dataset_metadata(id, struct {
time = lc.time,
rate = lc.rate
});

% examples for setting the fit-function
fit_fun("pulsartorque(1)");
fit_fun("dopplerorbit(1)\*pulsartorque(1)"); % add orbital Doppler shift

__See also__: pulsarGL79, dopplerorbit, set_dataset_metadata, fitfun_cache

----

#### pulsar_GTI
##### Synopsis
 Calculates GTIs for pulse phase resolved spectroscopy

##### Usage
```c
 pulsar_GTI(Double_Type tstart, tstop, String_Type satellite, basefilename, Double_Type t0, p, phase_lo, phase_hi);
```

##### Qualifiers

* pdot: first derivative of the pulse period in s/s (default: 0)
* pddot: second derivative of the pulse period in s/s^2 (default: 0)
* MJD: If set, tstart, tstop and t0 are assumed to in MJD
* local: create GTIs in satellite's local time system. Requires qualifiers 'nobarevt' and 'barevt' to be set.
* barevt: event file in barycentered time frame
* nobarevt: event file in local time frame
* : all other qualifiers are passed to BinaryPos

##### Description

This function calculates the GTIs for pulse phase resolved spectroscopy. Input arguments are

tstart - start time of the time interval to be covered (typically the start of the observation)
tstart - end time of the time interval to be covered (typically the end of the observation)
satellite - the name of the satellite (needed for setting the reference MJD correctly)
basefilename - the file created will be named 'basefilename.gti'
t0 - the reference time (time of phase zero)
p - the pulse period
phase_lo - the lower phase boundary
phase_hi - the upper phase boundary

Upon qualifier request, tstart, tstop, and t0 can be given in MJD instead of seconds. The pulse
period is always in seconds.

If the pulse period and the reference time are corrected for the binary
motion, the orbital parameters should be provided by qualifiers such that
the GTIs can be transformed into the observers time system. The
qualifiers are passed and equal to the <code>BinaryPos</code> function.

If GTIs in the satellite's local reference time system are needed (e.g., for Suzaku-XIS),
an event file in both local and barycenterd time can be passed via qualifiers and the GTIs
are interpolated to the local time system. Header keywords are set accordingly.
##### Example

pulsar_GTI (2.7082e8, 2.7097e8, "nustar", "phase_0.25-0.35", 2.708242e8, 443.07, 0.25, 0.35);

creates a GTI file named 'phase_0.25-0.35.gti', ranging from 2.7082e8--2.7097e8 seconds
in NuSTAR's mission specific time system for the pulsar 4U 1907+09 with pulse period 443.07 seconds
for the pulse phase interval 0.25--0.35 where phase 0.0 is set to be at 2.708242e8 seconds.

__See also__: MJDref_satellite, BinaryPos, pulse_time

----

#### pulse2pulse_flux_lc
##### Synopsis
 averages the given lightcurve over the pulsar's period

##### Usage
```c
 Struct_Type = pulse2pulse_flux_lc(
Struct_Type lightcurve,
Double_Type or Struct_Type period,
[, Struct_Type orbit]
);
```

##### Qualifiers

* remap: interpolate the resulting flux lightcurve
on the input time grid (default: no)
* interpol: function reference to perform the time
interpolation (default: &interpol_points)
* dphitol: minimum phase coverage (dphi) a pulse in
the lc has to have at least (default: .95)
* gaptol: minimum time difference between bins which
defines a gap (default: 2\*min(diff(lc.time)))
* t0: time of pulse phase zero (can be provided
using the ephemeris structure as well;
default: first time bin of the lightcurve)
* phase: array of the pulse phases corresponding to
the lightcurve time array (default: its
calculated using 'pulseperiod2phase'). If
the qualifier is set to a reference the
calculated phases are assigned to the
given variable.

##### Description

The underlying slope in a lightcurve of a pulsar
might affect any timing analysis of its pulsations
due to pulse to pulse variations of the luminosity.
This functions averages the count rates over each
pulse to get this luminosity dependance, which is
afterwards interpolated to the binning of the input
lightcurve.

The input lightcurve must be of struct {
Double_Type[] time, rate, error
}

The input pulse period may be either a single number
implying a constant pulse period or a structure
containing the pulse ephemeris as defined in
'check_pulseperiod_orbit_struct'. In addition, the
orbital parameters might be also given as a
structure to take also the Doppler shift of the
pulse period into account. This is necessary only
in case of a non binary corrected lightcurve.

The output lightcurve is a struct {
Double_Type[] time (center of pulse), rate, error,
dphi (phase coverage of each pulse, <1 for a gap)
}

By default, bad sampled pulses are ignored in the
final lightcurve, which would lead to wrong mean
count rates otherwise.

Note, that all parameters must have the same time
unit, if applicable.

Note further, that the lightcurve's time grid has
to be evenly spaced!

__See also__: pulseperiod2phase, interpol_points

----

#### pulseperiod
##### Synopsis
 calculates the pulse period at the given time depending
on the given pulse period evolution

##### Usage
```c
 Double_Type[] pulse_period(Double_Type[] time, Struct_Type pulseperiod[, Struct_Type orbit]);
```

##### Qualifiers

* interpol: reference to a function to interpolate the
pulse period evolution on the requested
time grid (default: &interpol_points)
* sameunit: set if the unit of 'time' is in the same
unit as the pulse period or set to the
conversion factor from days to 'time'

##### Description

Calculates the expected pulse period at the given time
(in days), which may be a single value or an array.
The structures containing the pulse period and the
optional orbital parameters must follow the conditions
described in 'check_pulseperiod_orbit_struct'.

If the pulse period is given as evolution (time vs.
period) the period at the requested time is calculated
by interpolation. Otherwise the pulse period is
calculated by a 'taylor' series using a given period
and its derivatives at a reference time in. In any
case the requested time has to be in MJD and the period
(and its Nth derivative) in seconds (/seconds^N)

Finally, if any orbital parameters are provided, the
returned period gets modified by the binary motion.

__See also__: check_pulseperiod_orbit_struct, taylor, radial_velocity_binary

----

#### pulseperiod2phase
##### Synopsis
 calculates the pulse phase from a given pulse period

##### Usage
```c
 Double_Type[] pulseperiod2phase(
Double_Type[] time,
Struct_Type pulseperiod[, Struct_Type orbit]
);
```

##### Qualifiers

* interpol: interpolation method to re-map
the period- onto the input time-
grid (default: &interpol_points)
* getphi: variable reference to return the
phase on the given period over time
grid (method (a), see below).
* sameunit: set if the unit of 'time' is in the same
unit as the pulse period or set to the
conversion factor from days to 'time'

##### Description

The pulse period p(t) of a pulsar and its pulse
phase phi(t) are connected by
dphi(t) / dt = 1. / p(t)
Thus, from a given pulse period the phase can be
calculated by integration, which this function
provides.

The pulse period may be given as
a) the pulse period over time
struct { time, period }
b) the taylor coefficients of the pulse
ephemeris via
struct { p0[, t0, pdot[, p2dot]] }
as defined in 'check_pulseperiod_orbit_struct'.

It is assumed that the unit of the pulse period
is a factor of 86400 larger than the time unit of
the light curve, i.e., light curve in days and
pulse period in seconds. If both have the same
unit (regardless whether its seconds or days)
use the sameunit-qualifier.

In case a), the phase is numerically integrated
using the trapez method on the full provided period
time grid. Finally, the calculated phase is re-mapped
onto the input time grid by interpolation.

In case b), the phase is calculated analytically by
a taylor-series:
phi(t) = (t-t0)/p0 - pdot/p0^2\*(t-t0)^2 + ...

Note, that the analytical calculation only supports
a pulse ephemeris up the the second order (p2dot).
If you need higher orders, you can first calculate
the pulse period over time via a taylor-series and
finally use method a).

In case orbital elements are provided, the additional
phase shift is calculated after Hilditch Eq 3.43:
delta phi = z(t)/c (f0 zdot(t)/c - f(t-t0))
with the projected position z(t) of the neutron star
and its spin frequency evolution f(t) = 1 / p(t),
where p(t) is the given pulse period evolution.

__See also__: pulse_period, taylor, BinaryPos, radial_velocity_binary

----

#### pulseperiod_epfold
##### Synopsis
 UNDER DEVELOPMENT; performs an automatic pulse period search on the given light curve(s)

##### Usage
```c
 Struct_Type pulseperiod_epfold(Struct_Type[] lc, Double_Type p0);
```

##### Qualifiers

* nbins: profile bins (default: 32)
* fracexp: minimum fracexp all bins should have (default: 1.0)
* dpscale: period search range relative to formal resolution
of epfold (default: 3)
* dpmin: minimum period search range (default: 0.01 s)
* gapscale: factor for maximum allowed gap length relative to
formal resolution o f epfold (default: .5)
* goodness: threshold for the goodness of any signal
(default: 3)
* pbins: mininum number of consecutive bins in epfold with
'goodness' to define a signal (default: 3)
* chatty: chattiness (default: 1)
* plotlc: reference to function(Struct_Type[] lc)
* plotepf: reference to
function(Struct_Type epf, Double_Type median, norm)

##### Description

UNDER DEVELOPMENT, USE WITH CAUTION! Send questions or bugs to
matthias.kuehnel@sternwarte.uni-erlangen.de

lc[] = struct { time, rate, error, fracexp }
with time in MJD

p0 = pulse period in seconds

returns struct {
time (mean in MJD)
period (in s)
error (in s)
epfold (structure returned by epfold)
lc (input light curves, but maybe splitted)
}

__See also__: epfold

----

#### pulseperiod_magic
##### Synopsis
 UNDER HEAVY DEVELOPMENT; USAGE ON YOUR OWN RISK

##### Usage
```c
 Struct_Type pulseperiod_magic(Struct_Type[] lc, Double_Type p0, dpmax);
```

##### Qualifiers

* ccflim: cross-correlation threshold (default: .7)

##### Description

UNDER DEVELOPMENT, USE WITH CAUTION! Send questions or bugs to
matthias.kuehnel@sternwarte.uni-erlangen.de
see pulseperiod_epfold

lc[] = struct { time, rate, error, fracexp }
with time in MJD

p0 = pulse period in seconds
dpmax = maximum allowed period derivative

returns struct {
time (mean in MJD)
period (in s)
error (in s)
}

__See also__: pulseperiod_epfold, pulseperiod_phase_connect, bayesian_blocks

----

#### pulseperiod_search
##### Synopsis
 Looks for periodic signal in a lightcurve.

##### Usage
```c
 Struct_Type pulseperiod_search( lc [, p0 [, sigma ] ] )
```

;
##### Description

The input lightcurve should be a structure of the form
lc = struct { time, rate, [ error ], [ fracexp ] }
If error resp. fracexp are not given, they will be filled with
sqrt(rate) resp. ones. All fields are arrays of doubles of the
same length.
p0 and sigma determine an initial guess for the period and an
approximate error.
The output is a structure of the form
{ ep, pp, lc }
Each field is a list, in which each element corresponds to one
segment of the lightcurve (multiple elements if the lightcurve
contains considerable gaps).
ep[i] contains epoch folding information, pp[i] the folded pulse profile
and lc[i] the lightcurve under consideration.
The function works the following way: (the functions used are given)

(1) If no p0 is given, a Fourier method is used to find an
initial guess for the period. A splitting is performed first
if necessary
\* split_and_epfold_lc (; split_only), foucalc
(2) The input lightcurve is split if it contains gaps.
\* split_and_epfold_lc (; split_only)
(3) A correction for any underlying variation in flux of the
lightcurve is performed.
\* pulse2pulse_flux_lc
(4) For each segment an epochfolding is performed.
\* split_and_epfold_lc
(5) The peak in the statistics of epfold is found.
\* find_peak

Qualifiers for the individual functions can be passed as structures
with the names given below. See their helps for further information.

##### Qualifiers

* compact: output contains only the essential information
* epfold_fourier_qu: contains qualifiers for step (1)
* fourier_qu: contains qualifiers for step (1)
* epfold_split_qu: contains qualifiers for step (2)
* pulse2pulse_slope_qu: contains qualifiers for step (3)
* epfold_qu: contains qualifiers for step (4)
* find_peak_qu: contains qualifiers for step (5)
* no_slope_correction: step (3) is not done
* no_splitting: step (2) is not done
* exact: forces epfold to use exact
* not_exact: forces epfold not to use exact
* fourier: fourier is used, even if p0 is given -- can be used to pass sigma
* chatty: boolean value (default: 1)

__See also__: foucalc, split_and_epfold_lc, pulse2pulse_flux_lc, find_peak

----

#### pulseperiod_transform
##### Synopsis
 transforms a period evolution given as taylor coefficients to a new t0

##### Usage
```c
 Struct_Type pulse_transform(Double_Type new_t0, Struct_Type pulseperiod);
```

##### Qualifiers

* sameunit: set if the unit of 'time' is in the same
unit as the pulse period or set to the
conversion factor from days to 'time'

##### Description

The structure containing the pulse period and its
derivatives at a certain time t0 must fullfil the
conditions given in 'check_pulseperiod_orbit_struct'.
This description of the pulse period evolution is
transformed to a new given t0. In case this time is
given as an array an array of transformed structures
is returned.

Note, that the uncertainty of the transformed pulse
ephemeris scales with (t - new_t0)^N \* pNdot with
the highest order N of the taylor series.

__See also__: check_pulseperiod_orbit_struct

----

#### pulseprofile_compose
##### Synopsis
 composes a pulse profile from sine and cosine functions

##### Usage
```c
 Struct_Type pulseprofile_compose(Struct_Type decomposition);
```

##### Description

Inverse of pulseprofile_decompose, see its help for details.

__See also__: pulseprofile_decompose, pfold

----

#### pulseprofile_decompose
##### Synopsis
 decomposes a pulse profile into sine and cosine functions

##### Usage
```c
 Struct_Type pulseprofile_decompose(
Struct_Type profile[, Integer_Type[] a_orders, b_orders]
);
```

##### Qualifiers

* amin/amax: array of min/max values for the allowed range
of coefficient a_n during the fit (same order
as a_orders). Needs a_orders and b_orders to
be specified (default: NULL)
* bmin: same as amin/amax for b_n
* phi0rng: range of allowed phase offets [min,max]
(default: [-1,1])
* amplrng: range of allowed amplitudes [min,max]
(default: [-_Inf,+_Inf])
* initpars: array of initial parameters in the form
[phi0[, ampl[, a_n..., b_n...]]]
The values for a_n and b_n only apply if
a_orders and b_orders are specified
(default: [0, mean(profile.value), 0..., 0...])
* maxord: highest order to use (if no specific orders for
a or b are given; default: nbins/2-1)

##### Description

The given pulse profile, F, of the form
struct { Double_Type[] bin_lo, bin_hi, value }
is fitted by a series of sine and cosine functions,

F(phi) = ampl + sum_n^N a_n\*sin(2PI\*(phi+phi_0)\*n)
+ b_n\*cos(2PI\*(phi+phi_0)\*n)

where phi is the phase bin, ampl is the mean flux, N is
the highest order to use, phi_0 is a phase offset, and
a_n and a_b are the coefficients of the sine and cosine,
respectively.
By default the series is calculated up to the highest
possible order, which is related to the number of phase
bins (Nyquist frequency). It is also possible to specify
the orders, which has to be taken into account during the
fitting, for the sine and cosine function (a_orders and
b_orders, respectively).
The returned structure contains the resulting fit
parameters,

struct {
Integer_Type nbins, % number of phase bins
Double_Type phi0,   % phase offset
Double_Type ampl,   % mean amplitude (zero order)
Double_Type[] a,    % sine coefficients
Double_Type[] b     % cosine coefficients
}

where the indices of the arrays a and b specify the order,
n, of the coefficient (starting with n=1). This structure
can be passed to 'pulseprofile_compose' to calculate the
modelled pulse profile from the coefficients.
##### Example

% synthetic example profile
variable nbins = 32;
variable prof = struct { bin_lo, bin_hi, value };
(prof.bin_lo, prof.bin_hi) = linear_grid(0, 1, nbins);
prof.value  = 2 + 8\*sin((prof.bin_lo)\*2\*PI)^2;
prof.value += 4\*sin((prof.bin_lo)\*PI);
hplot(prof);

% decomposition using the first order sine and second
% order cosine coefficients only
variable decomp = pulseprofile_decompose(prof, [1], [2]);
ohplot(pulseprofile_compose(decomp));

__See also__: pfold, pulseprofile_compose

----

#### pulseprofile_energy_interpolate
##### Synopsis
 interpolates a pulsephase-energy-histogram to a finer grid

##### Usage
```c
 Double_Type[egrid\*e_interp,phigrid\*p_interp] pulseprofile_energy_interpolate(
Struct_Type map, Integer_Type p_interp, Integer_Type e_interp
);
```

##### Description

##### Example

__See also__: pulseprofile_energy_map

----

#### pulseprofile_energy_lag
##### Synopsis
 calculates a lag (=shift) in a pulsephase-energy-histogram

##### Usage
```c
 Double_Type[] pulseprofile_energy_lag(
Struct_Type map, 'p' or 'e'[, Double_Type[] reference]
);
```

##### Description

##### Example

__See also__: pulseprofile_energy_map, CCF_1d

----

#### pulseprofile_energy_map
##### Synopsis
 sorts the given events into a pulsephase-energy-histogram

##### Usage
```c
 Double_Type[egrid,phigrid] pfold_event_energy_map(
Double_Type[] events, energies, Double_Type pulse_period;
gti = Struct_Type, egrid = Struct_Type, pgrid = Struct_Type
);
```

##### Description

##### Example

__See also__: pfold

----

#### pulseprofile_energy_normalize
##### Synopsis
 normalize a given pulse profile, spectrum, or pulseprofile-energy-map

##### Usage
```c
 Double_Type[] pulseprofile_energy_normalize(
Double_Type[] profile_or_spectrum,
String_Type method
);
```

```
or

```c
 Double_Type[egrid,pgrid] pulseprofile_energy_normalize(
Double_Type[egrid,pgrid] map,
String_Type method,
Char_Type dimension
);
##### Description

A function to normalize either a 1D array representing a pulse profile or
spectrum, or a 2D pulse profile energy map. In the latter case the dimension
the normalization should apply to has to be specified, as the normalization
is performed in 1D, i.e., either for each phase normalize the energies
(dim = 'e') or for each energy normalize the pulse profile (dmi = 'p').

Following normalization methods are available:

"sdev": Substracts the mean value and devides by the standard deviation:
isis> mom = moment( value );
isis> normvalue = ( value - mom.ave ) / mom.sdev;

"minmax": Substracts the min. value and deviedes by the min-max range.
isis> normvalue = ( value - min(value) ) / (max(value)-min(value));

##### Example

__See also__: pulseprofile_energy_map

----

#### pulseprofile_phase_connect
##### Synopsis
 UNDER DEVELOPMENT; returns the phase shift between two pulse profiles

##### Usage
```c
 (Double Type phi, ccf) = pulseprofile_phase_connect(Struct_Type prof, ref);
```

##### Qualifiers

* shift: automatically shifts the given profile in order to match
the phase of the reference profile (caution: overwrites
the input!)

##### Description

UNDER DEVELOPMENT, USE WITH CAUTION! Send questions or bugs to
matthias.kuehnel@sternwarte.uni-erlangen.de

Determines the phase shift of the pulse profile 'prof' with
respect to the reference profile 'ref' by a cross-correlation.
The cross-correlation is interpolated to enhance the precision
beyond the pulse profile binning. Both pulse profiles need to
have the same number of bins.

The input structures have to have the same fields as returned
by 'epfold'.

The resulting phase shift 'phi' and the maximum value of the
cross-correlation 'ccf' are returned.

__See also__: pfold, CCF_1d

----

#### pulse_fraction
##### Synopsis
 Calculate pulse fraction given a pulse profile

<!--%{{{ -->
##### Usage
```c
 Double_Type (pf, pf_err) = pulse_fraction(Struct_Type pp; method);
```
or

```c
 (pf, pf_err) = pulse_fraction(Struct_Type pp; method=value);
```

##### Description

This function calculates the pulse fraction from the given
pulse profile (output of pfold) and given method.

Available methods are:
ma  : Modulation amplitude (min max), if a value 'a' is given,
calculate the amplitude between integral of pulse profile
that falls below the fraction 'a' and that which is above.

fft : Calculate the pulse fraction as sqrt(sumsq(A_k))/abs(A_0) where
A_k are the FFT amplitudes (k=1..N) and A_0 is the constant
factor. If value is given and of type Int_Type, take only the
FFT factors up to this value into account. If it is of type
Double_Type, take all the harmonics into account until the
remaining factors have a power of this fraction or less.

dft:  Same as fft.

rms : Calculate the RMS of the pulse profile, normalized by its average.

area: Calculate the area, that is, the integral of the pulse profile
subtracted the minimum. Normalized by the total area. The value,
if given, specifies the fraction that is considered the minimum.

fit:  Similar to fft. Takes all harmonics from the fft (or up to value
tolerance of a best fit, given in value). The resulting series
is integrated. If value is of type Int_Type, the series is
truncated at this harmonic.

To compute the pulse fraction only the fields 'values' and 'error' are
used. So if the PF is not obtained from <code>pfold</code> one can also run
it as
% RMS method example
pf = pulse_fraction(struct{value=..., error=...}; rms);

The input should have only positive values (i.e., not mean subtracted).

A rule of thumb is, that if the method is given without a value, that
the input is exact (i.e., values have no uncertainty). This is
appropriate for modelled pulse profiles. For measured data, giving a
value cuts down on the noise contributions and gives a more robust
estimate.

All methods also return an uncertainty estimate. Warning! Take the word
'estimate' here very seriously!

__See also__: pfold

----

#### pulse_time
##### Synopsis
 returns the pulse arrival time of the given pulse number with
respect to the pulse ephemeris and orbit

##### Usage
```c
 Double_Type pulse_time(Integer_Type[] number, Struct_Type ephemeris[, Struct_Type orbit]);
or Double_Type pulse_time(Integer_Type[] number, Double_Type pulseperiod[, Struct_Type orbit]);
```

##### Qualifiers

* MJD: the values of the pulse ephemeris are given
in days (default: seconds)
* eph: may be set to the pulse ephemeris structure
* orb: may be set to the orbital structure
* dphi: an additive constant phase shift

##### Description

Calculates the expected pulse arrival time of the
given pulse number, which may be a single value
or an array. The structures containing the pulse
ephemeris and the orbital parameters must follow
the conditions decribed in 'check_pulseperiod_orbit_struct'.
Instead of the pulse ephemeris the pulse period
may be given only. These structures may be also
passed to the function by qualifiers, hence the
structure parameters can be omitted.
The equation to calculate the arrival time is
similar to Hilditch eq. 3.53, including the terms
of the fourth order (p3dot). The numerical calcu-
lation is optimized using the Horner schema. For
details see 'arrtimes'.

__See also__: check_pulseperiod_orbit_struct, pulseperiod, arrtimes

----

#### pushStructFieldArray
##### Synopsis
 appends a value to an array which is the field of structure

##### Usage
```c
 pushStructFieldArray(s, field, value);
```

##### Description

<code>s.field = [s.field, value];  %</code> if <code>s.field</code> was not <code>NULL</code>

----

#### __push_array
##### Synopsis
 pushes the values of an array onto the stack

##### Usage
```c
 (Any_Type v1, v2, ...) = __push_array(Any_Type a[]);
```

##### Description

NOTE that the Stack is limted to 2499 Elements, if the length
of a exceeds this value a Stack_Overflow Error is thrown!

----

#### pvm_fit_pars
##### Synopsis
 computes confidence intervals with PVM

##### Usage
```c
 Struct_Type results = pvm_fit_pars(String_Type SetupFile[, Integer_Type pars[]]);
```

##### Description

With SetupFile, one has to provide an ISIS-script which loads/rebins the spectra
and loads/assigns the response. If the model requires additional modules,
they have to be activated as well in <code>SetupFile</code>. It is, however, not necessary
to define/load the model itself, as the currently defined model will be saved
into a file <<code>dir</code>>/<<code>basefilename</code>><code>_initial.par</code>.

<code>pars</code> is an array of parameters, for which the confidence levels are to be fitted.
If <code>pars</code> is not specified, all free parameters of the current model are used.
The best fit which is eventually found is always saved in <<code>dir</code>>/<<code>basefilename</code>><code>.par</code>.

The verbosity of <code>pvm_fit_pars</code> is controlled by the intrinsic variable <code>Fit_Verbose</code>.

The return value <code>results = struct { index, name, value, min, max, conf_min, conf_max, buf_below, buf_above, tex }</code>
is a table with the following information for each parameter:

<code>min</code> and <code>max</code> are the minimum/maximum values allowed.
<code>conf_min</code> and <code>conf_max</code> are the confidence limits.
<code>buf_below</code> (<code>buf_above</code>) is the fraction of the allowed range <code>[min:max]</code>
which seperates the lower (upper) confidence limit from <code>min</code> (<code>max</code>).
If one of these buffers is 0, your confidence interval has bounced.

The same infomation is stored in the files <<code>dir</code>>/<<code>basefilename</code>><code>_conf.txt</code>
and <<code>dir</code>>/<<code>basefilename</code>><code>_conf.fits</code>.
In case of any error, the return value is <code>NULL</code>.
##### Qualifiers

* level: confidence level to be computed.
As for conf, 0 means 68%, 1 means 90% [default], and 2 means 99% confidence level.
* tolerance: the tolerance for chi^2 improvements without interrupting the search
for the confidence intervals, see <code>help("conf");</code>. The default is <code>1e-3</code>.
* fitmethod: fit-method to be used, see <code>help("set_fit_method");</code>
Default is the currently used fit-method returned by <code>get_fit_method()</code>.
* nph: the number of processes per host, see <code>pvm_ms</code>.
* debug: [=1] prints additional debug information from <code>pvm_ms</code>. (Default=0)
* dir: [="."] specifies the directory in which the logfiles shall be stored.
It may be a relative path to the current working directory.
* basefilename: [=startdate]
* verbose: log every output -- from the master script or any slave --
in the file <<code>dir</code>>/<<code>basefilename</code>><code>_stdout.log</code>,
and keep the initial parameters.
* isisscript: [="isis-script"] command to start ISIS for slaves.

__See also__: fit_pars; conf, set_fit_method, cl_master/cl_slave [Houck/Noble], pvm_ms [S-Lang module]

----

#### pvm_fit_pars_txt2fits
##### Usage
```c
 pvm_fit_pars_txt2fits(String_Type txt_filename);
```

----

#### qromb
##### Synopsis
 Integrate using Rombergs's rule to specified accuracy.

##### Usage
```c
 Double_Type int = qromb (Ref_Type function, Double_Type min, Double_Type max);
```

##### Description

Integrate a function between the limits <code>min</code> and <code>max</code> to specified
accuracy using the extended trapezoidal rule. Adapted from algorithm
in Numerical Recipes, by Press et al. (1992, 2nd edition), Section 4.3.
The precision and number of maximal iterations can be set via qualifiers.
Any other keywords are passed directly to the user-supplied function.
NOTE: Romberg is more efficient then Simpson.
##### Qualifiers

* qromb_eps [=1e-6]: :    Scalar specifying the fractional accuracy before
ending the iteration.
* qromb_max_iter [=16]: : Integer specifying the total number iterations
at which <code>qsimp</code> will terminate even if the
specified accuracy has not yet been met.
The maximum number of function evaluations is
2^(qromb_max_iter-2)-1.

* k [=5]: :    Integration is performed by Rombergs method
of order 2k, where, e.g., k=2 is Simpsons rule.

##### Example

%  Compute the integral of sin(x) from 0 to PI/3.
%  The value obtained should be cos(PI/3) = 0.5
variable val = qromb( &sin, 0, PI/3);

__See also__: integrate_trapez,polint,qsimp

----

#### qsimp
##### Synopsis
 Integrate using Simpson's rule to specified accuracy.

##### Usage
```c
 Double_Type int = qsimp (Ref_Type function, Double_Type min, Double_Type max);
```

##### Description

Integrate a function between the limits <code>min</code> and <code>max</code>to specified
accuracy using the extended trapezoidal rule. Adapted from algorithm
in Numerical Recipes, by Press et al. (1992, 2nd edition), Section 4.2.
The precision and number of maximal iterations can be set via qualifiers.
Any other keywords are passed directly to the user-supplied function.
##### Qualifiers

* qsimp_eps [=1e-6]: :    Scalar specifying the fractional accuracy before
ending the iteration.
* qsimp_max_iter [=16]: : Integer specifying the total number iterations
at which <code>qsimp</code> will terminate even if the
specified accuracy has not yet been met.
The maximum number of function evaluations is
2^(qsimp_max_iter+5)-1.

##### Example

%  Compute the integral of sin(x) from 0 to PI/3.
%  The value obtained should be cos(PI/3) = 0.5
variable val = qsimp( &sin, 0, PI/3);

__See also__: integrate_trapez,qromb

----

#### quantile
##### Synopsis
 gets an arbitrary quantile of an array

##### Usage
```c
 Any_Type quantile(Double_Type p, Any_Type a[]);
```

##### Description

<code>quantile(0, a) = min(a)</code> and <code>quantile(1, a) = max(a)</code>.
For values <code>0 < p < 1</code>, intermediate values of the <code>a</code> will be returned.

__See also__: median

----

#### quasar_accr (fit-function)
##### Synopsis
 fits a composite quasar spectra in the optical/UV

##### Description

This function fits a composite quasar spectrm to the data, taking into
account the redshift z. see Vanden Berk et al. 2001

##### Examples

% data definition:
load_data("optical.pha");
fit_fun("quasar_accr(1)+powerlaw(1)");

----

#### rad2RD
##### Synopsis
 Convert right ascension and declination from radians to (h, m, s) and (deg, arcmin, arcsec)

##### Usage
```c
 rad2RD(Double_Types RA[], D[])
```

##### Description

Given right ascension and declination in radians, the function converts them to
hours, minutes, seconds and degrees, minutes of arc, seconds of arc. In case of
negative declinations, the minus sign is assigned only to the highest non-vanishing
term, i.e., to degrees if degrees is nonzero, to minutes if minutes is nonzero but
degrees is zero, ... . Negative right ascensions are not expected.
##### Example

(ah, am, as, dd, dm, ds) = rad2RD(0,-PI/4.);
(ah, am, as, dd, dm, ds) = rad2RD(0,-PI/181.);
(ah, am, as, dd, dm, ds) = rad2RD(3/4.\*PI,0);
(ah, am, as, dd, dm, ds) = rad2RD([0,3/4.\*PI],[-PI/4,0]);
(ah, am, as, dd, dm, ds) = rad2RD(RD2rad(01, 45, 12.54, 87, 55, 45.34));

__See also__: RD2rad

----

#### RAdec_from_AzEl
##### Synopsis
 computes equatorial (RA, dec) coordinates from a point's (azimut, elevation) at a time MJD

##### Usage
```c
 (RA, dec) = RAdec_from_AzEl(az, el, MJD,  longw, lat);
```

##### Description

This function is deprecated. Please use horizon2equatorial instead.

__See also__: horizon2equatorial,equatorial2horizon

----

#### RAdec_from_galLB
##### Synopsis
 convert galactic (l, b) coordinates to equatorial (RA, dec) coordinates

##### Usage
```c
 (RA, dec) = RAdec_from_galLB(l, b);
```

##### Qualifiers

* l_unit:  [<code>="deg"</code>]: set the unit of the galactic longitude
<code>l_unit="rad"</code> <code>=></code>  l in rad
<code>l_unit="hms"</code> <code>=></code>  l in hours as a scalar
or an array of the form <code>[H, M]</code> or <code>[H, M, S]</code>
* b_unit:  [<code>="deg"</code>]: set the unit of the galactic lattitude

##### Description

This function is deprecated. Please use galactic2equatorial instead.

__See also__: galLB_from_RAdec, AzEl_from_RAdec, RAdec_from_AzEl, angle_to_rad

----

#### radial_velocity_binary
##### Synopsis
 computes the radial velocity of a binary system as a function of orbital phase or time

##### Usage
```c
 Double_Type v = radial_velocity_binary(Double_Type x);
```

##### Qualifiers

* v0: systemic velocity
* K: velocity semi amplitude, in km/s
* asini: value of a \* sin i, in kilometers
* P: orbital period, in days
* T0: epoch of periastron, x means time in days
* T90: epoch of mean longitude 90 degr, x means time in days
* e: eccentricity (0 <= e < 1)
* omega: longitude of periastron in radian (unless degrees is set), default = 0
* degrees: omega is measured in degrees instead of radian

##### Description

x has the meaning of orbital phase (0 <= x < 1) unless T0 or T90 is specified.

__See also__: Ch. 3 of R.W. Hilditch, An Introduction to Close Binary Stars, Cambridge Univ. Press, 2001

----

#### radial_velocity_LSR
##### Synopsis
 computes the radial velocity component of the local standard of rest

##### Usage
```c
 Double_Type radial_velocity_LSR(Doule_Type RA, dec, MJD)
```
or

```c
 Double_Type radial_velocity_LSR(Doule_Type az, el, MJD, longw, lat)

```

##### Description

right ascension and declination, Modified Julian Date
azimuth, elevation, geographic longitude (west), geographic lattitude

----

#### radio_mod2img
##### Synopsis
 creates an image using a model and a beam

##### Usage
```c
 Struct_Type img = radio_mod2img( Struct_Type <code>mdl</code>, Double_Type <code>beam</code>);
```

##### Qualifiers

* src_name: [=NULL] name of the source
* date_mjd: [=_NaN] observation date (MJD)
* obs_date: [=NULL] observation date (string). if only date_mjd or only obs_date
are set, the other one is calculated.
* nrpix_ra: [=512] number of pixels for right ascension
* nrpix_dec: number of pixels in declination (by default calculated from RA-DEC-range)
* ra: [=[ra_min,ra_max]]  RA range in mas
* dec: [=[dec_min,dec_max]] DEC range in mas, by default the RA-DEC-range is
calculated from the distribution of model components and the beam size
* delt: [=[ra_delt,dec_delt]] resolution in mas/pixel, overwrites nrpix qualifiers
* sigma: [=1e-3\*max(img)] value for 1 sigma (used by plot_vlbi_map)

##### Description

This function uses a model to generate an image and convolves it with the beam.
Here the "beam" is simply a Gaussian profile, which is given as an array:
<code>beam = [smajor_axis,sminor_axis,position_angle];</code>
The model has to have the fields:
<code>flux</code>   flux of each model component [Jy]
<code>ra</code>     relative RA of component (change to delta_x?)
<code>dec</code>    relative RA of component (change to delta_y?)
<code>smajor</code> component size (smajor axis) [mas] (0 for point source)
<code>sminor</code> component size (sminor axis) [mas]
<code>pang</code>   position angle of component's smajor axis
Currently the last two fields (<code>sminor</code>, and <code>pang</code>) are
ignored and only circular components (<code>smajor</code>) are used.
##### Example

variable mdl = struct {
flux   = [0.6 , 0.9,  0.2,  1.2,  3],
ra     = [2   , 1.4,  0.7, 0.25,  0],
dec    = [1   , 0.6, 0.35,  0.1,  0],
smajor = [0.3 , 0.2,    0,    0,  0],
sminor = [0.3 , 0.2,    0,    0,  0],
pang   = [0    ,   0,    0,    0,  0] };
variable beam = [0.2, 0.07, 0.4];
variable img = radio_mod2img (mdl, beam);
plot_vlbi_map (img, "test.pdf");

__See also__: plot_vlbi_map, read_difmap_fits

----

#### radius_to_unit
##### Synopsis
 converts a radius from a given unit into another

##### Usage
```c
 Double_Type = radius_to_unit(Double_Type radius, String_Type from_unit, to_unit);
```

##### Qualifiers

* asini: projected semi major axis (lt-s)
* i: inclination (degrees)
* mq: mass ratio of star to companion

##### Description

Converts the 'radius' from a given unit 'from_unit'
into another unit 'to_unit'. There might be additional
information needed for the calculation, e.g. the
projected semi major axis, which is passed via
qualifiers.

The following units are supported (with additional
needed qualifiers):
rsun - solar radii
cm   - centimeters
lts  - light seconds
disp - binary displacement (asini, i, mq)
fill - fill factor = radius/critical radius (asini, i, mq)

Note:
It might be possible, that less qualifiers may be passed,
if the variables are canceled during the calculation. For
example, converting from binary displacement to fill factor
requires the mass ratio 'mq' only.

Note:
Let the projected semi major axis be the distance from CM
to M1. Then, mq is defined as M1/M2.
That means, to convert the radius of the companion, mq has
to be inverted and asini has to be the distance from CM
to M2, which is simply asini\*mq[not inverted]

__See also__: Roche_potential, Roche_critical

----

#### ratio_error_prop
##### Synopsis
 calculates a ratio and error propagation

##### Usage
```c
 (rat, err) = ratio_error_prop(a, a_err, b, b_err);
```
or

```c
 (rat, err) = ratio_error_prop(a, b; Poisson);

```

##### Description

<code>rat = a/b</code>

<code>err = sqrt[ (1/b \* a_err)^2 + (a/b^2 \* b_err)^2 ]</code>
##### Qualifiers

* Poisson: <code>a_err = sqrt(a);  b_err = sqrt(b);</code>

__See also__: hardnessratio_error_prop

----

#### RD2rad
##### Synopsis
 Convert right ascension (h, m, s) and declination (deg, arcmin, arcsec) to radians

##### Usage
```c
 RD2rad(Double_Types ah[], am[], as[], dd[], dm[], ds[])
```

##### Description

Given right ascension in hours, minutes, seconds and declination in degrees,
minutes of arc, seconds of arc, the function converts them to radians. Always
provide six numbers, i.e., fill up with zeros where necessary. Right ascension
is assumed to be positive. If the degrees argument of declination is negative
the minus sign is automatically applied to the minutes and seconds parameters.
If the degrees argument of declination is zero, the sign of the minutes argument
(if nonzero) is applied to the seconds parameter.
##### Example

(raInRad, declInRad) = RD2rad(01, 45, 12.54, 87, 55, 45.34);
(raInRad, declInRad) = RD2rad(01, 45.209, 0, -87, 55, 45.34);
(raInRad, declInRad) = RD2rad(01.753472, 0, 0, 0, -55, 45.34);
(raInRad, declInRad) = RD2rad(01, 45, 12.54, 0, 0, 45.34);
(raInRad, declInRad) = RD2rad([01, 01], [45,45.209], [12.54,0], [87,-87], [55,55], [45.34,45]);
(raInRad, declInRad) = RD2rad(rad2RD(0,-PI/4.));

__See also__: hms2deg,dms2deg,rad2RD

----

#### Read a FITS header
##### Usage
```c
 Struct_Type fits_read_header(String_Type file or Fits_File_Type fp);
```

##### Description

This function reads the header of the fits file given by the
`file' argument and returns it as a structure.  If `file' is
a string, then the file will be opened, read-out, and closed
automatically. Otherwise, `file' should represent an already
opened FITS file (which will remain opened).
##### Qualifiers

* lowercase: return structure tags in lower case
(default: upper case)

__See also__: fits_read_records, fits_open_file

----

#### read_data_from_write_plot
##### Synopsis
 reads data that was saved with "write_plot" in a structure

##### Usage
```c
 Structure str = read_data_from_write_plot(String_Type file)
```

##### Qualifiers

* no_res: : no residuals should be loaded
* no_mod: : no model included in dat file, implies no_res
* y_fac[=0]: : scale the y-axis by 10^{y_fac}

##### Description

This function reads data from a plot saved with "write_plot" and returns
it in a structure which can be used for plotting.

The structure tags are:
lo:  low energy
hi:  high energy
val: data value
err: uncertainty of the data value
model: model value of fit
res: residual
res_min: lower error bar
res_max: upper error bar

IMPORTANT: The filename has to be given without the ".dat" ending!

Note that if the data were saved with plot_unfold(...;...,power=3);
the values are automatically converted to ergs/s/cm^2

__See also__: xfig_plot_unfold,xfig_plot_data,read_col,write_plot

----

#### read_difmap_fits
##### Synopsis
 read a fits image provided by DIFMAP

##### Usage
```c
 Struct_Type img_struct = read_difmap_fits(String_Type <code>fitsfile_name</code>)
```

##### Qualifiers

* fit_noise: fit properties of the image noise

##### Description

This function reads a .fits file provided by DIFMAP and returns
a structure containing the image and keywords.
The returned structure can be used as input for the function
<code>plot_vlbi_map</code>.

__See also__: plot_vlbi_map

----

#### read_ep
##### Synopsis
 read in the epoch files

##### Usage
```c
 read_ep([array of epoch fits files]);
```

##### Qualifiers

* quadrant: [=1] Quadrant which is defined as a positive distance ( RA, DEC > 0 == 1 || RA < 0, DEC > 0 == 2 || RA < 0, DEC < 0 == 3 || RA > 0, DEC < 0 == 4)

##### Description

This functions returns a structure of an Epoch . The require input is an array of epoch fits files.

----

#### read_histo
##### Synopsis
 read text data into histogram structure

##### Usage
```c
 Struct_Type hist = read_histo(String_Type filename);
```

##### Qualifiers

* cols: [=4] number of columns in the data file
* collist: array of column index for bin_lo, bin_hi,
value, err in that order. Needs col=-1.
* bin_lo: column index for bin_lo. Needs col=-1.
* bin_hi: column index for bin_hi. Needs col=-1.
* value: column index for value. Needs col=-1.
* err: column index for err. Needs col=-1.

##### Description

Read a text file with column data directly into a histogram
structure struct{bin_lo,bin_hi,value,err};.
The default assumption is that the text file contains the four
columns bin_lo, bin_hi, value, and err in that order as the first
four columns in the file (further columns being ignored).
Non-standard files can be processed via qualifiers. Missing
columns are populate with assumptions, e.g., the grid reflecting
the row numbers and the uncertainty assuming Poisson statistics.
If all columns are present, but out of order / other column
numbers, a list with column numbers can be supplied.

Qualifier cols:
cols=4:  bin_lo, bin_hi, value, err
cols=1:  value.
Then bin_lo=[0:length(value)-1], bin_hi=bin_lo+1,
err=sqrt(value).
cols=2:  bin_lo, value.
Then bin_hi=make_hi_grid(lo), err=sqrt(value).
cols=3:  bin_lo, bin_hi, value.
Then err = sqrt(value).
cols=-1: Either use collist qualifier to supply an array of
column indices for all of bin_lo, bin_hi, value, err
(in this order). Or, for a sub-selection, use the
bin_lo, bin_hi, value, and err to supply column
indices individually. If any of those four equals 0,
this field is ignored. Missing columns are populated
as described above.
Presence of collist takes presedence over the others.

__See also__: init_histo, add_hist, shift_hist,
scale_hist, stretch_hist

----

#### read_par
##### Synopsis
 Read function parameter from file

##### Usage
```c
 Struct_Type[] params = read_par(filename[, funp]);
```

##### Description

This function process a parameter file according to the ISIS
file convention (safed, e.g., with save_par) and returns the
paramter settings as an array of structs. This array is
compatible to the array retireved by get_params and can
therefore be used with set_params.

If an additional parameter is given, it is expected to be a
pointer to a variable in which the function string gets stored.

__See also__: get_params, set_params, save_par

----

#### read_sixte_lc
##### Synopsis
 Reads a LC created by the SIXTE makelc tool

##### Description

makelc writes the lightcurve file according to the first OGIP
standard, i.e. only a COUNTS column is written and the timing
information is stored in the TSTART, TSTOP, TIMEDEL, and
TIMEPIXR keywords. SIXTE uses the convention TIMEPIXR=0, which
means that the time field of the lightcurve returned by
read_sixte_lc equals the beginning of the bin (time_lo).
##### Usage
```c
 read_sixte_lc(filename);
```

----

#### read_spix
##### Synopsis
 reads the FITS file created with write_spix

##### Usage
```c
 Stuct_Type <code>spix</code> = read_spix( String_Type <code>filename</code>);
```

__See also__: make_spix, write_spix, plot_spix

----

#### rebinGroup
##### Synopsis
 rebins a <code>{bin_lo, bin_hi, value, err} struct</code>ure by a grouping factor

##### Usage
```c
 Struct_Type s_ = rebinGroup(Struct_Type s, Integer_Type n);
```

__See also__: rebin

----

#### rebin_combined_optimal
##### Usage
```c
 rebin_combined_optimal (Int_Type group_index);
```
or

```c
 rebin_combined_optimal Int_Type[] group_index);
```

##### Synopsis
 Rebin a dataset combination based on Kaastra & Bleeker 2016

##### Qualifiers

* min_counts: [=0]: Ensure a minimum number of counts per bin per dataset.

##### Description

Rebin a dataset combination using the numerical optimum defined by the
response. From the combination a combined response is calculated respecting
the weights.

__See also__: combine_datasets, rebin_combined

----

#### rebin_dataset_optimal
##### Usage
```c
 rebin_dataset_optimal (Int_Type index);
```

```
or

```c
 rebin_dataset_optimal (Int_Type[] index);
##### Synopsis
 Rebin datasets addressed by <index> based on Kaastra & Bleeker 2016

##### Qualifiers

* min_counts: [=0]: Ensure a minimum number of counts per bin (alters statistical properties).

##### Description

Rebin a dataset to a numerical optimum defined by the associated
response matrix. The algorithm tries to balance the maximum
possible information with the smallest possible grid to represent
it.

__See also__: rebin_data

----

#### rebin_fouquan
##### Synopsis
 rebins a Fourier quantity from timing analysis with foucalc

##### Usage
```c
 Struct_Type rebin_fouquan(freq, fouquan, numseg)
```

##### Description

<code>freq</code> is an array of the original Fourier frequencies.
<code>fouquan</code> is the array of original Fourier quantities.
<code>numseg</code> is the number of seqments used to calculate <code>fouquant</code>.

The output structure has the following fields, which are arrays:
- <code>freq_lo</code> and <code>freq_hi</code> define the new frequency bin.
- <code>freq</code> is the average original frequency in each bin.
- <code>n</code> is the number of original frequencies, and
- <code>n_tot</code> is the total number of values (including segmentation) contributing to each bin.
- <code>value</code> is the average Fourier quantity.
- <code>error = value/sqrt(n_tot)</code> is the 1 sigma error for the <code>n_tot</code> values.
- <code>sigma</code> is the standard deviation of the original quanities in each bin
##### Qualifiers

* logfreq:
* linfreq:
* newfreq: array of new frequencies
* nofreq: no rebinning
* verbose:

----

#### rebin_human2isis
##### Synopsis
 create isis binning from str = rebin_human2isis

##### Usage
```c
 Array_Type binning = rebin_human2isis(String_Type str);
```

##### Description

This routine converts a binning string created with
rebin_isis2human back to the ISIS conform binning array
(see e.g. get_data_info(idx).rebin). It can be used to
restore the binning of data directly.

__See also__: fits_save_fit, get_data_info, rebin_isis2human

----

#### rebin_isis2human
##### Synopsis
 converts isis binning in a human readable string

##### Usage
```c
 String_Type str = rebin_isis2human(Array_Type binning);
```

##### Description

This routine converts the binning as used by ISIS (see e.g.
get_data_info(idx).rebin) to a string which is easy to read.

The routine fits_save_fit() uses this string to save the binning
of the data. It can be converted back by using rebin_human2isis().

__See also__: fits_save_fit, get_data_info, rebin_human2isis

----

#### rebin_lc
##### Synopsis
 rebins a lightcurve structure to a new time resolution

##### Usage
```c
 Struct_Type new_lc = rebin_lc(Struct_Type lc, Double_Type new_dt);
```

##### Qualifiers

* time: [= <code>"time"</code>] field name in the structure containing the time
* rate: [= <code>"rate"</code>] field name(s) in the structure containing the rate(s)
* error: [= <code>"error"</code>] field name(s) containig the corresponding error(s)
* float: type cast rate(s) and error(s) to Float_Type
* verbose: shows the assumed time resolution of the initial light curve

##### Description

The original light curve <code>lc</code> may contain discontinuities.
<code>new_lc.rate[i]</code> contains the average <code>lc.rate</code>
where <code>new_lc.time[i] <= lc.time < new_lc.time[i]+new_dt</code>.
<code>error^2</code> is rebinned accordingly.

The structure fields "<code>time, rate, error</code>" may have arbitrary names,
but these must then be specified by the according qualifiers.
<code>new_lc</code> will also have  these field names. In addition, a "<code>time_hi</code>"
field is added, which contains the upper boundary of the time bins.
##### Example

<code>lc1 = struct { time=[1:10], rate=[1:10]^2, , error=[1:10] };</code>

<code>LC1 = rebin_lc(lc1, 2);</code>

<code>lc2 = struct { t=[1:10], r1=[1:10]^2, r2=[1:10]^3, e1=[1:10], e2=[1:10]^1.5 };</code>

<code>LC2 = rebin_lc(lc2, 2; time="t", rate=["r1", "r2"], error=["e1", "e2"]);</code>

__See also__: rebin

----

#### rebin_mean
##### Synopsis
 rebins units like intensity, where you expect the binning
to take the mean of the value, properly

##### Usage
```c
 intens_new = rebin_mean(r_nlo,r_nhi,r_lo,r_hi,intens);
```

----

#### rebin_to_energy_grid
##### Synopsis
 rebin data to a given energy grid

##### Usage
```c
 rebin_to_energy_grid(Dataset ID, bin_lo, bin_hi);
```

##### Description

This routine bins the data to a given energy grid. Bins outside
the given energy grid are left unbinned.

__See also__: rebin_data,rebin_satellite, rebin_human2isis

----

#### rebin_to_instrument
##### Synopsis
 rebin data from one instrument to another instrument

##### Usage
```c
 rebin_to_instrument(Dataset id_reference, Dataset id_to_be_rebinned);
```

##### Description

This routine tries its best to rebin the given dataset with the ID
"id_to_be_rebinned" to the dataset with id "id_reference".

__See also__: rebin_to_energy_grid,rebin_data

----

#### rectangles_overlap
##### Synopsis
 Checks whether two rectangles overlap

##### Usage
```c
 res=rectangles_overlap(src,clp)
```

##### Description

This function checks whether the two rectangles src and clp
overlap (return value=1) or not (return value =0).

The rectangles are defined by (xmin,ymin,xmax,ymax)
either as a 4 element array in this order or as a
struct with these tags. Both boxes must be defined
using the same format.

----

#### rectangle_where
##### Synopsis
 finds the rectangle in a 2d array, where an expression is true

##### Usage
```c
 (Integer_Type Y[], X[]) = rectangle_where(Integer_Type expr);
```

##### Description

The rectangle in the 2d array defined by the index-arrays
<code>Y</code> and <code>X</code> contains all elements for which <code>expr!=0</code>,
i.e., one can crop the elements for which <code>expr==0</code>.
(Note that <code>all(expr[Y,X])</code> is not necessarily true.)
##### Example

img = img[rectangle_where(img>0)];

----

#### redden (fit-function)
##### Synopsis
 fits the reddening of optical/UV data

##### Description

This function uses fm_unred to fit the reddening of optical/UV data.
See fm_unred for details.

##### Examples

% data definition:
load_data("optical.pha");
fit_fun("redden(1)\*powerlaw(1)");

__See also__: fm_unred

----

#### reduce_struct
##### Synopsis
 remove one or more fields from a strucure

##### Usage
```c
 Struct_Type reduced_struct = reduce_struct(Struct_Type s, String_Type fieldsnames[]);
```

##### Qualifiers

* extract:: If given, the returned struct does only contain the fields 'fieldnames'!

##### Description

Either removing the fields 'fieldnames' from the given structure 's' (if they even exist) or
if the qualifier 'extract' is given removing all other fields but those given with 'fieldnames'!

----

#### reflection_fraction_relxill
##### Synopsis
 calculates the reflection fraction as defined in relxill, using the rel_lp_table of the relxill code

##### Usage
```c
 Double_Type fR =
reflection_fraction_relxill(double a, double/array height, double rin, double rout);
```

##### Qualifiers

* path: [getenv("RELXILL_TABLE_PATH")]: path to the table
* table: [rel_lp_table_v0.5b.fits: name of the table
* struct: if set returns full structure returning fR, f_inf, and f_bh

__See also__: kerr_rms,kerr_rplus
##### Description

Assumptions:
- height, rin, and rout have to be given in R_g, a is the
dimensionless spin parameter
- height, rin, and rout can also be given in negative values,
which is interpreted the same way as the relxill definition:
negative heights are in units of the event horizon (kerr_rplus) and
and radii in units of the ISCO (kerr_rms)
- photons are not allowed to cross the disk plane
- produces identical results to relxill

This function

If relxill and the RELXILL_TABLE_PATH environment variable is set
up correctly, this function will work out of the box. Otherwise
the path needs to be set manually.

Note: this function has been tested only for
rel_lp_table_v0.5b.fits. It is not recommended to change this. Any
deviations are < 0.01.

Questions: contact Thomas Dauser

Reference: Dauser et al., 2016, A&A, 590, A76

----

#### refraction
##### Synopsis
 calculate the correction for astronomical refraction

##### Usage
```c
 Double_Type refraction(z0;qualifiers)
```

##### Qualifiers

* lambda: wavelength (in A, between 3000 and 17000 A)
* mum: wavelength is in microns
* nm: wavelength is in nanometers
* temperature: temperature at observer [K; default: 288.15K=15C]
* lapse_rate: temperature lapse rate [K/m; default: 0.0065K/m = 6.5K/km]
* centigrade: temperature is given in C
* pressure: ambient total pressure at observer (Pa, default: 1013.25kPa)
* kPa: ambient pressure is in kPa
* hPa: ambient pressure is in hPa (or mbar)
* rel_humidity: relative humidity at observer (between 0 and 1)
* altitude: altitude of observer above geoid (m; below 11000m)
* latitude: geographical latitude of the observer (rad; default: 0)
* deg: all angles are given in degrees, not radians
* exact: use numerical integration also for z0 below 80deg

##### Description

For a given zenith distance z and local observing conditions, this function calculates
the refraction angle, that is the difference R=z-z0 where z is the unrefracted zenith
distance that would be measured if the Earth did not have an atmosphere, and z0 is the
observed zenith distance.

The most common use of this function will be to calculate z0 for a given topocentric
zenith distance. For all practical purposes, R is so small and changes slowly enough,
such that users can call the function with z and determine z0 from the return value.
Note that the default arguments are in radians, use the deg qualifier to switch to
degrees.

The refraction depends very slightly on the atmospheric properties, i.e., its temperature
profile. These can be set with the respective qualifiers.

The default settings of the routine are that for zenith distances smaller than 80 degrees
the approximations given by Saastamoinen (1972, Bull. Geodesique 105, 279 and 1972, Bull.
Geodesique 106, 383) are used.

For larger zenith distances, or if the "exact"-qualifier is set, a numerical approach
is chosen, following the approach discussed by Auer & Standish (2000, AJ 119, 2472
[first submitted in 1979!]), Hohenkerk and Sinclair (1985, HM Nautical Almanac Office,
NAO Technical Note 63), and Mangum and Wallace (2015, PASP 127, 74). The function uses
the atmospheric model discussed by Hohenkerk and Sinclair, but uses the exact refraction
formula for air. This exact approach yields good results for zenith distances up to a
few degrees larger than 90 degrees (i.e., observation of the horizon from a mountain
top) and is the one on which the refraction formulae of the Astronomical Almanac are based.

For large zenith angles, there are slight differences at the arcsecond or less level
between the results discussed here and the numbers listed by Hohenkerk or Auer. These
are due to the different treatment of numerical instabilities and the use of numerical
differentiation formulae. Given that for large zenith angles the simplified atmospheric
model of Hohenkerk (constant temperature lapse rate in the troposphere, constant temperature
in the stratosphere) results in larger systematic errors anyway (see Nauenberg, 2017,
PASP 129, 44503), this should not be seen as an error of the function.

As a caveat, the calculations using the Saastamoinen formulae assume that all pressure
terms there are in Pa, rather than in mbar. This reproduces the results with respect
to the numerical simulations and values tabulated elsewhere to <1". But it is not
what Saastamoinen claims. I (J. Wilms) am puzzled...

If the exact qualifier is set or for large z, all input into the function MUST be
scalars - in this case this routine is NOT array safe.

For the Saastamoinen formulae, the routine is array safe in all relevant parameters.

----

#### refractive_index_air
##### Synopsis
 calculate the refractive index of dry and moist air

##### Usage
```c
 Double_Type refractive_index_air(lambda;qualifiers)
```

##### Qualifiers

* mum: wavelength is in microns
* nm: wavelength is in nanometers
* temperature: temperature [K; default: 288.15K]
* centigrade: temperature is given in C
* pressure: ambient total pressure (Pa, default: 1013.25kPa)
* kPa: all pressure arguments are in kPa
* hPa: all pressure arguments are in hPa (or mbar)
* CO2_ppm: CO2 fraction in ppm (default: 450)
* water_pressure: partial water vapor pressure
* rel_humidity: relative humidity
* silent: do not emit warning messages

##### Description

This function calculates the phase refractive index of dry and moist air
for light in the optical and IR following the standard paper by
Ciddor (1996, Appl. Optics 35(9), 1566) and the discussion by Stone
and Zimmerman (NIST Engineering Metrology Toolbox;
http://emtoolbox.nist.gov/Wavelength/Documentation.asp) for a given
wavelength (default A, but see the mum and nm qualifiers) and ambient
conditions (temperature, pressure,  humidity or partial vapor pressure,
and CO2 concentration). The function has been verified against the values
given by Ciddor and in the NIST Engineering Metrology Toolbox.

The relative uncertainty of the approximations used here is claimed to be
around 2e-8. The range of validity is 3000 A<lambda<17000 A, temperatures
between -40C and 100C (233-373K), and pressures between 10 and 140kPa.
The CO2 fraction is allowed to vary between 0 and 2000ppm.

This routine is array safe. If lambda is an array, the other qualifiers
can be either arrays of the same length as lambda or single valued.

----

#### rename_struct_fields
##### Usage
```c
 Struct_Type new_s = rename_struct_fields(Struct_Type s, String_Type fieldnames[]);
```

----

#### replicate_table
##### Synopsis
 repeats columns of a table, possibly with a periodic shift

##### Usage
```c
 Struct_Type replicate_table(Struct_Type t);
```

##### Qualifiers

* P: [= 1] period
* back: [= 0] repeat periods backwards
* ahead: [= 1] repeat periods forwards
* periodic: [<code>= ["bin_lo", "bin_hi"]</code>] periodic structure fields

##### Description

The return value is a structure with the same fields as <code>t</code>.
All array fields are repeated (back+1+ahead) times; periodic ones as

<code>[ val-back\*P, ..., val-P, val, val+P, ..., val+P\*ahead ]</code> ,

while other ones are just replicated:

<code>[ val       , ..., val  , val, val  , ..., val         ]</code> .

----

#### require_atoms
##### Usage
```c
 require_atoms();
```

##### Description

This function loads the atomic data from the
Astrophysical Plasma Emission Database via

<code>atoms(aped);</code>

unless <code>_isis->Dbase</code> is already initialized.

__See also__: atoms

----

#### rescale_range
##### Synopsis
 rescales a value

##### Usage
```c
 Double_Type y = rescale_range(Double_Type x);
```

##### Qualifiers

* in: inputrange
* out: outputrange

##### Description

possibilities for in/out and the corresponding scaling function:

<code>"0:1"</code>, no scaling

<code>"-inf:inf"</code>, arctan

----

#### reset_plot_defaults
##### Synopsis
 Changes some of the defaults on the isis_fancy_plots package

##### Usage
```c
 reset_plot_defaults(;dcol=Integer_Type, ...);
```

##### Qualifiers

* dcol: Data color value
* dsym: Data symbol value
* mcol: Model color value
* sum_exp: !=0, Sum the exposures when combining data
* use_con_flux: !=0, the unfolded model includes response smearing
* gap: ==0, plot models across data gaps.

##### Description

reset_plot_defaults(; dcol=#, dsym=#, mcol=#, sum_exp=#,
use_con_flux=#, gap=#);

Resets some of the plot defaults to a user's specifications. (See
help messages for individual plotting functions, and pg_info, to
understand these settings.)  Use with no arguments to see current
values.

__See also__: pg_info

----

#### residual_runs
##### Synopsis
 Perform runs test on model and data

##### Usage
```c
 status = residual_runs([&stat]);
```

##### Description

While the Chi2 test tests for the absolute difference
of model and data, the runs test (Wald-Wolfowitz test)
accounts for the sign difference.

The test is in particular usefull for checking if the
model misses essential features of the data. As a simple
example concider data coming from a linear relation
described by a constant function. Although the chi2 test
might give a reasonable result the improper model is
easily spotted in the residuals.

The results are presented for 3 different confidence
regions. Each model passing the test is added to the
entries of the result matrix.

Note: The Confidence region is the total confidence. It
can happen that the test fails for the two tailed test but
succeeds for both one tailed tests!

If a reference is given as argument the same information
is stored as struct in that reference.

__See also__: runs_test, normal_cdf

----

#### resolution_rebin
##### Synopsis
 Rebin spectra based on approximated detector resolution.

##### Usage
```c
 Array_Type resolution_rebin(dataset_id, instrument; oversampling, min_counts);
```

##### Qualifiers

* sampling: Float_Type, oversampling factor of detector resolution/bin width, default: 3
* min_sn: Float_Type, minimum signal-to-noise ratio, default: 5

##### Description

This function rebins a dataset to fulfill the following two criteria:

1: Each bin contains enough counts so that - assuming Poissonian noise -
Signal-to-Noise is larger than the given minimum.

2: If criterion 1 is fulfilled, the bin size is chosen as a fraction of the
detector resolution, an oversampling of 3 is recommended (Kaastra 2016).

Required arguments are the dataset ID and a string that specifies the used
instrument. Supported are:

XMM EPICpn: "epn"

Suzaku XIS: "xis"

NuSTAR FPM: "fpm"

##### Examples

Load and plot EPICpn data with a histogram oversampling detector resolution by 5:

variable EPN_data = load_data("src_s.pha");

resolution_rebin(EPN_data,"epn"; sampling = 5);

plot_data(EPN_data; dsym=0);

__See also__: rebin_data, group

----

#### rgb2color
##### Synopsis
 converts r, g, b values to 24 bit color values.

##### Usage
```c
 Integer_Type rgb2color(Double/Int_Type r, g, b)
```

##### Qualifiers

* string: returns value as hex encoded string.

##### Description

Convert given color values to one 24 bit value.
If values are doubles they are interpreted as ranging
from 0 to 1. If integers they are interpreted as
8 bit (0-255) color values.

__See also__: color2rgb

----

#### rgb2hex
##### Synopsis
 converts r, g, b values between 0 and 1 to a 24-bit integer

##### Usage
```c
 Integer_Type rgb2hex(Double_Type r, g, b)
```

##### Qualifiers

* str: return value is a string with preceding "#".
* des: input color will be desaturated to gray-scale values.
If a value is given, the saturation will be scaled accordingly.

__See also__: rgb2hsl

----

#### rgb2hpluv
##### Usage
```c
 Double_Type h, s, l = rgb2hpluv(Int_Type r, g, b);
```

##### Synopsis
 Calculate HSPuv triplet from RGB space

##### Description

Inverse function of <code>hpluv2rgb</code>.

__See also__: hpluv2rgb

----

#### rgb2hsl
##### Synopsis
 converts (red, green, blue) values to (hue, saturation, lightness)

##### Usage
```c
 (Double_Type h, s, l) = rgb2hsl(Integer_Type r, g, b);
```

##### Description

Converts 8 bit RGB values (0-255) to HSL values.

The return values are always normalized to [0, 1].
See <code>hsl2rgb</code> for a definition of hue, saturation, lightness.

__See also__: hsl2rgb

----

#### rgb2hsluv
##### Usage
```c
 Double_Type h, s, l = rgb2hsluv(Int_Type r, g, b);
```

##### Synopsis
 Calculate HSLuv triplet from RGB space

##### Description

Inverse function of <code>hsluv2rgb</code>.

__See also__: hsluv2rgb

----

#### rgb2hsv
##### Synopsis
 Convert RGB color to HSV

##### Usage
```c
 (Double_Type h,s,v) = rgb2hsv(Int_Type r,g,b);
```

##### Description

RGB colores encoded as 8 bit (0-255) values get
converted to HSV (Hue, Saturation, Value) as doubles
(0-1) are. Works for array values two (lengths must
match).

----

#### ridge_line
##### Synopsis
 calculates the ridge line

##### Usage
```c
 Struct_Type ridge_line = ridge_line (Array_Type <code>img</code>)
```

##### Qualifiers

* ref_pix: [=[y,x]] starting pixel of the ridge line (index convention: img[y,x])
brightest pixel used by default
* dr: [=0.8] step size in pixels
* steps: number of steps (default is maximal length of dimensions)

##### Description

This function calculates the ridge line in a (jet) image.
Starting from the brightest point (assumed to be the core),
or a point specified by the <code>ref_pix</code> qualifier, the ridge
line is calculated. The ridge line is given in different ways:
The brightest points at each distance (in steps of <code>dr</code> pixels)
from the reference pixel, are given by the fields <code>peak_x</code> and
<code>peak_y</code> of the returned structure. The field <code>peak_flux</code>
contains the corresponding pixel value.
As an alternative to the peak ridge line, a flux-centered ridge
line is provided. The fields <code>flux_cent_x</code> and <code>flux_cent_y</code>
specify the points, at which the integrated flux (along the same
distance from the refence pixel) to the left is equal to that on
the right side.
##### Notes

- elliptical beams will create artifacts (wiggles in the ridge line),
in order to avoid this effect, obtain the ridge line from an
image convolved with a circular beam
- valid points can be obtained, e.g., by filtering the radii at which
the peak flux exceeds the map's noise level (fit_gauss_to_img_noise)
- currently no smoothing of the points is done (e.g., fit spline to
ridge line)
- there can be problems if the radius (used for ridge line calculation)
lies completely within the jet/beam, <code>ref_pix</code> qualifier can be
used to select another starting point (on the "jet axis")
##### Example

variable mdl = struct {
flux   = [0.3, 0.5, 0.1,  0.2, 0.3,  0.9,    3],
ra     = [3.7, 2.8, 2.2,  1.4, 0.9,  0.5,    0],
dec    = [1.2, 0.8, 0.8,  0.7, 0.6,  0.4,    0],
smajor = [0.4, 0.2, 0.1, 0.03, 0.1, 0.01, 0.01],
sminor = [0.4, 0.2, 0.1, 0.03, 0.1, 0.01, 0.01],
pang   = [0,      0,   0,    0,   0,    0,    0] };
variable beam = [0.3, 0.3, 0.7];
variable img = radio_mod2img (mdl, beam);
variable r = ridge_line (img.img;);
struct_filter(r, where(r.peak_value>1e-4));
plot_image (log(img.img+1e-4));
color(4);  oplot(r.peak_x,r.peak_y);
color(13); oplot(r.flux_cent_x,r.flux_cent_y);

__See also__: fit_gauss_to_img_noise, radio_mod2img, plot_vlbi_map

----

#### rndbknpwrlc
##### Synopsis
 simulates a light curve with a broken power law distributed power spectrum

##### Usage
```c
 (t, rate) = rndbknpwrlc(Integer_Type nt);
```

##### Qualifiers

* beta1: [=1.5]: first power law index of the power spectrum
* beta1: [=1.0]: second power law index of the power spectrum
* perc: []
* mean: [=0]: mean rate of the simulated light curve
* sigma: [=1]: standard deviation of the simulated light curve
* dt: [=1]: time resolution of the simulated light curve

##### Description

<code>nt</code> is the number of bins of the simulated lightcurve.
It should be a power of two best performance of the fast Fourier transform.

----

#### rndpwrlc
##### Synopsis
 simulates a light curve with a power law distributed power spectrum

##### Usage
```c
 (t, rate) = rndpwrlc(Integer_Type nt);
```

##### Qualifiers

* beta: [=1.5] power law index of the power spectrum
* mean: [=0] mean rate of the simulated light curve
* sigma: [=1] standard deviation of the simulated light curve
* dt: [=1] time resolution of the simulated light curve

##### Description

<code>nt</code> is the number of bins of the simulated lightcurve.
It should be a power of two best performance of the fast Fourier transform.
See also Timmer & Koenig (1995): "On generating power law noise",
A&A 300, 707-710

----

#### Roche_critical
##### Synopsis
 calculates the critical potential at L1 and the corresponding radius in z-direction

##### Usage
```c
 Struct_Type crit = Roche_critical(Double_Type mq);
```

##### Description

The Roche potential describes the motion of a binary consis-
ting of two objects, M1 and M2. The mass ratio mq = M1/M2
must be given. From the position of the first Lagrange point
'xL1', which is a saddle point in the Roche potential, the
value of the critical potential 'critpot' at this point is
calculated. The corresponding equipotential surface describes
the inner most closed surface, which is also known as 'Roche
lobe'. Since the Roche potential does not depend on the
binary rotation, the radius 'rcrit' of the star in z-direction
(perpendicular to the orbital plane) is often used as the
star's radius.

All three values are returned by the following structure:
xL1     - distance of M1 to L1 in units of the binary
displacement
critpot - value of the critical potential at L1
rcrit   - radius of M1 in z-direction in units of the
binary displacement

__See also__: Roche_potential

----

#### Roche_equipotential_volume
##### Synopsis
 computes the volume inside an Roche equipotential surface

##### Usage
```c
 Double_Type Roche_equipotential_volume
```

##### Qualifiers

* phi: [= critical potential] the surface's Roche potential
* N: [= 100] number of subdivisions in x and y for numerical integration

----

#### Roche_lobe_dimension
##### Synopsis
 determines the size of the Roche lobe

##### Usage
```c
 Struct_Type Roche_lobe_dimension(Double_Type q)
```

##### Description

The structure has the following fields:

<code>potential</code>: the critical Roche potential of the Roche lobe

{<code>x</code>/<code>y</code>/<code>z</code>}{<code>min</code>/<code>max</code>}: the coordinates of the envelopping box

----

#### Roche_lobe_surface
##### Synopsis
 calculates surface elements of a binary star

##### Usage
```c
 Struct_Type = Roche_lobe_surface(Double_Type mq, Double_Type fill, Integer_Type ntheta);
```

##### Qualifiers

* noRoche: neglect the Roche potential -> spherical star
* noNorm: do not return the normal vectors
* noArea: do not return the areas
* poly: return the polygons defining the elements
* rotate: rotate the star around its (z-)axis by the
given degrees (default: 0)
* eps: numerical precision (default: 1e-8)
* chatty: be chatty

##### Description

This function calculates the surface of the primary star
in a binary, which is deformed by the Roche potential.
Since this potential can not be solved analytically the
surface must be divided into elements. The number of
elements into theta direction can be specified by the
'ntheta' argument. The total number of surface elements
taking into account the singularity at the poles and the
symmetry in theta is here
2\*ntheta \* (ntheta-2) + 2
The Roche potential for a spherical orbit depends on the
mass ratio mq = M_primary / M_secondary
To determine the size of the star, the undeformed radius
Rz in direction of the angular velocity vector (omega)
can be used via the so-called fill factor:
fill = Rz / R_crit
where R_crit is the critical undeformed radius for a
star, which fills its Roche lobe completely. In that
case, the potential value at the surface is equal to
that at the first Lagrange point, which might lead to
mass transfer onto the companion (Roche lobe overflow).

The returned structure contains the following fields:
Vector_Type[] r - position vector to each element
starting at the stars center
Vector_Type[] n - normal vector of each element
Vector_Type[] A - area of each element
Vector_Type[] p - if the 'poly' qualifier is given,
it contains the polygons defining
each surface element

NOTE: The origin of the reference frame is in the center
of the star and the first Lagrange point is on
the x-axis, while the rotation axis of the star is
along the z-axis!
If you want to rotate the star around its rotation
axis (z-axis), use the 'rotate'-qualifier!

__See also__: Roche_critical, Roche_potential, radius_to_unit, Vector_Type

----

#### Roche_potential
##### Usage
```c
 Double_Type Roche_potential(Double_Type x[, y[, z]]);
```

##### Qualifiers

* q: mass ratio
* sph: coordinates are considered as spherical coordinates r, phi, theta

##### Description

The default values for y and z is 0.

The Roche potential has the following form:
<code>-1/sqrt(x^2 + y^2 + z^2 ) - q/sqrt( (x-1.)^2 + y^2 + z^2 ) - (1+q)/2.\*( (x-q/(1.+q))^2 + y^2 )</code>

----

#### Roman
##### Synopsis
 translates n to upper-case string with roman numeral

##### Usage
```c
 String_Type res = Roman(Integer_Type n)
```

##### Qualifiers

* latex: typeset minus sign ("$-$"R)
* toobig: [=""] string that is returned of n is larger
than the largest known Roman numeral (3999)

##### Description

Converts an integer into a uppercase roman numeral.
Even though not known in Roman times, negative numbers are allowed.

Algorithm based on
https://www.geeksforgeeks.org/converting-decimal-number-lying-between-1-to-3999-to-roman-numerals/

__See also__: roman

----

#### roman
##### Synopsis
 replaces an integer with lowercase Roman numeral strings

##### Usage
```c
 String_Type rom = roman(Integer_Type);
```

##### Synopsis
 translates n to lower-case string with roman numeral

##### Usage
```c
 String_Type roman = romann(Integer_Type n)
```

##### Qualifiers

* latex: typeset minus sign ("$-$"R)
* toobig [=""]: string that is returned of n is larger
than the largest known Roman numeral

__See also__: Roman

----

#### roman2int
##### Usage
```c
 Integer_Type=roman2int(String_Type)
```

##### Synopsis
 translates a roman numeral into an integer

##### Description

This function converts roman numerals into integers.
The function is case insensitive and array safe.

__See also__: roman,Roman

----

#### round2
##### Synopsis
 Round to the nearest integral value or to given digit

##### Usage
```c
 Double_Type[] = round2( Double_Type[] value);
```

```
or

```c
 Double_Type[] = round2( Double_Type[] value, Integer_Type digit );
##### Description

This function rounds its argument to the nearest integral value and
returns it as a floating point result. If the argument is an array,
an array of the corresponding values will be returned.
If a 2nd argument is given it is used as digit the value is supposed
to be rounded to.

__See also__: round, floor2, ceil2, nint

----

#### round_conf
##### Synopsis
 converts confidence intervals after DIN 1333 and gives the rounded decimal place.

##### Usage
```c
 Struct_Type round_conf(Double_Type conf_lo, conf_val, conf_hi);
```

```
or

```c
 Struct_Type round_conf(Double_Type val, sym_err);
##### Description

<code>conf_lo</code> is the lower confidence limit
<code>conf_val</code> is the best fit
<code>conf_hi</code> is the upper confidence limit
The alternative usage with two arguemts allows to specify a
value <code>val</code> with a symmetric uncertainty <code>sym_err</code>.

The returned structure contains the fields
- <code>err_lo</code> (the rounded lower error)
- <code>value_val</code> (the rounded best fit)
- <code>err_hi</code> (the rounded upper error)
- <code>digit</code> (the rounded decimal place of the error)

__See also__: round_err, TeX_value_pm_error

----

#### round_err
##### Synopsis
 rounds an error after DIN 1333 and gives the rounded decimal place

##### Usage
```c
 Struct_Type round_err(Double_Type x);
```

##### Qualifiers

* digits: decimal place where rounding will be applied (suspends DIN 1333)
* sloppy: Deactivates moving rounding decimal place if significant decimal place < 3 (suspends DIN 1333)

##### Description

<code>x</code> is the error which will be rounded

The returned structure contains the fields
- <code>value</code> (the rounded error)
- <code>digit</code> (the rounded decimal place of the error)

EXAMPLES
round_err(0.1278) will return value=0.13 and digit=-2
round_err(1278)   will return value=1300 and digit= 2
since after DIN 1333, the decimal point may only be right after the rounded digit or left of it,
the error should be in LaTeX assigned as $13.0\times 10^{2}$
(? comment: in order to have the correct number of significant digits shouldn't it be:
$0.13\times 10^{4}$, $1.3\times 10^{3}$, or $13\times 10^{2}$)

__See also__: round_conf

----

#### runs_test
##### Synopsis
 Perform runs test on sequence

##### Usage
```c
 Int_Type = runs_test(Num_Type[]);
```

##### Qualifiers

* confidence: [=0.05]: Critical test probability
* overmixing: Test for overmixing
* undermixing: Test for undermixing

##### Description

This function performs the runs test (Wald-Wolfowitz test)
on the given array. The sequence is assumend to represent
a dichotom set with n1 where sequence > 0 and n2 the
complementary.

The test returns true if the sequence is sufficiently
randomly divided into the two sets (determined by the
confidence qualifier).

Per default the sequence is tested against over- and
undermixing but can be adjusted to only test for one with
the appropriate qualifier.

__See also__: normal_cdf

----

#### RXTE_ASM_countrate
##### Synopsis
 estimates the RXTE-ASM countrate from the current model

##### Usage
```c
 (A, B, C) = RXTE_ASM_countrate();
```

##### Description

Zdziarski et al. (http://adsabs.harvard.edu/abs/2002ApJ...578..357Z)
provide a "response matrix" for the RXTE-ASM.
The inverse of this matrix is applied to the energy flux
derived from the current fit-function and its parameters,
in order to estimate the RXTE-ASM count rates <code>A</code>, <code>B</code> and <code>C</code> (cps).

Note that these numbers may only give a rough estimate!

__See also__: energyflux

----

#### RXTE_ASM_lightcurve
##### Synopsis
 retrieves ASM lightcurves for a given source

##### Usage
```c
 Struct_Type RXTE_ASM_lightcurve(String_Type sourcename);
```

##### Qualifiers

* MJDmin: earliest MJD to be used
* MJDmax: latest MJD to be used
* dt: if specified, time resolution in MJD for rebinning
* no_filter_nan: do not remove empty bins after rebinning (only with <code>dt</code>)
* list: lists available sources; <code>sourcename</code> may be omitted but can be a regular expression
* get_list: as list, but the list of sources is returned as an array of strings
* save: saves the light curve data in a local FITS file
* verbose:

----

#### RXTE_filter_file_info
##### Synopsis
 returns RXTE filter file information

##### Usage
```c
 Struct_Type RXTE_filter_file_info(String_Type xflfiles[])
```

__See also__: aitlib/rxte/readxfl.pro

----

#### RXTE_nr_PCUs_from_filename
##### Synopsis
 counts how many PCUs were off from an \*_xyoff_excl_\* filename

##### Usage
```c
 Integer_Type RXTE_nr_PCUs_from_filename(String_Type filename)
```

----

#### RXTE_nr_PCUs_from_filterfile
##### Synopsis
 returns the number of PCUs switched on over time

##### Usage
```c
 Integer_Type[] RXTE_nr_PCUs_from_filterfile(String_Type filterfile[, Double_Type[] time])
```

##### Description

The number of PCUs switched on during an observation
may vary, which results in jumps in the lightcurve.
The filter file (your_extraction/filter/\*.xfl) provides
time resolved information about the operating PCUs,
which is read out and returned.

ATTENTION:
If no time array is given the number of PCUs is returned
for the full length of the observation (no GTIs applied!).
In the other case the given time array HAS TO be in the
SATELLITE TIME SYSTEM and in SECONDS since RXTE started
operating (see 'MJDref_satellite').

__See also__: MJDref_satellite, RXTE_nr_PCUs_from_filename

----

#### RXTE_obscat_info
##### Synopsis
 reads an RXTE human-readable obs(ervation)cat(alogue)

##### Usage
```c
 Struct_Type RXTE_obscat_info(Integer_Type obscat_days[]);
```

__See also__: aitlib/rxte/readobscat.pro

----

#### RXTE_PCA_info
##### Synopsis
 retrieves light curves for a given RXTE-PCA observation

##### Usage
```c
 Struct_Type RXTE_PCA_info(String_Type dirs[])
```

##### Qualifiers

* binning: how much datapoints are to be summed up into a single point
* path: path to the observation
* dirs: subdirectories to the individual observing blocks

* noback: set if no bkg subtraction is to be performed
* earthvle: set if EarthVLE background model is to be used
* faint: set if Faint background model is to be used
* q6: set if Q6 background model is to be used
(default is to test for earthvle,faint,q6)
* skyvle: set if SkyVLE background model is to be used
(default is 0 for noback,earthvle,faint,q6,skyvle)
* exclusive: set to search for data that was extracted
with the exclusive keyword to pca_standard being set.
* top: set to read top-layer data
* nopcu0: set to search for data that was extracted
ignoring PCU0
* fivepcu: plot count-rates wrt to whole PCA, i.e.,
normalizing to five PCU; default is to plot the average
countrate per PCU
* bary: Try to use barycenter time column in data. Must be
created with fxbary before into file with postfix _bary.
* t: time array of data in MJD.
* c: count array of data
* err: Estimated error by applying Poisson statistic.
Binning/background subtraction will be acknowledged.
##### Description

The elements of <code>dirs</code> may contain globbing expressions.

The returned structure has the following fields:

<code>obstime = struct { start, stop}</code> with the times for each observation in <code>dirs</code>

<code>lc = struct { time, rate, error }</code> with the PCA light curve

<code>obscat = struct</code> with information from the observation catalogue (occultation, saa, good time)

<code>gti</code>

<code>xfl = struct</code> with information from the filter file

__See also__: aitlib/rxte/readxtedata.pro

----

#### RXTE_PCA_modes
##### Usage
```c
 RXTE_PCA_modes(String_Type obsids);
```

##### Qualifiers

* compact: only one row per ObsID, omit TSTART, TSTOP and duration
* get_struct: return information on PCA modes in a structure, too
* quiet: do not show information, implies <code>get_struct</code>

##### Description

Reads RXTE-PCA data modes from the PCA FITS-index (FIPC) file.
The location of the RXTE data archive is determined from the
<code>local_paths.RXTE_data</code> variable (defined within the isisscripts).

----

#### RXTE_plot_PCA_info
##### Synopsis
 plots an overview of an RXTE observation (lc, GTI, SAA, bkg)

##### Usage
```c
 RXTE_plot_PCA_info(String_Type dirs[]);
```
or

```c
 Struct_Type RXTE_plot_PCA_info(String_Type dirs[]; get_info)

```

##### Qualifiers

* electron: set to electron ratio threshold for data extraction
* noback: set if no bkg subtraction is to be performed
* earthvle: set if EarthVLE background model is to be used
* faint: set if Faint background model is to be used
* q6: set if Q6 background model is to be used (default is to test for earthvle,faint,q6)
* skyvle: set if SkyVLE background model is to be used (default)
* exclusive: set to search for data that was extracted
with the exclusive keyword to pca_standard being set.
* top: set to read top-layer data
* nopcu0: set to search for data that was extracted ignoring PCU0
* fivepcu: plot count-rates wrt to whole PCA, i.e., normalizing to 5 PCUs.
Default is to plot the average countrate per PCU.
* charsize_obsid:
* get_info: returns the info structure

##### Description

The elements of <code>dirs</code> may contain globbing expressions.

__See also__: aitlib/rxte/rxtescreen.pro

----

#### r_in_from_disk
##### Synopsis
 Calculate inner disk radius from a continuum fitting disk model

##### Usage
```c
 Struct_Type r_in_from_disk(norm, distance, inclination)
```

##### Qualifiers

* f: Color-correction factor [default: 1.0]
* norm_err: Error on normalization [default: 0]
* distance_err: Error on distance in units of kpc [default: 0]
* inclination_err: Error on inclination in degree [default: 0]
* mass: Mass of the black hole in units of solar mass [default: 0]
* mass_err: Error on mass in units of solar mass [default: 0]

##### Description

This function can be used to calculate the values and errors of
the inner radius (in units of km) from a continuum fitting model
such as diskbb or ezdiskbb. See Mitsuda et al. (1984), Makishima
et al. (1986), and, e.g., Zimmerman et al. (2005) and Kubota et
al. (1998) on the color-correction. See also the HEASARC model
description of diskbb and ezdiskbb.

The distance is given in units of kpc and the inclination in
degrees. If a mass is given (units of solar mass), the struct
will also contain the radius in units of r_g as well as the size
of the gravitational radius in km.
##### Usage
```c
 r_in_from_disk(norm, distance, inclination)
```

##### Example

r_in_from_disk(1000, 8, 30; f=1.7, mass=10);

__See also__: gravitational_radius

----

#### SaturationVaporPressure
##### Synopsis
 calculate the saturation vapor pressure of water in air

##### Usage
```c
 Double_Type[] SaturationWaterPressure(T;qualifiers)
```

##### Qualifiers

* centigrade: temperature argument is in centigrade (default: K)
* kPa: Return saturation vapor pressure in kilopascals
* hPa: Return saturation vapor pressure in hectopascals (=mbar)
* water: Calculate saturation vapor pressure over water
* ice: Calculate saturation vapor pressure over ice
* iapws: Use the more precise IAPWS prescription (see below)

##### Description

This function calculates the saturation vapor pressure (svp) of water over
ice and water for a given temperature (default: K, but see the
centigrade qualifier), the routine returns the svp in Pa unless
the kPa or hPa keywords are given. By default, for T>0C (273.15K)
the svp over water is returned, for smaller temperatures that for
ice. Use the "water" and "ice" qualifiers if this is not what you want.

As a default, for the svp over water the equation of
Davis (1992), Metrologia 29, 67-70 is used, while for ice the
prescription given by Marti and Mauersberger (1993), Geophys. Res.
Lett. 20, 363-366 (1993) is applied. For the default settings,
the relative deviation between these equations and the IAPWS recommended
procedure is very small. It does not exceed 0.03% in the 0-100C range,
and is <1.5% in the -50-0C range and less than 2.5% between -100 and -50C,
while the absolute difference in the range below 50C does not exceed
1 Pa.

If the iapws qualifier is given, the routine uses the recommendations
of the International Association for the Properties of Water and Steam
(IAPWS), which was originally given by Peter H. Huang, "New equations
for water vapor pressure in the temperature range -100 deg C to 100 deg C
for use with the 1997 NIST/ASME steam tables," in: Papers and abstracts
from the third international symposium on humidity and moisture, Vol. 1,
p. 69-76, National Physical Laboratory, Teddington, Middlesex, UK,
April 1998. The algorithm used here is as described by
http://emtoolbox.nist.gov/Wavelength/Documentation.asp
The uncertainty is 20kPa at 100 C, less than 2 kPa at 45 C and
0.7 kPa at 20C.

Note that formally the calculation is only valid in the range from
-100 to +100 centigrade. The function returns "NaN" for T>100C and
extrapolates formalism smoothly to lower temperatures (the values
are very small in this regime anyway).

This function is array safe.

----

#### save_atime
##### Synopsis
 saves a structure of arrival times into a FITS-file

##### Usage
```c
 save_atime(String_Type filename, Struct_Type atime, String_Type extname[, String_Type[] comments]);
```

##### Qualifiers

* obj: observed object, written into FITS header
* sat: used satellite, written into extension header
* nfold: number of arrival times, which were merged
during the determination. Corresponds to the
'indiv' qualifier for the 'atime_det' function.
Written into extension header
* hfits: structure for additional FITS-header fields
* hext: structure for additional extension-header fields
* newfile: if the given filename exists a new file is
created instead of updating the existing one
* newext: if the given extension already exists in the
FITS-file a further one with the same name is
added instead of updating the existing one

##### Description

A structure of arrival times, e.g. as returned by the
'atime_det' function, is save into the given FITS-file
creating or updating the extension of the geiven name.
Most of the qualifiers allow to store addiotional
informations into the header of the FITS-file or the
extension. The optional fourth parameter can be used
to write additional comments into the FITS-file.

__See also__: atime_det, atime_merge, load_atime

----

#### save_atime_beta
##### Synopsis
 saves a structure of arrival times into a FITS-file

##### Usage
```c
 save_atime(String_Type filename, Struct_Type atime, String_Type extname[, String_Type[] comments]);
```

##### Qualifiers

* obj: observed object, written into FITS header
* sat: used satellite, written into extension header
* nfold: number of arrival times, which were merged
during the determination. Corresponds to the
'indiv' qualifier for the 'atime_det' function.
Written into extension header
* hfits: structure for additional FITS-header fields
* hext: structure for additional extension-header fields
* newfile: if the given filename exists a new file is
created instead of updating the existing one
* newext: if the given extension already exists in the
FITS-file a further one with the same name is
added instead of updating the existing one

##### Description

A structure of arrival times, e.g. as returned by the
'atime_det' function, is save into the given FITS-file
creating or updating the extension of the geiven name.
Most of the qualifiers allow to store addiotional
informations into the header of the FITS-file or the
extension. The optional fourth parameter can be used
to write additional comments into the FITS-file.

__See also__: atime_det, atime_merge, load_atime

----

#### save_par_to_FITS_header_struct
##### Synopsis
 saves fit-function and paramters to a FITS header structure

##### Usage
```c
 Struct_Type save_par_to_FITS_header_struct()
```

##### Description

The returned structure can be used as header keys
that are written to a FITS file.
This header can be read with <code>load_par_from_FITS_header</code>.

__See also__: load_par_from_FITS_header, load_par, save_par, fits_write_binary_table

----

#### save_plot
##### Synopsis
 saves ISIS spectral data into a FITS file

##### Usage
```c
 save_plot([filename[, ids]]);
```

##### Qualifiers

* A: Save the data in Angstrom and not in keV.

##### Description

This functions saves all data and model points as currently
noticed and rebinned to the file 'filename'.fits. Each dataset is
stored in an own extension. The current model is save in
'filename'.par. By default the name 'save_plot' is chosen.

Hereby the values are given in counts/bin and in
photons/s/cm^2/keV. To calculate the flux from the observed
data, the function get_convolved_model_flux() was used.

Additionally, information on the instrument, the target, the grating,
the filename of the model, the functions used for the model
and the frame time are stored in the header.

----

#### save_slang_variable
##### Synopsis
 allows to save S-Lang variables into a file

##### Usage
```c
 save_slang_variable(file, &var1, &var2, ...);
```

##### Qualifiers

* edit: open an editor to modify the variables;
in that case all variables have to be passed
as references and will be set to their new
values after the editor is closed
* delete: delete the file after editing (requires the
'edit' qualifier to be set); note that the
given variables are still modified!

##### Description

The S-Lang code defining the given variables is saved
into a file, specified by either the filename or an
already opened file-pointer. In order to handle arrays
with a large number (>1000) of items as well as
complex structures, the S-Lang code uses temporary
variable names. Their values are assigned step by step
to avoid a stack overflow. The file can be evaluated
later to push the saved variables onto the stack (see
the example).

This function allows to modify the given variables as
well. In that case the 'edit'-qualifier has to be set
and all passed variables have to be given as references.
The file the variables are saved into is shown in the
editor specified by the EDITOR environment variable
or jed, if EDITOR is undefined. After saving the file
and closing the editor, the file is evaluated, which
should push the (modified) S-Lang objects onto the
stack. These objects are finally assigned to the given
variables.

NOTE: the latter feature is based on the function
'edit_var', which does the same except that the
main purpose is to edit the variables using a
temporary file. Here, the S-lang code is human
readable as well, since no temporary variables
are used to assign the values stepwise. In that
case, however, stack overflow errors may occure.
But who wants to edit such large variables...?

The function supports the following data-types:
Integer_Type, Double_Type, Complex_Type,
Char_Type, String_Type, BString_Type,
Null_Tpye, Void_Type (=Undefined_Type),
as well as
Array_Type, Assoc_Type, Struct_Type, List_Type
Vector_Type, Ref_Type (as structure fields)
##### Example

% define a structure
variable a = struct { example = "foo" };

% save the structure into a file
save_slang_variable("mystruct.sl", a);

% restore the variable into a new one
variable b;
(b,) = evalfile("mystruct.sl");

% edit the original variable
% using a temporary filename
save_slang_variable("/tmp/myedit", &a; edit, delete);

% this operation can be performed using
% 'edit_var' as well (but better readable)
edit_var(&a);

__See also__: evalfile, edit_var

----

#### save_statistics
##### Synopsis
 saves the fit-statistic in a textfile

##### Usage
```c
 save_statistics(String_Type filename);
```

__See also__: eval_counts

----

#### save_xypar
##### Synopsis
 save current xy-fit-parameter in file

<!--%{{{ -->
##### Usage
```c
 save_xypar(String_Type file);
```

##### Description

Save current xy-parameter and xy-function in file.

__See also__: load_xypar, get_xyfit_fun, list_xypar

----

#### savitzky_golay_coefficients
##### Synopsis
 Calculate the Savitzky-Golay coefficients used for data smoothing

##### Usage
```c
 Double_Type[] c = savitzky_golay_coefficients(positive Integer_Type nl, nr, p; qualifiers)
```

##### Description

Calculate the Savitzky-Golay coefficients used for data smoothing. The arguments
`nl'/`nr' are hereby the data points to the left/right while `p' is the polynomial
degree (all have to be positive integer numbers; otherwise their absolute value is
rounded to the next nearest integer). The quanity `p' must not exceed `nl'+`nr'!
The returned array of coefficients is ordered as [c_-nl, ..., c_0, ..., c_nr].
##### Notes

Requires GSL module.
##### Qualifiers

* derivative [=0]: Savitzky-Golay coefficients used for calculating the numerical
derivative of the corresponding order (must not exceed `p', i.e., the order of
the polynomial).

##### Example

% coefficients to smooth data:
c = savitzky_golay_coefficients(15,15,4);
% -> coefficients to compute first derivative:
c = savitzky_golay_coefficients(15,15,4; derivative=1);

__See also__: savitzky_golay_smoothing

----

#### savitzky_golay_smoothing
##### Synopsis
 Smooth noisy data by using a Savitzky-Golay filter

##### Usage
```c
 Double_Type[] smoothed_data = savitzky_golay_smoothing(Double_Type[] data,
positive Integer_Type nl, nr, p; qualifiers)
```

##### Description

The idea of Savitzky-Golay filtering is to approximate the given data within
a moving window (ranging from `nl' data points to the left to `nr' data points
to the right) by a polynomial of order `p'. The respective polynomials are -
in principle - determined by least-squares fits to the window data points.
Luckily, Savitzky & Golay found a way to replace the fitting and evaluating
of the polynomial by taking just linear combinations of neighboring data points
tremendously speeding up the smoothing process. However, their method, which
is implemented here, is valid only for regularly spaced data points. For more
details on the method, see ``Numerical Recipes'', Third Edition, Section 14.9.

Note that the input parameters `nl', `nr', and `p' have to be positive integer
numbers (otherwise their absolute value is automatically rounded to the next
nearest integer). The quantity `p' must not exceed the minimum window semi-
length min(`nl',`nr') and `nl'+`nr' has to be smaller than or equal to the
number of total data points.

Practical hint: Best results are obtained when the full width of the degree 4
Savitzky-Golay filter is between 1 and 2 times the full width at half maximum
of the desired features in the data.
##### Notes

Requires GSL module.
##### Qualifiers

* derivative [=0]: Apart from smoothing noisy data, the Savitzky-Golay method
is also capable to compute numerical derivatives from the fitted polynomials.
In order to calculate the `k'-th derivative of the data, set this qualifier
equal to `k' and divide the returned array by the data stepsize to the power
of `k'. Note that `k' has to be a positive integer (otherwise it is replaced
by the next nearest integer of its absolute value). Note that `k' must not
exceed `p'.
* periodic: Set this qualifer to assume periodic boundary conditions for your
data avoiding special treatment of data points close to the edges and thus
speeding up the computation. In this case, the condition `p'<min(`nl',`nr')
is replaced by `p'<`nl'+`nr'.

##### Example

x = [0:20:#1000];
data = sin(x);
data = data + 0.1\*grand(length(x));
smoothed_data = savitzky_golay_smoothing(data,100,100,4);
first_derivative = savitzky_golay_smoothing(data,100,100,4; derivative=1)/(20./1000.);
second_derivative = savitzky_golay_smoothing(data,100,100,4; derivative=2)/(20./1000.)^2;

__See also__: savitzky_golay_coefficients

----

#### scale_hist
##### Synopsis
 scale a histogram

##### Usage
```c
 Struct_Type hist = scale_hist(hist, scal);
```

##### Description

Scale a histogram structure with fields bin_lo, bin_hi, value, and
err. The value field is scaled by the factor scal. The err field,
if present is scaled accordingly. If other fields are present,
those are preserved and passed on. Only presence of value and
err are checked for, but err is optional.

__See also__: add_hist, shift_hist, stretch_hist

----

#### scargle
##### Synopsis
 Computes the lomb-scargle periodogram of an unevenly sampled lightcurve

##### Usage
```c
 Struct_Type res = scargle (t, c); % where t and c contain time and counts of the lc
```

##### Qualifiers

* fmin: minimum frequency to be used (NOT ANGULAR FREQ!), has precede over pmin, pmax
* fmax: maximum frequency to be used (NOT ANGULAR FREQ!), has precede over pmin, pmax
* pmin: minimum period to be used
* pmax: maximum period to be used
* omega: array of angular frequencies for which the PSD values are desired;
if set, value for numf will be reset to length of omega during code
* noise: for the normalization of the periodogram.
if not set, equal to the variance of the original lc.
* numf: number of independent frequencies
* old: if set computing the periodogram according to J.D. Scargle, 1982, ApJ 263, 835
if not set, computing the periodogram with the fast algorithm
of W.H. Press and G.B. Rybicki, 1989, ApJ 338, 277.
* nu: if set, output structure also contains frequency
* om: if set, output structure also contains angluar frequency

##### Description

(transcribed from IDL-program scargle.pro)

The Lomb Scargle PSD is computed according to the definitions
given by Scargle, 1982, ApJ 263, 835, and Horne and Baliunas,
1986, ApJ 302, 757. Beware of patterns and clustered data
points as the Horne results break down in this case! Read and
understand the papers and this code before using it! For the
fast algorithm read W.H. Press and G.B. Rybicki, 1989, ApJ 338,
277.

The code is still stupid in the sense that it wants normal
frequencies, but returns angular frequency...

The transcribed version is version 1.7, 2000.07.28

Unlike the IDL function, the isis code returns a structure
containing the power spectral density (psd) and period and, if
specified by qualifiers, also the frequency (nu) and angular
frequency (om).

##### Example

variable t = [0:100:0.1];
variable c = sin(t)+((rand(1000)/(2^32-1)\*0.2)+0.9);
variable res = scargle(t, c; nu);
plot(res.period,res.psd);
plot(res.nu,res.psd);

----

#### segment_lc_for_psd
##### Synopsis
 Function to segment a lightcurve in preparation for a PSD,
filtering out the segments which do not fit into multiples of
the segmentation length.

##### Usage
```c
 segment_lc_for_psd(lc,dt,dimseg)
```

##### Qualifiers

* gapfactor: relative factor, telling how large the gap is relative
to dt [default: 1.1]
* ratefield: Name of rate field in lightcurve [default: rate]
* verbose: Increase verbosity to display which parts of the
lightcurve and what proportion was rejected [default=0].

##### Description

Given a lightcurve with gaps, this function segments it such that
only intervals of length "dimseg" (in bins) are present. Data
that does not fit into integer multiples of the segmentation
length are cut off.

ATTENTION: Never use a discrete Fourier transform (e.g.,
foucalc) with a segmentation length ("dimseg") larger than chosen
in this function!
##### Notes

The time array is not altered, so the lightcurve will still
contain gaps, however none that have different length than
"dimseg". In other words: The output data arrays can begin at
arbitrary times, so are \*not\* sorted to always start at integer
multiples of the segmentation length.
##### Example

dt=1.; % (s)
len=64.; % (s)
offset=10; % background level
T=5.; % (s), sinusoid periodidity
omega=2\*PI/T; % Angular frequency (rad/s)
time_arr=[0:len:dt];
lc = struct{ time = time_arr,
rate = offset+sin(omega\*time_arr)+0.1\*grand(int(len/dt)) };
lc_gaps=struct{
time=[lc.time[[0:20]],lc.time[[30:55]]],
rate=[lc.rate[[0:20]],lc.rate[[30:55]]] };
dimseg=16; % (bins)
lc_split = segment_lc_for_psd(lc_gaps, dt, dimseg);
res=foucalc(struct{time=lc_split.time,rate1=lc_split.rate},dimseg);

__See also__: split_lc_at_gaps, foucalc

----

#### setPGPLOTenv
##### Synopsis
 sets environment variables used by PGPLOT

##### Usage
```c
 setPGPLOTenv(Double_Type w, h[, hoff[, voff]]);
```

##### Qualifiers

* gif: sets the PGPLOT_GIF enviroment variables

##### Description

The environment variables for the PGPLOT postscript driver,
<code>PGPLOT_PS_{WIDTH,HEIGHT,HOFFSET,VOFFSET}</code>, are set
to the specified width <code>w</code> and height <code>h</code>. The default
horizontal and vertical offset is <code>hoff=0</code> and <code>voff=0</code>.
The parameters <code>w</code>, <code>h</code>, <code>hoff</code>, <code>voff</code> specify the size in cm,
while the enviroment variables are measured in milli-inches.

If the <code>gif</code> qualifier is given, <code>PGPLOT_GIF_{WIDTH,HEIGHT}</code>
are set to <code>w</code> and <code>h</code> (in pixels).

__See also__: putenv, http://www.astro.caltech.edu/~tjp/pgplot/devices.html

----

#### set_2d_data_grid
##### Usage
```c
 set_2d_data_grid(Double_Type X[], Double_Type Y[]);
```

```
or

```c
 set_2d_data_grid(Double_Type X_lo[], Double_Type X_hi[], Double_Type Y_lo[], Double_Type Y_hi[]);
##### Synopsis
 define a two dimensional data grid required for 2D fits

##### Description

For fitting 2d data the corresponding grid is set with this function.
If <code>set_2d_data_grid</code> is not called, the function <code>define_counts_2d</code>
uses the indices of the image as grid.
For binned fit functions bin_lo and bin_hi have to be provided.
If only single X and Y arrays are provided, only fit functions
which are evaluated on these grid points can be used.

__See also__: define_counts_2d, gauss_2d_integrated, gauss_2d

----

#### set_bin_corr_factor
##### Synopsis
 sets a simple bin correction factor (used in plot_data/unfold)

##### Usage
```c
 set_bin_corr_factor(Integer_Type data_id, Double_Type[nbins] corr_factor);
```

__See also__: load_fermi,get_bin_corr_factor,plot_unfold

----

#### set_gauss_line_par
##### Synopsis
 initializes a line in the lines-model with the parameters of a gauss-line

##### Usage
```c
 set_gauss_line_par([id,] line, area, center, sigma);
```

##### Description

If <code>id</code> is not specified, <code>id=1</code> is used.
<code>line</code> is the name in the lines-model, appearing as parameters
<code>line_lam</code>, <code>line_EW</code>, <code>line_FWHM</code> and <code>line_A</code>.

__See also__: gauss, lines

----

#### set_lines_par_fun
##### Synopsis
 sets the derived amplitude parameter in a lines-model

##### Usage
```c
 set_lines_par_fun([Integer_Type id]);
```

##### Description

The amplitude parameters of the lines-model are set for every line:

<code>set_par_fun("lines(id).line_A", "lines(id).line_EW/lines(id).line_FWHM");</code>

If code{id} is not specified, id=1 is used.

__See also__: gauss, lines, unset_lines_par_fun

----

#### set_params_interpol
##### Synopsis
 interpolates between two parameter sets

##### Usage
```c
 Struct_Type params[] = interpol_params(Struct_Type p1[], Struct_Type p2[]);
```
or

```c
 Struct_Type params[] = interpol_params(Struct_Type p1[], Struct_Type p2[], Double_Type frac);
```
or

```c
 Struct_Type params[] = interpol_params(Struct_Type p1[], Struct_Type p2[], par, Double_Type value);

```

##### Description

<code>p1</code> and <code>p2</code> are parameter lists for the same fit-function
as obtained with <code>get_params</code>. Changing <code>frac</code> from 0 to 1,
the parameter set is interpolated from <code>p1</code> to <code>p2</code>.
If <code>frac</code> is not specified, <code>frac=0.5</code> is assumed.
<code>frac</code> can also be obtained by interpolating
the parameter <code>par</code> to the value <code>value</code>.

----

#### set_par_from_confmap_table
##### Synopsis
 set parameters from a table obtained by get_confmap

##### Usage
```c
 set_par_from_confmap_results(Struct_Type table, Integer_Type i);
```

##### Description

The function sets the parameters of <code>table</code>'s row <code>i</code>.
As parameter names are infered from column names, the FITS
table may have to be read with the <code>casesen</code> qualifier.

__See also__: get_confmap

----

#### set_plot_labels
##### Synopsis
 Restore default plot labels of isis_fancy_plots package

##### Usage
```c
 set_plot_labels(;pg_font="\\fr") -or- set_plot_labels(;pg_font=``\\fr``)
```

##### Qualifiers

* pg_font: ="\\fn", "\\fr", "\\fs", or "\\fi"

##### Description

__See also__: new_plot_labels, fancy_plot_unit, add_plot_unit

----

#### set_plot_widths
##### Synopsis
 Sets plot widths for isis_fancy_plots package

##### Usage
```c
 set_plot_widths([;qualifiers]);
```

##### Qualifiers

* m_width: Model line width
* d_width: Data line width
* de_width: Data error bar line width
* r_width: Residual line width
* re_width: Residual error bar line width
* ebar_x: X error bar term cap length
* ebar_y: Y error bar term cap length
* data_err: !=0 X error bars plotted

##### Description

set_plot_widths(; d_width=#, de_width=#, r_width=#, re_width=#, m_width=#,
ebar_x=#, ebar_y=#, data_err=#);

Sets line widths on data, residuals, error bars, and models, sets the
length of x/y error bar term caps (ebar_x, ebar_y), and toggles the
X error bar plotting. Values are retained until explicitly overwritten.

__See also__: nice_width, pg_info

----

#### set_power_scale
##### Synopsis
 Determine the y-axis is scaled by energy when using the isis_fancy_plot package.

##### Usage
```c
 set_power_scale(Integer_Type);
```

##### Description

set_power_scale(a);

Determine how the y-axis is scaled by energy or wavelength when using
the fancy_plot routines. a=1, E|lambda is set to the midpoint of the
bin. a=2, E|lambda is set to the geometric midpoint (i.e., sqrt(Elo\*Ehi)).
a=3, E|lambda is set to the average value assuming an x^-2 powerlaw.
Any other values, and this message is printed.

__See also__: fancy_plot_unit, add_plot_unit, plot_unfold, plot_counts

----

#### set_simputfile_model_grid
##### Synopsis
 set the model grid in the SIMPUT structure

##### Usage
```c
 set_simputfile_model_grid(Struct_Type str);
```

%```
or

```c
 set_simputfile_model_grid(Struct_Type str, Elow, Eup, Estep);
##### Description

All energies are given in keV. By default, the spectrum is
evaluated from 0.05-24.0 keV in steps of 0.01 keV.

__See also__: create_basic_simputfile,get_simputfile_struct,eval_simputfile,set_simputfile_flux

----

#### set_xyfit_qualifier
##### Synopsis
 modify the meta data of an xy-dataset defined by <code>define_xydata</code> and used for an xy-fit

<!--%{{{ -->
##### Usage
```c
 set_xyfit_qualifier(data_id; qualifiers);
```

##### Description

This function can be used to modify the information for the xy-data.
The used qualifiers are combined with the data structure. Normally
the qualifiers to be set should be <code>x_mdl</code> or <code>curve_parameter</code>.
##### Example

set_xyfit_qualifier(id; curve_parameter=[0:2\*PI:#3000]);

__See also__: define_xydata, xyfit_fun, plot_xyfit

----

#### set_xyfit_sys_err_frac
##### Synopsis
 adds systematic uncertainties to an xy-dataset defined by <code>define_xydata</code>

<!--%{{{ -->
##### Usage
```c
 set_xyfit_sys_err_frac(data_id, [xsyserr,] ysyserr);
```

##### Description

A systematic uncertainty is added in quadrature to either
the x- and y-data or to the latter only. The combined
uncertainty considered by <code>xyfit_residuals</code> then is

err_new = sqrt( err^2 + (data \* syserr)^2 )

where <code>data</code> is the x- or y-data as defined using
<code>define_xydata</code> and <code>err</code> is the corresponding
defined uncertainty.

By default, no systematics uncertainties are considered.
##### Example

% adds 0.5% systematics to the y-data only
set_xyfit_sys_err_frac(1, .005);

% adds systematics to both, x- (0.5%) and y-data (1%)
set_xyfit_sys_err_frac(1, .005, 0.01);

__See also__: xyfit_residuals, define_xydata, set_sys_err_frac

----

#### shift_hist
##### Synopsis
 shift a histogram

##### Usage
```c
 Struct_Type hist = shift_hist(hist, shift);
```

##### Description

Shift the grid of a histogram structure with fields bin_lo,
bin_hi, value, and err. The bin_lo and bin_hi fields are shifted
by the amount shift. If other fields are present,
those are preserved and passed on. Only presence of bin_lo and
bin_hi are checked for.

__See also__: add_hist, scale_hist, stretch_hist

----

#### shift_intpol
##### Synopsis
 Shifts the elements of an array continuously

##### Usage
```c
 Array_Type shift_intpol(Array_Type array, Double_Type n)
```

##### Description

This function does in principle work like the 'shift'
function, with the exception that the amount of the
shift may be a floating point number. The values of
the resulting array are in that case re-distributed
by linear interpolation. Thereby, the the sum of the
array values is still preserved.

__See also__: shift

----

#### show_slang_code
##### Usage
```c
 show_slang_code(String_Type function);
```

##### Description

The function <code>show_slang_code</code> reads all <code>.sl</code> files
in the directories contained in the S-Lang load path,
and \*tries\* to find the definition of <code>function</code>
by parsing the code for {}-brackets and comments.
In its current version, <code>show_slang_code</code> gets confused, e.g.,
from {}-brackets and % characters in strings.

----

#### simbad2ds9
##### Synopsis
 Converts a SIMBAD cone search ASCII file into a DS9 region
file (default outfile: "ds9.reg")

##### Qualifiers

* radius: circle radius (arcsec), default: 20arcsec
* type: regex to filter for source type, default ""

##### Notes

See http://simbad.u-strasbg.fr/simbad/sim-display?data=otypes
for a list of type abbreviations
##### Example

simbad2ds9("simbadascii.txt","output.reg" ; radius=10, type="HXB");
##### Usage
```c
 simbad2ds9(String_Type filename, [String_Type outfile]);
```

----

#### simfit_namespace
##### Synopsis
 implements all SimFit-functions into a namespace

##### Usage
```c
 simfit_namespace(Struct_Type SimFit);
```

##### Qualifiers

* name: name of the new namespace (default: simfit)
* chatty: chattiness of this function (default: 1)

##### Description

Takes a simultaneous fit structure as input and
implements all available functions defined in there
into a new namespace. In this way the user no longer
has to type the structure's name in front of the
functions, but use the functions directly.

Note that in this namespace the ISIS intrinsic
functions, such as 'fit_fun', 'set_par', etc. are
being overwritten by the SimFit-versions.

Furthermore, 'eval_counts' is defined as a combination
of 'eval_groups' and 'eval_global', and 'fit_counts'
now points to 'fit_smart'.

To access the original ISIS functions just switch the
namespace back to 'isis' using 'use_namespace' or
access the functions via isis->function_name

WARNING: there is no check implemented yet that the
given structure actually is a SimFit-structure, so
every structure containing reference to functions may
be passed, which might HARM your ISIS-session or
machine!

FINALLY, if there will be any error the namespace is
most likely set to 'isis' afterwards (we tried to
catch errors in the SimFit-functions but this does
not work for, e.g., syntax errors within the shell).

__See also__: simultaneous_fit, use_namespace

----

#### simplify_polygon
##### Synopsis
 Simplify polygons using the Douglas Peucker Algorithm

##### Usage
```c
 (xx,yy)=simplify_polygon(x,y,d);
```

##### Description

Use the Douglas Peucker Algorithm to simplify the polygon P
defined by the positions in the arrays x,y such that the
maximum distance between all segments  of the resulting
polygon P2 defined by (xx,yy) is smaller than d.
See the help for the function douglas_peucker for caveats
Note that the argument d in simplify_polyon defines the
distance, while the corresponding argument in douglas_peucker
defines the distance squared!

__See also__: douglas_peucker

----

#### simput_athenacrab
##### Synopsis
 returns command to create a standard Athena Crab Simput File

##### Usage
```c
 String_Type cmd = simput_athenacrab(Double_Type flux);
```

##### Description

Flux has to be given in Crab. The naming convention is that the
flux (in micro Crab = 1e-6 Crab or in erg/cm^2/s if unit=cgs) is
encoded in the filename. The spectrum has an absorption of 4E21
cm^-2, norm of 9.5 ph/kev/cm^2/s at 1keV, and powerlaw index of
2.1. The source position is RA=Dec=0.
##### Qualifiers

* unit: crab or cgs, default: crab
* dir: To append a full directory path, default: cwd
* logEgrid: use a logarithmic energy grid (from Elow to
Eup with Nbins), default: no
* Nbins: number of energy bins created from Elow to Eup,
default: 1000

----

#### simulate_data
##### Synopsis
 fakes a spectrum

##### Usage
```c
 Integer_Type id = simulate_data(String_Type RSPfile, Double_Type exposure);
```

##### Description

The currently defined fit-function is used to fake the spectrum.

__See also__: fakeit

----

#### simultaneous_fit
##### Synopsis
 initializes a structure to handle simultaneous/combined
fits of a lot of data

##### Usage
```c
 Struct_Type simultaneous_fit();
```

##### Description

The advantage of fitting a lot of data at the same is
that fit parameters, which seem to be the same for all
data, can be fitted properly. That results in a reduced
number of free parameters for individual observations
or data groups, and thus constrains parameters even
better at low data quality.

The disadvantages are, that a) a lot of painful work
has to be done on tieing and freezing parameters and
b) a fit using 'fit_counts' will take hours to days.
There are several functions implemented within the
returned structure, which can help to solve that issues.

To access the help of a function, simply call it with
the 'help' qualifier (like for the xfig functions).

References for simultaneous fits in ISIS are
Kuehnel et al. 2015, Acta Polytechnica 55(2), 123127
Kuehnel et al. 2016, Acta Polytechnica 56(1), 4146

NOTE: The simultaneous fits are still in development.

----

#### simultaneous_fit.add_data
##### Synopsis
 adds the given data to the simultaneous/combined fit

##### Usage
```c
 simultaneous_fit.add_data(List_Type data_for_one_group);
or simultaneous_fit.add_data(List_Type[] multiple_groups);
```

##### Qualifiers

* nosort: do not sort the parameters (implies 'nologic')
* nologic: do not apply parameter logic

##### Description

NOTE: compared to the previous version of this function the data
has to be provided as a list or array of lists!

The given data will be loaded or defined and added to the
simultaneous/combined fit. The data can be provided in different
formats inside a surrounding list. All data within this list is
treated as a single data group. Further groups can be defined by
either calling add_data again or by providing an array of lists,
where each item corresponds to a group. The data inside the
list(s) can be given as
- String_Type filename: the given filename is loaded by a call
to 'load_data'.
- Integer_Type dataset: the ID of an already existing ISIS
dataset.
- Struct_Type, the field layouts allowed are
- { Double_Type[] bin_lo, bin_hi, value, error }: is passed
to 'define_counts' by default.
- { String_Type filename }: is passed to 'load_data' by
default.
Further fields allow additional features:
- { ..., Integer_Type roc }: Rmf_OGIP_Compliance is set to
'roc' before the data is defined or loaded.
- { ..., Ref_Type loadfun }: reference to a function which
should be used instead of 'load_data' or 'define_counts'.
This function has to return the new ISIS dataset ID.
- { ..., Struct_Type qualifiers } - the structure is passed
as qualifiers to the function for loading or defining
the data.

After the data and corresponding data groups have been defined
the resulting parameter logic is analyzed by
'simultaneous_fit.sort_params'. As this step might take a long
time and is only needed once (during the last call to 'add_data'
or manually), you can skip this step using the 'nosort'
qualifier.
Finally, the analyzed parameter logic is applied to the defined
model and parameters using 'simultaneous_fit.apply_logic' unless
the 'nologic' qualifier is set.
##### Example

% define a simultaneous fit structure first
variable simfit = simultaneous_fit();

% add a single RXTE observation (consisting of a PCA-
% and a HEXTE-spectrum, both taken simultaenously, of
% course)
simfit.add_data({"pca.pha", "hexte.pha"});

% add two data groups consisting of an RXTE (PCA and HEXTE) and
% a Swift-XRT observation
simfit.add_data([ % note the array
{"pha.pha", "hexte.pha"}, % first data group
{struct { filename = "xrt.pha", roc = 0 }} % second data group
]);

% add one already existing ISIS datasets and load an PHA-file
% both defining a single data group
% fit grouped into two data groups
simfit.add_data({1, "file.pha"});

__See also__: load_data, define_counts, simultaneous_fit.sort_params,
simultaneous_fit.apply_logic

----

#### simultaneous_fit.add_data_old
##### Synopsis
 adds the given data to the simultaneous/combined fit (old version)

##### Usage
```c
 simultaneous_fit.add_data(String_Type[] phafiles);
or simultaneous_fit.add_data(Struct_Type[] { bin_lo, bin_hi, value, error });
or simultaneous_fit.add_data(List_Type datagroups);
```

##### Qualifiers

* loadfun: function reference to load the given filename
(default &load_data), further arguments are passed
* loadfunlist: indicates that 'loadfun' already returns an
array of datagroups, i.e. a list with integer
arrays representing the datasets in each group
* nosort: do not sort the parameters (implies 'nologic')
* nologic: do not apply parameter logic
* ROC: value for Rmf_OGIP_Compliance for each data,
has to be given in the same structure as the
input data, i.e., as integer array or list of
integer arrays

##### Description

This function is deprecated and is superseded by the default
one in the simultaneous-fit-structure.

The given data will be loaded or defined and added to the
simultaneous/combined fit. This data can be given as either
a file name to the spectrum as accepted by 'load_data' or a
structure as accepted by 'define_counts'.

If an array of data is given, this data will be treated
as simultaneously recorded data (called a data group).
That means, if any parameter logic is applied afterwards,
the parameters of all datasets are tied to each other.
This logic will be applied automatically unless the
'nologic' qualifier is given. To apply it later,
'simultaneous_fit.apply_logic' may be called. This logic,
however, has to be known first, which is done by
'simultaneous_fit.sort_params' automatically. Again,
this may be skipped by the 'nosort' qualifier.

Further on, a list of several data groups can be given.
This list may contain both, filenames to spectra and
structures and arrays of these as well.
##### Example

% define a simultaneous fit first
variable simfit = simultaneous_fit();

% add a single RXTE observation (consisting of a PCA-
% and a HEXTE-spectrum, both taken simultaenously, of
% course)
simfit.add_data(["pca.pha", "hexte.pha"]);

% add an RXTE (PCA and HEXTE) and a Swift-XRT
% observation (both observations were NOT taken
% simultaneously -> List_Type)
simfit.add_data({["pha.pha", "hexte.pha"], "xrt.pha"});

__See also__: load_data, define_counts, simultaneous_fit.sort_params,
simultaneous_fit.apply_logic

----

#### simultaneous_fit.apply_logic
##### Synopsis
 ties parameters of simultaneous data to each other

##### Usage
```c
 simultaneous_fit.apply_logic();
```

##### Qualifiers

* keepparfun: do not reset all parameter functions
* chatty: chattiness of this function (default: 1)

##### Description

For each defined data an individual set of parameters
exist. If some of the data were taken simultaneously
the parameters should be the same. This function applies
this logic by tieing the parameters of these data to
each other by setting the corresponding parameter
functions via set_par_fun. To do so the functions for
all parameters are set to NULL first (this can be
inhibited using the keepparfun-qualifier).

__See also__: simultaneous_fit.add_data, simultaneous_fit.fit_fun,
set_par_fun

----

#### simultaneous_fit.copy_par
##### Synopsis
 copy the parameters of one group to another

##### Usage
```c
 simultaneous_fit.copy_par(Integer_Type from_group, to_group);
```

##### Qualifiers

* limits: copy parameter limits as well

##### Description

The values of the group parameters of the first given
datagroup are copied to the second datagroup. Parameter
limits are not copied unless the limits-qualifier is
set.

Instead of a single target data group, 'to_group', an
array of groups, Integer_Type[], may be given.
##### Example

% copy the parameter values of group 5 to group 6
simultaneous_fit.copy_par(5, 6);

__See also__: simultaneous_fit.list_groups

----

#### simultaneous_fit.delete_data
##### Synopsis
 deletes the given data from the simultaneous/combined fit

##### Usage
```c
 simultaneous_fit.delete_data(Integer_Type[] group[, Integer_Type[] data]);
```

##### Qualifiers

* keep: the associated data are not deleted by
'delete_data', thus only the logic of the
simultaneous fit is modified

##### Description

The given data 'group' is removed from the simultaneous
fit and the associated data is deleted (using the ISIS
internal function 'delete_data'. The second, optional
argument can be used to delete specific data from a
group specified by its number within the group (starting
at one).

If the first group is deleted, the global parameters
might change. In that case a warning message will be
raised and you should check the parameter dependencies!

Further on, if the first dataset of a group is deleted,
the parameter logic will change and paramaters will be
tied again according to that logic (but of that group
only). Please check the resulting parameter dependencies
(in particular the value-functions of global parameters)
as suggested by the warning message!
##### Example

% delete data group 3 and 5
simultaneous_fit.delete_data([3,5]);

% delete data group 1
% this might cause that a global parameter gets deleted
simultaneous_fit.delete_data(1);

% delete the first spectrum from group 4 only
% this will probably change the group parameter dependencies
simultaneous_fit.delete_data(4, 1);

__See also__: delete_data, simultaneous_fit.add_data

----

#### simultaneous_fit.eval_global
##### Synopsis
 evaluates the model for all global parameters

##### Usage
```c
 Integer_Type simultaneous_fit.eval_global();
```

##### Description

All data groups are included within the evaulation
of the model, but the only free parameters are the
global parameters.
The displayed fit statistic includes all data, but
the global parameters only. The statistics are
available afterwards in the model.stat struct-array.

All qualifiers are passed to eval_counts.

__See also__: simultaneous_fit.eval_groups, eval_counts

----

#### simultaneous_fit.eval_groups
##### Synopsis
 evaluates the model for each (given) data group

##### Usage
```c
 Integer_Type simultaneous_fit.eval_groups([Integer_Type[] groups]);
```

##### Description

Loops over each (given) data group and evaulates the
model using only those parameters assigned to that
group. All other groups and parameters are excluded.
If no group is given, every group is evaluated.
Note, that the number of the first data group is 1
(not 0 as for arrays).
The displayed fit statistics are those of the
individual group only. The statistics are available
afterwards in the model.stat struct-array.

All qualifiers are passed to eval_counts

__See also__: simultaneous_fit.eval_global, eval_counts

----

#### simultaneous_fit.filter_groups
##### Synopsis
 return the group numbers matching a filter

##### Usage
```c
 simultaneous_fit.filter_groups([Integer_Type or String_Type filter]);
```

##### Description

Returns the group numbers which reduced chi-square
matches the given filter. The filter can be one of
the following three options:
1) no filter given - the group with the worst fit
statistic is returned
2) integer (n) given - sorts the groups after their
fit statistic (beginning at the worst) and returns
the first n groups
3) string given - has to be given in the format
"[operator][number]". Those group number are
returned which reduced chi-squares (chi) matches
chi [operator] [number]
The operators >, >=, <, <=, and == are possible.
Multiple of those rules can be specified if
separated with ','.

This function can be very useful if combined with
.select_groups
##### Example

% initialize the simultaneous fit
simpi = simulteneous_fit();
...

% return the three worst fitted groups
grps = simpi.filter_groups(3);

% return those which have 1.7 <= chi^2_red <= 3
grps = simpi.filter_groups(">=1.7,<=3");

% directly select the worst group for fitting,
% plotting, etc.
simpi.select_groups(simpi.filter_groups());

__See also__: simultaneous_fit.select_groups

----

#### simultaneous_fit.fit_fun
##### Synopsis
 defines the model applied within the simultaneous fit

##### Usage
```c
 simultaneous_fit.fit_fun(String_Type fit_fun);
```

##### Qualifiers

* nosort: do not sort the parameters
(implies 'nologic' and 'nohistory')
* nologic: do not apply parameter logic
* nohistory: do not apply the set_par_fun-history
* ask: see set_par_fun_history
* chatty: chattiness of this function (default: 1)

##### Description

The given string is used to define the fit function.
Usually, a lot of data is added to the simultaneous
fit, which might lead to more complicated fit functions.
In order to simplify its definition, some place holders
can be used within the fit function:
% - will be replaced by Isis_Active_Dataset
More placeholders will be implemented in the future.

Afterwards, the parameters are sorted into global and
group ones and the parameter logic is applied to the
model (see simultaneous_fit.sort_params and
simultaneous_fit.apply_logic).

Finally, any parameter functions previously define
with simultaneous_fit.set_par_fun are restored by
calling simultaneous_fit.set_par_fun_history(; apply).
##### Example

% the model shall be an absorbed powerlaw, where there
% are independent parameters of the powerlaw for each
% data group, but a single absorber, which is applied
% to all data
simultaneous_fit.fit_fun("tbnew(1)\*powerlaw(%)");

__See also__: fit_fun, simultaneous_fit.sort_params,
simultaneous_fit.apply_logic, simultaneous_fit.set_par_fun_history

----

#### simultaneous_fit.fit_global
##### Synopsis
 performs a fit of all global parameters

##### Usage
```c
 Integer_Type simultaneous_fit.fit_global();
```

##### Description

All data groups are included within the fit, but the
only free parameters are the global parameters. In
particular, all group parameters are fixed!
The displayed fit statistic includes all data, but
the global parameters only. The statistics are
available afterwards in the model.stat struct-array.

All qualifiers are passed to fit_counts.

__See also__: simultaneous_fit.fit_group, fit_counts

----

#### simultaneous_fit.fit_groups
##### Synopsis
 performs a fit of each (given) data group

##### Usage
```c
 Integer_Type simultaneous_fit.fit_groups([Integer_Type[] groups]);
```

##### Description

Loops over each (given) data group and performs a fit
of only those parameters assigned to that group. All
other groups and parameters are excluded from the fit.
In particular, all global parameters are fixed! If no
group is given, a fit for every group is performed.
Note, that the number of the first data group is 1
(not 0 as for arrays).
The displayed fit statistics are those of the
individual group only. The statistics are available
afterwards in the model.stat struct-array.

All qualifiers are passed to fit_counts.

__See also__: simultaneous_fit.fit_global, fit_counts

----

#### simultaneous_fit.fit_pars
##### Synopsis
 runs fit_pars for the given data group

##### Usage
```c
 Struct_Type simultaneous_fit.fit_pars( Integer_Type group );
```

```
or

```c
 Struct_Type simultaneous_fit.fit_pars( String_Type parname );
##### Qualifiers

* frozen: [=0] Perform fit_pars also for frozen Parameters.
NOTE: just works if 'parname' is given!
* force: If group=0 (globals) force to perform fit_pars for all
globals. Without this qualifier the parname of ONE global
parameter is required!

##### Description

Calculates the confidence level(s) of the parameter(s)
associated to the given data 'group' or 'parname'.
The function uses 'fit_pars' and returns its result.

Instead of the number of a data group, the name of
a parameter may be given instead. In that
case the confidence level of this parameter is
calculated only.

Note that for a global parameter the 'parname' has
to be given!

Also note that normally frozen parameters are ignored.
If this function is called with 'parname' and the
'frozen' qualifier is given, the confidence level
is calculated nevertheless.

It is important to keep in mind, that a 'fit_pars'
can lead to a new best fit. If the confidence levels
of a group as a whole are calculated a new best fit
of one of the group parameter is automatically taken
into account, but not if the confidence level of a
single parameter (e.g., using 'parname') is looked
at. This is a problem especially for the global
parameters. Use 'mpi_fit_pars' for your advantage!

Note, that a usual 'fit_pars' will take a tremendous
amount of time (like 'fit_counts'). Thus, this
function accepts one data group only and it is
recommended to use only one parameter in addition.
It might be helpful to reduce the accuracy with which
fitting methods try to calculate chi square values
and/or parameters (see set_fit_method).

Further on, this approach is ideal to be used with
Torque (see 'simultaneous_fit.fit_pars_jobfile').

All qualifiers are also passed to fit_pars.

__See also__: fit_pars, simultaneous_fit.list_groups,
simultaneous_fit.list_global, simultaneous_fit.fit_pars_jobfile

----

#### simultaneous_fit.fit_pars_collect
##### Synopsis
 reads the results of a former fit_pars or mpi_fit_pars
and checks for a new best-fit

##### Usage
```c
 Struct_Type simultaneous_fit.fit_pars_collect(String_Type FITSpattern);
```

##### Qualifiers

* chitol: how much a delta chi-square  has to be
to actually consider this fit as a new
best-fit or a worse-fit (default: 1e-10)
* setnewbestpars: sets the parameters to those of a
possible new best-fit (see below)
* bestpars: reference to a variable where all found
parameter values and other helpful
information is returned
* parspriority: in case parameters of a new best-fit
are set, this qualifiers decides
whether the changed "global"- or
"group"-parameters are set (both are
not possible!) (default: "global")
* PARpattern: the string which replaces "_conf.fits"
to match the parameter file
(default: "_best.par")
* silent: suppress warning messages (BIT wise)
1: "fit ... is worse"
2: "new best-fit ... found"
4: "no uncertainties ... found"
8: "setting new ... re-fit ..."

##### Description

If the uncertainties of a simultaneous fit have been
calculated using Torque-jobfiles (e.g., by using the
mpi_fit_pars_jobfile function), the results will be
saved in several FITS-files.
This function reads all FITS-files matching the given
'FITSpattern' and returns a single structure containing
all results (similar to a single fit_pars structure).
Furthermore, if a new best-fit was found during one
of the calculations, a warning message will be shown.
In case of a crashed calculation (resulting in missing
uncertainties) a warning message will be shown as well.

If the qualifier "setnewbestpars" is set, the parameters
of a new best-fit will be set automatically. However,
new global parameters causes the group parameters to be
fitted again and vise versa. For this reason, new group
parameters are discarded in favor for new global ones
(to change this priority use the 'parspriority'
qualifier).

Note, that the par-files saved by fit_pars are needed to
set the remaining parameters in case of a new best-fit!

__See also__: simultaneous_fit.mpi_fit_pars_jobfile, simultaneous_fit.fit_pars_jobfile

----

#### simultaneous_fit.fit_pars_jobfile
##### Synopsis
 writes a Torque-jobfile to calculate confidence levels

##### Usage
```c
 simultaneous_fit.fit_pars_jobfile(String_Type jobfile, scriptfile);
```

##### Qualifiers

* force: overwrites an existing jobfile or script
(default: don't overwrite)
* writescript: writes a template for the script into
the given filename (file will be overwritten)

##### Description

Writes a Torque 'jobfile' to calculate the confidence
levels of all (free) parameters. Therefore, the filename
of the script for loading the data, defining the model
and running simultaneous_fit.fit_pars is mandatory.
This script will be called by each job with a
command line argument, which is either
- the data group index, for which the confidence levels
should be calculated for or
- the parameter name to compute the level
for a single parameter in the global group.
This means that the parameters of a data group are
treated in parallel by multiple jobs.
In case of a global parameter, the data group argument
is omitted and the name of the global parameter is
given instead. The command lines arguments can be
accessed using '__argv' and '__argc'.

If the qualifier 'writescript' exists, a template for
the script described above will be written into the
given 'scriptfile'name. This has to be modified
afterwards to ensure compatibility and should be
treated as a support!
Warning: in case of an already existing filename this
file will be overwritten!

__See also__: simultaneous_fit.fit_pars

----

#### simultaneous_fit.fit_pars_run_job
##### Synopsis
 submits the (MPI-)fit_pars-jobfiles until no better fit is found

##### Usage
```c
 Struct_Type simultaneous_fit.fit_pars_run_job(
String_Type or String_Type[] globaljobs, groupjobs,
String_Type FITSpattern, String_Type or Ref_Type save
);
```

##### Qualifiers

* first: submits either the jobs for the global- (=0)
or the group-parameters (=1, default) first
* maxiter: maximum number of iterations (default: 3)
* wait: seconds to wait before it is checked if the
Torque-jobs have completed (default: 10)

##### Description

Usually, the uncertainties of the group- and global-
parameters should be calculated using Torque-jobs.
However, if one job finds a new best-fit of a, e.g.,
group parameter, the uncertainties of the global
parameters have to be re-calculated (and vise versa).
Note, that the calculations of remaining groups in
that case, which might still be running, don't have
to be canceled, because the global parameters might
stay the same even a better group parameter is found!

This function submits the Torque-jobs for different
kinds of parmeters (given as filename-patterns or the
filename(s) for the 'globaljobs' and 'groupjobs')
until no further best-fit has been found. By default,
the group jobs are submitted first. If a new best-fit
was found, the internal .save function is called with
the given 'save'-filenam to ensure that the current
(better) parameters can be loaded by the  re-submitted
jobs. If the 'save'-parameter is a reference to a
function, this one will be called instead of saving
the fit automatically. This function does not get any
parameters and should save parameter AND the model
field of the simultaneous fit.
Once no better fit is found a structure similar to
that of fit_pars is returned.

As a protection for an (infinite) loop, the above
procedure is repeated only a few times (adjustable
using the 'maxiter' qualifier).

IMPORTANT:
This function is only a control function! It has to
know the current parameters and dataset logic, but
does not require any CPU power! Thus, to free memory,
the complete loaded DATA, ARFs, and RMFs are DELETED!
So you CANNOT work with your data afterwards! If you
agree with that procedure please set the 'agree'-
qualifier. Otherwise, the function will exit.

__See also__: simultaneous_fit.fit_pars_jobfile

----

#### simultaneous_fit.fit_smart
##### Synopsis
 combines group- and global-fits to achieve the best-fit

##### Usage
```c
 Integer_Type simultaneous_fit.fit_smart();
```

##### Qualifiers

* maxiter: maximum number of iterations (default: 10)
* tol: favored difference in chi square (default: 0.1)
* chatty: output statistics for each iteration (default: 1)

##### Description

By alternating between fitting the group parameters
and then the global parameters only, a best-fit is
tried to achieve. The fit is successful, if the
difference in delta chi square compared to the
previous iteration is less than the given tolerance.
The loop interrupts, if a maximum number of allowed
iterations is reached (the default number is low on
purpose).

Some tests showed that the final best-fit here is worse
than that achieved by 'fit_counts' (in the order of 10%
in reduced chi square). If a lot of data is fitted,
this method is, however, much faster than a simple
'fit_counts' (which might take days...).

All qualifiers not listed above are passed to fit_counts

__See also__: simultaneous_fit.fit_global, simultaneous_fit.fit_groups

----

#### simultaneous_fit.freeze
##### Synopsis
 freezes a/many parameter/parameters

##### Usage
```c
 simultaneous_fit.freeze(String_Type parameter);
```

##### Description

In princible, this function does the same as 'freeze'
with the modifcation that place holders are allowed:
% - set the function for all defined data
Note, that here the parameter name has to be provided,
not the parameter id!

__See also__: freeze

----

#### simultaneous_fit.get_par
##### Synopsis
 get the value of a/many fit parameter/parameters

##### Usage
```c
 Double_Type[] simultaneous_fit.get_par(String_Type parameter);
```

##### Description

Does the same as 'get_par' with the modification that
the following place holders are allowed:
% - set the value for all defined data
Note, that here the parameter name has to be provided,
not the parameter id!

All qualifiers are passed to get_par.
##### Example

% get the normalization of all powerlaws
norms = simultaneous_fit.get_par("powerlaw(%).norm");

__See also__: get_par

----

#### simultaneous_fit.group_stats
##### Synopsis
 prints a summary about the groups current fit-statistics

##### Usage
```c
 Integer_Type[] simultaneous_fit.group_stats();
```

##### Description

A histogram of the current red. chi-squares of all
groups is printed into the terminal. The histogram
ranges from the smallest to the largest found
red. chi-square. This range is shown as two ticmarks
below the x-Axis. The detailed statistics of each
group can be found in the .model.stat-field.
The returned array holds the numbers of groups
sorted by their red. chi-square, starting at the
worst.

__See also__: printhplot

----

#### simultaneous_fit.list_data
##### Synopsis
 lists the data groups and their associated dataset IDs

##### Usage
```c
 simultaneous_fit.list_data([&variable]);
```

##### Description

Lists the data groups and their associated dataset IDs and
number of group parameters. If the optional reference to a
variable is provided, then the IDs as an array of lists
is put into this variable, where each item corresponds to
a data group.

----

#### simultaneous_fit.list_global
##### Synopsis
 lists all global parameters

##### Usage
```c
 simultaneous_fit.list_global();
```

##### Description

Like 'list_par' this function lists all global parameters.

__See also__: list_par

----

#### simultaneous_fit.list_groups
##### Synopsis
 lists all parameters of specific data groups

##### Usage
```c
 simultaneous_fit.list_groups([Integer_Type[] groups]);
```

##### Qualifiers

* tied: list parameters, which are determined by a
value function, also

##### Description

Like 'list_par' this function lists all parameters of
one or more specific data groups. Note, that unlike
arrays the index of the first data group is 1. If no
data groups are given the parameters of all groups
are listed. By default, parameters without a value
function are listed only.

__See also__: list_par

----

#### simultaneous_fit.load
##### Synopsis
 loads a simultaneous fit from a FITS-table

##### Usage
```c
 simultaneous_fit.load(String_Type filename);
```

##### Description

Uses 'fits_load_fit' to first restore the fit and then
to load the model-field of the simultaneous fit from
the FITS-table. Because the data associations don't
have to be analyzed, any additional use of
'simultaenous_fit.add_data' before loading the fit (if
the data is defined by, e.g, 'define_counts') should
be called with the 'nosort' qualifier to save the time
needed to create the model-field.

The function recognizes if the simfit was saved with
the 'alt'-qualifier of  simultaneous_fit.save. In this
case 'fits_load_fit' is not used.

All qualifiers are passed to fits_load_fit.

##### Example

% initialize a new simultaneous_fit
simfit = simultaneous_fit();
% define the data
simfit.add_data({
[define_counts(...), ...],
...
}; nosort);
% restore the fit (parameters and model-field)
% from a file previously created by simfit.save
simfit.load("best-fit.fits"; nodata);

__See also__: simultaneous_fit.save, simultaneous_fit, fits_load_fit

----

#### simultaneous_fit.load_model
##### Description

DEPRECATED, use simultaneous_fit.load

__See also__: simultaneous_fit.load

----

#### simultaneous_fit.mpi_fit_pars
##### Synopsis
 runs mpi_fit_pars for the given data group

##### Usage
```c
 Struct_Type simultaneous_fit.mpi_fit_pars( Integer_Type group );
```

##### Description

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
ATTENTION: This function does not work in an open
isis session, as it links to 'mpi_fit_pars'!
It is supposed to be used in a script file
submitted as a torque job only!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

Calculates the confidence levels of the FREE parameters
associated to the given data group.
This function uses the function 'mpi_fit_pars' and its
result is returned.

The argument <group> represents the index  of the
data GROUP, of which the confidence levels are supposed
to be calculated.
group = 0 corresponds to the 'group' of the GLOBAL
parameters!

Note, that a usual 'fit_pars' will take a tremendous
amount of time (like 'fit_counts'). Thus, this
function accepts one data group only and it is
recommended to use only one parameter in addition.
It might be helpful to reduce the accuracy with which
fitting methods try to calculate chi square values
and/or parameters (see set_fit_method).

Further on, this approach is ideal to be used with
Torque (see 'simultaneous_fit.mpi_fit_pars_jobfiles').

All qualifiers are also passed to mpi_fit_pars

__See also__: fit_pars, mpi_fit_pars, simultaneous_fit.list_groups,
simultaneous_fit.list_global, simultaneous_fit.mpi_fit_pars_jobfiles

----

#### simultaneous_fit.mpi_fit_pars_jobfiles
##### Synopsis
 writes a Torque-jobfile to calculate confidence levels

##### Usage
```c
 simultaneous_fit.mpi_fit_pars_jobfiles(String_Type jobfile, scriptfile);
```

##### Qualifiers

* walltime: : [="00:01:00"] Torque walltime for global & group
jobfile
* wt_global: : [=walltime] Torque walltime for global jobfile
* wt_groups: : [=walltime] Torque walltime for groups jobfile
* jobname: : [="simpi_fitpars"] Name of Torque job (& files!)
* logpath: : [=pwd+jobname] Directory for log files
* force: : overwrites an existing jobfile or script
(default: don't overwrite)
* writescript: :  writes a template for the script into
the given filename (file will be overwritten)

##### Description

Writes a Torque 'jobfile' to calculate the confidence
levels of all parameters. Therefore, the filename of
the script for loading the data, defining the model
and running simultaneous_fit.fit_pars is mandatory.
This script will be called by each job with a
command line arguments, which represents the data
group, for which the confidence levels should be
calculated for. The command line arguments can be
accessed using '__argv' and '__argc'.

In case the 'scriptfile' requires additional command
line arguments add them to the 'scriptfile'-string,e.g.,
like "scriptfile.sl arg1 arg2", and make sure these
are asigned correctly!

If the qualifier 'writescript' exists, a template for
the script described above will be written into the
given 'scriptfile'name. This has to be modified
afterwards to ensure compatibility and should be
treated as a support!
Warning: in case of an already existing filename this
file will be overwritten!

__See also__: simultaneous_fit.fit_pars

----

#### simultaneous_fit.plot_group
##### Synopsis
 plots data and model of a specific data group

##### Usage
```c
 simultaneous_fit.plot_group([Integer_Type group]);
```

##### Description

This function plots the data and model of the given
data group using the 'plot_data' function.

If no group number is given the currently selected
group is plotted (if it is the only one selected).
A specific group can be selected using .select_groups

All qualifiers are passed to plot_data

__See also__: plot_data, simultaneous_fit.select_groups

----

#### simultaneous_fit.restore
##### Synopsis
 To be written

##### Usage
```c
 simultaneous_fit.restore();
```

##### Description

To be written...

__See also__: simultaneous_fit.setrestore

----

#### simultaneous_fit.save
##### Synopsis
 saves the simultaneous fit to a FITS-table

##### Usage
```c
 simultaneous_fit.save_model(String_Type filename[, Struct/String_Type conf]);
```

##### Qualifiers

* alt: use an alternative to 'fits_save_fit', see text;
all other qualifiers are passed to 'fits_save_fit'

##### Description

Uses 'fits_save_fit' to save the simultaneous fit and,
most importantly, its model-field. The creation of this
field may take some time due to the fact that the fit-
function as well as the data associations have to be
analyzed. Thus, saving it to a FITS-table speeds up
the loading process if 'simultaneous_fit.load' is used.

However, the large number of parameters of a simfit
can lead to "out of memory" exception when using
'fits_save_fit'. In this case, the 'alt'-qualifier
uses an alternative FITS-structure for saving, i.e.,
'fits_save_fit' is not used. Note that in this case
only the parameters (like in 'save_par') are saved,
but _not_ the loaded data, noticed energy bins, etc.

__See also__: simultaneous_fit.load, fits_save_fit

----

#### simultaneous_fit.select_groups
##### Synopsis
 select the default groups to be worked on

##### Usage
```c
 simultaneous_fit.select_groups([Integer_Type[] groups]);
```

##### Description

Some functions within in the simultaneous structure
accept an optional array of group numbers, on which
they perform their taks. For instance, .fit_groups
either performs a fit for the given groups only. If
none are given, the default is to fit all groups.
This function, however, changes this default such
that the here given group(s) are used by default.
If no groups are given the default is set back to
all groups. To get the current set default you may
check the .model.current_groups variable (-1 means
all groups are used).

----

#### simultaneous_fit.setrestore
##### Synopsis
 To be written

##### Usage
```c
 simultaneous_fit.setrestore();
```

##### Description

To be written...

__See also__: simultaneous_fit.restore

----

#### simultaneous_fit.set_global
##### Synopsis
 Sets a specific group parameter to be fitted globally

##### Usage
```c
 simultaneous_fit.set_global(String_Type grouppar);
```

##### Description

A wrapper around simultaneous_fit.set_par_fun, which
simply ties the given group parameter name (using the
%-placeholder instead of the dataset index) to a single,
global parameter.
If successful, a warning message will be shown.
##### Example

% use a single photon index for all data
simultaneous_fit.fit_fun("powerlaw(%)");
simultaneous_fit.set_global("powerlaw(%).PhoIndex");

__See also__: simultaneous_fit.unset_global,simultaneous_fit.set_par_fun

----

#### simultaneous_fit.set_par
##### Synopsis
 set the value of a/many fit parameter/parameters

##### Usage
```c
 simultaneous_fit.set_par(String_Type parameter[, Double_Type value[, Integer_Type freeze[, Double_Type min, max]]]);
```

##### Description

Does the same as 'set_par' with the modification that
the following place holders are allowed:
% - set the value for all defined data
Note, that here the parameter name has to be provided,
not the parameter id!

All qualifiers are passed to set_par.
##### Example

% set the normalization of all powerlaws
simultaneous_fit.set_par("powerlaw(%).norm", 1, 0, 0, 10);

__See also__: set_par

----

#### simultaneous_fit.set_par_fun
##### Synopsis
 Define the value of a/many fit parameter.parameters using a function

##### Usage
```c
 simultaneous_fit.set_par_fun(String_Type parameter, String_Type valuefunction);
```

##### Description

In princible, this function does the same as 'set_par_fun'
with the modifcation that place holders are allowed:
% - set the function for all defined data
Note, that here the parameter name has to be provided,
not the parameter id!

This function tries to recognize, if the value function
is a parameter itself, which should be applied to a set
of the same parameters (e.g. the photon indices are set
to a single one). In that case the parameter given in
the value function will be treated as a global one from
now on.

On the other side, if the value functions of a set of
parameters are deleted (valuefunction=NULL), which were
tied to a global parameter before, this parameter is
treated as a group one.

In both cases, a warning message will be shown in order
to inform the user which parameter has been treated as
global or group parameter.

In an upcoming version, the place holders are allowed
in the value function as well.

Any call to this function is remembered in an internal
history for applying the calls later again (see
simultaneous_fit.set_par_fun_history).
##### Example

% use a single photon index for all data, while
% keeping individual normalizations
simultaneous_fit.fit_fun("powerlaw(%)");
simultaneous_fit.set_par_fun("powerlaw(%).PhoIndex",
"powerlaw(1).PhoIndex");

% allow individual photon indices again
simultaneous_fit.set_par_fun("powerlaw(%).PhoIndex",
NULL);

% more fascinating, tie the photon index to a function
% of the powerlaw normalization
simultaneous_fit.set_par_fun("powerlaw(%).PhoIndex",
"constant(1).factor + powerlaw(%).norm \* constant(2).factor");

__See also__: set_par_fun, simultaneous_fit.set_par_fun_history

----

#### simultaneous_fit.set_par_fun_history
##### Synopsis
 applies or clears the history of set_par_fun

##### Usage
```c
 simultaneous_fit.set_par_fun_history(; qualifiers);
```

##### Qualifiers

* get: returns the history of calls to set_par_fun
* print: print the history
* apply: applies all calls of the history again
* ask: prompts the user before applying each call
of the history (apply-qualifier required)
* clear: clears the history
* chatty: chattiness of this function (default: 1)
* nologic: do not call apply_logic during the history
is applied (apply-qualifier)

##### Description

Whenever simultaneous_fit.set_par_fun is called the
arguments passed are remembered in an internal
history. This functions allows to apply each call of
the history again, retrieve the history, or clear it.

This is particularly useful once the parameter logic
is set by simultaneous_fit.apply_logic. Note that
simultaneous_fit.fit_fun applies the history auto-
matically.
Note that applying the history first resets the
parameter logic with simultaneous_fit.apply_logic.

In case the history should be returned a list is
returned, where each item is a call to set_par_fun
with the two strings which have been passed.

__See also__: simultaneous_fit.set_par_fun,simultaneous_fit.apply_logic

----

#### simultaneous_fit.sort_params
##### Synopsis
 sort all fit parameters into global and group ones

##### Usage
```c
 simultaneous_fit.sort_params();
```

##### Qualifiers

* chatty: chattyness of this function (default: 1)

##### Description

The defined data may contain both, simultaneous and non-
simultaneous data. Thus, there are parameters which apply
to individual data on one hand (called group parameters),
and on the other hand parameters which act on all defined
data (called global parameters). This function determines
the relationship between the defined data in order to sort
the existing parameters into global and group parameters.

__See also__: simultaneous_fit.add_data, simultaneous_fit.apply_logic

----

#### simultaneous_fit.steppar
##### Synopsis
 runs steppar based on the simultanous fit logic

##### Usage
```c
 Struct_Type simultaneous_fit.steppar( String_Type parname );
```

```
or

```c
 Struct_Type simultaneous_fit.steppar( Integer_Type idx );
##### Qualifiers

* keys: An additional structure is returned that can be used as FITS header keys
* frozen: [=0] Perform steppar also for frozen Parameters.
* range: [parmin,parmax] Stepping range. Default is the
minimal/maximal allowed parameter value.
* nsteps: [=10] Number of steps the parameter 'par' is
stepped from range[0] to range[1].
* reset: If given after each step the initial parameter set, which was
valid before this function was called, is restored.
* fit: [=&fit_counts] Reference to the function running the fit algorithm.
* fitargs: Arguments required by the 'fit' function. See __push_list for
format information!
* rerun: Reruns a stepping procedure based on results of a previous run,
i.e., before each step the according parameter set of the previous
run is loaded, e.g., to improve the results using another fit_method.
* resume: Missing steps in the given steppar-file will be calculated based
on the previous steps, i.e., resuming the stepping where it was
stopped.
* check: [=0] Before each step saved steppar informations of other stepped
parameters are gathered and checked for a parameter set with a
better chi2 (using steppar_get_bestparams). In case a better
parameter set was found the stepping will be restarted.
\* ATTENTION: 'save' qualifier is required !!!
\* Gathered are steppar-files, which match the pattern
given with 'save',e.g., if save is "steppar_PID001.fits"
all files "steppar_PID???.fits" are globed!
Note that the affix "_PID???" is automaticcaly appended to
the save string if it does not exist (see 'save' qualifier!)
\* The Integer 'check' is set to is the maximal number of
restarts.
\* A parameter set is considered better if
chi2_new < chi2_init \* ( 1 - dchi2 )
\* NOTE: Parameter grouping is possible (see steppar_get_bestparams)

* dchi2: [=0.1] Fractional limit for the chi2 of a new parameter set to be
considered as a better parameter set (see 'check'):
chi2_new < chi2_init \* ( 1 - dchi2 ).
* save: After each stepping the result is saved in the file given
(as String_Type) with this qualifier. The chi2 of undone steps
are set to 0.! Also note that the filename is appended with
the parameterindex: 'steppar.fits' -> 'steppar_PID001.fits'
* force: Forces to overwrite an existing file given with 'save'.
* chatty: Prints fitting information.

##### Description

This function is calling 'steppar' with an adjusted fitting function:
fit = &_simultaneous_fit_steppar_fit which first calls either %.fit_groups
or %.fit_global depending on the affiliation of the given parameter.
Afterwards %.fit_smart is called (with the passed qualifiers).
For more detailed information see the help of 'steppar'!

Qualifiers are also passed to 'steppar' & '%.fit_smart'!

__See also__: %.fit_smart, steppar

----

#### simultaneous_fit.thaw
##### Synopsis
 thawes a/many parameter/parameters

##### Usage
```c
 simultaneous_fit.thaw(String_Type parameter);
```

##### Description

In princible, this function does the same as 'thaw'
with the modifcation that place holders are allowed:
% - set the function for all defined data
Note, that here the parameter name has to be provided,
not the parameter id!

__See also__: thaw

----

#### simultaneous_fit.unset_global
##### Synopsis
 A specific group parameter is fitted individually again

##### Usage
```c
 simultaneous_fit.unset_global(String_Type grouppar);
```

##### Description

A wrapper around simultaneous_fit.set_par_fun, which
simply unties the given group parameter name (using the
%-placeholder instead of the dataset index), which was
tied to a single global parameter before.
If successful, a warning message will be shown.
##### Example

% use a photon index for each data group
simultaneous_fit.unset_global("powerlaw(%).PhoIndex");

__See also__: simultaneous_fit.set_global,simultaneous_fit.set_par_fun

----

#### sinwave2 (fit-function)
##### Description

a\*sin(b\*alpha+c)+d
(ISIS fit-function sinwave seems to be defined for keV space:
sinwave({a,b,c,d};alpha) = sinwave2({a,b,c,d};_A(alpha)))

----

#### SIprefix
##### Usage
```c
 Double_Type SIprefix(String_Type prefix)
```

----

#### sitar_avg_cpd
##### Synopsis
 Create an averaged cross power spectral density.

##### Usage
```c
 (f,psd_a,psd_b,cpd,navg,avg_a,avg_b,) = sitar_avg_cpd(cnts_a,cnts_b,l);
```

##### Qualifiers

* dt: [Length of evenly spaced bins. Default == 1.]
* times: [Times of measurements (otherwise presumed to have no gaps).]
* norm: [Determine PSD normalization convention. =1, 'Leahy normalization'. Poisson noise PSD == 2, in absence of deadtime effects. !=1, rms or Belloni-Hasinger or Miyamoto normalization, i.e., PSD == (rms)^2/Hz & Poisson noise== 2/Rate.]

##### Description

Take an evenly spaced lightcurve (presumed counts vs. time), and
calculate the PSD and CPD in segments of length l, averaged over
the whole lightcurve.  Segments with data gaps are skipped.
Deadtime corrections to Poisson noise are \*not\* made. Poisson
noise is \*not\* subtracted from average PSDs.

Inputs:
cnts_a/b: Arrays of total counts in each time bin
l       : Length of individual PSD segments (use a power of 2!!!)

Outputs:
f       : PSD frequencies ( == 1/Input Time Unit)
psd_a/b : Average PSDs
cpd     : Normalized Cross Power Spectral Density (complex array)
navg    : Number of data segments going into the averages
avg_a/b : Average number of counts per segment of length l

__See also__: sitar_avg_psd, sitar_lbin_cpd, sitar_lbin_psd, sitar_define_psd, sitar_lags

----

#### sitar_avg_psd
##### Synopsis
 Create an averaged power spectral density.

##### Usage
```c
 (f,psd,navg,avg_cnts [,psd_err]) = sitar_avg_psd(cnts,l);
```

##### Qualifiers

* dt: [Length of evenly spaced bins. Default == 1.]
* times: [Times of measurements (otherwise presumed to have no gaps).]
* norm: [Determine PSD normalization convention. =1, Leahy normalization. Poisson noise PSD == 2, in absence of deadtime effects. !=1, rms or Belloni-Hasinger or Miyamoto normalization, i.e., PSD == (rms)^2/Hz & Poisson noise== 2/Rate.]
* err: [If it exists, also return the PSD error calculated directly by assuming each sample has 100% error.]

##### Description

Take an evenly spaced lightcurve (presumed counts vs. time), and
calculate the PSD in segments of length l, averaged over the
whole lightcurve.  Segments with data gaps are skipped.  Deadtime
corrections to Poisson noise are \*not\* made. Poisson noise is
\*not\* subtracted from average PSD.

Inputs:
cnts    : Array of total counts in each time bin
l       : Length of individual PSD segments (use a power of 2!!!)

Outputs:
f       : PSD frequencies ( == 1/Input Time Unit)
psd     : Average PSD.
navg    : Number of data segments going into the average
avg_cnts: Average number of counts per segment of length l

Optional Output:
psd_err : Estimated error on the PSD, calculated from lightcurve sample

__See also__: sitar_avg_cpd, sitar_lbin_cpd, sitar_lbin_psd, sitar_define_psd, sitar_lags

----

#### sitar_bin_events
##### Synopsis
 Bin an event-based lightcurve.

##### Usage
```c
 lc = sitar_bin_events(t,dt,gti_lo,gti_hi);
```

##### Qualifiers

* tstart: [Beginning of first output time bin. Default: min(t).]
* tstop: [End of last output time bin. Default: max(t).]
* obin: [For a tstop, last bin width might be < dt.  Include this overflow bin if width is > obin\*dt. Default: obin=0.1.]
* user_bin.lo: [Lower time bounds for user defined grid.]
* user_bin.hi: [Upper time bounds for a user defined grid. Overrides dt, tstart, and tstop inputs.]
* minexp: [Do not include bins with exposure < minexp. Default: 0.]
* delgap: [If set, delete 0 exposure bins from the lightcurve, otherwise set their rate & error to 0.]

##### Description

Inputs:
t          : Discrete times at which rates are measured
dt         : Width of evenly spaced time bins in rebinned lightcurve
(Ignored if a user_bin is input.)

Outputs:
lc.rate    : Mean rate of resulting binning
lc.err     : Error on bin rate (minimum = -log(0.32)/(bin exposure))
lc.cts     : Counts in a bin
lc.bin_lo  : Lower time bounds of binned lightcurve
lc.bin_hi  : Upper time bounds of binned lightcurve
lc.expos   : Exposure of a time bin (i.e., intersection with
good time intervals)

__See also__: sitar_rebin_rate

----

#### sitar_define_psd
##### Synopsis
 Store a power spectral density as a fittable dataset.

##### Usage
```c
 id = sitar_define_psd(flo,fhi,psd,err [,noise]);
```

##### Qualifiers

* noise: [Same as optional input, noise.]

##### Description

Inputs:
f_lo   : Low value of PSD frequency bin (Hz -> keV)
f_hi   : High value of PSD frequency bin (Hz -> keV)
psd    : Array of PSD values (Power -> Counts/bin)
err    : Array of PSD Errors

Optional Input:
noise  : Array (\*or single value\*) of Poisson noise levels.
If undefined, background is undefined.

Outputs:
id     : Dataset Index

__See also__: sitar_avg_cpd, sitar_lbin_cpd, sitar_avg_psd, sitar_define_psd, sitar_lags

----

#### sitar_global_optimum
##### Synopsis
 Loads a dataset with a non-unity AREASCAL keyword or column

##### Usage
```c
 ans = sitar_global_optimum( cell, ncp_prior, type [; first, mean_prior, rate_prior, alpha=Double_Type, beta=Double_Type] );
```

##### Description

Inputs:
cell      : A structure, with cell.pops, cell.size, cell.lo_t
cell.hi_t,cell.dtcor (see sitar_make_data_cells)
ncp_prior : Parameter for prior on number of 'blocks'
type      : Identical to type from sitar_make_data_cells

Qualifiers:
first     : If set, the code runs in 'trigger' mode, and returns upon
the first sign of a change, so long as it is greater
than 'first' cells from the beginning of the
lightcurve

EVENT MODE PRIORS (type=1 or 2)-

Default prior is that p_1, the probability of one or
more photons in a frame, is uniformly dsitributed
from 0->1.

alpha     : >=0 implies p_1 prior is (1+alpha) (1-p_1)^alpha

mean_prior: if set, prior on \*rate\* is exp(-Lambda/Lambda_0),
where Lambda_0 is the mean rate from the entire
observation.  Supercedes any choice on alpha.

rate_prior: if set, prior is chosen to be uniform between
rate_low,   rates ranging from rate_low -- rate_high, with
rate_high   defaults of rate_low = 1/3 mean rate and
rate_high = 3 times mean rate. Supercedes any
choice of alpha or mean_prior.

BINNED MODE PRIORS AND POSTERIORS (type=3)-

alpha,    : The prior on the bin rate (sort of) goes as
beta        (Lambda)^(alpha-1) Exp(-beta\*Lambda), where
Lambda=rate, and the default is alpha=beta=1

max_like  : Use maximum likelihood, log(Pmax) = N log(N/T) -N,
as the posterior test function.  Overrides any
choice of alpha & beta for binned mode.

Outputs:
results.cpt  : Array of change point locations for the maximum
likelihood solution (indices are specific to the
cell input);
results.last,: (Diagnostic purposes only) Arrays of the
.best   location of the last change point and the
associated maximum log probability
results.cts  : Counts in each block
results.rate : Rate in each block
results.err  : Poisson error for the block rate
results.lo_t,: Times of lower (>=) and upper (<) block
.hi_t   boundaries.

__See also__: sitar_make_data_cells

----

#### sitar_glvary
##### Synopsis
 Create an optimal lightcurve using the Gregory-Loredo algorithm.

##### Usage
```c
 gl = sitar_glvary(t);
```

##### Qualifiers

* tmin: [The minimum time to consider. Default=min(t)-1]
* tmax: [The maximum time to consider. Default=max(t)+1]
* mmax: [Consider lightcurve divisions from 2 to mmax evenly spaced bins. Default=300.]
* thresh : [Truncate the number of partitions by ignoring those for which \\sum_m(odds ratio)<max(\\sum_n(odds ratio))/exp(thresh), where n = 2 -> mmax.  thresh sets a minimum probability: (1-p_min) ~ exp(thresh)\*(1-p_peak). Default=2.]
* nbins: [Create an output lightcurve with nbins. Default=mmax.]
* texp, frac_exp: [Array pair that give for fractional exposure as a function of time, which will be interpolated and used to correct lightcurve rates. Arrays must have a minimum of five entries. Default is for no correction.]

##### Description

Use the Gregory-Loredo algorithm to find the odds ratios that
even divisions of a lightcurve are better descriptions of the
data than a constant lightcurve.  A 'best estimate' lightcurve
can also be output for a lightcurve with nbins.

Inputs:
t      : Array of event times

Outputs:
gl.p         : Total probability that some evenly partitioned lightcurve, with up
to gl.mmax bins, is a better description than a constant lightcurve
gl.ppart     : The probability for an individual evenly partitioned lightcurve
that it is a better description than a constant lightcurve
gl.lodds_sum : The natural logarithm of the sum of the odds ratios comparing
lightcurves with two or more partitions to a constant lightcurve.
gl.p == exp(gl.lodds_sum)/[1+exp(gl.lodds_sum)]
gl.mpeak     : The number of partitions for the evenly partitioned lightcurve
with the maximum probability.
gl.mmax      : The maximum number of partitions actually used (influenced by
the setting of the thresh parameter)
gl.m         : The number of partitions corresponding to each evenly partitioned
lightcurve considered (=[2:mmax])
gl.pm        : Total probability that some evenly partitioned lightcurve
is a better description than a constant lightcurve for each
maximum number of partitions considered ([2:mmax])
gl.nj        : The counts histogram corresponding to each partitioning above
gl.aj        : The integrated fractional exposure for each partitioning above
gl.a_avg     : The averaged fractional exposure.
gl.tmin      : The value of tmin actually used (maximum of [tmin,min(texp)]);
gl.tmax      : The value of tmax actually used (minimum of [tmax,max(texp)]);
gl.tlc       : The output lightcurve times (an array with input nbins bins)
gl.rate      : Best estimate of the lightcuve rates at the above times
gl.erate     : Best estimate of the lightcuve rate errors at the above times

__See also__: sitar_global_optimum

----

#### sitar_lags
##### Synopsis
 Create time lags and coherence function from input power spectra.

##### Usage
```c
 (lag,dlag,g,dg) = sitar_lags(freq,psda,psdb,cpd,noisea,noiseb [,navg]);
```

##### Description

Given two input PSD (without noise subtracted), their CPD, and
their associated noise levels, all as functions of Fourier
frequency, calculate the time lag and coherence function (and
associated errors) vs. f

Inputs:
freq    : Fourier frequency array
psda/b  : Power spectra array associated with two lightcurves
(Noise subtraction \*not\* applied!)
cpd     : Cross power spectra array associated with two lightcurves
noisea/b: Power spectra noise level. Array \*or\* a constant.

Optional Unput:
navg    : Number of averages (over independent data segments and frequency
bins) associated with each input frequency bin. Can be a constant
vs. f (defaulted to 1).

Outputs:
lag     : Time lag vs. frequency. Negative values mean psdb lags psda
dlag    : Associated error on the lag.
g       : Coherence function
dg      : Error on the coherence function

__See also__: sitar_avg_cpd, sitar_lbin_cpd, sitar_avg_psd, sitar_lbin_psd, sitar_define_psd

----

#### sitar_lbin_cpd
##### Synopsis
 Logarithmically rebin a cross power spectral density.

##### Usage
```c
 (aflo,afhi,apsda,apsdb,acpd,nf,[anoisea,anoiseb]) =  sitar_lbin_cpd(f,psda,psdb,cpd,dff,[noisea,noiseb,&rev]);
```

##### Description

Logarithmically rebin two PSDs (and, optionally, their associated
Poisson noise levels) and the associated Cross Power Spectral
Density

Inputs:
f        : Array of Fourier frequencies
psda/b   : Arrays of PSD values
dff      : Delta f/f value for logarithmic bin spacing

Optional Inputs:
noisea/b : Arrays (\*or single values\*) of Poisson noise levels
rev      : If declared (i.e., 'isis> variable rev;') and input,
rev returns the reverse indices for the binning (i.e.,
(apsda[i] = mean( psda[ rev[i] ] ), etc.)

Outputs:
aflo     : Lower boundary of Fourier frequency bin
afhi     : Upper boundary of Fourier frequency bin
apsda/b  : Rebinned Power Spectral Density values
acpd     : Rebinned Cross Power Spectral Density values
nf       : Number of frequencies going into the bin
anoisea/b: Rebinned noise level (array, even for single value input)

__See also__: sitar_avg_cpd, sitar_avg_psd, sitar_lbin_psd, sitar_define_psd, sitar_lags

----

#### sitar_lbin_psd
##### Synopsis
 Logarithmically rebin a power spectral density.

##### Usage
```c
 (aflo,afhi,apsd,nf [,anoise,apsd_err]) = sitar_lbin_psd(f,psd,dff);
```

##### Qualifiers

* noise: [Array (\*or single value\*) of Poisson noise levels.]
* rev: [If declared (i.e., 'isis> variable rev;') and input, rev returns the reverse indices for the binning (i.e., af[i] = mean( freq[ rev[i] ] ), etc.).]
* psd_err: [Array of errors for the PSD, in which case a PSD error array will be returned.]

##### Description

Logarithmically rebin a PSD (and, optionally, its associated
Poisson noise and error values)

Inputs:
f      : Array of Fourier frequencies
psd    : Array of PSD values
dff    : Delta f/f value for logarithmic bin spacing

Outputs:
aflo   : Lower bounds of Fourier frequency bins
afhi   : Upper bounds of Fourier frequency bins
apsd   : Rebinned PSD values
nf     : Number of frequencies going into the bin

Optional Outputs:
anoise  : Rebinned noise level (array, even for single value input)
apsd_err: Rebinned PSD error array

__See also__: sitar_avg_cpd, sitar_lbin_cpd, sitar_avg_psd, sitar_define_psd, sitar_lags

----

#### sitar_make_data_cells
##### Synopsis
 Loads a dataset with a non-unity AREASCAL keyword or column

##### Usage
```c
 cell = sitar_make_data_cells(tt,type,max_delt,frame,tstart,tstop);
```

##### Description

Create data cells from event data to be used with the Bayesian
blocks algorithm. tt are the times of the events; type=1,2, or 3
determines cell breaks (midway between events; right before
subsequent event, or binned); events closer than max_delt are
grouped together in a single cell; output cell sizes are in units
of frame (or = bin size for type=3), tstart/tstop are the
stop/start times for the output cells.

Output is a structure with cell.pops (number of events per cell),
cell.size (duration of cell in units for frame), cell.lo/hi_t
(start/stop times of cell), cell.dtcor (array, currently set to
unity, for storing cell deadtime corrections).

__See also__: sitar_global_optimum

----

#### sitar_pfold_event
##### Synopsis
 Fold an event-based lightcurve on a given period (with derivatives).

##### Usage
```c
 profile  = sitar_pfold_event(t, p, gti_lo, gti_hi);
```

##### Qualifiers

* pdot: [Period derivative.]
* pddot: [Period second derivative.]
* nphs: [Number of phase bins in output folded lightcurve.]
* tzero: [Time of zero phase. Default = t[0].]
* phase_lo: [Arrays for phase bin boundaries (e.g., for uneven phase bins).]
* phase_hi: [Arrays must be same length with matched boundaries. Supercedes nphs.]

##### Description

Inputs:
t             : Times at which rates are measured
rate          : Lightcurve rate
p             : Period on which to fold the lightcurve
gti_lo        : Array of lower boundaries of good time intervals
gti_hi        : Array of upper boundaries of good time intervals

Outputs:
profile.bin_lo: Start value of phase bin
profile.bin_hi: Stop value of phase bin
profile.cts   : Counts in phase bin
profile.var   : Square root of counts in phase bin
profile.expos : Integrated exposure in phase bin

__See also__: sitar_pfold_rate, sitar_epfold_rate

----

#### sitar_pfold_rate
##### Synopsis
 Fold a rate-based lightcurve on a given period (with derivatives).

##### Usage
```c
 profile  = sitar_pfold_rate(t,rate,p);
```

##### Qualifiers

* pdot: [Period derivative.]
* pddot: [Period second derivative.]
* nphs: [Number of phase bins in output folded lightcurve.]
* tzero: [Time of zero phase. Default = t[0].]
* phase_lo: [Arrays for phase bin boundaries (e.g., for uneven phase bins).]
* phase_hi: [Arrays must be same length with matched boundaries. Supercedes nphs.]

##### Description

Inputs:
t             : Times at which rates are measured
rate          : Lightcurve rate
p             : Period on which to fold the lightcurve

Outputs:
profile.bin_lo: Start value of phase bin
profile.bin_hi: Stop value of phase bin
profile.mean  : Mean rate in phase bin
profile.var   : Variance of rate in phase bin
profile.sdm   : Standard deviation of mean rate in a phase bin
profile.num   : Number of data points in phase bin

__See also__: sitar_pfold_event, sitar_epfold_rate

----

#### sitar_readasm
##### Synopsis
 Read and RXTE ASM data file

##### Usage
```c
 event = sitar_readasm( file );
```

##### Qualifiers

* tstart: [Start time to be read; units of MET or MJD]
* tstop: [Stop time to be read; units of MET or MJD]
* maxchi2: [Maximum acceptable chi2 for ASM solution]
* chnl: [0 for total band; !=0 for three ASM colors+total]
* mjd: [Changes from default of Mission Elapsed Time (days) to MJD]
* jd: [Changes from default of Mission Elapsed Time (days) to JD]

##### Description

Inputs:
file      : ASM filename, e.g. 'xa_cygx1_d1.lc' or 'xa_cygx1_d1.col'

Outputs:
event.time: Time of each event
event.rate: Total ASM count-rate
event.err : Uncertainty in count rate
event.chi2: Chi2 of ASM solution

Optional Outputs:
event.[ch1,ch2,ch3]_rate: ASM count rate in each channel
event.[ch1,ch2,ch3]_err : ASM count rate error in each channel
event.[ch1,ch2,ch3]_chi2: Chi2 for ASM solution in each channel
(Overrides event.chi2, which won't be output)

----

#### sitar_rebin_rate
##### Synopsis
 Rebin a rate lightcurve

##### Usage
```c
 lc = sitar_rebin_rate(t,dt,rate [,err]);
```

##### Qualifiers

* tstart: [Beginning of first output time bin]
* tstop: [End of last output time bin]
* minbin: [Minimum required events per bin, else the bin is set to 0,  or ignored. Default=1.]
* user_bin.lo: [Lower time bounds for user defined grid]
* user_bin.hi: [Upper time bounds for a user defined grid. Overrides  dt, tstart, and tstop inputs]
* delgap: [If set, delete empty bins from the lightcurve, otherwise,  set them to 0]
* weight: [If set and err input, the mean is weighted by the error.  I.e., mean = (\\sum rate/err^2)/(\\sum 1/err^2), and the output variance becomes (\\sum (mean-rate/err^2)^2)/(\\sum 1/err^2)^2]

##### Description

Variables in [] are optional, but are order specific unless a qualifier.

Inputs:
t          : Discrete times at which rates are measured
dt         : Width of evenly spaced time bins in rebinned lightcurve
(Ignored if a user_bin is input.)
rate       : (Presumed GTI & Exposure Corrected) rates

Optional Input:
err        : Error on the rates

Outputs:
lc.rate    : Mean rate of resulting rebinning
lc.bin_lo  : Lower time bounds of rebinned lightcurve
lc.bin_hi  : Upper time bounds of rebinned lightcurve
lc.num     : Number of events going into a bin
lc.var     : Variance of the rate in a time bin. (Only calculated
where lc.num >= 2, otherwise set to zero.)

Optional Outputs:
lc.err     : Rate errors combined in quadrature, i.e., it's
sqrt{\\sum{ err^2 }}/N, where N is the number of points
in that particular bin (i.e., lc.num).  Only computed if
err is input [otherwise, just use sqrt(lc.var)].

__See also__: sitar_bin_events

----

#### sixte_create_img_wfi
##### Synopsis
 returns cmd to create an Image from an EventFile for the XIFU Baseline config

##### Usage
```c
 string cmd = sixte_create_img_wfi(double ra, double dec, string event_file, string image_file);
```

##### Qualifiers

* mode: ["large"]: change mode of the WFI

----

#### sixte_create_img_xifu
##### Synopsis
 returns cmd to create an Image from an EventFile for the XIFU Baseline config

##### Usage
```c
 String cmd = sixte_create_img_xifu(double ra, double dec, string event_file, string image_file);
```

----

#### sixte_psfgen(hew, npix, resolution_meter, focallength, filename)
##### Synopsis
 simple wrapper to Sixte-Tool "psfgen"

##### Description

hew: HEW of PSF [arcsec]
npix: Number of pixels in X and Y direction
resolution_meter: width of one pixel in the focal plane [meter]
focallength: focal length of telescope [meter]
filename: name of output file

Note: this functions requires Sixte to be installed!

----

#### sltable
##### Synopsis
 Generate a LaTeX table

##### Usage
```c
 String_Type table = sltable(par1[,par2,par3,...])
```

##### Description

sltable() is intended to streamline the production of tables of,
e.g., spectral parameters with error bars, although it should be flexible
enough to produce most simply-structured tables. There is a set of examples
on the Remeis wiki:
http://www.sternwarte.uni-erlangen.de/wiki/doku.php?id=isis:sltable

By default this builds tables using the "deluxetable" package; this can be
disabled to produce standard "tabular" tables by setting the "deluxe"
qualifier to zero. The deluxetable environment has been tested using the
latest aastex61.cls stylefile. Tabular tables will require the "booktabs"
package, as they provide the toprule, midrule, and
bottomrule LaXeX macros used here.

Each argument given to sltable() provides the values of one
column of the table (or one row, if the "horiz" qualifier is nonzero).
The length of each argument (or the length of the "value" field of a
Struct_Type argument) defines the number of rows (or columns, if horiz=1).
The arguments can be String_Type (in which case they are printed
literally), Double_Type (or some other numerical type), in which case they
are printed to three decimal places (TODO: figure out a better, more
flexible way of doing this), or Struct_Type, as defined below.

Struct_Type arguments should at least have a "value" field, which should be
an array of some type. If only the "value" field is present, the value
printed to the table follows the rules for String_Type and Double_Type
arguments above. Further fields which can be provided are:
min: the minimum values of this parameter
max: the maximum values of this parameter
freeze: if 1, the parameter is frozen, if 0, it is thawed
limit: if 1, this can be an upper/lower limit
nodata: if 1, there is no data here and "..." should be printed
These should all be arrays of the same length as the "value" field, and
allow for the printing of error bars and indicating upper/lower limits and
frozen parameters.

If the min and max fields are provided and the parameter is not frozen and
not an upper or lower limit, the confidence intervals are printed using the
TeX_value_pm_error() function. If it is an upper or lower limit, it is
rounded to three decimal places and indicated accordingly with "<" or ">"
symbols. If frozen, it is rounded to three decimal places and surrounded by
parentheses (these delimiters can be customized by changing the
"frozendelim" qualifier).

If the "nodata" field is nonzero, then a "no data" indicator will be
printed. By default, for a deluxetable, this is "\\nodata" and for a
tabular table it is "\\ldots". This is useful if you are putting multiple
models which do not share the same parameters into the same table.

This is a lot of words, so here is an
EXAMPLE
This will produce a simple 3x3 table with values with error bars, some
frozen parameters, some upper limits, and some cells in the table filled
with literal strings.
<code>
variable par1 = struct{value=[1,2,3],min=[0.9,1.9,0.0],max=[1.1,2.3,3.2],
freeze=[0,1,0],limit=[1,1,1]};
variable par2 = struct{value=[1,2,3],min=[0.9,1.9,2.9],max=[1.1,2.3,3.2],
freeze=[1,0,0],limit=[1,1,1]};
variable par3 = struct{value=["foo","bar","baz"]};
variable parnames = ["par1","par2","par3"];
variable parunits = ["unit1","unit2","unit3"];
variable obsNames = ["obs1","obs2","obs3"];
variable notes = ["note1","note2"];
variable noteSym = ["1","2"];
variable t = sltable(par1,par2,par3;
colnames={parnames,parunits},rownames=obsNames,
notes={notes,noteSym},label="tab:example",
caption="this is the table's caption");
</code>
The variable "t" now contains the full LaTeX table - drop it into a LaTeX
document and see what it ends up looking like. Note the use of the
"colnames" and "rownames" qualifiers to define the names and units for the
columns and rows, and how List_Type and Array_Type values are interpreted
differently there. Footnotes are also possible via the "notes" qualifier
(although currently we can't place the footnote markers into the table
automatically - you'll have to handle that yourself).

This script is under development. Contact Paul Hemphill (pbh@space.mit.edu)
if you find any bugs.

##### Qualifiers

* deluxe: Integer_Type. If nonzero, we'll produce a deluxetable.
Otherwise, tabular. Tabular tables aren't as fancy and aren't
implemented as well at the moment. In theory we could add other table
types. Default 1.
* horiz: Integer_Type. If nonzero, arguments to sltable
indicate _rows_ of the table. If 0, they indicate _columns_.
* rownames: String_Type[] or List_Type[]. Names for the rows
of the table. Multiple columns for the row names (e.g., parameter names
and units in separate columns) can be handled by providing a List_Type
containing multiple String_Type arrays.
* colnames: String_Type[] or List_Type[]. Names for the columns of
the table (i.e., the column headers). Similar to rownames above,
multi-line headers can be produced by passing a List_Type to this
qualifier.
* caption: String_Type. LaTeX caption for the table. Default is
blank. Don't include a label statement here - that's handled by the
"label" qualifier below.
* label: String_Type. LaTeX label for the table. Default is
"placeholder," so make sure to set this.
* nodata: String_Type, set to what should be printed if there is no
data for a particular field (e.g., if you are putting multiple models
into the same table and they do not share the same parameters).
* frozendelim: String_Type[], two-element string array containing
opening and closing delimiters for a frozen value. By default this is
["(",")"], i.e., the frozen value is surrounded by parentheses.
* star: Integer_Type. If nonzero, the table will be a table\* or
deluxetable\*. If 0, the table will be a table or deluxetable.
* tabletypesize: String_Type. Sets the font size of the table.
Should be a LaTeX font size without the backslash. Default is
"footnotesize".
* longtable: Integer_Type. If nonzero (and we're making a
deluxetable), this is a long table, so a startlongtable statement will
be included in the table header. I don't think tabular tables do
anything with this right now. Default 0.
* landscape: Integer_Type. If nonzero, this is a
landscape-orientation table. Includes a \\rotate command if
deluxetable, or wraps everything in a begin/end landscape block if
tabular. Default 0.
* notes: List_Type[2]. Element 0 should be a String_Type[] array of
the text of any footnotes; element 1 should be a String_Type[] array of
the symbols associated with those notes.

__See also__: TeX_value_pm_error

----

#### sltableBuildBody
##### Synopsis
 Build a 2D array of table cells

##### Usage
```c
 String_Type table[] = sltableBuildBody(Array_Type par1[, Array_Type par2,...])
```

##### Qualifiers

* horiz: Integer_Type. If zero, each argument defines one column of
the table. If nonzero, each argument defines one row. Default 0.
* frozendelim: String_Type[2]. Defines strings to use before and
after a frozen parameter value. Default ["(",")"].
* nodata: String_Type. Defines string to use when no data is
present in a cell. Default is "\\nodata" for deluxetables and
"\\ldots" for tabular tables.
* rownames: String_Type[] or List_Type. Names for rows of table.
If given as a List_Type of String_Type arrays, each element of the
list will be included in its own column (this is useful for, e.g.,
putting the parameter name and the units in separate columns).

##### Description

Builds the "body" of a table (in the form of a 2D array of strings,
containing the fields of the table).

Arguments should be either 1D arrays or structs, the same as one would give
to sltable(). An array of strings will be used as-is. Arrays of numbers
will be rounded to 3 significant figures.  Structs allow the handling of
error bars and offer considerably more flexibility, as defined below:

Struct arguments should, at minimum, have a "value" field, which must be
an array containing the value of the parameter for each row (or column, if
the table is horizontally-aligned). Further fields can be used to modify
the output. All should be arrays of the same length as the value field,
and they have the following names and uses:

min: minimum value of the parameter.
max: maximum value of the parameter. Min & max determine rounding & errors.
freeze: if 1, parameter is frozen, if 0, parameter is thawed.
limit: if 0, parameter can be zero without being an upper/lower limit.

Note that most of these are the same as those in the struct returned by
get_par_info(). The exception is the "limit" field, which determines how a
value of 0 for the parameter is handled. If "limit" is 1, then a confidence
interval containing zero is interpreted as an upper or lower limit. If
"limit" is 0, the value and error bars are typeset as a standard confidence
interval. E.g., one would set limit to 1 for a power-law normalization and
to 0 for a power-law index (the system is not flexible enough at the moment
to handle pathological cases like upper/lower limits on logarithmic
parameters like photon indices).

The number of "rows" in the table is determined by the length of the first
array or the first struct's value field. All later arrays and struct fields
should have the same number of elements.

__See also__: sltable

----

#### socket_send_object, socket_get_object
##### Synopsis
 send or get an SLang object to or from another machine via a TCP socket

##### Usage
```c
          socket_send_object("[username@]to_host", Any_Type object);
Any_Type socket_get_object("[username@]from_host");
```

##### Description

Established a connection to another machine in order to send or
receive an SLang object. Of course, this requires user input
from an active ISIS environment on the host. See the help of
`pack_obj' for the supported object formats.

socket_send_object:
A TCP server is started and as soon as a client connects the
object is sent. The server is shut down afterwards.
socket_get_object:
A TCP client tries to connect to the host in order to receive
the object. The connection is closed after the object has been
received.

For security reasons, it is recommended to provide the username
expected on the host. In this case the server and the client
exchange and check the corresponding username before the object
is transferred. If the username does not match the expected one
the connection is not trusted and closed automatically.

It might occur that machine A which is about to send an object
is behind a router/firewall or does not has a public internet IP
address, while the retrieving machine B does. Using the qualifier
`re' machine B starts a server for retrieving the object and
machine A a client connection for sending purposes (i.e., the
connection is established with server/client inverted with
respect to the default behavior).
##### Example

% receive an object from user "falkner" on "indus"
obj = socket_get_object("falkner@indus");

% send an array of doubles to "ara" without a greet message
socket_send_object("ara", Double_Type[10000]);

% send a structure `s' to an outside machine, while the own
% machine "laptop" is behind a router
socket_send_object("volans.sternwarte.uni-erlangen.de", s; re);
% the call on "volans" then would be
obj = socket_get_object("laptop"; re); % starts a server

__See also__: tcp_server, tcp_client

----

#### solarAbund
##### Synopsis
 returns the solar abundance of an element

##### Usage
```c
 Double_Type solarAbund(Integer_Type Z)
```

##### Description

<code>Z</code> is the element's proton number.

__See also__: Grevesse et al., 1996: Standard Abundances

----

#### solveODEbyIntegrate
##### Synopsis
 solves an ordinary differential equation on a grid by integration

##### Usage
```c
 x = solveODEbyIntegrate(&f, tgrid);
```

##### Qualifiers

* rdt: integration step size relative to 'tgrid' binsize (default: 0.1)
* x0: integration constant (default: 0)
* t0: time reference for x0 (default: first 'tgrid' bin)
* method: integratipn method (default: &integrateRK4)

##### Description

The integral of the ordinary differential equation (ODE)

dx/dt = f(x(t), t)  with  x(t0) = x0

reads

x(t) = x0 + int_{t0}^{t} f(x(t'), t') dt'

<code>&f</code> is a reference to a function with two arguments:
<code>define f(x, t)</code>

<code>{</code>

<code>  return ...;</code>

<code>}</code>

__See also__: integrateRK4

----

#### solve_2d_system_of_equations
##### Usage
```c
 (x, y) = solve_2d_system_of_equations(ax1, ay1, c1, ax2, ay2, c2)
```

##### Description

<code>ax1 \* x  +  ay1 \* y  =  c1</code>

<code>ax2 \* x  +  ay2 \* y  =  c2</code>

----

#### solve_Eddington_quartic_equation
##### Synopsis
 Solve the Eddington quartic equation

##### Usage
```c
 Double_Type beta = solve_Eddington_quartic_equation(Double_Type M, mu)
```

##### Description

For a given mass 'M' (in solar masses) and mean molecular
weight 'mu', solve the Eddington quartic equation
1-beta = 0.003\*M^2\*mu^4\*beta^4
numerically for 'beta' by using Newton's method to find
the root of a function.
##### Notes

According to Equation (2-15) in the book "Principles of
Stellar Evolution and Nucleosynthesis" by D.D. Clayton,
the mean molecular weight can be approximated by
mu ~ 2/(1+3\*X+0.5\*Y)
where 'X' and 'Y' are the mass fractions of hydrogen
and helium.

The Eddington quartic equation needs to be solved to
compute the polytropic constant of the polytropic standard
model, see the function 'polytropic_standard_model'.
##### Example

X = 0.73; Y = 0.26; mu = 2/(1+3\*X+0.5\*Y);
beta = solve_Eddington_quartic_equation(1, mu);

__See also__: polytropic_standard_model

----

#### solve_Lane_Emden_equation
##### Synopsis
 Solve the Lane-Emden equation numerically

##### Usage
```c
 Struct_Type s = solve_Lane_Emden_equation(Double_Type n)
```

##### Description

The Lane-Emden equation for index 0<'n'<5 is a second order
differential equation of the form

1   d (     dtheta)
---- --- (xi^2 ------) = -theta^n
xi^2 dxi (        dxi)

with the boundary conditions

dtheta
theta = 1, ------ = 0 at xi = 0 .
dxi

The solution 'theta' satisfying these boundary conditions
is called Lane-Emden function of index 'n' and is returned
by this function together with its derivative dtheta.

The Lane-Emden functions are used to study the structures
of so-called polytropes, that is, gaseous spheres in hydro-
static equilibrium which obey a polytropic equation of state:
pressure = constant times density^((n+1)/n).
For details, see, e.g., Chapter 2.4 in the book "Principles
of Stellar Evolution and Nucleosynthesis" by D.D. Clayton.
The output structure contains also the polytropic constants
Rn = first zero of the Lane-Emden function of index n,

dtheta
Mn = -xi^2 ------ evaluated at Rn.
dxi

( 3 dtheta)^(-1)
Dn = -(-- ------)      evaluated at Rn,
(xi    dxi)

Rn^((n-3)/n)(3Dn)^((3-n)/3n)
Bn = ---------------------------- .
(n+1)Mn^((n-1)/n)
##### Notes

The numerical solution of the Lane-Emden equation is achieved
here by rewritting it as a system of first order differential
equations
d
--- [y_0,y_1] = [y_1, -(y_0)^n - 2/xi y_1 ]
dxi
which then allows an adaptive Runge-Kutta method of 4./5. order
to be applied.
##### Qualifiers

* tol: [=1e-10] Absolute error control tolerance. Lower limit is 1e-15.

##### Example

s = solve_Lane_Emden_equation(3);
print(s);

__See also__: polytropic_standard_model

----

#### sort_arrays
##### Synopsis

##### Usage
```c
 Integer_Type[] sort_arrays( Array_Type[] A1 [, A2 [, A3 ...]] );
```

##### Qualifiers

* dir [=1]:: 1: Ascending sorting; -1: Descending sorting
* method [='msort']::  Choose sorting method, 'msort' for merge-
and 'qsort' for quick-sort.

##### Description

Similar to 'array_sort' this funtion sorts arrays, but also sorts
multiple appearing array entries based on an addition given array
and so on. In other words this function allows to sort several arrays
(e.g., columns in a FITS-file) depending on the sorting of the previous
array.

This is especially useful if the arrays represent parameter combinations
and you want to perform a resorting. See example below.

NOTE THAT all arrays must have the same length!

##### Example

% Example 1:
a1 = [ 5,6,1,7,5,6,7 ];
a2 = [ 8,9,4,4,1,2,3 ];
i12= sort_arrays(a1,a2);
array_map( Void_Type, &vmessage, "%.2d %.2d", a1[i12], a2[i12] );
i21 = sort_arrays(a2,a1);
array_map( Void_Type, &vmessage, "%.2d %.2d", a1[i21], a2[i21] );

% Example 2: resorting parameter combinations:
par = struct{ a = [0:1:#3],
b = ["hello","world"],
c = [ 2001, 2012]
};
parcomb = get_par_combinations( par );
print(parcomb);

parcomb =  struct_array_2_struct_of_arrays(parcomb);
struct_filter( parcomb, sort_arrays(parcomb.b,parcomb.a,parcomb.c) );
print(struct_of_arrays_2_struct_array(parcomb));

__See also__: array_sort, get_par_combinations

----

#### sort_struct_arrays
##### Usage
```c
 Struct_Type sort_struct_arrays(Struct_Type s, String_Type fieldname);
```

----

#### sort_struct_fields
##### Synopsis
 sorts structure tags in a predefined order

##### Usage
```c
  Struct_Type newstruc = empty_struct(Struct_Type s, String_Type taglist[]);
```

##### Description

This function creates a new structure newstruc with the fiels given by the
array taglist, and fills them with the values from structure s.

The order in which the fields are added is given by taglist, fields not
listed in taglist are ignored.

The function is useful, e.g., when using fits_binary_table to create a FITS-file
from a structure. In this case the order in which the FITS columns are created
corresponds to the order in which they are contained in the structure. One can then
use this function to create a FITS-file with the desired order of columns.

----

#### sov
##### Synopsis
 Set pgplot outer viewport (isis_fancy_plots package)

##### Usage
```c
 sov(Double_Type, Double_Type, Double_Type, Double_Type);
```

##### Description

sov(xmin,xmax,ymin,ymax);

Equivalent to:
isis> v=struct{xmin,xmax,ymin,ymax};
isis> v.xmin=xmin;
isis> v.xmax=xmax;
isis> v.ymin=ymin;
isis> v.ymax=ymax;
isis> set_outer_viewport(v)
and:
isis> set_outer_viewport(struct{xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax});

__See also__: set_outer_viewport, apj_size, keynote_size, nice_width, open_print, close_print, pg_color, pg_info

----

#### spearmanrho
##### Synopsis
 Timing Tools: Spearman's Rank Correlation Coefficient

##### Usage
```c
 (rho) = spearmanrho (a,b);
```

##### Description

rho = 1 - frac {6 sum d_i^2} {n(n^2 -1)}

d_i = a_i - b_i :  difference between the ranks of corresponding values
n :  number of values

Alternative: The statistics module (<code>require("stats");</code>) includes
several functions for determining (rank) correlations coefficients,
such as <code>spearman_r</code>, which provides the p-value (as well as the
correlation coefficient <code>rho</code>).

----

#### sphere_urand
##### Synopsis
 generate spherical coordinates uniformly distributed on a sphere

##### Usage
```c
 (Double_Type theta, phi) = sphere_urand();
```
or

```c
 (Double_Type theta[], phi[]) = sphere_urand(Integer_Type n);

```

##### Description

The function generates <code>n</code> (default: <code>1</code>) pairs <code>(theta[i], phi[i])</code>
of spherical coordinates -- such that the points
<code>[ sin(theta)\*cos(phi), sin(theta)\*sin(phi), cos(theta) ]</code>
are uniformly distributed on the surface of the unit sphere.

----

#### spherical_volume
##### Synopsis
 computes the volume of an object parameterized in spherical coordinates

##### Usage
```c
 Double_Type vol = spherical_volume(Ref_Type &r);
```

##### Qualifiers

* Ntheta: [=180]
* Nphi: [=180]
* logfile: [=NULL]: If logfile is a filehandle, the function evaluations are logged.

##### Description

<code>r</code> has to be a real function with two arguments (theta, phi).

<code>vol = int_0^2pi dphi  int_0^pi dtheta sin(theta)  int_0^r(theta, phi) dr r^2</code>

<code>    = int_0^2pi dphi  int_0^pi dtheta sin(theta)  r(theta, phi)^3/3</code>

The numerical integration of phi and theta is performed on the following grid:

<code>theta = [0 : Pi : #Ntheta];   phi = [0 : 2\*Pi : #Nphi];</code>

----

#### split_and_epfold_lc
##### Synopsis
 Takes lightcurve and pulse period, splits if necessary and executes epfold for each segment.

##### Usage
```c
 Struct_Type split_and_epfold_lc(Struct_Type OR Array_Type lc, Double_Type p0), all times in the same units
```

##### Qualifiers

* exact: Forces execution of pfold with exact qualifier
* not_exact: Forces execution of pfold without exact qualifier
* exact_threshold: see description (default: 6.)
* split_only: Only the splitting is performed
* nbins: Sampling of pfold (default: min(32, p0 / dt), dt time resolution
* nsrch: Number of trial periods for epfold (default: 1e4)
* grid_steps: Period resolution for epfold (default: not set)
* search_range: Period interval considered left/right of p0 in terms of dp=p0^2/T (default: 2.)
* dpmin: For very long lightcurves, this can replace dp (default: p0e-3)
* gap_scale: the smaller, the higher is the sensitivity for gaps (default: .5)
* fracexp: Only timebins with fracexp >= this value will be considered (default: 1.)
* chatty: chattiness (default: 1)

##### Description

The input lightcurve(s) should be a structure or an array of
structures of the form:
lc = struct { time, rate, fracexp, error }
where each field is an array of doubles.
The output is a structure of the form:
out = struct { time, [ epfold ], lc, dp, exact }
Each field is an array, where each element corresponds to one of the
segments the split has produced. The individual fields are:
\* time: average time of segment
\* epfold: struct { p, stat, nbins, badp }
(not output if 'split_only' qualifier has been used)
\* lc: of the same form as input structure lc
\* dp: either p^2 / T or dpmin
\* exact: 1 if exact qualifier was used for epfold, 0 otherwise
Remarks regarding qualifiers:
\* by default, exact is only chosen if there are less than exact_threshold
pulses in the timespan considered. However, as of Sep 16,
there was a bug in pfold, so that exact is ONLY used if exact_threshold
the 'exact_threshold' qualifier exists. When this bug is fixed, please
change the constant at the beginning of the script
\* nsrch and grid_steps are mutually exclusive. If you set nsrch
to 0, the default epfold routine will be
used
\* All qualifiers can also be passed using a structure named
'epfold_qualifiers'. If this qualifier is present, its
content will overwrite all other qualifiers given. If passed
using this structure, all qualifiers must be assigned values
(e.g. exact = 0, split_only = 1). Makes scripts easier to
read.

__See also__: pfold, epfold, pulseperiod_epfold, pulseperiod_search, find_peak

----

#### split_lc_at_gaps
##### Synopsis
 splits a light curve at gaps of a certain length

##### Usage
```c
 Struct_Type split_lc[] = split_lc_at_gaps(Struct_Type lc, Double_Type gap_threshold);
```

##### Qualifiers

* time: [<code>="time"</code>] time field

##### Description

<code>lc</code> has to be a structure containing a <code>time</code> field, which is an array of ascending values,
and other fields, which are arrays of the same length. As soon as the difference of
sequential times is larger than <code>gap_threshold</code>, the structure is split, such that finally
an array of structures like <code>lc</code> is returned.

The following constructions are equivalent:

<code>split_lc_at_gaps(lc, gap_threshold)</code>

<code>split_struct(lc, blocks_between_gaps(lc.time, gap_threshold))</code>

__See also__: split_struct, blocks_between_gaps

----

#### split_struct
##### Synopsis
 splits a structure of related arrays into several structures of the same kind

##### Usage
```c
 Struct_Type structs[] = split_struct(Struct_Type s, Integer_Type group[]);
```

##### Description

All fields of the structure <code>s</code>, as well as <code>group</code>, have to be related arrays
of equal length. The array elements with the same corresponding <code>group</code> value
are selected to form a new structure, unless the <code>group</code> value is negative.
In the latter case (<code>group<0</code>), the array elements are discarded.
The split structures are returned in an array, indexed by the <code>group</code> value.
In other words:

<code>structs[g].field = s.field[where(group==g)]</code>

for <code>0 <= g <= max(group)</code> and any <code>field</code> of the structure <code>s</code>.
##### Examples

<code>variable prime_struct = struct { i, p };</code>

<code>prime_struct.i = [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10];</code>

<code>prime_struct.p = [ 2,  3,  5,  7, 11, 13, 17, 19, 23, 29];</code>

<code>variable group = [-1,  1, -1,  2,  0,  1,  2,  3,  1,  3];</code>

<code>% which might be obtained from the following selection:</code>

<code>group = Integer_Type[length(prime_struct.p)];</code>

<code>group[\*] = -1;</code>

<code>group[where(prime_struct.p mod 10 == 1)] = 0;</code>

<code>group[where(prime_struct.p mod 10 == 3)] = 1;</code>

<code>group[where(prime_struct.p mod 10 == 7)] = 2;</code>

<code>group[where(prime_struct.p mod 10 == 9)] = 3;</code>

<code>variable primes = split_struct(prime_struct, group);</code>

<code>writecol(stdout, primes[1].i, primes[1].p);  % primes with last digit 3</code>

__See also__: split_lc_at_gaps

----

#### split_struct_cols
##### Synopsis
 split structure in an array of structures with maximal num
columns

##### Usage
```c
 Struct_Type str_array = split_struct_cols(Struct_Type str,
Integer_Type num);
```

##### Description

This function splits a structure in an array of structures,
with maximal 'num' columns in each structure.

This can be useful, as fits-tables only allow 999 colums to
be written in the same extension. With split_struct_cols these
can be splitted an written into different extensions. Afterwards
they can be easily combined with struct_combine().

__See also__: fits_save_fit, struct_combine

----

#### SRT_get_mw_spectra
##### Synopsis
 computes Milky Way spectrum from SRT data

##### Usage
```c
 Struct_Type[] spectra = SRT_get_mw_spectra(Struct_Type data, Integer_Type[] chunks
```

##### Description

This function requires as input the SRT data in the format
given by SRT_read() and an array of integer numbers which are the chunks
with the spectrum data. If an array of chunk numbers is given then all
corresponding spectra are calculated and returned.
The spectra are determined with SRT_spectrum and all qualifiers of this
function can be used.
##### Example

variable data = SRT_read("milkyway.rad");
variable spectra = SRT_get_mw_spectra(data,[1,4,7]);

__See also__: SRT_spectrum, SRT_read

----

#### SRT_image
##### Synopsis
 extracts an image from a SRT data structure containing an npoinscan

##### Usage
```c
 Float_Type img[] = SRT_image(Struct_Type data);
```

##### Qualifiers

* plot: plots the image

__See also__: SRT_read

----

#### SRT_plot_mw_spectra
##### Synopsis
 plots Milky Way spectra from SRT data

##### Usage
```c
 SRT_plot_mw_spectra(Struct_Type[] spectrum);
```

```
or

```c
 SRT_plot_mw_spectra(Struct_Type[] data, Integer_Type[] chunks);
##### Qualifiers

* pad: additional space between plot frame and data limits
* fMax: give the frequency of the cloud to be plotted, has to be of same length as spectra/chunks
* fConfMax: upper confidence level of the maximal frequency of the cloud to be plotted, has to be of same length as spectra/chunks
* fConfMin: lower confidence level of the maximal frequency of the cloud to be plotted, has to be of same length as spectra/chunks
* fMaxLin: type of line used to plot fMax
* fConfLine: type of line used to plot fConfMin and fConfMax
* xlabel: label for x-axis
* ylabel: label for y-axis
* title: title for plot, either as single title or for each plot individually as an array of strings
* name: file name of plot, either a single one or for each plot as a an array of string, specify file format, i.e., mw_scan.pdf
* return_xfig: return xfig-data instead of plotting

##### Description

The function automatically plots Milky Way spectra obtained with the SRT.
It can be given a single or an array of spectra or the data and an array of chunk numbers. The required data format is based on the output of SRT_get_mw_spectrum and all of its qualifiers can be used.
It is possible to give the previously determined maximal frequency of the cloud and its upper and lower confidence interval as qualifier. This will create lines in the plot at the provided frequency.

__See also__: SRT_get_mw_spectra, SRT_read, SRT_spectrum

----

#### SRT_read
##### Synopsis
 reads SRT data structures from a SRT .rad file

##### Usage
```c
 Struct_Type data[] = SRT_read(String_Type filename);
```

##### Qualifiers

* verbose:
* onechunk: read all data into one structure instead of an array
(default if file has no comments)
* bins_to_cut: [=8]: number of bad bins at high and low frequencies
* position: [lat,longw] position of the SRT
(default: lat=49.90 and longw=349.10)

__See also__: SRT_spectrum, SRT_image

----

#### SRT_show_chunks
##### Synopsis
 prints information for each chunk in an array of SRT data structures

##### Usage
```c
 SRT_show_chunks(Struct_Type data[]);
```

__See also__: SRT_read

----

#### SRT_spectrum
##### Synopsis
 extracts a spectrum from a SRT data structure

##### Usage
```c
 Struct_Type spec = SRT_spectrum(Struct_Type data);
```

##### Qualifiers

* verbose:
* bins_to_cut: [<code>=8</code>] number of bins at both sides of the spectrum that are discarded
* bins_cut_low: [<code>=0</code>] number of bins to additionaly cut from lower side
* bins_cut_high: [<code>=0</code>] number of bins to additionaly cut from upper side
* normalize: <code>spec.value</code> is normalized between 0 and 1.
* vLSR: transform the frequency grid to a velocity grid
* filename=name: plots the spectrum as name.ps in the
current directory

##### Description

__See also__: SRT_read

----

#### stacking_vlbi_images
##### Synopsis
 stack VLBI images of same size

##### Usage
```c
 stacking_vlbi_images(Array_Type <code>string(cleanfiles)</code>, String_Type <code>outputfile</code>);
```

##### Qualifiers

* ra_mas: [={20,-20}] {left,right} limits of image in mas
* dec_mas: [={-20,20}] {top,bottom} limits of image in mas
* plot_size: [=15] size of plot
* n_sigma: [=3.0] lowest contour of clean image
* sourcename: [=default] name of the source, by default the name is read from the
.fits file, set to NULL for not plotting a source name
* obs_date1: [=default] observation date, by default the date of the first
observation is used
* obs_date2: [=default] 2nd observation date, by default the date of the last
observation is used
* cont_scl: [="2"] set factor to change the separation between contour levels
* cont_lvl: [=[c1,c2,..] contour levels [Jy] manually, overwrites other contour parameters
* major: specify a vector for the major tic marks of the plot
* minor: specify a vector for the minor tic marks of the plot

##### Description

This function creates a stacked image of individual VLBI-clean images.

Important note: all images need to be of the same size! Different beam sizes are
NOT recognized or corrected.

The required input format are fits-file for both the clean and the modelfit images.
The format of the output file depends on the suffix of the given

<code>filename</code>. Possible formats of the output file are PDF, EPS,

PNG, GIF, etc.

----

#### step1 (fit-function)
##### Synopsis
 a step function which is 1 above x0

##### Description

If one bin encloses <code>x0</code>, the value of step1 function
is the fraction of the bin which is above <code>x0</code>.

__See also__: step2

----

#### step2 (fit-function)
##### Synopsis
 a step function which is 1 between x1 and x2

If one bin encloses <code>x0</code> or <code>x2</code>, the value of the step2 function
is the fraction of the bin which is between <code>x1</code> and <code>x2</code>.

__See also__: step1

----

#### steppar
##### Synopsis
 performs a fit while stepping the value of a fit parameter through a given range

##### Usage
```c
 Struct_Type info = steppar(String/Integer_Type par [, Double_Type val1, val2, step] );
```

```
or

```c
 (Struct_Type info, keys) = steppar( String/Integer_Type par [, Double_Type val1, val2, step]; keys);
##### Qualifiers

* keys: An additional structure is returned that can be used as FITS header keys
* frozen: [=0] Perform steppar also for frozen Parameters.
* range: [parmin,parmax] Stepping range. Default is the
minimal/maximal allowed parameter value.
* nsteps: [=10] Number of steps the parameter 'par' is
stepped from range[0] to range[1].
* reset: If given after each step the initial parameter set, which was
valid before this function was called, is restored.
* fit: [=&fit_counts] Reference to the function running the fit algorithm.
* fitargs: Arguments required by the 'fit' function. See __push_list for
format information!
* rerun: Reruns a stepping procedure based on results of a previous run,
i.e., before each step the according parameter set of the previous
run is loaded, e.g., to improve the results using another fit_method.
* resume: Missing steps in the given steppar-file will be calculated based
on the previous steps, i.e., resuming the stepping where it was
stopped.
* stepping: Provide user defined grid [Array_Type], e.g., for a log grid (default: linear)
* check: [=0] Before each step saved steppar informations of other stepped
parameters are gathered and checked for a parameter set with a
better chi2 (using steppar_get_bestparams). In case a better
parameter set was found the stepping will be restarted.
\* ATTENTION: 'save' qualifier is required !!!
\* Gathered are steppar-files, which match the pattern
given with 'save',e.g., if save is "steppar_PID00001.fits"
all files "steppar_PID?????.fits" are globed!
Note that the affix "_PID???" is automaticcaly appended to
the save string if it does not exist (see 'save' qualifier!)
\* The Integer 'check' is set to is the maximal number of
restarts.
\* A parameter set is considered better if
chi2_new < chi2_init \* ( 1 - dchi2 )
\* NOTE: Parameter grouping is possible (see steppar_get_bestparams)

* dchi2: [=0.1] Percental limit for the chi2 of a new parameter set to be
considered as a better parameter set (see 'check'):
chi2_new < chi2_init \* ( 1 - dchi2 ).
* save: After each stepping the result is saved in the file given
(as String_Type) with this qualifier. The chi2 of undone steps
are set to 0.! Also note that the filename is appended with
the parameterindex: 'steppar.fits' -> 'steppar_PID00001.fits'
* force: Forces to overwrite an existing file given with 'save'.
* chatty: Prints fitting information.

##### Description

The given parameter is stepped through in the given parameter 'range',
which is devided into 'nsteps' equidistant value points. If 'val1', 'val2'
and 'step' are given 'range' = ['val1','val2'] and
'nsteps' = ('val2'-'val1')/'step'.
At each of this points a fit is performed. The fitting starts with the
value point closed to the best fit value and alternatingly progresses outwards
to each side. The 'reset' qualifier restores the initial parameter set
after each step, otherwise the parameter set of the nearest stepping point
is used.
The 'rerun' qualifier allows to rerun a stepping using the steppar information
of a previous run, i.e., at each step the according parameter set of that
previous run is loaded before the fit algorithm is started.
In case the steppar function was killed, the 'resume' qualifier
can be used to resume the stepping (given that 'save' was used!).
If the 'save' qualifier is given the results of the stepping are stored
as a .fits file after each step! NOTE that the affix "_PID?????" is
automatically appended to the filename (if not already included), where
the ??? are the ID of the stepped parameter. If the specified file
already exists an error is thrown if the 'force' qualifier for overwriting
is not set.
The 'save' qualifier is also requiered if the 'check' for a better
parameter set is enabled, i.e., before each step it is checked if there
is a parameter set amongst other stepped parameters with
chi2 < chi2_init \* ( 1 - 'dchi2') leading to a restart of the stepping
using the better parameter set, where chi2_init is the chi2 of the parameter
set the stepping was initialized with (which will be updated after a restart).
The maximal number of restarts is given by 'check'.
This qualifier is useful if several steppar processes are running at the same
time saving their results after each step to a fits-file, as in this case
a better fit will be automatically applied! NOTE THAT using 'check'
can lead to inconsistent steppar resulsts in terms of inital parameter sets,
e.g., one steppar process is already finished and afterwards in another one
a better parameter set is found leading to a reastart in the remaining
steppar processes!

=> After using 'check' either make sure all steppar run with the same initial
parameter set or manually extract the best parameter set and run all steppars
once more!

The fitting itself is performed using the 'fit' function, to which
all qualifiers are passed, which gets the 'fitargs' as arguments (see
__push_list).

IMPORTANT:
steppar is based on the current version of the parameter set!

KEYS:
fit_method: fit method used for fitting (see get_fit_method)
statistic:  chisqr according to the parameter set the function was callled with
num_variable_params:
num_bins:
pval:       initial value of the stepped parameter
pname:      exact name of the stepped parameter
%_freeze, %_min, %_max: additional information about the parameters, where
% is the escapedParameterName

__See also__:

----

#### steppar_get_bestparams
##### Synopsis
  Extracts new best fit parameter values out of steppar information

##### Usage
```c
  Struct_Type[] params = steppar_get_bestparams( String_Type[] File );
```

```
or

```c
  Struct_Type[] params = steppar_get_bestparams( Struct_Type[] steppar );
##### Qualifiers

* chatty: Information output
* minchi2: Chi2 limit the new parameter set has to beat
to be taken into accounts!
Default: eval_stat_counts.statistic
* groups: Allows to extract best parameter sets for defined parameter
groups. 'groups' has to be an Array_Type, where each entry
represents a group and contains an Integer/String array
with the according parameter indices/names.
Useful in combination with 'simultaneous_fit' settings, e.i.
groups = %.model.groups!

##### Description

This function searches for the minimal chisqr value within the given
files/steppar information and returns a parameter structure with the
according parameters (see get_params). With the groups qualifier a
groupping can be specified, i.e., the search for a minimal chi2 is
done for each individual groups. The returned structure array
only contains those parameter, which lead to the better chi2 value.
If no better chi2 was found or there was no better chi2 than the
specified minchi2 value, the function returns Struct_Type[0].

ATTENTION:
It is neccessary that the model with which the steppar was executed
is loaded as this functions uses get_params and only changes those
values of the freeParameters as the values of the frozen ones are
not saved!
If another parameter set is loaded there will be a difference in
the new chi2 value this function gives (use 'chatty') and that
chi2 an eval_counts will return!

__See also__: get_params

----

#### steppar_get_conf
##### Synopsis
 Obtains confidence limits out of steppar information

##### Usage
```c
  Struct_Type[] conf = steppar_get_conf( String_Type[] File );
```

```
or

```c
  Struct_Type[] conf = steppar_get_conf( Struct_Type[] steppar );
##### Qualifiers

* chatty: Information output
* dchi2: [=2.71] Delta Chisqr

##### Description

Tries to obtain confidence level related to the given 'dchi2'
value (default: 2.71) based on the steppar information.
To do so this function calculates interpolated intersections
of the chi2 landscape and min(chi2)+'dchi2'.
Only if 2 or more such intersections are found the confidence
limits are set. In case of more then 2 solutions always the
minimal/maximal solutions are taken.

__See also__: interpol

----

#### steppar_load
##### Synopsis
 loads saved steppar information

##### Usage
```c
  Struct_Type[] steppar = steppar_load( String_Typep[] pat );
```

```
or

```c
  Struct_Type[] steppar, keys = steppar_load( String_Type[] pat ; keys );
##### Qualifiers

* keys: If given also the key structure is returned (using fits_read_header).
If keys is a List_Type with keynames, only these keys are read using
fits_read_key_struct, which is faster!
* ext: Only loads extension fitting 'ext' (String_Type)!

##### Description

Loads a \*.fits file storing the steppar information saved with
steppar_save. The given string 'pat' can be a single file
including several extension, an array with files or used as
a pattern for multiple files in globbing format (see glob).

__See also__: steppar, steppar_save, glob

----

#### steppar_plot
##### Synopsis
 xfig plot of the chi2 landscape of (a) stepped parameter(s)

##### Usage
```c
 steppar_plot( Struct_Type steppar, key );
```

```
or

```c
 steppar_plot( String_Type stepparfile );
##### Qualifiers

* norender: If given xfig plots are returned instead of rendered
* pdfunite: If given the rendered plots are united into a single one
* ignorez: Ignores Chi2 values equal to Zero
* size: =[15,11] Size of the plot
* path: ="steppar.pdf": Path for the rendered file
* ext: =".pdf": File Type, e.g., "png"
* yoff: Constant offset for the y-axis. Set to the initial statistic
by default
* yrange: Range of the y-axis. Either Double_Type[1] or [2].
If only one value is given it is taken as ymax!
* dchi2: =2.71: Delta Chisqr

----

#### steppar_save
##### Synopsis
 Saves steppar information (& keys) to a \*.fits file

##### Usage
```c
 steppar_save( String_Type file, Struct_Type[] steppar [, keys]);
```

##### Description

Saves the output of 'steppar' to a \*.fits file.

__See also__: steppar

----

#### storevar
##### Synopsis
 use `save_slang_variable' instead

----

#### stretch_hist
##### Synopsis
 stretch a histogram grid

##### Usage
```c
 Struct_Type hist = stretch_hist(hist, scal);
```

##### Description

Stretch the grid of a histogram structure with fields bin_lo,
bin_hi, value, and err. The bin_lo and bin_hi fields are scaled
by the factor scal. If other fields are present, those are
preserved and passed on. Only presence of bin_lo and bin_hi are
checked for. If scal is an array with [a0,a1,a2,a3...], the grid
is stretched with a polynomial function of
a0 + a1\*bin_lo + a2\*bin_lo^2 + ... .

__See also__: add_hist, shift_hist, scale_hist

----

#### strftime_MJD
##### Synopsis
 formats an Modified Julian Date as a string

##### Usage
```c
 String_Type strftime_MJD([String_Type fmt,] Double_Type MJD)
```

##### Description

If <code>fmt</code> is not specified, <code>"%Y-%m-%d, %H:%M:%S"</code> is assumed.

__See also__: strftime, gmtime, MJD2UNIXtime

----

#### string2sys_err_array
##### Synopsis
 create sys_err_array from str = sys_err_array2string

##### Usage
```c
 Array_Type sys_err = string2sys_err_array(String_Type str);
```

##### Description

This routines converts a string created by the function
"sys_err_array2string" back to an array, which can then be applied
to the data by the function set_sys_err_frac.

__See also__: fits_save_fit, set/get_sys_err_frac, sys_err_array2string

----

#### string_intersection
##### Synopsis
 Returns the common substrings within all strings of the given array

##### Usage
```c
 String_Type string_intersection(String_Type[] strings);
```

##### Qualifiers

* minlen: restrict the returned substrings to a minimum length
* longest: return the longest substring only

##### Example

a = string_intersection(["mister", "twister"]; minlen = 3);
% -> ["ister", "ster", "ter", "ste", "iste", "ist"]

----

#### string_match_perl
##### Synopsis
 matches a string against a RE and stores the results in $1, $2, ...

##### Usage
```c
 Integer_Type string_match(String_Type str, pat[, Integer_Type pos])
```

##### Description

The string <code>str</code> is matched against the regular expression <code>pat</code>,
starting at the position <code>pos</code> (numbered from 1, which is the default).
The function returns the position of the start of the match in <code>str</code>.
The entire matching string is stored in the global variable $0,
the substrings of patterns enclosed by "\\( ... \\)" pairs
are stored in $1, $2, ..., $9  (as in Perl).

<code>string_match_perl</code> is deprecated. Use S-Lang's string_matches instead.
##### Example

<code>if( string_match_perl("hello world", "\\([a-z]+\\) \\([a-z]+\\)"R) )</code>

<code>  ()=printf("1=%s, 2=%s

", $1, $2);</code>

<code>%</code> Equivalent way using <code>string_matches</code>:

<code>variable m = string_matches("hello world", `\([a-z]+\) \([a-z]+\)`, 1);</code>

<code>if(m!=NULL)  vmessage("1=%s, 2=%s", m[1], m[2]);</code>

__See also__: string_matches

----

#### strjoin_wrap
##### Synopsis
 concatenates elements of an array and inserts linebreaks

##### Usage
```c
 Sting_Type strjoin_wrap(Array_Type x, String_Type delim);
```

##### Qualifiers

* maxlen: [=72]: maximum number of characters in a line
* newline: [="  "]: new line string
* initial: [=""]: initial delimiter
* final: [=""]: final delimiter

__See also__: strjoin

----

#### strreplace1
##### Synopsis
 replaces one occurence of a substring in a string by another string

##### Usage
```c
 String_Type res = strreplace1(String_Type str, search_str, repl_str);
```

##### Description

replaces the first occurence of <code>search_str</code> in <code>str</code> by <code>repl_str</code>:

<code>(res, ) = strreplace(str, search_str, repl_str, 1);</code>

----

#### strreplaces
##### Synopsis
 Replace one or more substrings

##### Usage
```c
 String_Type strreplaces(String_Type a, String_Type[] b, String_Type[] c[, Integer_Type max_n]);
```

##### Description

This is a modificaiton to 'strreplace', where
multiple, different substrings (given as arrays)
are replaced at the same time.

__See also__: strreplace

----

#### strsplit
##### Synopsis
 split a string at a separator and return contents as an array

##### Usage
```c
 Array_Type strsplit(String_Type s, String_Type separator);
```

##### Description

This routine takes a string s and splits it into parts separated by
a separator character.
##### Example

variable ra="12:34:56.78";
variable rastr,hh,mm,ss;
rastr=strsplit(ra,":");
hh=atof(rastr[0]); mm=atof(rastr[1]); ss=atof(rastr[2]);
ra=hms2deg(hh,mm,ss);

----

#### struct_array
##### Synopsis
 creates an array of structures

##### Usage
```c
 Struct_Type[] struct_array(Integer_Type n, Struct_Type s);
```

##### Description

An array of n structures is created,
where each structure is a copy of the
given one s.
##### Example

variable sarr = struct_array(4, struct { firstname, lastname });
sarr[2].firstname = "Karl";
sarr[2].lastname = "Remeis";

print(sarr);
% will return
% {firstname=NULL, lastname=NULL}
% {firstname=NULL, lastname=NULL}
% {firstname="Karl", lastname="Remeis"}
% {firstname=NULL, lastname=NULL}

__See also__: table_copy

----

#### struct_array_2_struct_of_arrays
##### Synopsis
 Converts a Struct_Type[] to Struct_Type with array fields

##### Usage
```c
 Struct_Type struct_array_2_struct_of_arrays(Struct_Type[] SA);
```

##### Qualifiers

* depth [0]::  If a field is a Struct_Type itself,
the this function calls itself iteratively
'depth' times going down the rabbit hole.
* dim [0]::  If a field is multi-dimensional 'dim' is the
dimension to which the array is appended to.

##### Description

This function converts a Struct-Array 'Struct_Type[]' to
a single Struct_Type by converting the COMMON fields of
all structs into arrays.
The function works iteratively in case a field of the given
struct array SA itself is a Struct_Type. The function will
call itself maximaly 'depth' times.
In case a field is multi-dimensional the array will be appended
to the 'dim'-th dimension.

NOTE that this function runs orders faster than 'merge_struct_arrays'
while offering the same features as, e.g., reshaping multi-dimensional
arrays (the reshaping in this function also works if not every field
is multidimensional!).

The only drawback is that the function fails if an entry is NULL as
this case cannot be catched. In that case you may use
'merge_struct_arrays'!
##### Examples

%%%%% SIMPLE example
variable sa = struct_array( 3, struct{ a=1, b=2 } );
sa[0] = struct_combine( struct{c}, sa[0] );
variable s = struct_array_2_struct_of_arrays( sa );
print(s);
{a=Integer_Type[3],
b=Integer_Type[3]}

%%%%% COMPLEX example
variable sa = struct_array( 30000, struct{ a=1,
b=_reshape([1:120],[1,2,60]),
c=struct{ d="hello" }
}
);
%%% only merge the parent structure
variable s = struct_array_2_struct_of_arrays( sa ; depth=0 );
isis>    print(s);
%  {a=Integer_Type[30000],
%   b=Integer_Type[30000,2,60],
%   c=Struct_Type[30000]}

%%% merge also the first generation
variable s = struct_array_2_struct_of_arrays( sa ; depth=1 );
print(s);
%  {a=Integer_Type[30000],
%   b=Integer_Type[30000,2,60],
%   c=Struct_Type with 1 fields}
print(s.c);
%  {d=String_Type[3]}

%%% use the second dimension of mudlti-dimensional arrays for merging:
variable s = struct_array_2_struct_of_arrays( sa ; dim=1 );
print(s);
%  {a=Integer_Type[30000],
%   b=Integer_Type[1,60000,60],
%   c=Struct_Type[30000]}

%%% Runtime comparision to 'merge_struct_array'
tic;  s = struct_array_2_struct_of_arrays( sa );
vmessage(" sa2soa took %g seconds to call",toc);
print(s);
tic;  m = merge_struct_arrays( sa );
vmessage(" msa took %g seconds to call",toc);
print(m);

__See also__: merge_struct_array, array_struct_field, array_flatten, unique, intersection

----

#### struct_copy
##### Synopsis
 makes a copy of a struct with all its fields

##### Usage
```c
 Struct_Type copy = struct_copy(Struct_Type struct);
```

##### Description

<code>struct_copy</code> copies a <code>Struct_Type</code> with all its
fields, which can be of any Type! If a field is an Array_Type[]
<code>struct_copy</code> calls <code>array_copy</code> and if a field is
<code>Struct_Type</code>, <code>struct_copy</code> calls itself.
Further it copies Ref_Type, which allows copying XFIG-Objects.
##### Example

s = Struct_Type[1]; s[0]=struct{ a=Array_Type[1,2] };
s[0].a[[0]]=[0:9]; S = struct{ f=s };
C = struct_copy(S); C.f[0].a[[0]] = ["modified"];
print(S.f[0].a);

__See also__: array_copy, list_copy, COPY, assoc_copy

----

#### struct_fields_list_to_array
##### Synopsis
 convert all fields of a structure from lists to arrays

##### Usage
```c
 struct_fields_list_to_array(Struct_Type s[, DataType_Type t]);
```

__See also__: list_to_array

----

#### struct_field_or_default
##### Synopsis
 return value of a structure field or a default value

##### Usage
```c
 value=struct_field_or_default(Struct_Type s, String_Type tag, default);
```

##### Description

return s.tag if it exists, otherwise default

----

#### struct_of_arrays_2_struct_array
##### Synopsis
 Converts a Struct_Type with array fields to a Struct_Type[]

##### Usage
```c
 Struct_Type[] struct_of_arrays_2_struct_array(Struct_Type S);
```

##### Description

This function converts a 'Struct_Type' containing fields
which are arrays (all arrays must have the same dimension!)
to a Struct-array 'Struct_Type[]' with the same fields but
one dimensional. That means the returned Struct_Type[] has
then the dimension (array_shape) of the fields.
The returned Struct-Array will contain all fields the original
'S' also had, BUT for those fields with a different
array_shape then the first field and the value will be set to the
first entry of its field!
##### Example

variable s = struct{ a=[1:3], b=[4:6], c=[3,20] };
variable sa = struct_of_arrays_2_struct_array( s );
print(sa);
{a=1, b=4, c=3}
{a=2, b=5, c=3}
{a=3, b=6, c=3}

__See also__: array_map

----

#### struct_print_field_statistics
##### Usage
```c
 struct_print_field_statistics(Struct_Type s);
```

__See also__: moment

----

#### struct_to_assoc_array
##### Synopsis
 converts a structure to an associative array

##### Usage
```c
 Assoc_Type struct_to_assoc_array(Struct_Type structure[, DataType_Type data-type]);
```

##### Description

The given structure is converted into an associative
array. Thereby, the keys of the returned array will
be equal to the field names of the structure.

If the second argument is provided, the values of the
associative array will be of that type. Otherwise,
the type of the first field of the structure will be
used. Note, that all fields have to be of the same
data-type!
##### Example

c = struct_to_assoc_array(struct {
pi = 3.141592653589793,
c = 2.99792458e10,
h = 6.62606876e-27
});
foreach key (c) using ("keys")
vmessage("c[%s] = %e", key, c[key]); ;

__See also__: Assoc_Type, assoc_get_keys, get_struct_field_names

----

#### sum_lc
##### Synopsis
 combines light curves from one structure

##### Usage
```c
 Struct_Type sum_lc(Struct_Type lc, Array_Type inds)
```

##### Qualifiers

* time: name of the time field (default: <code>"time"</code>)
* rate: format string for the rate field (default: <code>"rate%S"</code>)
* error: format string for the error field (default: <code>"error%S"</code>)

##### Description

The rates in the fields of <code>lc</code> (named by <code>inds</code>
via the <code>rate</code> format statement) are summed up.
The corresponding errors (named by the <code>error</code> format statement)
are added in quadrature.
The returned structure has the fields <code>time, rate, error</code>.
##### Examples

% 1. Assume you have
lc = struct { time, rate1, error1, rate2, error2, rate3, error3 };
% Then
slc = sum_lc(lc, [1:3]);
% is equivalent to
slc = struct {
time = lc.time,
rate = lc.rate1 + lc.rate2 + lc.rate3,
error = sqrt( lc.error1^2 + lc.error2^2 + lc.error3^2 )
};

% 2. Assume you have
lc = struct { time, rate_a, err_a, rate_b, err_b, rate_c, err_c };
% Then
slc = sum_lc(lc, ["a", "b", "c"]; rate="rate_%s", error="err_%s");
% is equivalent to
slc = struct {
time = lc.time,
rate = lc.rate_a + lc.rate_b + lc.rate_c,
error = sqrt( lc.err_a^2 + lc.err_b^2 + lc.err_c^2 )
};

----

#### sunpos
##### Synopsis
 computes the RA and Dec of the Sun at a given date.

##### Usage
```c
 (Double_Type eq, Double_Type ecl) = sunpos(Double_Type JD);
```

##### Description

Computes the position of the Sun at the date JD (or dates, if JD
is an array), given in Julian Date. Position calculation takes
into account pertubations from the planets, aberration and
nutation.  Output value 'eq' is a structure in equatorial
coordinates: eq = struct{ra, dec}, 'ecl' is in ecliptic plane
coordinates: ecl = struct{lon, obl} (Longitude and true
obliquity).

Note: Function adopted from the IDL function with the same name.
See there for accuracy tests, which should also apply here.
##### Qualifiers

* MJD: give time in MJD instead of JD
* radian: return all variables as radians rather than degrees
* hour: return RA in hours rather than degrees (not possible when radian is set).

##### Example

(eq, ecl) = sunpos(2455055.5) ;
()=printf("Right ascension: %.4f deg, Declination: %.4f deg

", eq.ra, eq.dec) ;

----

#### switch_tbnew_rel_abund
##### Usage
```c
 switch_tbnew_rel_abund([String_Type parnames]);
```

##### Description

Unless one or more <code>parnames</code> are given, all elements are switched.
##### Qualifiers

* inst: [=1] instance of tbnew
* verbose:

----

#### sys_err_array2string
##### Synopsis
 creates a string from an Array returned by "get_sys_err_frac"

##### Usage
```c
 String_Type str = sys_err_array2string(Array_Type sys_err);
```

##### Description

This routine creates a String from the Array of systematic errors
apllied to the data. Such an array is returned by the function
"get_sys_err_frac".

__See also__: fits_save_fit, set/get_sys_err_frac, string2sys_err_array

----

#### table_add_row
##### Usage
```c
 table_add_row(table, ...);
```

----

#### table_copy
##### Synopsis
 makes a copy of all columns of a table

##### Usage
```c
 Struct_Type copy = table_copy(Struct_Type table);
```

##### Description

<code>copy.field = @(table.field);  %</code> for every <code>field</code>
NOTE: This also works for XFIG-PLOT-OBJECTS

----

#### table_model.add_additional
##### Synopsis
 Add additional contribution to interpolated spectra

##### Usage
```c
 table_model.add_additional(String_Type name);
```

<!--%{{{ -->
##### Qualifiers

* unit: [=""] Set the unit of the parameter
* minimum: [=min(values)] Set hard lower limit
* bottom: [=min(values)] Set minimum parameter range
* top: [=max(values)] Set maximum parameter range
* maximum: [=max(values)] Set hard upper limit
* initial: [=mean(values)] Set initial parameter value
* delta: [=(max(values)-min(values))\*1e-2] Set parameter step hint

##### Description

Add additional contributions to the interpolated spectra. These parameters
are simply a normalization for the contributions, e.g., 0 means there is
no contribution, 1 means there is full contribution. For each of this
contributions an additional spectrum is added to the interpolated model.

__See also__: table_model.add_parameter

----

#### table_model.add_parameter
##### Synopsis
 Add interpolation parameter to table model

##### Usage
```c
 table_model.add_parameter(String_Type name, Double_Type[] values);
```

<!--%{{{ -->
##### Qualifiers

* log: if given, parameter is interpolated logarithmically rather than linearly
* unit: [=""] Set the unit of the parameter
* minimum: [=min(values)] Set hard lower limit
* bottom: [=min(values)] Set minimum parameter range
* top: [=max(values)] Set maximum parameter range
* maximum: [=max(values)] Set hard upper limit
* initial: [=mean(values)] Set initial parameter value
* delta: [=(max(values)-min(values))\*1e-2] Set parameter step hint

##### Description

Each call to this function adds a new parameter with the given name
and given interpolation points for this parameter. The table model gets
interpolated for this given points.

__See also__: table_model.add_additional

----

#### table_model.close
##### Synopsis
 Finish table model

##### Usage
```c
 table_model.close();
```

<!--%{{{ -->
##### Description

Write the checksums to each HDU and close the
table model file.

----

#### table_model.set_additional
##### Synopsis
 Set interpolation model contributions

##### Usage
```c
 table_model.set_additional(Ref_Type function);
```

<!--%{{{ -->
##### Description

Set the table model contributions function that gets stored
in the table on the defined energy grid. The function must
be of the form
<code>define modelfunction (bin_lo, bin_hi, params, k)</code>
where bin_lo and bin_hi are the bin boundary arrays and
params is the parameter array set by table_model.add_parameter.
The additional argument k is set to the number of the additional
parameter. So k=1 for the first additonal parameter, k=2 for the
second and so on.

The function is expected to calculate the k-th contribution with
the parameter for this contribution set to 1.

__See also__: table_model.set_additional

----

#### table_model.set_function
##### Synopsis
 Set interpolation model function

##### Usage
```c
 table_model.set_function(Ref_Type function);
```

<!--%{{{ -->
##### Description

Set the table model function that gets stored in the table
on the defined energy grid. The function must be of the form
<code>define modelfunction (bin_lo, bin_hi, params)</code>
where bin_lo and bin_hi are the bin boundary arrays and
params is the parameter array set by table_model.add_parameter.
The function may use qualifiers.

__See also__: table_model.set_additional

----

#### table_model.set_grid
##### Synopsis
 Set the energy grid for the table model

##### Usage
```c
 table_model.set_grid(bin_lo, bin_hi);
```

<!--%{{{ -->
##### Qualifiers

* lolimit: [=0] The model value if lower than lowest bin
* hilimit: [=0] The model value if higher than highest bin

##### Description

Set the energy grid on which the model gets interpolated.
Boundaries of the bins have to match.

__See also__: table_model.set_function, table_model.set_additional

----

#### table_model.write
##### Synopsis
 Write table model to file

##### Usage
```c
 table_model.write();
```

<!--%{{{ -->
##### Qualifiers

* redshift: if given, set redshift parameter flag
* mult: if given, model is multiplicative (default additive)
* verbose: show additional information

##### Description

Given the model function and additional contributions, this
function evaluates the model and contributions on the given
parameter values and writes the resulting spectra to the
table file. Any qualifier passed to this function is passed
on to the model functions.

IMPORTANT: This function calls the evaluation functions
several times and may take a long time to finish. Depending
on the evaluation time of the model functions.

__See also__: table_model.close

----

#### table_print_TeX
##### Synopsis
 prints certain columns of a structure as a TeX table

##### Usage
```c
 table_print_TeX(Struct_Type tab[, String_Type cols[]]);
```

##### Description

If no columns are specified by the string-array <code>cols</code>,
all columns of the table tab are used.
##### Qualifiers

* align: alignment of all columns: "l", "c", "r" [default: "l"]
* heading: [=<code>cols</code>]: headings for TeX table
* output: [=stdout]: output can be written in a file by stating
a File_Type or the filename (String_Type)

----

#### tai2tt
##### Synopsis
 Convert a (M)JD in International Atomic Time into Terrestrial Time (TT, also known as TDT or ET)

##### Usage
```c
 tt=tai2tt(JD)
```

##### Description

This routine converts a Julian Date that is given in International Atomic
Time (TAI) into Terrestrial Time, which is roughly corresponding to
Terrestrial Dynamic Time or Ephemeris Time. This is done by
adding 32.184s to the TT. This routine is array safe.

##### Qualifiers

* mjd: The argument is given in MJD, not in JD.
* deltat: Return the TT-TAI in seconds, rather than the corrected (M)JD.

__See also__: utc2tai,tai2utc,tt2tai,tt2tdb

----

#### tai2utc
##### Synopsis
 Converts a (M)JD in International Atomic Time into civil time (UTC)

##### Usage
```c
 utc=tai2utc(JD)
```

##### Description

This routine converts a Julian Date that is given in international
atomic time into Coordinated Universal Time (UTC) by applying the
relevant correction for leap seconds. This routine is array safe.

NOTE: This function is only approximately correct. Within about a
minute of a leap second this routine can be off by as much as
one second.
##### Qualifiers

* mjd: The argument is given in MJD, not in JD.
* deltat: Return the UTC-TAI in seconds, rather than the corrected (M)JD.
* leapfile: Path to a file containing the leap second
information. This file is available, e.g., from
ftp://maia.usno.navy.mil/ser7/tai-utc.dat
Most astronomical software systems distribute this file. The default
is getenv("LHEASOFT")/refdata

__See also__: utc2tai,tt2tai,tai2tt

----

#### taylor
##### Synopsis
 Returns the taylor series for given coefficients

##### Usage
```c
 Double_Type taylor(Double_Type[] x, coefficients)
```

##### Description

Returns the taylor series around x with the given
'coefficients', which lengths determines the order.
The sum is evaluated using the Horner (1819) schema
for numerical accuracy and computation speed:

c0 + c1\*x + 1/2!\*c2\*x^2 + 1/3!\*c3\*x^3 + ...
= (((... + c3)\*x/3 + c2)\*x/2 + c1)\*x + c0
##### Example

x = [0, 1];
c = [1, 4e-3, 0, 3e-6]; % up to third order

taylor(x, c); % returns [1.0, 1.0040005]

----

#### taylorcoeff_from_struct
##### Synopsis
 extracts taylor coefficients from the field names of a structure

##### Usage
```c
 Double_Type[] taylorcoeff_from_struct(Struct_Type struct[,
String_Type 0th_pattern, String_Type Nth_pattern]);
```

##### Description

If a structure has fields which names reflect the
different orders of a taylor series, this function
extracts these coefficients by matching the field
names against two patterns.

'0th_pattern' is the field name of the zero order
and 'Nth_pattern' this of all higher order terms.
Both patterns have to be regular expressions. In
particular, the expression of the Nth order must
contain a number extraction two determine the order
N of that field.

By default, '0th_pattern' is set to "[a-zA-Z]0" and
'Nth_pattern' to "[a-zA-Z]\([0-9]\*\)dot"R. If the
latter _pattern matches, but the extracted number
is an empty string N=1 is assumed.

The returned array contains the taylor coefficients
in ascending order as used by the 'taylor'-function.

__See also__: taylor, string_matches

----

#### tcg2tt
##### Synopsis
 Convert a (M)JD in TCG to Terrestrial Time (TT, aka TDT or ET)

##### Usage
```c
 tai=tcg2tt(JD)
```

##### Description

This routine converts a Julian Date that is given in geocentric coordinate
time (TCG) to Terrestrial Time. The two time scales differ by a constant
rate(!) because TT uses the SI second at the surface of the geoid, and TCG
uses the SI second at the potential of the center of the Earth.
This routine is array safe.
##### Qualifiers

* mjd: The argument is given in MJD, not in JD.
* deltat: Return the TT-TCG in seconds, rather than the corrected (M)JD.

__See also__: tcg2tt,utc2tai,tai2utc,tai2tt,tt2tdb

----

#### tcp_client
##### Synopsis
 connects to a TCP server

##### Usage
```c
 Struct_Type  tcp_client(String_Type host[, Integer_Type port]);
```
or

```c
 Integer_Type tcp_client(String_Type host[, Integer_Type port];
msg_handler = Ref_Type, obj_handler = Ref_Type);
```

##### Qualifiers

* nogreet: disable greet messages (see below)
* chatty: chattiness (default: 1)
* COMMENT:: Further qualifiers are listed at HOOKS below.

##### Description

Uses the `socket' module to connect to a TCP server. After a
connection attempt, a greet message is exchanged with the server
by default unless the `nogreet' qualifier is set. In the latter
case the `tcp_server' has be set up with the same qualifier.
After the connection has been established, a structure with
functions for communicating with the server is returned.
Alternatively, if the `msg_handler` and `obj_handler` hooks are
set (see the HOOK section below) the client remains in a main
loop until the connection to the server has been closed. In this
case, the function returns 0 if any error occured during the
lifetime of the connection or 1 otherwise. The client structure,
which is passed to all hooks and returned if these hooks are no
set, has the following fields:

Integer_Type &send(String_Type msg or Any_Type obj)
Function for sending a string message or an SLang object
to the server (see `pack_obj' for list of supported types).
Returns the number of bytes sent.
Warning: Currently, sending objects is slow (~40 kB/s,
i.e., ~20 s for 100,000 doubles).
Qualifiers:
receipt - wait for a confirmation by the client for the
receipt (the server's `receive' function needs the
same qualifier to be set).
BString_Type or Any_Type &receive()
Wait for and receive a message from the server. Returns
either the message itself (BString_Type) or in case of a
received object the object itself.
Qualifiers:
dontwait - do not wait for a message and return NULL in
case no message or object is pending.
receipt  - send a receipt to the client after having
received a message or an object
Integer_Type &disconnect()
Disconnect from the server, i.e., close the communication
socket. Returns 1 in success or 0 otherwise.
Integer_Type connected - boolean value indicating whether
the connection is still established (1) or not (0)
Struct_Type config - internal configuration
Struct_Type hook - defined hooks

HOOKS
The following functions are called via qualifiers of the same
name, which need to be set to references (Ref_Type) to user-
defined functions (see below for an example). The passed
`client' is the client's structure as defined above.

String_Type or Integer_Type &greet_hook(client, greetmsg)
Called after having received the greet message from the server
(if not disabled by the `nogreet' qualifier). Should return
the greet message to be sent back to the server. Return 0 in
case the greet message from the server should be rejected,
which will cancel the connection.
Void_Type &connect_hook(client)
Called after a connection to the server is established. Can
be used to start the communication with the server in
combination with the `msg_handler' hook.
Void_Type &closed_hook(client)
Called after the connection has been closed from the server's
side.
Void_Type &msg_handler(client, msg)
Called after a message (BString_Type) has been received from
the server.
Void_Type &obj_handler(client, obj)
Called after an object has been received from the server.
##### Example

% simple functions for receiving messages and objects
define getmsg(c, msg) { vmessage("message from server: %s", msg); };
define getobj(c, obj) { message("received an object:"); print(obj); };
% start the client
variable stat = tcp_client("localhost"; msg_handler = &getmsg, obj_handler = &getobj);
% check its exit status
if (stat == 0) { message("lost connection to server"); }

% a more sophisticated example can be found on the Remeis wiki
% www.sternwarte.uni-erlangen.de/wiki/doku.php?id=isis:socket

__See also__: tcp_server, socket, unpack_obj

----

#### tcp_get_server_handle
##### Synopsis
 get a handle to a running TCP server

##### Usage
```c
 Struct_Type tcp_get_server_handle();
```

##### Qualifiers

* kill: shut down / kill the server

##### Description

In case the handle, i.e., the structure of a running
`tcp_server' got lost by accident, this function
returns this structure again. Alternatively, the
`kill' qualifier tries to shut down the server. If
this fails all communication sockets are closed,
which basically means to kill the server.

__See also__: tcp_server

----

#### tcp_server
##### Synopsis
 implements a basic TCP server

##### Usage
```c
 Integer_Type tcp_server();
or  Struct_Type tcp_server(; background);
```

##### Qualifiers

* port: bind port (default: 1149)
* maxclients: maximum allowed number of clients connected
simultaneously (default: 10)
* nogreet: disable greet messages (see below)
* background: run server in the background (see below)
* ip: bind address (default: "0.0.0.0", i.e., accept
connections from outside; only change if you know what
you are doing)
* chatty: chattiness (default: 1)
* COMMENT:: Further qualifiers are listed at HOOKS below.

##### Description

Uses the `socket' module to implement a basic TCP server. It
listens for clients trying to connect and accepts a connection
after a greet message has been exchanged successfully. The
greet message can be disabled using the `nogreet' qualifier,
which in this case needs to be set for a `tcp_client' as well.
Furthermore, any message or object received from a client is
read automatically. After any of these actions taken by the
server, a user-defined function may be called in order to handle
these events further (see the HOOK section below).

The `background' qualifier allows the server to be started in
background mode, such that commands can still be entered into
the ISIS prompt. This background mode is realized by calling
the main server function, which handles client events, each
second scheduling an `alarm` signal (SIGALRM).
NOTE: the alarm signals are triggered in the main program loop
of ISIS, i.e., while it's "working". That means the
main server function is not executed while ISIS awaits
input from the prompt (ISIS "sleeps" here). Thus, you
might want to do at least something, e.g, press enter.
WARNING: further alarms should not be scheduled using `alarm'
or `signal'. Otherwise, the server might crash.

If not in background mode, `tcp_server' returns either 1 after
the server has been shut down successfully or 0 otherwise. Else
the structure of the following form is returned. Note that this
structure is also passed to each hook (see below):

Struct_Type[] client - list of clients
Integer_Type &shutdown()
Function to shut down the server. After all clients are
requested to disconnect, all sockets are closed. Returns
whether the shut down was successful (1) or not (0).
Qualifiers:
trigger - shut down the server at the end of the main
loop, which does not interrupt ongoing communication
Void_Type &cleanclients()
Function to remove clients no longer connected from the list.
Integer_Type running - boolean value indicating the server's
state (1: running; 0: shut down)
Struct_Type config - internal configuration
Struct_Type hook - defined hooks

Each `client' structure has the following fields:

Integer_Type &send(String_Type msg or Any_Type obj)
Function for sending a string message or an SLang object
to a client (see `pack_obj' for list of supported types).
Returns the number of bytes sent.
Warning: Currently, sending objects is slow (~40 kB/s,
i.e., ~20 s for 100,000 doubles).
Qualifiers:
receipt - wait for a confirmation by the client for the
receipt (the client's `receive' function needs the
same qualifier to be set).
BString_Type or Any_Type &receive()
Wait for and receive a message from the client. Returns
either the message itself (BString_Type) or in case of a
received object the object itself.
Qualifiers:
dontwait - do not wait for a message and return NULL in
case no message or object is pending.
receipt  - send a receipt to the client after having
received a message or an object
Integer_Type &kick()
Kick the client, i.e., close the communication socket.
Returns 1 in success or 0 otherwise.
Integer_Type connected - boolean value indicating whether
the client is still connected (1) or not (0)
Integer_Type number - the client's number, which is a serial
increasing identifier starting with zero
Struct_Type config - internal configuration
BString_Type[] unhmsg - in case the `msg_handler'-hook is not
set, messages of the client, which have been received
without a call to `receive` during the server's main loop
are appended here
List_Type unhobj - in case the `obj_handler'-hook is not set,
objects without a call to `receive' are appended here

HOOKS
The following functions are called via qualifiers of the same
name, which need to be set to references (Ref_Type) to user-
defined functions (see below for an example). The passed
`server' and `client' are the server's and corresponding
client's structures as defined above.

Integer_Type &connect_hook(server, client)
Called after a client tries to connect to the server. Should
return 1 or 0 for accepting or rejecting the connection,
respectively.
String_Type  &greet_hook(server, client)
or Integer_Type &greet_hook(server, client, greetmsg)
Called after accepting a client's connection, which should
return the greet message to be sent to the client. Is called
again after the re-greet message has been received from the
client, which should return 1 or 0 for accepting or rejecting
the greet, i.e, the connection, respectively. The hook is not
called if the server was set up with the `nogreet' qualifier.
Void_Type &established_hook(server, client)
After a connection has been accepted including the greet, this
function allows to start the communication between the client
and the server by, e.g., sending messages to the client in
combination with the `msg_handler' hook.
Void_Type &disconnect_hook(server, client)
Called after a client disconnected from the server by itself,
i.e., the client has not been kicked.
Void_Type &msg_handler(server, client, msg)
Called after a message (BString_Type) has been received from
the client. If this hook is not set, then the message is
appended to the `unhmsg` field of the client's structure.
Void_Type &obj_handler(server, client, obj)
Called after an object has been received from the client. If
this hook is not set, then the object is appended to the
`unhobj` field of the client's structure.
##### Example

% after a client's connection has been accepted,
% send a data structure and disconnect client
define do_client(s,c) {
vmessage("sending data to client #%d", c.number);
()=c.send("welcome client! sending data...");
()=c.send(struct { data = [1:5]\*10, err = [1:5] });
()=c.kick();
% remove kicked client from the list
s.cleanclients();
}
% start the server
variable stat = tcp_server(; established_hook = &do_client);
% check its exit status
if (stat == 0) { message("server exited unexpectedly"); }

% a more sophisticated example can be found on the Remeis wiki
% www.sternwarte.uni-erlangen.de/wiki/doku.php?id=isis:socket

__See also__: tcp_client, socket, alarm, pack_obj

----

#### tdb2tt
##### Synopsis
 Convert a (M)JD in Terrestrial Barycentric Time (TDB) into Terrestrial Time (TT, aka TDT)

##### Usage
```c
 tt=tdb2tt(JD)
```

##### Description

This function converts a Julian Date that is given in Terrestrial Barycentric
time (TDB) into Terrestrial Time (TT).

By default the routine uses equation 2.6 of Kaplan (2005, USNO Circular 179),
which is a truncated version of the series provided by Fairhead and Bretagnon,
1990, A&A 229, 240 and which is better than +/-10mus between AD1600 and
AD2200.

Since that series is for TT-TDB, we formally calculate the deltat for the TT
that equals the given JD, we make no attempt to correct for the slight
change in deltat between JD(TT) and JD(TDB), since the correction is smaller
than the precision of the Fairhead and Bretagnon series. Use the JPL ephemeris
for ms pulsar work.

If the qualifier ephemeris is given, and points to a JPL ephemeris that
does contain TT-TDB information, then the value determined from the
ephemeris is computed (which has a higher precision than Fairhead & Bretagnon,
but is slower to evaluate).

Note that for virtually all practical applications apart from barycentering
ms radio pulsar data it is sufficient to use TT as the argument to DE405
or VSOP1987.

This routine is array safe.
##### Qualifiers

* mjd: The argument is given in MJD, not in JD.
* deltat: Return the difference TT-TDB in seconds, rather than the corrected (M)JD.
* ephemeris: if set and no argument, then correct using DE430, otherwise
use the ephemeris provided (see function jpl_initeph).

__See also__: tdb2tt,utc2tai,tai2utc,tai2tt,jpl_initeph

----

#### tdist_fit
##### Synopsis
 Fitting a student's t-distribution to data in energy space

##### Usage
```c
 fit_fun("tdist");
```

##### Description

Student's t-distribution with LineE being the centroid energy,
Width the full width at half maximum and nu the number of degrees
of freedom. nu=1 reproduces a Lorentzian, nu->infty a Gaussian.

__See also__: tdist_pdf

----

#### TeX_value_pm_error
##### Synopsis
 formats a <code>(value, min, max)</code> triple as TeX string

##### Usage
```c
 String_Type TeX_value_pm_error(Double_Type value, Double_Type min, Double_Type max)
```

```
or

```c
 String_Type TeX_value_pm_error(Struct_Type output_of__round_conf)
##### Qualifiers

* factor: [=<code>1</code>]: factor to multiply <code>value, min, max</code>, will not be shown,
works only if the function is called with three arguments
* neg: factorize overall minus sign
* sci: [=<code>2</code>]: exponent to switch to scienficic notation
* scismall: [=<code>-sci</code>]: exponent for small numbers
* scilarge: [=<code>+sci</code>]: exponent for large numbers

##### Description

<code>TeX_value_pm_error</code> tries to produce a reasonable TeX output
from a <code>(value, min, max)</code> tripel or the output of the function
<code>round_conf</code>.
Rounding and obtaining the number of digits is done with the
function <code>round_conf</code>.

__See also__: round_conf,round_err

----

#### thawedParameters
##### Synopsis
 find all parameters of the current fit-function that are not frozen

##### Usage
```c
 Integer_Type[] thawedParameters()
```

##### Description

Note that <code>thawedParameters</code> may include ones that are
tied to another one, or derived as functions of other parameters.

__See also__: freeParameters

----

#### timeOfPhase
##### Synopsis
 Compute the time corresponding to given phase

##### Usage
```c
 Double_Type[] timeOfPhase(Double_Type[] phase, Double_Type, p, dp, ddp);
```

##### Description

Given a phase and a period evolution by the period P <code>p</code>,
first, and second derivative of P, <code>dp</code> and <code>ddp</code>,
respectively, calculate the time.

Note: This function is essentially the inverse of <code>timeOfPhase</code>.
For non-zero <code>ddp</code> the inverse is only approximated through
series inversion!

__See also__: phaseOfTime

----

#### time_array
##### Synopsis
 Converts a time [s] (e.g., _time) into an array [sec,min, ...]

##### Usage
```c
 Integer_Type[] = time_array( Integer_Type );
```

```
or

```c
 String_Type = time_array( Integer_Type ; str);
##### Qualifiers

* str: Instead of a time array a String_Type is returned!

##### Description

Converts a time given in seconds into a time array, where
the first entry corresponds to the seconds, the second to
the minutes, etc. The length of the array is variable,
i.e., if the given time is of the order of hours, the array
will not include days and years.

If the qualifier 'str' is given the array will be converted
into a string (see example).
##### Example

isis> ta = format_time ( _time ); ta;
Integer_Type[5];
isis> print(ta);
54
1
14
302
43

%or
isis> ts = format_time ( _time ;str ); ts;
43y 302d 14h  1m 54s

__See also__: _time

----

#### transpose_table
##### Synopsis
 transforms a structure of arrays into an array of structures and vice versa

##### Usage
```c
 Array_Type table_by_rows    = transpose_table(Struct_Type table_by_columns);
```
or

```c
 Struct_Type table_by_columns = transpose_table(Array_Type table_by_rows);

```

##### Description

<code>table_by_columns.field[i] = table_by_rows[i].field;</code>  % for each <code>field</code> and index <code>i</code>

----

#### try_or_timeout
##### Usage
```c
 try_or_timeout(UInteger_Type seconds, Ref_Type function, ...);
```

##### Description

Runs the function referenced by <code>function</code> for at most
<code>seconds</code> seconds. If <code>function</code> finishes before
<code>seconds</code> have elapsed it returns the return values of
<code>function</code>. If <code>function</code> does not finish in that time
it throws a <code>TimoutError</code>.
Additional arguments passed on to <code>function</code> may simply be
specified as additional arguments to <code>try_or_timeout</code>.
Qualifiers can be passed on as usual.

----

#### tt2tai
##### Synopsis
 Convert a (M)JD in Terrestrial Time (TT, aka TDT or ET) into TAI

##### Usage
```c
 tai=tt2tai(JD)
```

##### Description

This routine converts a Julian Date that is given in Terrestrial Time
(formerly known as Terrestrial Dynamic Time or Ephemeris Time) into
TAI. This is done by subtracting 32.184s from the TT.
This routine is array safe.
##### Qualifiers

* mjd: The argument is given in MJD, not in JD.
* deltat: Return the TAI-TT in seconds, rather than the corrected (M)JD.

__See also__: utc2tai,tai2utc,tai2tt,tt2tdb

----

#### tt2tcg
##### Synopsis
 Convert a (M)JD in Terrestrial Time (TT, aka TDT or ET) into TCG

##### Usage
```c
 tai=tt2tcg(JD)
```

##### Description

This routine converts a Julian Date that is given in Terrestrial Time
(formerly known as Terrestrial Dynamic Time or Ephemeris Time) into
geocentric coordinate time (TCG). The two time scales differ by a constant
rate(!) because TT uses the SI second at the surface of the geoid, and TCG uses
the SI second at the potential of the center of the Earth.
This routine is array safe.
##### Qualifiers

* mjd: The argument is given in MJD, not in JD.
* deltat: Return the TCG-TT in seconds, rather than the corrected (M)JD.

__See also__: tcg2tt,utc2tai,tai2utc,tai2tt,tt2tdb

----

#### tt2tdb
##### Synopsis
 Convert a (M)JD in Terrestrial Time (TT, aka TDT or ET) into Terrestrial Barycentric Time (TDB)

##### Usage
```c
 tdb=tt2tdb(JD)
```

##### Description

This function converts a Julian Date that is given in Terrestrial
Time into Terrestrial Dynamic Barycentric Time.

By default the routine uses equation 2.6 of Kaplan (2005, USNO Circular 179), which
is a truncated version of the series provided by Fairhead and Bretagnon,
1990, A&A 229, 240 and which is better than +/-10mus between AD1600 and AD2200.

If the qualifier ephemeris is given, and points to a JPL ephemeris that
does contain TT-TDB information, then the value determined from the
ephemeris is computed (which has a higher precision than Fairhead & Bretagnon,
but is slower to evaluate).

Note that for virtually all practical applications apart from barycentering
ms radio pulsar data it is sufficient to use TT as the argument to DE405
or VSOP1987.

This routine is array safe.
##### Qualifiers

* mjd: The argument is given in MJD, not in JD.
* deltat: Return the difference TDB-TT in seconds, rather than the corrected (M)JD.
* ephemeris: if set and no argument, then correct using DE430, otherwise
use the ephemeris provided (see function jpl_initeph).

__See also__: tdb2tt,utc2tai,tai2utc,tai2tt,jpl_initeph

----

#### tt2ut1
##### Synopsis
 Convert a (M)JD in TT into UT1

##### Usage
```c
 ut1=tt2ut1(JD)
```

##### Qualifiers

* mjd: The argument is given in MJD, not in JD.
* deltat: Return the TT-UT1 in seconds, rather than the corrected (M)JD.
* morrison: Perform the correction using a linear interpolation
to the points by Morrison and Stephenson, 2004,
Journal for the History of Astronomy 35, 327.
Not good after 2000.

##### Description

This function converts a (Modified) Julian Date that is given in
TT into UT1, i.e., the timescale that defines the earth rotation angle.

By default, for years before 2005 the function uses the polynomial
expressions for TT-UT1 published by F. Espenak and J. Meeus, 2006,
Five Millenium Canon of Solar Eclipses: -1999 to +3000,
NASA TP-2006-214141, for years after 2005 the polynomials published
by Espenak at http://www.eclipsewise.com/help/deltatpoly2014.html are
used.

Alternatively, a linar interpolation in the solar eclipse derived
data by Morrison and Stephenson (2000) can be used (see morrison
qualifier).

The uncertainty of the result is 1s or less from 1780 until 1830,
less than 1s from 1830-2000. It increases quadratically backwards
from 1820, sigma ~32((year-1820)/100)^2.

This routine is array safe.

Note: Because of the uncertainty in TT-UT1, the same
polynomial is used for the TT->UT1 and UT1->TT conversion,
and therefore it generally is NOT true that JD==ut12tt(tt2ut1(JD)).

__See also__: ut12tt,utc2tai,tai2utc,tai2tt

----

#### unique_n
##### Synopsis
 finds the indicies of unique tupels

##### Usage
```c
 Integer_Type[] unique_n(Array_Type a1, ..., an)
```

##### Description

The arrays <code>a1</code>, ..., <code>an</code> (with <code>n>=1</code>) must have the same length,
but may contain different data types.
The return value is an array of all indices <code>i</code>
of all unique tupels <code>(a1[i], ..., an[i])</code>.

----

#### UNIXtime2MJD2
##### Synopsis
 converts UNIX time to modified Julian date

##### Usage
```c
 Double_Type UNIXtime2MJD2(Long_Type secs)
```

__See also__: MJD2UNIXtime

----

#### unpack_obj
##### Synopsis
 converts a binary string back into an SLang object

##### Usage
```c
 Any_Type pack_obj(BString_Type obj);
```

##### Description

An input array of binary strings (BString_Type), which has
been created by the `pack_obj' function, is converted back
into an SLang object using the `unpack' function.

See the documentation of `pack_obj` for more details.
##### Example

<pre>

    s = pack_obj(PI);        % s[0] = "d\\030-DT\\373!\\011@"

    a = unpack_obj(s);       % a = 3.141592653589793;

</pre>

__See also__: pack_obj, unpack, pack

----

#### unset_lines_par_fun
##### Synopsis
 removes the par_fun's in a lines-model to speed up the model

##### Usage
```c
 unset_lines_par_fun([Integer_Type id]);
```

##### Description

The amplitude parameters of the lines-model are reset for every line:

<code>set_par_fun("lines(id).line_A", NULL);</code>

If <code>id</code> is not specified, code{id=1} is used.

__See also__: gauss, lines, set_lines_par_fun

----

#### unshift
##### Synopsis
 fit function to determine the shift of an array to a reference one

##### Usage
```c
 unshift(id)
```

##### Description

The function 'shift' rotates an array by a given number
of indices. The fit function described here tries to
get this number back: the counts of the dataset 'id'
are assumed to be a shifted version of a reference
array. In order to do the fit, this reference array
has to be associated to the dataset via:

set_dataset_metadata(id, reference_array)

It is also possible to scale the array values to match
the reference ones or to add an offest to the array.
Summarized, the fit parameters are as follows:
shift  - relative shift of the counts to the
reference array
scale  - factor the reference is multiplied with
offset - offset added to the model counts

The model counts are calculated by
model = scale\*shift(reference_array, shift) + offset

__See also__: backshift, shift_intpol, set_dataset_metadata, shift

----

#### ut12tt
##### Synopsis
 Convert a (M)JD in UT1 into TT

##### Usage
```c
 utc=ut12tt(JD)
```

##### Qualifiers

* mjd: The argument is given in MJD, not in JD.
* deltat: Return the TT-UT1 in seconds, rather than the corrected (M)JD.
* morrison: Perform the correction using a linear interpolation
to the points by Morrison and Stephenson, 2004,
Journal for the History of Astronomy 35, 327.
Not really good after 2000

##### Description

This function converts a (Modified) Julian Date that is given in UT1,
i.e., the timescale that defines the earth rotation angle,
into a (M)JD in TT.

By default, for years before 2005 the function uses the polynomial
expressions for TT-UT1 published by F. Espenak and J. Meeus, 2006,
Five Millenium Canon of Solar Eclipses: -1999 to +3000,
NASA TP-2006-214141, for years after 2005 the polynomials published
by Espenak at http://www.eclipsewise.com/help/deltatpoly2014.html are
used.

Alternatively, a linar interpolation in the solar eclipse derived
data by Morrison and Stephenson (2000) can be used (see morrison
qualifier).

The uncertainty of the result is 1s or less from 1780 until 1830,
less than 1s from 1830-2000. It increases quadratically backwards
from 1820, sigma ~32((year-1820)/100)^2.

This function is array safe.

__See also__: tt2ut1,utc2tai,tai2utc,tai2tt

----

#### utc2tai
##### Synopsis
 Convert a (M)JD in civil time (UTC) into International Atomic Time

##### Usage
```c
 tai=utc2tai(JD)
```

##### Description

This routine converts a Julian Date that is in civil time (Coordinated
Universal Time, UTC) into International Atomic Time (TAI) by applying
the relevant correction for leap seconds. This routine is array safe.
##### Qualifiers

* mjd: The argument is given in MJD, not in JD.
* deltat: Return the TAI-UTC in seconds, rather than the corrected (M)JD.
* leapfile: path to a file containing the leap second
information. This file is available, e.g., from
ftp://maia.usno.navy.mil/ser7/tai-utc.dat
Most astronomical software systems distribute this file. The default
is to look for it in getenv("LHEASOFT")/refdata

__See also__: utc2tai,tt2tai,tai2tt

----

#### UTC2UNIXtime
##### Synopsis
 converts Universal Time (GMT) to seconds since 1970-01-01, 0:00 UTC

##### Usage
```c
 Long_Type secs = UTC2UNIXtime(Struct_Type tm);
```
or

```c
 Long_Type secs = UTC2UNIXtime(Integer_Type Y[, m[, d[, H[, M[, S]]]]]);

```

##### Description

<code>UTC2UNIXtime</code> can be seen as the inverse of the <code>gmtime</code> function,
operating on Coordinated Universal Time instead of dates in a local time zone,
as <code>mktime</code> does, which is the inverse of <code>localtime</code>.

<code>UTC2UNIXtime</code> can also take the components of the date <code>Y</code>-<code>m</code>-<code>d</code>, <code>H</code>:<code>M</code>:<code>S</code> UTC
as separate arguments. The year <code>Y</code> is then given directly (unlike <code>tm.tm_year = Y - 1900</code>),
and likewise the month <code>m</code> (unlike <code>tm.tm_mon = m-1</code>).
For omitted arguments, <code>m=1</code>, <code>d=1</code>, <code>H=0</code>, <code>M=0</code>, and <code>S=0</code> are assumed.

__See also__: mktime, gmtime, localtime

----

#### vacuum_to_air
##### Synopsis
 Convert vacuum wavelengths to air wavelengths

##### Usage
```c
 Double_Type l_a[] = vacuum_to_air(Double_Type l_v[])
```

##### Description

Convert vacuum wavelengths l_v (in Angstroem) to air wavelengths l_a (in Angstroem)
for dry air at 15 degrees Celsius, 101.325 Pa, and with 450 parts per million CO2
content. Valid in the wavelength range between 2300 to 17000 Angstroem.
##### Notes

According to Equation 1 in Ciddor 1996, Applied Optics, 35, 1566:
1e8\*(l_v-l_a)/l_a = n-1 = k1/(k0-l_v^(-2)) + k3/(k2-l_v^(-2))
=> l_a = l_v / ( k1\*1e-8/(k0-l_v^(-2)) + k3\*1e-8/(k2-l_v^(-2)) + 1 )
with k0 = 238.0185 \* 1e-8 / Angstroem^2,
k1 = 5792105  \* 1e-8 / Angstroem^2,
k2 = 57.362   \* 1e-8 / Angstroem^2,
k3 = 167917   \* 1e-8 / Angstroem^2.
##### Qualifiers

* verbose [=1]: : Set to 0 to suppress warnings.

##### Example

l_a = vacuum_to_air([2000,4000,8000,16000]);

__See also__: air_to_vacuum

----

#### vector_astro
##### Synopsis
 vector initializer that is more appropriate for astronomy

##### Usage
```c
 Vector_Type vector_astro(Double_Type x, y, z)
```

```
or

```c
 Vector_Type vector_astro(Double_Type r, phi, theta; sph)
```
or

```c
 Vector_Type vector_astro(Double_Type r, lon, lat; astro)
```
or

```c
 Vector_Type vector_astro(Double_Type phi, theta; sph)
```
or

```c
 Vector_Type vector_astro(Double_Type lon, lat; astro)
##### Qualifiers

* astro: consider the given coordinates to be astronomical (r, lon, lat)
following the astronomical definition (i.e., lon ranges from
0 to 2pi, lat from -pi/2 to pi/2; default for two arguments)
* sph: consider the given coordinates to be spherical (r, phi, theta)
following the mathematical definition (i.e., theta ranges from
0 to pi)
* deg: interpret angular arguments in degrees

##### Description

The components of the vector are returned within the Vector_Type
and are accessible like a structure with the fields x, y, and z.

If the astro qualifier is given, cartesian coordinates are
calculated as
<pre>
    [x, y, z] =
        r \\* [cos(lon)\\*cos(lat), sin(lon)\\*cos(lat), sin(lat)]
</pre>
If the sph qualifier is given, the cartesian coordinates are
calculated as
<pre>
    [x, y, z] =
        r \\* [cos(phi)\\*sin(theta), sin(phi)\\*sin(theta), cos(theta)]
</pre>

If the function is called with only two arguments, then these represent the
spherical or astronomical coordinates, and we assume that r=1.

If the initializer is called with a single argument of type Vector_Type,
the corresponding Vector_Type is returned

__See also__: Vector_Type,Matrix33_Type,vector_to_spherical,dms2deg,hms2deg

----

#### vector_to_spherical
##### Synopsis
 Returns the spherical coordinates corresponding to a 3D Vector

##### Usage
```c
 (r,lon,lat)=vector_to_spherical(Vector_Type v)
```

##### Qualifiers

* astro: return coordinates using the astronomical convention (the default)
* sph: return coordinates (r,theta,phi) using the mathematical definition
(i.e., theta ranges from 0 to pi)
* deg: return angular arguments in degrees (default: radian)

##### Description

This function returns the spherical coordinates corresponding to a vector.
See the description of function vector_astro for the relevant equations.

__See also__: Vector_Type,vector_astro,dms2deg,hms2deg

----

#### Vector_Type=matrix33_get_diag(Matrix33_Type)
##### Synopsis
 return the diagonal elements of a 3x3 matrix

##### Usage
```c
  dia=matrix33_get_diag(m);
```

##### Description

Return the diagonal elements of a Matrix33_Type as a Vector_Type.
Also available through the accessor function m.diag

__See also__: vector,Vector_Type, matrix33_new

----

#### Vector_Type=matrix33_get_trace(Matrix33_Type)
##### Synopsis
 return the trace of a 3x3 matrix

##### Usage
```c
 trac=matrix33_get_trace(m);
```

##### Description

Return the sum of the diagonal elements of a Matrix33_Type
Also available through the accessor function m.trace

__See also__: vector,Vector_Type, matrix33_new

----

#### Voigt (fit-function)
##### Synopsis
 implements the bare convolution of a Gaussian and a Lorentzian

##### Description

The <code>Voigt</code> fit-function uses the bare parameters of the
convolved Gaussian and Lorentzian profiles G and L:

<code>G(x; sigma) = 1/[sqrt(2 pi)\*sigma] \* exp(-(x/sigma)^2/2)</code>

<code>L(x; gamma) = gamma/pi \* 1 / [x^2 + gamma^2]</code>

<code>V(x; sigma, gamma) = int dt G(t; sigma) \* L(x-t; gamma)</code>

Unlike ISIS' internal <code>voigt</code> fit-function,
which implements a Voigt profile in astrophysical context
associating enerigies with <code>x</code> in the above formula,
<code>Voigt</code> uses <code>x</code> in wavelength units or any unit
associated with the "spectrum" through <code>define_counts</code>.

__See also__: voigt, voigt_profile

----

#### Voigt_complex
##### Synopsis
 Compute complex Voigt profile

##### Usage
```c
 Complex_Type[] = Voigt_complex(z, z0, sigma, gamma);
```

----

#### voigt_profile
##### Synopsis
 computes a normalized Voigt profile

##### Usage
```c
 Double_Type voigt_profile(Double_Type x, [[N,] x0,] sigma, gamma)
```

##### Description

The Voigt profile V is the convolution
of a Gaussian profile (with width <code>sigma>0</code>)

<code>G(x; sigma)  =  exp{-x^2/(2 sigma^2)} / [sqrt(2 pi) sigma]</code>

and a Lorentzian profile (with width gamma>0)

<code>L(x; gamma)  =  gamma/pi / (x^2 + gamma^2)</code>

i.e.:

<code>V(x; sigma, gamma)  =  int G(t; sigma) \* L(x-t; gamma) dt</code>

The <code>voigt_profile</code> function computes

<code>N \* V(x-x0; sigma, gamma)</code>

i.e., <code>x0</code> is the center of the Voigt profile (default: 0)
and <code>N</code> is its normalization (default: 1), i.e.

<code>int voigt_profile(x, N, x0, sigma, gamma) dx  =  N</code> .

Do not confuse this "Voigt profile" with the "Voigt function H(a, u)".

__See also__: voigt, get_cfun2

----

#### vradbinary (fit-function)
##### Synopsis
 describes the radial velocity in a binary system

##### Description

Note that only bin_lo is taken into account.

__See also__: radial_velocity_binary

----

#### vsop87
##### Synopsis
 calculates high precision planetary positions using the VSOP87 theory

##### Usage
```c
 Struct_Type vsop87(JD,planet;qualifiers)
```

##### Description

This routine implements the planetary theory VSOP87 of
Bretagnon and Francou (1988, A&A 202, 309).
The routine can return high precision planetary positions for all planets
for a given (array) of times (in TT).

Depending on the qualifiers the routine can return rectangular coordinates
(X,Y,Z) or ecliptical coordinates (longitude, latitude, distance) in a
heliocentric coordinate system either for epoch J2000 or for the epoch
of date. In addition, elliptical orbital elements and standard orbital
elements can also be calculated.

By default the routine returns rectangular heliocentric coordinates in a
structure with elements x, y, z, vx, vy, vz.
Here x, y, z are in an ecliptical coordinate system for the epoch J2000,
where the x-axis is in the direction of the vernal equinox, the z-axis
points to the ecliptical North pole, and the y-axis forms a right handed
coordinate system with the x- and z-axes. The default units are AU and AU/day.

For heliocentric coordinates the planet can have the values
"Mercury", "Venus", "Earth", "Mars", "Jupiter", "Saturn",
"Uranus", and "Neptune". For heliocentric rectangular coordinates
the value "Earth-Moon" will return the position of the
Earth-Moon barycenter.

In the case of solar system barycentric data, it is not possible to
obtain the elements of the Earth-Moon barycenter, only the coordinates
of the Earth can be queried. In addition, for this set of
coordinates it is also possible to request the rectangular
position of the Sun.

For the years 1900-2100 interval the precision of the positions
is at the level of a few milli-arcseconds, with the exception of
Saturn, for which a precision of "only" 0.1'' is reached.

The precision is better than 1" for the following time intervals
around AD2000:
Mercury, Venus, Earth-Moon Barycenter, Mars: 4000 years
Jupiter, Saturn: 2000 years
Uranus, Neptune: 6000 years

The time argument to the routine is the Julian Date in Terrestrial Time (TT),
which corresponds to the international atomic time TAI+32.184s.

This is a powerful routine with a large number of options. A set of helper
functions provide simpler interfaces.

##### Qualifiers

* mjd: The argument is in MJD(TT), not in JD(TT)
* tdb: The argument is in TDB, not TT
* barycentric: Return coordinates with respect to the solar system barycenter rather
than heliocentric coordinates. This implies that coordinates are for J2000.
* spherical: Return spherical coordinates in the ecliptical coordinate system.
Only possible for heliocentric data.
In this case the structure returned contains the elements
lat, lon, r, latdot, londot, rdot, where lat and lon are the ecliptical
latitude and longitude (in rad), r is the distance in AU, and
latdot, londot, rdot are their time derivatives (in rad/day or
AU/day, respectively.)
* mean_equinox: Coordinates are given in the frame defined by the
mean equinox and ecliptic of the date. In VSOP87, this
system is derived from the J2000 one by pure precessional
motion. The default is to return J2000 coordinates.
* elements: Return the orbital elements. The structure contains
the following tags:
a: semi-major axis (in AU)
l: mean longitude (rad)
k=e cos(p): elliptical element k
h=e sin(p): elliptical element h
q=sin(g) cos(omega): elliptical element q
p=sin(g) sin(omega): elliptical element p
e: orbital eccentricity
plon: perihelion longitude (in rad)
g: semi inclination (rad)
i: inclination (rad)
omega: longitude of the ascending node (also called G)

* deg: All angle quantities to be returned are in deg, or deg/day.
* mks: All distances returned by the function are given in meters or m/s, depending
on the deg qualifier, angles are returned in rad and rad/s or deg and deg/s.
* cgs: Dito, but use centimeters instead of meters.
* vsopfile: Path to file containing the VSOP quantities; only necessary if
this is a non-standard installation of isisscripts. This qualifier is
only used if the vsop87 data have not yet been read.
By default, the file with the coefficients is searched for in the
directory pointed to by the environment variable ISISSCRIPTS_REFPATH.
* forcearray: Force the tags in the returned struct to be arrays. The default is
that they are arrays only if JD is an array.

__See also__: planetpos,jpl_eph,jpl_eph_vec

----

#### v_relativistic_to_optical
##### Synopsis
 Convert relativistic velocity to optical velocity.

##### Usage
```c
 v_relativistic_to_optical(V_rel);
```

##### Description

Calculate the optical velocity definition from a given relativistic velocity.
Velocities must be given in km/s.

----

#### wcs_axes_plot
##### Synopsis
 gets WCS coordinates of axes and returns xfig plot object

##### Usage
```c
 xfig_plot_object = wcs_axes_plot (String_Type image_filename);
```

```
or

```c
 xfig_plot_object = wcs_axes_plot (image, wcs);
##### Qualifiers

* width: set plot width
* height: [=14] set plot height, unless width and height are both
set, the other one is calculated based on the
format of the image (currently CDELT1 != CDELT2
is not taken into account, but only #pixels)
* x1label: [=WCS of major] set ticlabels of x1-axis
* x2label: [=0] set ticlabels of x2-axis
* y1label: [=WCS of major] set ticlabels of y1-axis
* y2label: [=0] set ticlabels of y2-axis
* axis_color: [="white"] set the color of the axes
* x1major: set WCS values for major tics of x1-axis.
similar qualifiers exist for x2, y1, and y2-axes.
unless x1 and x2 are both set, the qualifier affects
both x-axes. the same holds for the y-axes and the
minor qualifiers.
* x1minor: set WCS values for minor tics of x1-axis.
similar qualifiers exist for x2, y1, and y2 axes
* return_axes: set qualifier to additionally return
data (Assoc_Type) including axes information.
the returned object <code>wcsaxes</code> can be accessed
with <code>wcsaxes["x1"]</code> (keys are ["x1","x2","y1","y2"])
* info: print the WCS (RA-DEC) ranges of the axes
(helpful for setting minor and major by hand)

##### Description

Creates an xfig plot object based on a sky image with WCS coordinates
and determines the major and minor tics as well as the tic labels.
The underlying coordinates in the xfig plot are pixels (with integers
corresponding to the pixel centers).
The tic marks of each axis correspond to the "leading" (most varying)
coordinate along this axis (see wcs.xtype). There can/will be problems
when poles (and similar things) are within the field of view.
It is possible (and recommended) to specify major and minor tics and
the ticlabels (e.g., in order to use sexagesimal labels) of each axis
using the available qualifiers.
The alternative usage allows to specify the image and the wcs
information separately. They can be given either as a string of the
filename or directly as the image (array) and the WCS struct. In the
latter case they can be modified before.

WARNINGS:
- check WCS coordinates (the wcsfuns module uses less keywords
than, e.g., ds9)
- when plotting sub-images (i.e., cutting the image before
calling this function), make sure that the WCS structure is
consistent (e.g., modified center pixel)
##### Example

variable filename = "img.fits";
variable p = wcs_axes_plot (filename);
p.plot_png (log(img); cmap="ds9b");
p.render("img.pdf");

% if, e.g., WCS has to be modified/corrected:
variable wcs = fitswcs_get_img_wcs(filename);
wcs.cdelt[1] \*= -1; % can be necessary if a keyword was not read
variable p = wcs_axes_plot ( filename, wcs );

% use sexagesimal axis labels (example for declination from 44 8' - 44 20')
variable dec_major = [8:20:2]; % arcmin
variable y1major = 44 + dec_major / 60.0;
variable y1minor = 44 + [8:20:1] / 60.0; % minor in 1' steps
variable dec_ticlabels = array_map (String_Type, &sprintf, "$44^\circ\,%02d'$", dec_major);
variable p = wcs_axes_plot (filename; y1major = y1major, y1minor = y1minor, y1label = dec_ticlabels);

----

#### Weibull (fit-function)
##### Description

<code>W(x) = norm \* k/lambda \* ((x-x0)/lam)^(k-1) \* exp(-((x-x0)/lam)^k);</code>

<code>W( x0 + lambda \* (1-1/k)^(1/k) )  =  max.</code>

----

#### weighted_mean
##### Usage
```c
 Double_Type m = weighted_mean(x, w);
```
or

```c
 Double_Type m = weighted_mean(x; err=err);  % or weighted_mean(x, err; err)

```

##### Description

<code>m = sum(w\*x) / sum(w);</code>

<code>%</code> for Gaussian errors:

<code>w = 1/err^2;</code>

----

#### where_max
##### Synopsis
 finds the indices of an array where the values are maximal

##### Usage
```c
 Integer_Type i[] = where_max(Array_Type a);
```

##### Description

<code>i = where(a==max(a));  % =>  a[i] == max(a)</code>

__See also__: where_min

----

#### where_min
##### Synopsis
 finds the indices of an array where the values are minimal

##### Usage
```c
 Integer_Type i[] = where_min(Array_Type a);
```

##### Description

<code>i = where(a==min(a));  % =>  a[i] == min(a)</code>

__See also__: where_max

----

#### wienhump (fit-function)
##### Synopsis
 describes a Wien hump

##### Description

Describes a Wien hump with peaks at 3kT.

__See also__: bbody

----

#### winding_number_polygon
##### Usage
```c
 wn=winding_number_polygon(P,V)
```

##### Synopsis
 return the winding number for a point P in a polygon

##### Description

return the winding number for a point P in a (potentially
complex polygon V)

The winding number counts the number of times the polygon V winds
around point P. The point is outside if the winding number is 0.

The algorithm used here is as efficient as the determination
of the crossing number.

The point P is a struct{x,y}, while the polygon is a
struct{x[],y[]} where the arrays are the x- and y-coordinates.
The polygon has to be closed, i.e. V.x[n]==V.x[0] and
V.y[n]==V.y[0] where n is the number of polygon points.

See the URL below for more explanations.

Based on code by Dan Sunday,
http://geomalgorithms.com/a03-_inclusion.html

__See also__: crossing_number_polygon,point_in_polygon,simplify_polygon

----

#### WorldCoastLine
##### Usage
```c
 Struct_Type WCL[] = WorldCoastLine();
```

##### Description

<code>WCL</code> is an array of structures with <code>x</code> and <code>y</code> fields
which specify the coordinates (longitude east and lattitude north)
in degrees of the World's coast lines.
##### Example

xrange(-2, 2); yrange(-1, 1);
variable cl;
foreach cl (WorldCoastLine())
oplot( Hammer_projection(cl.x, cl.y; deg, normalized) );

----

#### write_plot
##### Synopsis
 Write the data from the last plot made with the isis_fancy_plots package

##### Usage
```c
 [pd =] write_plot(root; head=0, data);
```

##### Qualifiers

* head: ==0 to suppress header in output file
* data: if set, return data as a structure instead

##### Description

[pd =] write_plot(root; head=0, data);

Creates ASCII files with the data from the last plot made (with any
plot device) using plot_counts, plot_data, plot_residuals, or
plot_unfold.  Data will be stored in columns in the following order-
bin_lo, bin_hi, data_value, data_error (single column), model,
{mean residual, residual-1sigma, residual+1sigma}.  There can be
multiple sets of columns for the groups of residuals if the data are
combined, but the residuals are not.

Important notes:

The X-axis and Y-axis units will reflect those of the plot. The
binning and noticed data ranges will reflect data filters applied
within ISIS, but not the (usually more limited) plot range filters.

Each uncombined data set, or group of combined data sets, will be
be written to a separate ASCII file.  A file for combined data sets
can have multiple columns for residuals if they are left uncombined.

Combined data or residuals will only write out the chosen
combinations, not the individual pieces used to create them.

Files created from plot_residuals will only output the bin_lo/hi
grid and the residual/-/+ columns, not the data or model.

If the model or residuals were not plotted, they will not be
written to the ASCII file.

Plots made from plot_unfold will create separate files for the
data and the unfolded model, as they can be on different grids.
The model file will begin with the appropriate bin_lo, bin_hi.

Inputs:

root- A string with the base file name.  Outputs will be--
root_#.dat, root_#.res (for plot residuals), and root_#.mod (for
plot_unfold, if the data and model are on separate grids). # will
will cycle from 0 to the number of input data groups-1, assigning
data sets in the order that they were input to the plot command.
\*\*\*Old files will be overwritten if 'root' is not a unique name.\*\*\*

head- Set as a qualifier only.  If !=0 (default=1), the ASCII data
files will have useful header information appended, otherwise,
the files will just contain columns of data.

data- If the data qualifier exists, instead of writing an ASCII file, the
write_plot function will return a structure with the data values from
the last plot generated.

__See also__: pg_info

----

#### write_simput_dummy_bkg
##### Synopsis
 plots a sky image, including an optional scale and/or grid

##### Usage
```c
 write_simput_dummy_bkg(fsimput,fsrc,fpar);
```

##### Description

fsimput:  Name of the ouput simput-File
fsrc:     Name of a SRC-FITS-Image (with FK5 WCS Header)
fpar:     ISIS-par File (with proper normalization) of the BKG
##### Qualifiers

* src_name: ["BKG"] name of the source in the SIMPUT file
* overwrite: if given, already exsiting simput files are overwritten
* arcmin_area: =[1.0] area in arcmin specifying the flux for the given spectrum

__See also__: xfig_plot_new,fitswcs_get_img_wcs

----

#### write_slurm_script
##### Synopsis
 writes a slurm job script, which can be submitted with squeue

##### Usage
```c
 write_slurm_script(file,jobname,walltime,cmds);
```

##### Qualifiers

* queue: set the queue (remeis by default)
* silent: do not show any output
* serial: instead of parallel, execute commands one after the other
* option: setting commands or environment variables before executing the actual commands
* ntaks: [=1] number of tasks per CPU
* memory: [=1000] MByte in memory allocated (--mem-per-cpu in slurm)
* output: output logfile name
* error: error logfile name
* account: if the selected queue needs a specific account set this qualifier accordingly
* dir: [=getcwd()] absolut path where the script should be run (default is cwd)

##### Description

Writing a slurm job script, which can be submitted with squeue.
The function might yet not include all options and works best for
simple cases. The cmds variable is a String_Type array, with each
field being one command line. The
##### Example

% define your commands
variable cmds =
[ "echo 123" , "echo 456" ];
% call the function
variable file = "slurmscript.slurm";
variable jobname = "script";
variable walltime = "00:30:00";
write_slurm_script(file,jobname,walltime,cmds);

----

#### write_spix
##### Synopsis
 writes the structure provided by make_spix in a FITS file

##### Usage
```c
 write_spix(Stuct_Type <code>spix</code>, String_Type <code>filename</code>);
```

__See also__: make_spix, read_spix, plot_spix

----

#### x1axis
##### Synopsis
 (re)draws a first x-axis

##### Usage
```c
 x1axis(Double_Type min_value, Double_Type max_value[, Double_Type step]);
```

##### Qualifiers

* nsub: [=0] number of minor tick marks within each major divison (nsub=0 => no minor ticks)
* maji: [=0.5] length of major tick marks, drawn inwards (in units of the character height)
* majo: [=0] length of major tick marks, drawn outwards (in units of the character height)
* fmin: [=0.5] length of minor tick marks (as fraction of the major tick marks)
* disp: [=0.5] displacement of baseline of tick labels to the axis (in units of the character height)
* angle: [=0] orientation of the text (in degrees)
* color: [=1] color of the axis
* linewidth: [=1] line width of the axis
* opt: [="N"/"LN"] pgaxis-options: "L" (log), "N" (numbers), "1" (force decimal), "2" (force EE)
* yrel: [=0] relative position of the x1axis (0=bottom, 1=top)
* xmin: [=xmin] absolute x-position of the axis
* xmax: [=xmax] absolute x-position of the axis

__See also__: x2axis (and references therein)

----

#### x2axis
##### Synopsis
 draws a second x-axis

##### Usage
```c
 x2axis(Double_Type min_value, Double_Type max_value[, Double_Type step]);
```

##### Qualifiers

* nsub: [=0] number of minor tick marks within each major divison (nsub=0 => no minor ticks)
* maji: [=0.5] length of major tick marks, drawn inwards (in units of the character height)
* majo: [=0] length of major tick marks, drawn outwards (in units of the character height)
* fmin: [=0.5] length of minor tick marks (as fraction of the major tick marks)
* disp: [=0.5] displacement of baseline of tick labels to the axis (in units of the character height)
* angle: [=0] orientation of the text (in degrees)
* color: [=1] color of the axis
* linewidth: [=1] line width of the axis
* opt: [="N"/"LN"] pgaxis-options: "L" (log), "N" (numbers), "1" (force decimal), "2" (force EE)
* yrel: [=1] relative position of the x2axis (0=bottom, 1=top)
* xmin: [=xmin] absolute x-position of the axis
* xmax: [=xmax] absolute x-position of the axis

##### Description

<code>x2axis</code> has to be called after the plot window is drawn.
It relies on the world coordinates set by <code>xrange</code>, <code>yrange</code>.
The automatical x2axis can be switched off with <code>change_plot_options</code>.
##### Example

()=change_plot_options(; xopt="BNST");  % default: "BCNST", see _pgbox
xrange(0, 360); yrange(-1.1, 1.1);
plot([0:360], sin([0:2\*PI:#361]));
x2axis(0, 2);

__See also__: _pgaxis, change_plot_options, coords_in_box, y2axis, x1axis, y1axis

----

#### x2axis_with_tics
##### Usage
```c
 x2axis_with_tics(Double_Type X[][, Label]);
```

##### Qualifiers

* ftick: [=0.08]: fraction of box-height that tick marks are below axis
* flabel: [=0.05]: fraction of box-height that labels are above axis

----

#### x2label
##### Synopsis
 labels the second x-axis

##### Usage
```c
 x2label(String_Type s);
```

##### Qualifiers

* color: [=1] textcolor
* f: [=0.03] fraction of the plot-area's height that the label is above

__See also__: xylabel

----

#### xfigplot_hardnessratio_grid
##### Synopsis
 plots hardness-grid and/or hardness-datapoints

##### Usage
```c
 xfigplot_hardnessratio_grid(Struct_Type tracks);
or xfigplot_hardnessratio_grid(Struct_Type tracks, String_Type fits_hr_table
);
```

##### Qualifiers

* outputdir: String_Type, name of output directory,
default: 'testplot.pdf'
* W: Integer_Type, width of new xfig-plot
* H: Integer_Type, height of new xfig-plot
* xrange: Double_Type[2], range on x-axis
* yrange: Double_Type[2], range on y-axis
* padx: Double_Type, percentage of padding of whole plot in x direction,
default: 0.05
* pady: Double_Type, percentage of padding of whole plot in y direction,
default: 0.05
* xlabel: String_Type, label on x-axis
* ylabel: String_Type, label on y-axis
* par1label: String_Type, label within plot of par1
* par1label_x: Double_Type, x-position of 'par1label' as percentage
(needs to be set, if 'par1label' is given)
* par1label_y: Double_Type, y-position of 'par1label' as percentage
(needs to be set, if 'par1label' is given)
* par1label_c: Integer_Type/String_Type, color of 'par1label' as RGB,
default: 0x000000 (black)
* par2label: String_Type, label within graph of par2
* par2label_x: Double_Type, x-position of 'par2label' as percentage
(needs to be set, if 'par2label' is given)
* par2label_y: Double_Type, y-position of 'par2label' as percentage
(needs to be set, if 'par2label' is given)
* par2label_c: Integer_Type/String_Type, color of 'par2label' as RGB,
default: 0x000000 (black)
* extralabel: String_Type, extra label within graph
* extralabel_x: Double_Type, x-position of 'extralabel' as percentage
(needs to be set, if 'extralabel' is given)
* extralabel_y: Double_Type, y-position of 'extralabel' as percentage
(needs to be set, if 'extralabel' is given)
* extralabel_c: Integer_Type/String_Type, color of 'extralabel' as RGB,
default: 0x000000 (black)
* extralabel2: String_Type, extra label within graph
* extralabel2_x: Double_Type, x-position of 'extralabel2' as percentage
(needs to be set, if 'extralabel' is given)
* extralabel2_y: Double_Type, y-position of 'extralabel2' as percentage
(needs to be set, if 'extralabel' is given)
* extralabel2_c: Integer_Type/String_Type, color of 'extralabel2' as RGB,
default: 0x000000 (black)
* cstart: Integer_Type/String_Type, start color of grid as RGB,
default: 0xC1CDCD (gray)
* cstop: Integer_Type/String_Type, stop color of grid as RGB
default: 0xC1CDCD (gray)
* lend1: if exists, switch end (or begin) of tracks1
(where each tracks' value will be assigned)
* lend2: if exists, switch end (or begin) of tracks2
(where each tracks' value will be assigned)
* shift1x: Double_Type, x-position of par1-values at end of track, default: 0.
* shift1y: Double_Type, y-position of par1-values at end of track, default: 0.
* shift2x: Double_Type, x-position of par2-values at end of track, default: 0.
* shift2y: Double_Type, y-position of par2-values at end of track, default: 0.
* hr_x_col: String_Type, name of hr_x-column ('fits_hr_table') for plotting datapoints
* hr_y_col: String_Type, name of hr_y-column ('fits_hr_table') for plotting datapoints
* err_x_col: String_Type, name of error_x-column ('fits_hr_table') for plotting datapoints
* err_y_col: String_Type, name of error_y-column  ('fits_hr_table)' for plotting datapoints
* err_c: Integer_Type/String_Type, color of errorbars as RGB
default: 0x000000 (black)
* symbol_shape: String_Type, shape of datapoints
* symbol_size: Double_Type, size of datapoints, default: 1.
* symbol_cstart: Integer_Type/String_Type, (start) color of datapoints as RGB
* symbol_cstop: Integer_Type/String_Type, stop color of datapoints as RGB,
if not given 'symbol_cstart' is color of all
* source_col: String_Type, name of source-column ('fits_hr_table') for plotting datapoints,
needs to be given only if different colors for different sources
* extralabel_sources_x: Double_Type, x-position of source_names as percentage
(if given, source names are displayed in their respective color)
* extralabel_sources_y: Double_Type, y-position of source_names as percentage
* tracks1: Integer_Type, if given, only tracks1 are plottet
* tracks2: Integer_Type, if given, only tracks2 are plottet
* notracks: Integer_Type, if given, no tracks are plottet, 'fits_hr_table' must be
given for datapoints

##### Description

- for only grid: give only tracks
- for grid with datapoints: give tracks and FITS-table with hardnessratios (and errors)
- for only datapoints: give tracks and FITS-table, but use 'notracks'-qualifier

__See also__: hardnessratio_from_dataset

----

#### xfigplot_pulseprofile_energy_map
##### Synopsis
 returnes an Xfig plot object containing the pulse-profile-energy-map

##### Usage
```c
 Xfig_Object xfigplot_pulseprofile_energy_map(Struct_Type map);
```

##### Description

Struct_Type map = struct{
pgrid = struct{ bin_lo = Double_Type[np],
bin_hi = Double_Type[np]
},
egrid = struct{ bin_lo = Double_Type[ne],
bin_hi = Double_Type[ne]
},
map = Double_Type[ne,np]
};

##### Example

__See also__: pulseprofile_energy_map

----

#### xfig_3d_orbit_on_cube
##### Synopsis
 Visualize 3d orbits by projecting them onto a cube

##### Usage
```c
 xfig = xfig_3d_orbit_on_cube(Struct_Type orbits [, Struct_Type text]; qualifiers)
```

##### Description

The orbits have to be given in cartesian coordinates (x,y,z) and are passed
to the function via a structure. Each individual orbit is itself a structure
with fields 'x', 'y', and 'z'. The orbits are then visualized by plotting the
projections to the xy-, xz-, and yz-plane on the surfaces of a cube. Use the
qualifiers to change the viewing angle, labels, or properties of the cube and
the background grid. The function's optional second argument can be used to
add text or symbols to the plot (see example section below).
##### Notes

If one of the three coordinates is missing, the projection on the plane defined
by the remaining two coordinates is still plotted. This feature can be used to
add lines or text to one specific plane only.

The properties of the orbits (line style, color, ...) can be changed by adding the
field 'qualies' to the structure that decribes the orbit. The field 'qualies' is
again a structure whose fields are qualifiers of the function 'xfig_new_polyline'.
##### Qualifiers

* phi [=-45]: Azimuthal angle in the x-y-plane in degrees (-90 < phi < 0).
* theta [=60]: Polar angle from the z-axis in degrees (0 < theta < 90).
* dist [=1e6]: Distance of the eye from the focus.
* scale [=4]: Factor to scale dimensions with respect to the character size (scale > 0).
* x_label [="$x$\,(kpc)"]: x-label.
* y_label [="$y$\,(kpc)"]: y-label.
* z_label [="$z$\,(kpc)"]: z-label.
* digits [=1]: Digits for ticmarks (a non-negative integer).
* cube: Modify the cube by providing a structure whose fields are qualifiers of the function 'xfig_new_polyline'.
* grid: Modify the grid by providing a structure whose fields are qualifiers of the function 'xfig_new_polyline'.
* center: Center the cube at (0,0,0).
* z_adjust: Use separate scale for z-axis.

##### Example

% basic example:
o = struct{ orbit1, orbit2, orbit3 };
o.orbit1 = struct{ x=[0,1], y=[0,1], z=[0,1] };
o.orbit2 = struct{ x=[1,1], y=[4,1], z=[-3,0], qualies=struct{color="blue"} };
o.orbit3 = struct{ x=[-1,0,1], y=[-1,1,-1], qualies=struct{closed, fillcolor="tomato", depth=5} }; % filled triangle in the xy-plane
xfig = xfig_3d_orbit_on_cube(o);
xfig.render("test.pdf");
xfig_set_eye(1e6,0,0,0); % restore the default position of the eye

% adding text to xy-plane:
t = struct{ triangle=struct{text="triangle", x0=0, y0=0, depth=4} };
xfig_3d_orbit_on_cube(o,t).render("test.pdf");
xfig_set_eye(1e6,0,0,0); % restore the default position of the eye

% example involving the function 'orbit_calculator':
o = orbit_calculator([12,12],[22,22],[29.6,29.6],[40,40],[49,49],[36,36],[3.078,4],[262,262],[-13.52,-13.52],[16.34,16.34],-1000; r_disk=50, set);
set_struct_field(o.tr, "o0", struct_combine(o.tr.o0, "qualies")); set_struct_field(o.tr.o0, "qualies", struct{ color="red", depth=2, backward_arrow });
set_struct_field(o.tr, "o1", struct_combine(o.tr.o1, "qualies")); set_struct_field(o.tr.o1, "qualies", struct{ color="blue", depth=1, backward_arrow });
xfig_3d_orbit_on_cube(o.tr).render("test.pdf");
xfig_set_eye(1e6,0,0,0); % restore the default position of the eye

% changing the appearance of the cube and grid:
xfig_3d_orbit_on_cube(o.tr; cube=struct{color="red",width=2}, grid=struct{line=0}).render("test.pdf");
xfig_set_eye(1e6,0,0,0); % restore the default position of the eye

% adding symbols:
t = struct{ sun, gc };
t.sun = struct{ text="$\odot$", x0=-8.4, y0=0, z0=0, depth=3 };
t.gc = struct{ text="+", x0=0, y0=0, z0=0 };
xfig_3d_orbit_on_cube(o.tr, t).render("test.pdf");
xfig_set_eye(1e6,0,0,0); % restore the default position of the eye

__See also__: orbit_calculator

----

#### xfig_compress_eps
##### Synopsis
 Compresses an EPS-File via "pdftops -level3 -eps"

##### Usage
```c
 int = xfig_compress_eps(String_Type file)
```

##### Description

PS and EPS-Files created with xfig are usually much too large.
Using this function the size can be reduced by a factor of few. Simply
call this function after creating a PS or EPS with ".render(file)".

----

#### xfig_draw_orbit
##### Synopsis
 draws the orbit of a binary system into an exsiting xfig-object and
allow also to highlight specific phases

##### Usage
```c
 xfig_draw_orbit(Xfig_Object xf, Double_Type asini, i, ecc, omega, rstar)

```

##### Qualifiers

* line_color: [<code>="gray"</code>] color of the lines showing the
coordinate main axes and the orientation of the semi-major axis of
the orbit
* phases: [<code>={}</code>] list of Double_Type[2] arrays indicating
the phases which should be highlighted
* scale: [<code>=1.05</code>]  compression/streching for the highlighted
phases over/under the orbit
* phase_color: [<code>="red"</code>] color of the highlighted phases,
can be a single string or an array of strings, with the same length
as phases so that every highlighted phase can be drawn in
a different color.
* phase_width: [<code>=2</code>] width of the highlighted phases, can
also be an array, just as phase_color.
* star_color: [<code>=lightblue</code>]  fill-color of the companion star
* trueanom: if set, phases are given in true anomaly, i.e., equal
delta-phi values will correspond to equal delta-t on the
orbit.
* zerolines: [<code>=1</code>] plot x- and y-axis lines through [0,0]
* phaselines: draw a lightgray line every phase n\*0.1 and label it
* label_phase_switch: [<code>=0</code>] : phase at witch phase labels
are switched from before the line to after the line.
* label_pos: [<code>=0.85</code>] distance of the phase labels from the
orbit line, in fraction of distance to center.
* nolabel:  : removes the coordinate system

##### Description

This function plots the orbit of a binary system as seen from
above into a given xfig-object. The orbital parameters asini
(semi-major axis, in lt-sec), i (inclination, in deg), ecc (eccentricity),
omega (argument of periastron, in deg) and the radius rstar (in r_sun)
of the companion star need to be supplied.
Qualifiers are passed through the xfig-plotting routine of the
orbit.

##### Examples

%orbit parameters of GX 301-2 according to Koh et al (1997).
variable asini = 368.3 ; % lt-sec (semi major axis)
variable i = 66; % degree to rad
variable ecc = 0.462 ;  %
variable omega = 310.4 ; % degrees
variable rstar = 43 ; % solar radii  in lt-sec

variable xfgx = xfig_plot_new(12,12) ;
xfgx.world(-600,450,-450, 600) ;
xfig_draw_orbit(xfgx, asini, i, ecc, omega, rstar ;
phases={[0.9184,0.9315]}, phase_color="red", phase_width=4, scale=1) ;
xfgx.plot([0,0],[-100,-370] ; line=1, forward_arrow, depth = 10,
arrow_thickness =2) ;
xfgx.xylabel(0,-400, "To Earth");
xfgx.render("plots/gx301_skizze2.eps") ;

__See also__: ellipse

----

#### xfig_draw_orbit_3D
##### Synopsis
 draws the orbit of a binary system in 3D

##### Usage
```c
 Xfig_Object xfig_draw_orbit([Xfig_Object xf,] Double_Type asini, i, ecc, omega);
```

##### Qualifiers

* caminc: the camera inclination to the line of sight
(in degrees; default: 90-i)
* camroll: the camera roll angle around the z-axis (along the
line of sight; in degress; default: 0)

##### Description

Similar to 'xfig_draw_orbit' this function plots the orbit of a
binary, but seen from a user-defined direction and, thus, in 3D.
In order to draw the orbit the projected semi-major axis (asini),
inclination (i), eccentricity (ecc), and longitude of periastron
(omega) have to be provided.

Additionally to the orbital plane the tangent plane of the sky
is drawn as well. This plane is defined to be perpendicular to
the line of sight and through the center of mass, i.e. the focal
point of the eccentric orbit nearest to the periastron (P).
Thereby, the observer is located below the tangent plane of the
sky, indicated by the arrow pointing to Earth.
All dashed lines are within the orbital plane, which are the
intersection of the orbital and tangent plane of the sky, the
semi-major and -minor axis (in red), and the line connecting the
orbit's center and the periastron. The projected semi-major axis
(asini) is drawn as dotted dashed line.

The camera is controlled via qualifiers and by default the binary
is seen face-on.

Note that so far only basic functionallity have been implemented.

__See also__: xfig_draw_orbit, ellipse

----

#### xfig_get_normalized position
##### Synopsis
 Compute normalized (world0) x,y-position from world1 x,y-position

##### Usage
```c
 xnorm=xfig_get_normalized_position(p,xval,yval)
```

##### Description

For a given xfig plot p and coordinate values xval,yval given in the world1
coordinate system, compute the corresponding normalized world0 x,y-position.

This function is necessary since the xfig module does not export
its world normalization functions. It is heavily based on these.

__See also__: xfig_get_normalized_x_position,xfig_get_normalized_y_position

----

#### xfig_get_normalized_x_position
##### Synopsis
 Compute normalized (world0) x-position from world1 x-position

##### Usage
```c
 xnorm=xfig_get_normalized_x_position(p,xval)
```

##### Description

For a given xfig plot p and x-coordinate value xval given in the world1
coordinate system, compute the corresponding normalized world0 x-value.

This function is necessary since the xfig module does not export
its world normalization functions. It is heavily based on these.

__See also__: xfig_get_normalized_position,xfig_get_normalized_y_position

----

#### xfig_get_normalized_y_position
##### Synopsis
 Compute normalized (world0) y-position from world1 y-position

##### Usage
```c
 ynorm=xfig_get_normalized_y_position(p,yval)
```

##### Description

For a given xfig plot p and y-coordinate value yval given in the world1
coordinate system, compute the corresponding normalized world0 y-value.

This function is necessary since the xfig module does not export
its world normalization functions. It is heavily based on these.

__See also__: xfig_get_normalized_position,xfig_get_normalized_x_position

----

#### xfig_mix_colors
##### Synopsis
 mix two named xfig colors

##### Usage
```c
 xfig_mix_colors(color1,color2,fraction)
```

##### Qualifiers

* name: xfig name of the color mix

##### Description

This function mixes two named xfig colors in rgb space. The function looks up
the rgb values of color1 and color2, and mixes their rgb values according
to
new color=color1\*fraction+color2\*(1-fraction)
The operations are analoguous to the color mixing performed by the xcolor
package of LaTeX (the operation is similar to LaTeX's color1!fraction!color2
syntax).
The function returns the xfig name of the new color, or nothing if the
name qualifier is given (recommended).

__See also__: mix_rgb_colors

----

#### xfig_multibox
##### Synopsis
 combines M x N xfig-objects in one box

##### Usage
```c
 pl = xfig_multibox(XFig_Plot_Type pl[M,N] [, Double_Type spacing])
```

##### Qualifiers

* rotate: switch the meaning of M and N

__See also__: xfig_new_vbox_compound, xfig_new_hbox_compound

----

#### xfig_plot_allbezier
##### Synopsis
 adds the plot of all Bezier curves from the bezier function to a xfig plot object

##### Usage
```c
 Xfig_Struct pl_new = xfig_plot_allbezier(Xfig_struct pl, bez [, conlines ]);

```

##### Description

Adds the plot of all Bezier curves to a previously defined
xfig-object 'pl'. 'conlines' and 'bez' are the values returned from
the bezier-function called with both qualifiers "allbez" and
"conlines".
Colors of each Bezier line collection is changed automatically.
If conlines are plotted, they will be plotted in "gray".

__See also__: bezier

----

#### xfig_plot_colormap
##### Synopsis
 Plots a colormap/colorscale

##### Usage
```c
 Struct_Type xfig_plot_new( Double_Type[n,m] IMG );
```

##### Qualifiers

* cmap: [="ds9b"] Either a name (String_Type) of a colormap
(see png_get_colormap_names), or a self defined
colormap (Integer_Type[]).
* gmin: [=min(IMG)] Minimal value of image to be plotted
* gmax: [=max(IMG)] Maximal value of image to be plotted
* W: [=14] Plot width [cm]. 'ratio' is overwritten if W & H are given!
* H: [=W/ratio] Plot height [cm]. 'ratio' is overwritten if W & H are given!
* orientation: [=1] Horizontal if 1, vertical if 0. Set Horizontal if W/H > 1,
otherwise set to vertical.
* label: Label for the colormap
* format: Format for colormap axis ticlabels, see 'help xfig_plot.axis'
* depth: [=80] Depth of the colormap
* fontsize: [="scriptsize"] Font size of tic & axis label
* ticlen: [=.15] Length of major tic marks (minor tic are .5\*ticlen).
* maxtics: [=5] Maximal number of labeled tics
* box: Draws a box behind the colormap
* border: [=.01] Relative size of box excess length
* boxcolor: [="#FFFFFF"] Color of the box

##### Description

This function uses xfig_plot_image to create a colormap based on the given
IMaGe (with dimension n and m).

##### Example

variable x = [PI:10\*PI:#100];
variable y = [PI:5\*PI:#80];
variable IMG = sin(x) # transpose(cos(y));
variable xf = xfig_plot_colormap( IMG );
xf.render("/tmp/test.pdf");

__See also__: xfig_plot_new, %.shade_region, xfig_plot_image

----

#### xfig_plot_conf
##### Synopsis
 plots contour levels stored with save_conf

##### Usage
```c
 XFig_Plot_Type pl = xfig_plot_conf(String_Type file[, XFig_Plot_Type pl])
```

##### Qualifiers

* lvls: specify the Delta chi-sqr values for the contour levels,
default: [2.30, 4.61, 9.21], i.e., 1 sigma, 90% and 99% CL
* color: specify the colors of the contour lines
The array's last value is used for the best fit's cross (if
length of array > number of levels).
* line: [=0] specify the line styles of the contour lines
* width: [=1] specify the width of the contour lines
The array's last value is used for the best fit's cross.
* smooth: [=1] this integer>=1 specifies the interpolation factor
for the image used to calculate the contours
* W: width of the plot if created by <code>xfig_plot_contours</code>
* H: height of the plot if created by <code>xfig_plot_contours</code>
* worldXY: any world qualifier to the xfig-plot will be passed,
which requires an existing SLxfig plot object to be given
* transpose: transposes the countour map (exchange x- and y-values)
* nocross: do not plot best fit cross
* noclip: if used with a sltikz plot object, do not clip

##### Description

If no SLxfig plot object <code>pl</code> is given, a new one is created
and its world coordinate system is defined according to the
ranges used to calculate the confidence map. x- and y-labels
are initialized with the parameter names, but can be changed
afterwards.

__See also__: get_confmap, xfig_plot_new, enlarge_image

----

#### xfig_plot_confmap
##### Synopsis
 Create an xfig plot of a confidence map

##### Usage
```c
 xfig_plot_new fig = xfig_plot_confmap(String_Type cm; qualifiers)
```

##### Description

Create an xfig plot from a pre-calculated confidence map `cm' computed and saved with
the function `get_confmap'.
##### Qualifiers

* best_fit: Mark the best fit with a cross.
* CDF: If set to a positive integer, the chi^2 values are converted to a cumulative
distribution function with the degree of freedom given by this qualifier. For
instance, CDF=1 implies that chi^2 values of 1, 2.71, and 6.63 are converted
to 0.68, 0.9, and 0.99 (this qualifier requires the gsl-module).
* colormap [="haxby"]: Choose, e.g., "ds9sls", "seis", "rainbow", "haxby", "topo",
"globe" (see the function `png_get_colormap' for more information).
* colormap_gmin, colormap_gmax: Minimum and maximum grayscale value for the colormap,
see `png_gray_to_rgb'.
* chi2 [=Double_Type[0]]: Chi^2 values for which contour lines should be drawn (this
qualifier requires the gcontour-module).
* chi2_color [="magenta"]: Color of the contour lines and the best fit cross.
* factor [=1]: Factor by which the x- and y-sampling of the confidence map is increased.
* field [="chisqr"]: Which field of the confidence map shall be plotted.
* width [=8], height [=8]: Width and height of the confidence map.
* latex_package [="txfonts"]: Load a package in the preamble of LaTeX documents.
* reverse_axes: If present, both axes are reversed.
* [xyz]label: Add a x-, y-, or z-label to the confidence map.
* [xyz]axis [=struct{ticlabels_confine=0, ticlabels2=0}]: Modify the x-, y-, or z-axis
by providing a structure whose fields are qualifiers of the function `xfig_plot.axis'.
Note that the `log' qualifier (set logarithmic axis scale) does not work.
* nomultiplot: Return the confidence map and its corresponding colormap in two separate
xfig objects instead of one multiplot object.

##### Example

fig = xfig_plot_confmap("confmap.fits"; chi2=[1, 2.71, 6.63], zlabel="$\chi^2$"R, zaxis=struct{format="%g", ticlabels1=0});
fig.render("test.pdf");

__See also__: get_confmap

----

#### xfig_plot_data
##### Synopsis
 plots data which was loaded by "read_data_from_write_plot"

##### Usage
```c
 XFig_Plot_Type pl = xfig_plot_data(XFig_Plot_Type pl, Struct_Type dat)
```

##### Qualifiers

* color: specify the color
* width: line width
* sym: symbol
* size: size of the symbol
* depth: depth in plot
* pp: data are plotted twice (pulse profile)

__See also__: xfig_plot_unfold,read_data_from_write_plot,read_col,write_plot

----

#### xfig_plot_distribution_matrix
<!--%{{{ -->
##### Synopsis
 Plot distribution matrix

##### Usage
```c
 xfig_plot_distribution_matrix(Struct_Type dm[, String_Type file]);
```

##### Qualifiers

* names: string array containting the names for all dimensions
* nameX: add label for dimension X

##### Description

Plot the distribution matrix to file <code>file</code> using xfig. If
<code>file</code> is not given or is <code>NULL</code> return instead the xfig
object.

##### Example

variable dm = distribution_matrix({v0, v1, v2}); % vX are the state values in the dimensions
variable names = ["dim0", "dim1", "dim2"];
xfig_plot_distribution_matrix(dm, "distribution.pdf"; names=names, name1="other label");

__See also__: distribution_matrix

----

#### xfig_plot_epfpd
##### Synopsis
 plot the results of epfoldpdot with Xfig, including the
pulse profile of the stronges P/P-dot values

##### Usage
```c
 xfig_plot_epfpd(Struct_Type eppd, Struct_Type lc)

```

##### Qualifiers

* W: width of resulting plot (default=12)
* H: height of resulting plot (default=W)
* pdstart: start of P-dot axis (default read from eppd)
* pdstop: end of P-dot axis (default read from eppd)
* pstart: start of P axis (default read from eppd)
* pstop: end of P axis (default read from eppd)
* p0: center of P  axis (default mean of periods in eppd)
* cmap: [<code>="iceandfire"</code>] Color-map of Chi^2 landscape
* cont: switch to plot FWHM contour on map
* pp: switch to plot pulse profile below map
* t0: [<code>="0"</code>] t0 for pulse profile
* nbins: [<code>="12"</code>] number of phase bins for pulse profile

##### Description

This function plots the results for "epfoldpdot" into a nice
colorful xfig image, with the cuts in P and P-dot over the most
significant period as well as (if desired) the pulse profile of
that period. This style of plot is inspired by the results plots
of PRESTO.

This code is still under development and not very flexible yet.
Feel free to improve it.

__See also__: epfoldpdot

----

#### xfig_plot_image
##### Synopsis
 Plots an image (with x/y-grid)

##### Usage
```c
 Struct_Type xfig_plot_new( Double_Type[n,m] IMG, [Double/Struct_Type x, y] );
```

```
or

```c
 xfig_plot_new( Double_Type[n,m] IMG, [Double/Struct_Type x, y [, Struct_Type xf]] );
##### Qualifiers

* cmap: [="ds9b"] Either a name (String_Type) of a colormap
(see png_get_colormap_names), or a self defined
colormap (Integer_Type[]).
* gmin: [=min(IMG)] Minimal value of image to be plotted
* gmax: [=max(IMG)] Maximal value of image to be plotted
* xmin: [=min(x)] Minimal value of x-axis
* xmax: [=max(x)] Maximal value of x-axis
* ymin: [=min(y)] Minimal value of y-axis
* ymax: [=max(y)] Maximal value of y-axis
* dx: [=0.] Relative justification of pixels in x-direction. Used if 'x' is no grid.
* dy: [=dx] Relative justification of pixels in y-direction. Used if 'y' is no grid.
* fill: [=20] global filling method (see %.shade_region)
* fmap: [=Integer_Type[n,m]+fill] individual filling method for each pixel
%* nancol: [="black"] Extra color for IMG pixel values, which are NAN.
* ratio: [=1] Desired ratio of x and y-axis scale
* W: [=14] Plot width [cm]. 'ratio' is overwritten if W & H are given!
* H: [=W/ratio] Plot height [cm]. 'ratio' is overwritten if W & H are given!
* colorscale: If given an inlay colorscale is plotted using xfig_plot_colorscale
* format: Format for colormap axis ticlabels, see 'help xfig_plot.axis'
* just: [=[.95,.05,-.5,.5]] Position (world00) & relative justification
of the colorscale.
* scale: [=[.33,.05]] : Relative size of the colorscale in respect to W & H.
* xlabel: Label of x-axis
* ylabel: Label of y-axis
* depth: [=150] xfig depth

##### Description

Other than the %plot_png function of the xfig_plot structure this function
aims to plot images with a (given) ARBITRARY x/y-grid in a correct way
(NOTE that .plot_png does not care for x/y values!). This also allows to
plot images with logarithmic scales without any problems! In addition
it is easy to plot gabbed images by just giving the x and y grid as bin_lo
and bin_hi.

ARGUMENTS
IMG:
In any case a IMaGe has to be given, which can arbitrary dimensions n and m
(it even can be 1-dimensional).

x, y:
x and y-grids are optional arguments but cannot be given individually.
If no grid is given the grids are set to the pixel number assuming a linear
grid! The grids can be Array_Types either of length n and m, respectively, in
which case the bin_lo and bin_hi is created by assuming a linear grid.
Otherwise their length must be n+1, m+1!
It is also possible that x and y are Struct_Types already containing the bin_lo
and bin_hi (it is only required that the bin_lo filed has 'lo' in its name and
the bin_hi field 'hi', respectively). In that last case it is also possible to
plot images with gabs!

xf:
Must be and xfig_plot structure. If given the image is plotted into xf and there
will be no return value. This way all automatic plot settings of this function will
be disregarded. Otherwise a new xfig_plot is created (qualifiers are
passed through).

##### Example

% Example 1: logscale
variable x = [PI:10\*PI:#100];
variable y = [PI:5\*PI:#80];
variable IMG = sin(x) # transpose(cos(y));
variable xf = xfig_plot_image( IMG, x\*180/PI, y\*180/PI;
padx=0.025, pady=0.025,
dx=-.5,
xlog, ylog,
fill=20
);
xf.render("/tmp/test.pdf");

% Example 2: image of Example 1 but with gaps
variable tmp = [[1:30],[35:65],[75:115]];
variable x = struct{ lo = tmp/11.5\*PI, hi = (tmp+1)/11.5\*PI };
tmp = [[1:40],[50:90]];
variable y = struct{ lo = tmp/18.\*PI, hi = (tmp+1)/18.\*PI };
variable IMG = sin(x.lo) # transpose(cos(y.lo));
variable xf = xfig_plot_image( IMG, x, y ; cmap="drywet");
xf.render("/tmp/test.pdf");

__See also__: xfig_plot_new, %.shade_region, xfig_plot_colormap

----

#### xfig_plot_ionization_structure
##### Synopsis
 plots the ionization structure from an abundance file produced by xstar

##### Usage
```c
 plot_ionization_structure(String_Type abundace_file, String_Type[] elements, String_Type ouput_file)
```

##### Qualifiers

* xpow: plot radius in units of 10^xpow (default: 10)
* xaxis: use 'logxi' or 'radius' to set the abscissa (default: radius)
* temp: add temperature panel
* press: add pressure panel
* xee: add electron fraction panel
* dens: add density panel
* athresh: only ionization states are plotted which exceed a certain threshold (default: 0.3)
* ion_states: string array of ionization states in roman numbers
* width: plot witdh
* height: plot height

All other qualifiers are passed to xfig_plot.plot()

##### Description

This function produces and xfig plot of the ion abundance structure of
an xstar calculation. The input parameters are the xstar abundance FITS
file, a string array of the elements of interest and an output file name.

##### Examples

xfig_plot_ionization_structure ("xout_abund1.fits", ["si", "FE", "Mg", "O"], "ion_abundance.pdf"; ion_states = ["iii", "v"], temp );

plots the ion abundance of the ionization states III and V for the elements Silicon, Iron, Magnesium and Oxygen
and the temperature as a function of radius.

----

#### xfig_plot_model
##### Synopsis
 plots the model which was loaded by "read_data_from_write_plot"

##### Usage
```c
 XFig_Plot_Type pl = xfig_plot_model(XFig_Plot_Type pl, Struct_Type dat)
```

##### Qualifiers

* color: specify the color
* width: line width
* depth: depth in plot
* hplot: make it a histogram plot
* pp: model is plotted twice (pulse profile)

__See also__: xfig_plot_data,read_data_from_write_plot,read_col,write_plot

----

#### xfig_plot_params
##### Synopsis
 Returns a xfig-plot of the given parameter (value, limits, [conf, chi2])

##### Usage
```c
  Struct_Type xplot = xfig_plot_params( Struct_Type params1, params2, ... );
```

##### Qualifiers

* tmpdir: [='/tmp/'] Directory for temporar files
* size: [=[12,9]]: Dimension in cm of the (main) plot
* space: [=.05\*size[0]]: Space between parameter columns.
Dimension in cm of the (main) plot
* xwidth: [=.5]: Width of the parameter symbols (same units as x values).
* x: Alternative values for the x-axis (e.g., time in MJD)
* xlabel: Label for the alternative x-axis.
* connect: Connects the individual parameter values with a line.
* conf: Confidence level for the given parameters are plotted, if given.
conf must be a Struct_Type[] with fields: the 'index' of the
parameter and the corresponding confidence (absolut) limits
'conf_min' and 'conf_max'.
* steppar: Steppar information (see 'steppar'). Either steppar filename
which is loaded with steppar_load or a List_Type with two
elemtents 1. stepparinformation and 2. the keys.
* chi2log: Logarithmic scales for chi2 plots
* grid: Enables gridlines on the chi2 plots
* chi2max: Custom max value for chi2 range
* chi2min: Custom min value for chi2 range
* cmap: [='ds9b'] Colormap for the colorcoded chi2 landscapes
* ticmap: [='rainbow'] Colormap for the ticlabels/chi2 landscapes

##### Description

This function creates and returns a xfig-plot showing a compact overview
of the given parameter information.
The function takes a arbitrary number of arguments, which however are
expected to be all parameter struct arrays (see get_params)! For each
argument/parameter-array a individual xfig-plot will be created, which
in the end will be combined in an xfig_new_vbox_combound spaced by 'space'.

The main plot shows the parameter values
within its limits (y-axis). Its dimension are determined by the 'size'
qualifier. By default the x-axis is either the parameter index or the
number/dataset of the parameter, if the names of all given parameter are
the same.
The values are represented by horizontal lines, where their width
can be specified by the 'xwidth' qualifier (measured in x units). If
'xwidth' exceeds the minimal distant of adjacent x-values, 'xwidth' is set
to that value.
The 'x' qualifier allows to use custom x-values, e.g., the time at which
the parameters are valid. The corresponding label can be set with 'xlabel'.
If the 'x' qualifier is used, a second x-axis will be added to the plot,
which will be used to plot the parameter information, i.e., the spacing
is given be those 'x' values!
It is possible to give additional information about the parameters. Firstly
the 'conf' qualifier can be used to give confidence levels of the parameters.
'conf' must be a Struct_Type[] with fields 'index' (index of the parameter),
'conf_min' and 'conf_max' corresponding to the absolut values of the confidence
levels. The 'index' field is needed to find the corresponding parameter! Only
matches will be plotted!
Further information about the chi2 landscape can be given with the 'steppar'
qualifier, which expect filename(s) or filepattern(s) to load steppar
information produced with 'steppar'. The files are loaded using the
'steppar_load' function. Using 'steppar' qualifier creates a multiplot
with two additional plots besides main plot (caution, the return xfig-plot
will then be a xfit-multiplot!) showing the individual chi2 landscales
of the parameters, if existent and a mean chi2 of those landscapes.
With the 'chi2log' qualifier the chi2 landscapes are plotted logarithmic.
'grid' will extent the tics to a grid. To set custom limits for the chi2 range
use 'chi2min' and 'chi2max'! To easily visualize which chi2 landscape
belongs to which parameter, the parameter x-labels are colorized
accordingly using the colormap given by 'ticmap'.
Furthermore, color-coded chi2 landscapes are added to the main plot using
the colormap given with 'cmap'. The colormaps can be given by either a
name (String_Type) of an existing colormap (png_get_colormap_names) or
a colormap itself.

__See also__: steppar, steppar_load, png_get_colormap_names

----

#### xfig_plot_res
##### Synopsis
 plots the residuals which were loaded by "read_data_from_write_plot"

##### Usage
```c
 XFig_Plot_Type pl = xfig_plot_model(XFig_Plot_Type pl, Struct_Type dat)
```

##### Qualifiers

* color: specify the color
* width: line width
* depth: depth in plot
* chi: specifies that the residuals are in chi
* ratio: specifies that the residuals are a ratio
* pp: residuals are plotted twice (pulse profile)

__See also__: xfig_plot_data,read_data_from_write_plot,read_col,write_plot

----

#### xfig_plot_sky_img
##### Synopsis
 plots a sky image, including an optional scale and/or grid

##### Usage
```c
 Xfig_Plot_object pl = xfig_plot_sky_img(String_type fits_img);
```

##### Description

This function uses xfig to plot a sky image, with a given color
scale ("hot" by default). With a separate qualifier, a scale can
be switched on. The
##### Qualifiers

* cmap: ["hot"] color map
* scale: switch on the scale
* arcmin: [=5] length of the scale in arcmin
* lin: linear image scale instead of logarithmic
* func: giva a reference to an arbitrary function to be applied to the image
* size: [10,10] size of the image in cm
* ref_img: [fits_img] if not given as direct argument, a reference FITS image has to be provided for the scale (filename!)
* grid: draw a grid and corresponding labels
* step_ra: [=1] step size of the RA-grid (given in min)
* step_ra: [=5] step size of the Dec-grid (given in arcmin)
* grid_color: [#BBBBBB] color of the grid
* scale_color: [white] color of the scale

__See also__: xfig_plot_new,fitswcs_get_img_wcs

----

#### xfig_plot_spectrum
##### Synopsis
 Makes an array of slxfig objects from a set of plots saved with write_plot

##### Usage
```c
 Struct_Type[] pl = xfig_plot_spectrum(Struct_Type plt[],[...])
```

##### Description

Generates an array of SLxfig plot objects from a given set of plot data
structs (as generated by write_plot).

Arguments should be structs as returned by write_plot(;data). The first
argument should be the "best-fit" model - i.e., the spectrum and model you
want to plot in the top pane. Subsequent arguments should be structs
returned by write_plot(;data) for "intermediate" residuals (e.g. with other
spectral features turned on or off).

The function returns an array of SLxfig plot objects, which can then be
rendered using, e.g., xfig_multiplot().render. The colors, symbols,
linestyles, and other parameters can be adjusted using qualifiers (see
below). Since the xfig objects themselves are returned, you can also modify
them yourself after the fact (in order to, e.g., add labels or do more
plotting).

EXAMPLE: consider a scenario where we fit some model containing a Gaussian
emission line (using an "egauss" component) to a dataset of three spectra.
We want to create a plot that has a top pane (occupying 50% of the total
plot area) showing the spectrum and best-fit model, a middle pane showing
the residuals without the emission line, and a bottom panel showing the
best-fit residuals. The three spectra will be plotted in black, red, and
blue, with the model overplotted in green, purple, and orange, and the
output will be a PDF called "spectrum.pdf".

<code>
plot_data({1,2,3};res=1);                 % plot data and best-fit model with residuals
variable best = write_plot(;data);        % write plot to a structure
set_par("egauss(1).area",0.0,1);          % Turn off the emission line
() = fit_counts;                          % re-fit without the line
plot_data({1,2,3};res=1);                 % plot data without the line
variable noline = write_plot(;data);      % write the last plot to another structure
pl = xfig_plot_spectrum(best,noline;      % call xfig_plot_spectrum to create the xfig objects
colors=["black","red","blue"],          % data colors
mcolors=["green","purple","orange"],    % model colors
topPanelFrac=0.5);                      % top panel (data+model) occupies 50% of total plot area
xfig_multiplot(pl).render("spectrum.pdf");% render the final plot as a PDF
</code>

More qualifiers (see below) are available to fine-tune how the plot
appears. The colors, style, and size modifiers (dsym, symsize, mstyle,
mscale, dataDepth, modelDepth) can be given as arrays, with one element for
each spectrum plotted, or as single values, in which case each spectrum is
plotted with the same symbol/style/color/size.

By default, the x- and y-ranges for the resulting plot will depend on the
energy (or wavelength) ranges which were _noticed_ when you called
write_plot(). The simplest way to change the range of the resulting plot is
to only notice the wavelength/energy range you want to plot with xnotice()
or xnotice_en() - this will ensure that the y-axis and residuals scale
properly with what is plotted. There are also "xrange" and "yrange"
qualifiers to set the range of the top panel; however, the residual ranges
are still determined based on the full range of data.

Labels for the individual panels can be enabled via the "labels" qualifier.
If labels is present, but not set (or if its first element is NULL), then
the panels will be automatically labeled with letters starting from 'a'.
The "firstPanelLabel" qualifier can be used to change the starting label;
it should be a single letter. If the "labels" qualifier is not present at
all, the panels will be unlabeled. The x/y positions of the labels can be
set via the label_x and label_y qualifiers, which should be arrays of
Double_Type values indicating the positions of the lower-right corners of
the labels for each panel in 'world0' coordinates for that panel (see
'xfig_plot--wcs'). By default these are [0.94,0.90] for the data+model
panel and [0.94,0.78] for the residuals.

The "gaps" qualifier lets you specify where the model should not be plotted
(e.g., between 1.7 and 2.4 keV in the Suzaku-XIS). It should be given as a
List_Type list of Array_Type arrays, one array for each spectrum plotted.
The arrays should be a list of start and stop energies for the gaps (this
means they need to have even length); for instruments with no gaps, pass
<code>Double_Type[0]</code>.  E.g., for a Suzaku observation with XIS0, XIS1,
XIS3, and the HXD/PIN where you don't want to plot the model between 1.6
and 2.3 keV in the XIS spectra, you would pass
<code>gaps={[1.6,2.3],[1.6,2.3],[1.6,2.3],Double_Type[0]}</code>.

This script is mostly feature-complete, but please contact Paul Hemphill
(pbh@space.mit.edu) regarding bugs or missing features (please do not
report missing bugs; any bugs that are not present are missing
intentionally).

##### Qualifiers

* topPanelFrac: Double_Type, fraction of plot taken up by top panel, default 0.5
* height: Double_Type, height of plot in cm, default 14.2
* width: Double_Type, width of plot in cm, default 12.6
* colors: String_Type[] or Integer_Type[], xfig colors for each spectrum plotted, by default uses get_sron_colors() to get a set of colors
* mcolors: String_Type[] or Integer_Type[], xfig colors for each model plotted. By default each model is plotted with the same color as its associated data.
* dsym: String_Type[] or Integer_Type[], xfig symbols for data for each spectrum plotted, defaults to "point"
* symsize: Integer_Type[], size of symbols for each spectrum plotted. Can be a single value or an array (one element for each spectrum).
* mstyle: Integer_Type[], xfig linestyle for overplotted best-fit model for each spectrum. mstyle = -1 plots the model as a histogram. As with symsize, can be single value or array. Default -1
* mwidth: Integer_Type[], xfig line width for overplotted best-fit model. As with symsize, can be single value or array. Default 1.
* mscale: Double_Type[], multiplicative scale for model (e.g., if you want to plot your model above your data points). Single value or array.
* dataDepth: Integer_Type[], xfig depth for data points, either a single value or an array specifying the depth for each spectrum. Default 1
* modelDepth: Integer_Type[], xfig depth for model lines. See dataDepth. Default 0 (this means models are plotted over data by default)
* ratio: If present, residuals are ratio residuals, otherwise residuals are assumed to be some variant of data-model.
* no_residuals: If set, no residuals are plotted.
* gaps: List_Type, indicates where gaps in an instrument's spectrum mean the model should not be plotted.
* xrange: Double_Type[2], range for x-axis (default autoscaled)
* yrange: Double_Type[2], range for y-axis of top panel (default autoscaled)
* rrange: List_Type[]. Should be a list of two-element arrays containing the minimum and maximum for the y-axis of each residual plot, in the order that they appear on the plot.
* xlog: Axes are linear by default. If "xlog" is set, or if it is set to a nonzero number, the x-axis will be logarithmic. If "xlog" is not set, or is set to zero, the x-axis will be linear.
* ylog: See xlog; sets log/linear scale for y-axis on top panel. Residual plots always have linear y-axes.
* unit: String_Type, either "keV" (energy, default) or "A" (wavelength).
* xlabel: String_Type, label for x-axis, default depends on units. If unit="keV", "Energy (keV)"; if unit="A", "Wavelength (\AA)". Set to NULL for no label.
* ylabel: String_Type, label for y-axis of spectrum, default depends on units. If unit="keV", "Counts s$^-1$ keV$^-1$"; if unit="A", "Counts s$^{-1}$ \AA$^{-1}$".
* rlabel: String_Type, label for y-axis of residuals. If the "ratio" qualifier is set, default is "Ratio", otherwise default is "$\chi$".
* labels: String_Type[], labels for individual panels.
* firstPanelLabel: String_Type or Integer_Type, label for first panel (further panels will increment this value, so if you give 'b' the next panels will be 'c', 'd', etc).
* label_x: Double_Type[], x-positions (in world0 coordinates) of panel labels.
* label_y: Double_Type[], y-positions (in world0 coordinates) of panel labels.
* arrowY: Double_Type[2], lower and upper device coordinates for arrows for bins extending off the screen, default [0.01,0.1].
* version: Display version information and exit.

__See also__: write_plot, xfig_multiplot, xfig_plot_unfold, xfig_plot--wcs

----

#### xfig_plot_unfold
##### Synopsis
 tries to plot the complete plot loaded by "read_data_from_write_plot"

##### Usage
```c
 XFig_Plot_Type pl = xfig_plot_unfold(Struct_Type dat)
```

##### Qualifiers

* size: [dx,dy,dr] size of the xfig-plot
* dcol: color of the data
* mcol: color of the model
* xrng: [xmin,xmax]
* yrng: [ymin,ymax]
* rrng: [rmin,rmax]
* ranges: [xmin,xmax,ymin,ymax,rmin,rmax]
* chi: specifies that the residuals are chi
* ratio: specifies that the residuals are ratio
* y_label: set a y-label for the data/model plot
* keV2erg_fac: if given, the y-label is given in units of
ergs/s/cm^2 x 10^keV2erg_fac
* pp: data is plotted twice (pulse profile)

##### Description

With "read_data_from_write_plot", previously stored data can be
loaded into a structure. This structure ("dat" in the example
above) can now be plotted with "xfig_plot_unfold".

The routines xfig_plot_data, xfig_plot_model, and
xfig_plot_res do the single steps on its own.

__See also__: xfig_plot_data,xfig_plot_model,xfig_plot_res,read_data_from_write_plot,write_plot

----

#### xfig_polarplot_new
##### Synopsis
 creates a xfig_plot with polar axis

##### Usage
```c
 Struct_Type xfig_plot_new( Double_Type Size )
```

```
or

```c
 Struct_Type xfig_plot_new()
##### Qualifiers

* S: [=10] Size of quadratic plot in width and height [cm].
Is overwritten by argument size!
* min: [=0] Minimal angle of polar plot [degree]
* max: [=180] Maximal angle of polar plot [degree]
* origin: [=90] Origin of angular axis measured from x-axis [degree]
* dir: [=-1] Clockwise direction of polar plot axis (-1/1)
* ticlabels: [=.6] If 0 ticlabels are turned of. If not 0 it is used
as relative justification
* ticlabelsize: [="small"] Size of ticlabels
* ticlabelrotate: [=1] Rotate polar ticlabels corresponding to their position (0/1)
* ticthickness: [=2] Thickness of tics
* smallticinc: [=2] Increment for small tics [degree]
* medticinc: [=10] Increment for medium tics [degree]
* bigticinc: [=20] Increment for big tics [degrees]
* aticlables: [=[min:max:bigticinc]] Ticlabels of angular axis
* aticformat: ["$%d^\circ$"] Format for the angular ticlabels
* rlabel: [=NULL] Label for the radial axis
* rtics: [=11] Number of radial tics
* rticlabel: [ =[0:1:#rtics/2] ] Radial tic labels. The 0th rtic label will not be drawn!
* norticlabel: If given, disabels radial tic labels.
* rticlabelrotate: [=0] Rotate polar ticlabels corresponding to their position (0/1)
* padr: [=0.05] Padding of radial axis
* grid: If given grid lines are plotted
* gridcolor: [="#BBBBBB"] Color of the grid lines
* debug: If given the x-y-axis of the underlying xfig_plot are shown

##### Description

This function returns a xfig_plot_new structure but imprinted with polar axis.
This way one can use the functionality of xfig_plot_new. The polar axis
can be modified with the qualifiers above.

NOTE that when using %.(h)plot still requries 'x' and 'y' values, not 'radius'
and 'angle'. That means the user has to do the transformation manually accounting
for the 'origin', 'direction' and 'minimal'/'maximal' values (see examples).

TO BE IMPLEMENTED:
\* functionality to us 'radius' and 'angle' for plotting!

##### Example

% Plot coordinate transformation
variable min = 0,
max = 180,
dir = 1,
org = 45;
variable ang = [min:max:#100];
variable rad = 0.5+0.5\*sin(ang\*PI/180);
variable xf = xfig_polarplot_new(; min=min, max=max, origin=org, dir=dir, grid );
xf.plot( rad\*cos( dir\*(ang+org)\*PI/180 ),
rad\*sin( dir\*(ang+org)\*PI/180 ) ; color="red" );
xf.render("/tmp/test.pdf");

__See also__: xfig_plot_new

----

#### xnotice_atime
##### Synopsis
 notices a range of defined arrival times

##### Usage
```c
 xnotice_atime(Integer_Type index[, Double_Type time_lo, Double_Type time_hi]);
or xnotice_atime(Integer_Type index, Double_Type time);
or xnotice_atime(Double_Type time);
```

##### Description

There are three different ways to notice the time
range of arrival times defined in a dataset:
1. Like 'xnotice' set the time range of dataset
'index' explicitly from 'time_lo' to 'time_hi'.
2. Find the border of the time range of dataset
'index' nearest to the given time. Then set
the found border to this time. The border of
a possible adjacent dataset is changed respect-
ively.
3. Find that dataset, which time range has the
nearest border to the given time and proceed
like option two.
If the dataset only is given, then the full time
range is used.

__See also__: define_atime, xnotice

----

#### xspec_to_isis
##### Synopsis
 Parse xspec parameter file to isis parameter file

##### Usage
```c
 Integer_Type t = xspec_to_isis(String_Type xspec_par)
```

##### Qualifiers

* set: set loadad parameters
* save:  [=String_Type filename] save parameters as isis parameter file
if filename is not specified it is saved as the .xcm file but with .par suffix
* nonverbose: suppress any output not produced by errors

##### Description

Parse an xspec parameter file <code>.xcm</code> to an isis parameter file.
If desired parameters can be set after parsing.
\*\*\* Warning:
Xspec tying expressions are only supported in the form of
<code>= p1</code>
\*\*\* Warning:
Convolution models are not supported!
If tied parameters is out of range of the respective parameter
the limits are set to fit and a warning is given.
##### Example

isis> t=xspec_to_isis ("test.xcm"; save);
Running Xspec.................
parameters saved to test.par as:
diskbb(1) + nthComp(2)
idx  param            tie-to  freeze         value         min         max
1  diskbb(1).norm        0     0          21.7378           0       1e+10
2  diskbb(1).Tin         0     0         0.230239       0.001          10  keV
3  nthComp(2).norm       0     0       0.00019705           0       1e+10
4  nthComp(2).Gamma      0     0           1.9752       1.001           5
5  nthComp(2).kT_e       0     0          1.68497     1.68497        1000  keV
6  nthComp(2).kT_bb      2     0         0.230239       0.001          10  keV
7  nthComp(2).inp_type   0     1                1           0           1  0/1
8  nthComp(2).Redshift   0     1                0      -0.999          10

__See also__: set_par, load_par

----

#### XSTAR_read_pops
##### Synopsis
 reads the ionization balances from an XSTAR population file

##### Usage
```c
 Struct_Type XSTAR_read_pops(String_Type filename)
```

##### Qualifiers

* verbose:
* Z: array of Z values of elements to include
* ions: array of ions to include (overrides Z qualifier)

----

#### xyfit_fun
##### Synopsis
 define xy-function to fit data defined via <code>define_xydata</code>

<!--%{{{ -->
##### Usage
```c
 xyfit_fun(String_Type function_expression);
```

##### Description

Setting up an xy-fit-function with <code>fitfun</code> with <code>xyfit_fun("fitfun");</code>
is done by interpreting the string "fitfun" and creates a fit function that can
be understood by the isis routines. The string is searched for known functions
and special symbols. Every thing else is interpreted as a new fit parameter belonging
to a generic function <code>F</code>.

The known functions can either be a registered isis function with name <code>fun_xyfit</code>
or an slang intrinsic (see examples). If a symbol starts with '#' it is replaced
with the x-axis of the current data set.

If the xy-fit-function describes the graph a function,
it usually computes <code>@yref</code> in terms of <code>@xref</code> and the <code>par</code>-array.
This is the only option for xy-data without <code>xerr</code>, see <code>define_xydata</code>.

If the xy-fit-function describes a parameterized curve,
it usually computes <code>(@xref, @yref)</code> in terms of <code>par</code>
and probably further (constant) parameters passed to <code>fitfun_xyfit</code>
as qualifiers, which have been defined by <code>set_xyfit_qualifier</code>

If a function of the form <code>fitfun_xyfit</code> is loaded and a function
<code>fitfun_xyfit_default</code> exists, this will be passed to
<code>set_param_default_hook</code>.

Importand Notes:
The routine will first search for functions with the appendix _xyfit
and afterwards for intrinsic functions. This means if a function <code>fun</code> exists
and there is also a function <code>fun_xyfit</code> registered the routine will use the
latter.

Calling a parameterized function together with functions of the form f(x) = y or
two parameterized functions redults in undefined behavior. Calling a parameterized
alone behaves as expected.

The internal structure of the routine requires it that a call to <code>list_par</code>,
<code>save_par</code> or <code>load_par</code> do not work as expected. Equivalent _xypar functions
exist.
##### Examples

xyfit_fun("linear"); % or
xyfit_fun("linear(1)"); % sets up xyfit-function linear_xyfit
% in this form it is the xy-equivalent to fit_fun

% example for defining a proper _xyfit function:
% (example for y = x\*a+b; as available already with: xyfit_fun("linear");)
define another_linear_regression_xyfit ()
{
variable xref, yref, par;
switch(_NARGS)
{ case 0: return ["a [unit_a]", "b [unit_b]"];}
{ case 3: (xref, yref, par) = (); }

@yref = par[0] \* @xref + par[1];
}
define another_linear_regression_xyfit_default(i)
{
switch(i)
{ case 0: return (1, 0, -10, 10); }
{ case 1: return (0, 0,  -5, 10); }
}
xyfit_fun("another_linear_regression");
list_xypar;

% example for specifying normalization parameters
% (see 'norm_indexes' parameter of 'add_slang_function')
define fun_with_norm_xyfit ()
{
variable xref, yref, par;
switch(_NARGS)
{ case 0: return struct { pars = ["a [unit_a]", "b [unit_b]"], norm = [0] }; }
{ case 3: (xref, yref, par) = (); }

@yref = par[0] \* (@xref ^ par[1]);
}
xyfit_fun("fun_with_norm");

% example for a simple function call
xyfit_fun("Norm\*sin(#x)/exp(#x-xoff)"); % results in fit-function of the form
% Norm\*sin(x)/exp(x-xoff)
% with two parameters: Norm, xoff

% example of a combination of the previous cases
xyfit_fun("linear(1)+tan(#x^2-xoff)/linear(2)");
list_xypar; % output:
%   linear(1)+tan(#x^2-xoff)/linear(2)
%   idx  param    tie-to  freeze         value         min         max
%   1  linear(1).a   0     0                1     -100000      100000  coefficient of x
%   2  linear(1).b   0     0                0     -100000      100000  additive constant
%   3  linear(2).a   0     0                1     -100000      100000  coefficient of x
%   4  linear(2).b   0     0                0     -100000      100000  additive constant
%   5  F(1).xoff     0     0                0           0           0

__See also__: define_xydata, set_xyfit_qualifier, list_xypar, save_xypar, load_xypar, plot_xyfit

----

#### xyfit_residuals
##### Synopsis
 calculates the difference between xy-data and xy-model

<!--%{{{ -->
##### Usage
```c
 Double_Type res[] = xyfit_residuals(Integer_Type data_id);
```

##### Description

The residuals <code>res[i]</code> are determined differently for xy-data with
uncertainties in y only or in both dimensions.

If the xy-data have no x-uncertainties <code>xerr</code>:

<code>res[i] = (data.y[i] - model.y[i]) / data.yerr[i];</code>

If the xy-data have uncertainties <code>xerr</code> as well:

<code>res[i] = min( relative_distance_from_curve[i] );</code>

where <code>relative_distance_from_curve[i]</code> is composed of
<code>(model.x - data.x[i]) / data.xerr[i]</code> and
<code>(model.y - data.y[i]) / data.yerr[i]</code>.

__See also__: define_xydata, xyfit_fun

----

#### xylabel_in_box
##### Synopsis
 places a text label at a relative position in the plot box

##### Usage
```c
 xylabel_in_box(Double_Type x_rel, y_rel, String_Type label[, angle[, justify]]);
```

##### Description

<code>xylabel_in_box</code> uses relative coordinates <code>x_rel</code> and <code>y_rel</code>:
the plot box corresponds to <code>0<=x_rel<=1</code> and <code>0<=y_rel<=1</code>,
but the <code>label</code> can also be placed outside of this area.
In order to calculate the world coordinates (with <code>coords_in_box</code>),
the <code>x</code>- and <code>yrange</code> has to be set before the first plot command.

The world coordinates and the optional parameters are passed to
<code>xylabel</code>, so see <code>xylabel</code> for a description of <code>angle</code> and <code>justify</code>.

__See also__: coords_in_box, xylabel

----

#### y1axis
##### Synopsis
 (re)draws a first y-axis

##### Usage
```c
 y1axis(Double_Type min_value, Double_Type max_value[, Double_Type step]);
```

##### Qualifiers

* nsub: [=0] number of minor tick marks within each major divison (nsub=0 => no minor ticks)
* maji: [=0.5] length of major tick marks, drawn inwards (in units of the character height)
* majo: [=0] length of major tick marks, drawn outwards (in units of the character height)
* fmin: [=0.5] length of minor tick marks (as fraction of the major tick marks)
* disp: [=0.5] displacement of baseline of tick labels to the axis (in units of the character height)
* angle: [=0] orientation of the text (in degrees)
* color: [=1] color of the axis
* linewidth: [=1] line width of the axis
* opt: [="N"/"LN"] pgaxis-options: "L" (log), "N" (numbers), "1" (force decimal), "2" (force EE)
* xrel: [=0] relative position of the y1axis (0=left, 1=right)
* ymin: [=ymin] absolute y-position of the axis
* ymax: [=ymax] absolute y-position of the axis

__See also__: x2axis (and references therein)

----

#### y2axis
##### Synopsis
 draws a second y-axis

##### Usage
```c
 y2axis(Double_Type min_value, Double_Type max_value[, Double_Type step]);
```

##### Qualifiers

* nsub: [=0] number of minor tick marks within each major divison (nsub=0 => no minor ticks)
* maji: [=0.5] length of major tick marks, drawn inwards (in units of the character height)
* majo: [=0] length of major tick marks, drawn outwards (in units of the character height)
* fmin: [=0.5] length of minor tick marks (as fraction of the major tick marks)
* disp: [=0.5] displacement of baseline of tick labels to the axis (in units of the character height)
* angle: [=0] orientation of the text (in degrees)
* color: [=1] color of the axis
* linewidth: [=1] line width of the axis
* opt: [="N"/"LN"] pgaxis-options: "L" (log), "N" (numbers), "1" (force decimal), "2" (force EE)
* xrel: [=1] relative position of the y2axis (0=left, 1=right)
* ymin: [=ymin] absolute y-position of the axis
* ymax: [=ymax] absolute y-position of the axis

__See also__: x2axis (and references therein)

----

#### y2label
##### Synopsis
 labels the second y-axis

##### Usage
```c
 y2label(String_Type s);
```

##### Qualifiers

* color: [=1] textcolor
* f: [=0.03] fraction of the plot-area's width that the label is to the right

__See also__: xylabel

----

#### yearOfMJD
##### Synopsis
 transforms a date given as MJD into the year (with fractional parts)

##### Usage
```c
 Double_Type year = yearOfMJD(Double_Type MJD);
```

__See also__: jd2year

----

#### z2fold
##### Synopsis
 peforms Z^2_m search on a lightcurve or event data in a given period
interval

##### Usage
```c
 (Struct_Type res) = z2fold(Double_Type t, r, pstart, pstop);
or (Struct_Type res) = z2fold(Double_Type t, pstart, pstop) ; (event data)
```

##### Qualifiers

* sampling: how many periods per peak to use (default=10)
* nsrch: how many periods to search in a linear grid (default not set)
* dp: delta period of linear period grid (default  not set)
* m: number of harmonics used (default =2)
* chatty: set the verbosity, (default=0)
* gti: GTIs for event data, given as struct{start=Double_Type, stop=Double_Type}

##### Description

Performs Z^2_m test  on a given lightcurve or event data between the periods
pstart and pstop. The function is based on epfold.sl.
GTI correction is implemented only  for event-data.

By default, periods are sampled according to the triangular rule
for estimating the period error, using "sampling" periods per peak.
If a linear grid is to be used, either "dp" for a given distance
between two consecutive periods or "nsrch" for a given number of
periods can be given. These qualifiers are mutually exclusive.

The returned structure "res" contains four fields: "p" for the
evaluated period and "stat" for the value of the statistic used.

Please see Buccheri et al., 1983, Astron. Astrophys. 128, 245 for
more information on the Z-square statistics.

__See also__: zsquare, epfold, pfold

----

#### zams
##### Synopsis
 return properties of the ZAMS per Tout et al., 1996, MNRAS 281, 257

##### Usage
```c
 (radius,luminosity,temperature)=zams(mass;z=metallicity);
```

##### Qualifiers

* z: metallicity (between 0.0001 and 0.03; default: 0.02 (solar))

##### Description

This function uses the rational function fits of Tout et al. (1996, MNRAS 281, 257)
and calculates the radius, luminosity, and temperature for zero age main sequence stars
of a given mass (in solar units;  can be an array, must be between 0.1 and 100 Msun).
The radius and luminosity are returned in solar units, the temperature is in K.
Tout et al. state that in general the fits are better than 7.5per cent in luminosity and
5 per cent in radius, for solar metallicity they are good to 3 per cent in L and
1.2 per cent in R.

----

#### zang
##### Synopsis
 Determine the angular size of an object as a function of redshift

##### Usage
```c
 Double_Type angsize = zang (Double_Type size, Double_Type redshift);
```

##### Description

Requires an input size in kpc and returns an angular size
in arc seconds. (Analog to the function <code>zsize</code>,
which converts angular size to projected size size given the
redshift.)
The default cosmology according is used. The function passes
qualifiers to the functions <code>lumdist</code> and <code>cosmo_param</code> allowing
to change the cosmology.
##### Example

variable size = 50.; % kpc
variable    z = 1.5; % redshift
zang(50,1.5; omega_m = 0.3, omega_lambda = 0.0, silent);
% ---> 6.58 arc seconds

__See also__: lumdist, cosmo_param

----

#### zpc_tbnew_simple (fit-function)
##### Synopsis
 partial covering absorption

##### Description

This function describes two partial coverers with
covering fraction f, according to the formula:
<code> (1-f) +  f\*exp(-nH\*sigma) </code>
This definition is equal to how, e.g., zpcfabs is defined.

__See also__: tbnew_simple,tbnew,zpcfabs

----

#### zsize
##### Synopsis
 Determine the projected size of an object as a function of redshift

##### Usage
```c
 Double_Type proj_size = zsize (Double_Type angle, Double_Type redshift);
```

##### Description

Requires an input angular size in arc seconds and returns
the projected size in kpc. (Analog to the function <code>zang</code>,
which converts projected size to angular size given the
redshift.)
The default cosmology according is used. The function passes
qualifiers to the functions <code>lumdist</code> and <code>cosmo_param</code> allowing
to change the cosmology.
##### Example

variable angsize = 1.; % arc seconds
variable    z = 1.5; % redshift
zsize(angsize,z);
% ---> 8.46 kpc

__See also__: zang, lumdist, cosmo_param

----

#### zsquare
##### Synopsis
 calculate Z^2 statistics for pulse period search

##### Usage
```c
 Double_Type Z2 = zsquare(Double_Type times, Double_Type testperiod
```

##### Description

Calculates the Z^2 statistics of an event list or light-curve for
a given period. By itself not very useful, but is used in z2fold
to search for periodicities using the Z^2 statistics.

##### Qualifiers

* lc: =Double_Type rate; allows the use of a lightcurve instead of event files
* m: = Integer_Type; determines the highest order of summations (default 2)
